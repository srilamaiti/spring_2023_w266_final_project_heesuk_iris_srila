{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilamaiti/spring_2023_w266_final_project_heesuk_iris_srila/blob/main/iris/IL_data_exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ9w2FlGlNDV"
      },
      "source": [
        "https://www.kaggle.com/competitions/feedback-prize-english-language-learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oUehh9Tfk8rA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f768b28-f36a-479a-cd7c-ef508af61a53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.9/dist-packages (1.5.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.9/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.9/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ktrain\n",
            "  Downloading ktrain-0.35.1.tar.gz (25.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from ktrain) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from ktrain) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from ktrain) (1.4.4)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.9/dist-packages (from ktrain) (1.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from ktrain) (2.27.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from ktrain) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from ktrain) (23.0)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 KB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.9/dist-packages (from ktrain) (0.42.1)\n",
            "Collecting cchardet\n",
            "  Downloading cchardet-2.1.7-cp39-cp39-manylinux2010_x86_64.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.4/265.4 KB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.9/dist-packages (from ktrain) (4.0.0)\n",
            "Collecting syntok>1.3.3\n",
            "  Downloading syntok-1.4.4-py3-none-any.whl (24 kB)\n",
            "Collecting tika\n",
            "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers>=4.17.0 in /usr/local/lib/python3.9/dist-packages (from ktrain) (4.27.4)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras_bert>=0.86.0\n",
            "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting whoosh\n",
            "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.8/468.8 KB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from keras_bert>=0.86.0->ktrain) (1.22.4)\n",
            "Collecting keras-transformer==0.40.0\n",
            "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-pos-embd==0.13.0\n",
            "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-multi-head==0.29.0\n",
            "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-layer-normalization==0.16.0\n",
            "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-position-wise-feed-forward==0.8.0\n",
            "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-embed-sim==0.10.0\n",
            "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-self-attention==0.51.0\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (4.39.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (0.11.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (5.12.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (8.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (1.0.7)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.1->ktrain) (2022.7.1)\n",
            "Requirement already satisfied: regex>2016 in /usr/local/lib/python3.9/dist-packages (from syntok>1.3.3->ktrain) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.17.0->ktrain) (4.65.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.17.0->ktrain) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers>=4.17.0->ktrain) (3.10.7)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.17.0->ktrain) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.17.0->ktrain) (0.13.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from langdetect->ktrain) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->ktrain) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->ktrain) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->ktrain) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->ktrain) (3.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->ktrain) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->ktrain) (1.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tika->ktrain) (67.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=4.17.0->ktrain) (4.5.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.0.0->ktrain) (3.15.0)\n",
            "Building wheels for collected packages: ktrain, keras_bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, langdetect, tika\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.35.1-py3-none-any.whl size=25316191 sha256=9c13a58e68dd76157838cd3762a0112e38db4c1f267271a006481daae1a3819b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/86/fe/b944ff9fb89c0ce9aab68e7a0c5d53c98c52ae0326fe0942ca\n",
            "  Building wheel for keras_bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33517 sha256=e52f29a3bf15ab6b56f61d4ed4b9596682f2addebb7b13a652b8d7a8da90d0e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/26/24/14ecbc0166364db7f5500164b7d796263cf3cd10c57e892180\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12303 sha256=7456cf18bf362e39b138ce454825caa9268c83fb857de03065ce61f1fe67047a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/d6/d1/c588c3b2b112c8f1173934995836ab2f2de8323cce99fa998f\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3959 sha256=b0c95f64969159052ae9d81970309e36882328eafdf8a33b05728dff38947308\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/25/02/4bb438785ef9c10d07f6b3519f080b38917153fdac3108d738\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4666 sha256=2ce5ffa6d325c74a39c32b824f89d582c3cb06ea675a0f477bb6905139fbe585\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/df/15/a88cdf68ce687574649f65063a743123e1bee79932b6eea3b6\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14992 sha256=ea1c471f70ae6b7ac816abf8e3e432a1b77bf93ac16a6c9d99a87f7c96e6573b\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/85/50/f232cac81ed1eb4dc20db31a9d1f4a8a1a8c696d4d27bff442\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6958 sha256=7de6d87986fdc96a059cbe2bfb775cd2a99b0a362bd4bc18ec514fae5c5bfc07\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/8c/9a/917bf72d493e084ca1706a02679185789c2715f50770d8c987\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4983 sha256=f3f19a310f98322fd039ce71d58aa7c3b777959671cb5cc71ebbc60fbe6282b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/36/25/efb605ab1742a179274a6f7cb113da1c6758f45e212b59bb4d\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18910 sha256=0276fa01155605de953e485990a7dda17e39d81b6f1c72bdceb9c3438818d1dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/c1/84/b83a2fd6f1d63e136cba74bac4126bee3b8705eef6486635fd\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993243 sha256=6a451a235918a76c5909244bfe4ec54f8525edc8cf9092381e1e32c98c9f6b08\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/c1/d9/7e068de779d863bc8f8fc9467d85e25cfe47fa5051fff1a1bb\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32641 sha256=08a087878473090ec6d53d0dc4ffd4c667a4e26245412c3e9926ba636052757b\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/56/18/e752060632d32c39c9c4545e756dad281f8504dafcfac02b95\n",
            "Successfully built ktrain keras_bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention langdetect tika\n",
            "Installing collected packages: whoosh, sentencepiece, cchardet, syntok, langdetect, keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-layer-normalization, keras-embed-sim, tika, keras-multi-head, keras-transformer, keras_bert, ktrain\n",
            "Successfully installed cchardet-2.1.7 keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 keras_bert-0.89.0 ktrain-0.35.1 langdetect-1.0.9 sentencepiece-0.1.97 syntok-1.4.4 tika-2.6.0 whoosh-2.7.4\n"
          ]
        }
      ],
      "source": [
        "# install\n",
        "!pip install kaggle\n",
        "!pip install transformers\n",
        "!pip install ktrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qNmUd_vinst-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pprint\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import copy\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "import math\n",
        "from typing import Optional\n",
        "import transformers\n",
        "from ktrain import text\n",
        "\n",
        "import torch\n",
        "import torch.utils.checkpoint as checkpoint\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries/code\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine"
      ],
      "metadata": {
        "id": "eZEHWnZqs8rJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c1d4f20-6394-4e56-f423-2e383ace8979"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Couldn't find torchinfo... installing it.\n",
            "[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\n",
            "Cloning into 'pytorch-deep-learning'...\n",
            "remote: Enumerating objects: 3578, done.\u001b[K\n",
            "remote: Counting objects: 100% (200/200), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 3578 (delta 88), reused 189 (delta 82), pack-reused 3378\u001b[K\n",
            "Receiving objects: 100% (3578/3578), 647.31 MiB | 19.64 MiB/s, done.\n",
            "Resolving deltas: 100% (2044/2044), done.\n",
            "Updating files: 100% (240/240), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lXFJZt1KlRIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddc1d066-fd87-4bea-b137-dc1bd0ff73d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "# data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "%cd \"gdrive/MyDrive/Colab Notebooks/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdaPcHmjmlFS"
      },
      "outputs": [],
      "source": [
        "## only needed to run it once to download\n",
        "\n",
        "# os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Colab Notebooks/\"\n",
        "\n",
        "# !kaggle competitions download -c feedback-prize-english-language-learning \n",
        "# !unzip -q feedback-prize-english-language-learning.zip -d ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "x3sZG8BKnUTx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "8d71112b-6842-421f-f98f-c22719a837a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train shape: (3911, 8)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        text_id                                          full_text  cohesion  \\\n",
              "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
              "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
              "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
              "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
              "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
              "\n",
              "   syntax  vocabulary  phraseology  grammar  conventions  \n",
              "0     3.5         3.0          3.0      4.0          3.0  \n",
              "1     2.5         3.0          2.0      2.0          2.5  \n",
              "2     3.5         3.0          3.0      3.0          2.5  \n",
              "3     4.5         4.5          4.5      4.0          5.0  \n",
              "4     3.0         3.0          3.0      2.5          2.5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ae35e08-9036-41cb-a72e-e75d232e852d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>full_text</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0016926B079C</td>\n",
              "      <td>I think that students would benefit from learn...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0022683E9EA5</td>\n",
              "      <td>When a problem is a change you have to let it ...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00299B378633</td>\n",
              "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>003885A45F42</td>\n",
              "      <td>The best time in life is when you become yours...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0049B1DF5CCC</td>\n",
              "      <td>Small act of kindness can impact in other peop...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ae35e08-9036-41cb-a72e-e75d232e852d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ae35e08-9036-41cb-a72e-e75d232e852d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ae35e08-9036-41cb-a72e-e75d232e852d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "print(f\"train shape: {train.shape}\")\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ncsa5RK4n2EC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "84c7d481-bb1c-40e1-a74e-6801a6d81347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test shape: (3, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        text_id                                          full_text\n",
              "0  0000C359D63E  when a person has no experience on a job their...\n",
              "1  000BAD50D026  Do you think students would benefit from being...\n",
              "2  00367BB2546B  Thomas Jefferson once states that \"it is wonde..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17c165b0-114c-425c-9d25-b49667f8774d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>full_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000C359D63E</td>\n",
              "      <td>when a person has no experience on a job their...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000BAD50D026</td>\n",
              "      <td>Do you think students would benefit from being...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00367BB2546B</td>\n",
              "      <td>Thomas Jefferson once states that \"it is wonde...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17c165b0-114c-425c-9d25-b49667f8774d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-17c165b0-114c-425c-9d25-b49667f8774d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-17c165b0-114c-425c-9d25-b49667f8774d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "test = pd.read_csv(\"test.csv\")\n",
        "print(f\"test shape: {test.shape}\")\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TX_R3R7U8xQ4"
      },
      "outputs": [],
      "source": [
        "# # histogram with cohesion, syntax, vocabulary, phraseology, grammar, conventions \n",
        "# for y in [\"cohesion\",\"syntax\",\"vocabulary\", \"phraseology\",\"grammar\", \"conventions\"]:\n",
        "#   print(train[y].value_counts().sort_index())\n",
        "#   print()\n",
        "#   train[y].hist()\n",
        "#   plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "saSRFRT_Vvqy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "55386ad7964e416d81ae92730851ee48",
            "2b93146e5e274160859aab6f216d2b6e",
            "caaad5949d8f4210bf5e50b5e85cb1a7",
            "ded17492aa8b4da49f9b18e07c15d6e5",
            "cd9e071c3f90472aaf8fc3162f9daf8f",
            "ef2fef90c9004d79a9b9875f1306ca33",
            "04c3ffc4ca30446bae3271f33f330ad9",
            "bce909e325024c9f9723d740371ae82f",
            "7f1561aa513947c1b5e1b1bba1e9ed33",
            "b9dc4f135fc847e2a5c84ff8c9ad333d",
            "48abb91e7ff04205a2ba6817cedf9e6d",
            "0f02eb512cc34bfe883332ce3025bceb",
            "3f45c9ada4b3429b934432cc14ba15d1",
            "cc0fed33d6484eb597783e913290ff7a",
            "61d9bf39bb18461e9b09701d60ec2ca3",
            "dee05c237bb04f3abf39502acebed12f",
            "a910ce70354649579e4d87bba8e2f5dd",
            "8ab21f044ac644848de9449fd7c3d31e",
            "6565d9f185d74a17bb30261f58d9d6ee",
            "a4da9515aea24a2492292029ba636387",
            "efe0b38b25584ca0814b4e8f1c771125",
            "744dfbbb501a41c2aeb709dca6cabe6f",
            "deaf57fd355d41cfb8c0e12f0b107ca8",
            "c15bdf26567f4292b23bbbaf66eda82a",
            "402a9f1f49c64fe89a11c67e4bb885bf",
            "7da0ec990c1448d4a6ad231f2450f42b",
            "540c9d1e7b234a7fbb287a648e85901a",
            "183498dc4faa48a9a35f6ab218829f67",
            "cdacd5d145ad492a9bf5ec920242f700",
            "c55a4f7b4bed4f9eb7ed6906fce267af",
            "85f604731b224aaa98bd99e1445e70ac",
            "bbddd1d878064369b04b6e16128350c0",
            "2f4a1f8fb7714f15ae1b3d771683a1d8"
          ]
        },
        "outputId": "3b9a071c-4f61-440a-e058-132e172392a6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/487 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55386ad7964e416d81ae92730851ee48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/325M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f02eb512cc34bfe883332ce3025bceb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "deaf57fd355d41cfb8c0e12f0b107ca8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "retribert_model_checkpoints = \"yjernite/retribert-base-uncased\"\n",
        "retribert_model = transformers.BertModel.from_pretrained(retribert_model_checkpoints)\n",
        "# retribert_model\n",
        "\n",
        "# Freeze all base layers in the \"features\" section of the model (the feature extractor) by setting requires_grad=False\n",
        "for param in retribert_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "retribert_tokenizer = transformers.BertTokenizer.from_pretrained(retribert_model_checkpoints)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "osrK4zpiryVZ"
      },
      "outputs": [],
      "source": [
        "retri_cuda = retribert_model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "j20twVVktlZY"
      },
      "outputs": [],
      "source": [
        "def set_config_param(seed = 99):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    tf.keras.backend.clear_session()\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Kaggle\"\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    pd.set_option('display.max_columns', None)\n",
        "\n",
        "set_config_param()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QG6hNNysrmyU"
      },
      "outputs": [],
      "source": [
        "input_train_df = train\n",
        "input_test_df = test\n",
        "label_cols = input_train_df.columns[2:]\n",
        "orig_train_df = copy.deepcopy(input_train_df)\n",
        "orig_train_df.head()\n",
        "     \n",
        "shuffle = np.random.permutation(np.arange(orig_train_df.shape[0]))\n",
        "orig_train_df = orig_train_df.iloc[shuffle]\n",
        "split=(0.8,0.1,0.1)\n",
        "splits = np.multiply(len(orig_train_df), split).astype(int)\n",
        "df_train, df_val, df_test = np.split(orig_train_df, [splits[0], splits[0] + splits[1]])\n",
        "\n",
        "X_train, X_val, X_test = df_train['full_text'], df_val['full_text'], df_test['full_text']\n",
        "y_train, y_val, y_test = np.array(df_train[label_cols]), np.array(df_val[label_cols]), np.array(df_test[label_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "k6dKVou5uMo5"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 512\n",
        "epochs = 5\n",
        "batch_size = 8\n",
        "dropout = .1\n",
        "learning_rate = .00005\n",
        "number_of_hidden_layer = 1\n",
        "hidden_layer_node_count = 256\n",
        "trainable_flag = False\n",
        "retrain_layer_count = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DLosOxRss8B2"
      },
      "outputs": [],
      "source": [
        "def MCRMSE(y_true, y_pred):\n",
        "    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n",
        "    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=-1, keepdims=True)\n",
        "\n",
        "def plot_loss_accuracy(history, col_list):\n",
        "    fig, ax = plt.subplots(2, 6, figsize=(16, 6), sharex='col', sharey='row')\n",
        "    fig.tight_layout(pad=5.0)\n",
        "    for idx, col in enumerate(col_list):\n",
        "\n",
        "        ax[0, idx].plot(history[col + '_loss'], lw=2, color='darkgoldenrod')\n",
        "        ax[0, idx].plot(history['val_' + col + '_loss'], lw=2, color='indianred')\n",
        "        #ax[0, idx].legend(loc='center left')\n",
        "        ax[0, idx].legend(['Train', 'Validation'], fontsize=5)\n",
        "        ax[0, idx].set_xlabel('Epochs', size=10)\n",
        "        ax[0, idx].set_title('Loss: ' + col)\n",
        "\n",
        "        ax[1, idx].plot(history[col + '_accuracy'], lw=2, color='darkgoldenrod')\n",
        "        ax[1, idx].plot(history['val_' + col + '_accuracy'], lw=2, color='indianred')\n",
        "        #ax[0, idx].legend(loc='center left')\n",
        "        ax[1, idx].legend(['Train', 'Validation'], fontsize=5)\n",
        "        ax[1, idx].set_xlabel('Epochs', size=10)\n",
        "        ax[1, idx].set_title('Accuracy: ' + col)\n",
        "\n",
        "def encode_text(text, tokenizer):\n",
        "    \n",
        "    encoded = tokenizer.batch_encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=MAX_LENGTH,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors=\"tf\",\n",
        "    )\n",
        "\n",
        "    input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n",
        "    attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_masks\": attention_masks\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XKTyGEb7wRwo"
      },
      "outputs": [],
      "source": [
        "train_encodings = encode_text(df_train['full_text'].tolist(), retribert_tokenizer)\n",
        "val_encodings = encode_text(df_val['full_text'].tolist(), retribert_tokenizer)\n",
        "test_encodings = encode_text(df_test['full_text'].tolist(), retribert_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwu_HuGqzvCG"
      },
      "outputs": [],
      "source": [
        "# double check encodings and length=512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O710Kp2ClQpP"
      },
      "outputs": [],
      "source": [
        "#### from\n",
        "# https://stackoverflow.com/questions/55369821/how-to-train-a-neural-network-model-with-bert-embeddings-instead-of-static-embed\n",
        "\n",
        "X_train = [retribert_tokenizer.tokenize('[CLS] ' + sent + ' [SEP]') for sent in X_train] \n",
        "X_train_tokens = [retribert_tokenizer.convert_tokens_to_ids(sent) for sent in X_train]\n",
        "# # X_train[0]\n",
        "# # X_train_tokens[0]\n",
        "X_test = [retribert_tokenizer.tokenize('[CLS] ' + sent + ' [SEP]') for sent in X_test] \n",
        "X_test_tokens = [retribert_tokenizer.convert_tokens_to_ids(sent) for sent in X_test]\n",
        "# y_train_tensor = torch.from_numpy(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lIKdSf6rkyQ"
      },
      "outputs": [],
      "source": [
        "### train individual tensors\n",
        "y_train_cohesion = [y_train[i][0] for i in range(len(y_train))]\n",
        "y_train_syntax = [y_train[i][1] for i in range(len(y_train))]\n",
        "y_train_vocabulary = [y_train[i][2] for i in range(len(y_train))]\n",
        "y_train_phraseology = [y_train[i][3] for i in range(len(y_train))]\n",
        "y_train_grammar = [y_train[i][4] for i in range(len(y_train))]\n",
        "y_train_convention = [y_train[i][5] for i in range(len(y_train))]\n",
        "\n",
        "y_train_cohesion_tensor = torch.Tensor(y_train_cohesion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "f4k7Cqm3CFLw"
      },
      "outputs": [],
      "source": [
        "# https://stackoverflow.com/questions/64156202/add-dense-layer-on-top-of-huggingface-bert-model\n",
        "class CustomBERTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "          super(CustomBERTModel, self).__init__()\n",
        "          self.retribert = transformers.BertModel.from_pretrained(retribert_model_checkpoints)\n",
        "          # for param in self.retribert.parameters():\n",
        "            # param.requires_grad = False\n",
        "          self.linear1 = nn.Linear(768, 9)\n",
        "          self.dropout1 = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, ids, mask):\n",
        "          outputs = self.retribert(ids,attention_mask=mask)\n",
        "          last_hidden_state = outputs[0]\n",
        "\n",
        "          # sequence_output has the following shape: (batch_size, sequence_length, 768)\n",
        "          linear1_output = self.linear1(last_hidden_state[:,0,:].view(-1,768)) ## extract the 1st token's embeddings\n",
        "          # ### New layers:\n",
        "          linear2_dropout_output = self.dropout1(linear1_output)\n",
        "\n",
        "          return linear2_dropout_output\n",
        "\n",
        "retribert_model = CustomBERTModel() # You can pass the parameters if required to have more flexible model\n",
        "retribert_model.to(torch.device(\"cuda\")) ## can be gpu\n",
        "criterion = nn.CrossEntropyLoss() ## If required define your own criterion\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, retribert_model.parameters()))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch code from the instructors (updated to try and combine with my code)"
      ],
      "metadata": {
        "id": "TiobxdxkCzT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_pairs = []\n",
        "for line in range(len(df_train)):\n",
        "    orig = df_train.iloc[line, 1]\n",
        "    target = df_train.iloc[line, 2]\n",
        "    text_pairs.append({'orig': orig, 'target': target})\n",
        "\n",
        "def preprocess_data(text_pair, tokenizer, max_length=128):\n",
        "    orig_text, target_text = text_pair\n",
        "    orig_encoded = tokenizer.batch_encode_plus(\n",
        "        [orig_text],\n",
        "        max_length=max_length,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    orig_input_ids = orig_encoded['input_ids'][0]\n",
        "    orig_attention_mask = orig_encoded['attention_mask'][0]\n",
        "\n",
        "    target_encoded = float(target_text)\n",
        "    \n",
        "    label_ids = target_encoded\n",
        "    \n",
        "    return {'input_ids': orig_input_ids,\n",
        "            'attention_mask': orig_attention_mask,\n",
        "            'labels': label_ids}"
      ],
      "metadata": {
        "id": "JI_pj4WPGdP0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TranslationDataIterator:\n",
        "    \n",
        "    def __init__(self,\n",
        "                 tokenizer,\n",
        "                 n_examples,\n",
        "                 max_load_at_once,\n",
        "                 data_filename,\n",
        "                 max_length=128,\n",
        "                 shuffle=True):\n",
        "        \n",
        "        self.tokenizer = tokenizer\n",
        "        self.n_examples = n_examples\n",
        "        self.max_load_at_once = max_load_at_once\n",
        "        self.data_filename = data_filename\n",
        "        self.max_length = max_length\n",
        "        self.shuffle = shuffle\n",
        "        \n",
        "        # Initialize row order, call on_epoch_end to shuffle row indices\n",
        "        self.row_order = np.arange(1, self.n_examples+1)\n",
        "        self.on_epoch_end()\n",
        "\n",
        "        # Load first chunk of max_load_at_once examples\n",
        "        self.df_curr_loaded = self._load_next_chunk(0)\n",
        "        self.curr_idx_in_load = 0\n",
        "    \n",
        "    def _load_next_chunk(self, idx):\n",
        "        load_start = idx\n",
        "        load_end = idx + self.max_load_at_once\n",
        "\n",
        "        # Indices to skip are the ones in the shuffled row_order before and\n",
        "        # after the chunk we'll use for this chunk\n",
        "        load_idx_skip = self.row_order[:load_start] + self.row_order[load_end:]\n",
        "        self.df_curr_loaded = pd.read_csv(self.data_filename, skiprows=load_idx_skip)\n",
        "        self.df_curr_loaded = self.df_curr_loaded.sample(frac=1)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.n_examples\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if self.df_curr_loaded is None or self.curr_idx_in_load >= len(self.df_curr_loaded):\n",
        "            self._load_next_chunk(idx)\n",
        "            self.curr_idx_in_load = 0\n",
        "        \n",
        "        text_pair = self.df_curr_loaded[['orig', 'target']].values.astype(str)[self.curr_idx_in_load]\n",
        "        self.curr_idx_in_load += 1\n",
        "        \n",
        "        item_data = preprocess_data(\n",
        "            text_pair,\n",
        "            self.tokenizer,\n",
        "            self.max_length\n",
        "        )\n",
        "        \n",
        "        return item_data\n",
        "    \n",
        "    def __call__(self):\n",
        "        for i in range(self.__len__()):\n",
        "            yield self.__getitem__(i)\n",
        "            \n",
        "            if i == self.__len__()-1:\n",
        "                self.on_epoch_end()\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            self.row_order = list(np.random.permutation(self.row_order))\n",
        "\n",
        "max_length = 32\n",
        "max_load_at_once = 100\n",
        "\n",
        "train_data_iterator = TranslationDataIterator(\n",
        "    tokenizer=retribert_tokenizer,\n",
        "    n_examples=len(text_pairs),\n",
        "    max_load_at_once=max_load_at_once,\n",
        "    data_filename=\"train.csv\",\n",
        "    max_length=max_length\n",
        ")"
      ],
      "metadata": {
        "id": "sMV0wtIZGoqI"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_iterator.__getitem__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7YSBotSKFfi",
        "outputId": "29c9dbd0-9da3-45a0-d77d-1210f4100d41"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method TranslationDataIterator.__getitem__ of <__main__.TranslationDataIterator object at 0x7f67c1a26e20>>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "  optimizer.zero_grad()\n",
        "  predicted = []\n",
        "  outputs_1 = retribert_model(encoded_sent[\"input_ids\"].to(\"cuda\"), encoded_sent[\"attention_mask\"].to(\"cuda\"))\n",
        "  outputs_1\n",
        "  train_data_iterator\n",
        "  #   final_outputs = torch.nn.functional.log_softmax(outputs_1, dim=1)\n",
        "  # # print(final_outputs)\n",
        "  #   final_outputs_max = torch.max(final_outputs)\n",
        "  #   predicted.append(final_outputs_max)\n",
        "  # print(predicted)\n",
        "  # print(final_outputs_2)\n",
        "        # input_ids = encoding['input_ids']\n",
        "        # attention_mask = encoding['attention_mask']\n",
        "  # loss = criterion(final_outputs, targets)\n",
        "        # loss.backward()\n",
        "        # optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "flQVUOWUDOGY",
        "outputId": "6230b029-fda1-4e55-8cb8-96056f1cf364"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-2c18ddf3fcde>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0moutputs_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretribert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0moutputs_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m#   final_outputs = torch.nn.functional.log_softmax(outputs_1, dim=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'mask'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class My_Custom_Generator(tf.keras.utils.Sequence) :\n",
        "  \n",
        "    def __init__(self, images, labels, batch_size) :\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "    \n",
        "    \n",
        "    def __len__(self) :\n",
        "        return (np.ceil(len(self.images) / float(self.batch_size))).astype(np.int)\n",
        "  \n",
        "  \n",
        "    def __getitem__(self, idx) :\n",
        "        with tf.device('/cpu:0'): \n",
        "            batch_x = self.images[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "            batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "    \n",
        "        return batch_x, batch_y"
      ],
      "metadata": {
        "id": "kNCRpHLgM8Op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch code from the instructors"
      ],
      "metadata": {
        "id": "FwP0qvk-Gmln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(text_file) as f:\n",
        "#     lines = f.read().split('\\n')[:-1]\n",
        "\n",
        "# prefix = 'translate old to modern: '\n",
        "# text_pairs = []\n",
        "# for line in lines:\n",
        "#     orig, target = line.split('\\t')\n",
        "#     text_pairs.append({'orig': prefix + orig, 'target': target})"
      ],
      "metadata": {
        "id": "FT9Mn2gGC6ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def preprocess_data(text_pair, tokenizer, max_length=128):\n",
        "#     orig_text, target_text = text_pair\n",
        "#     orig_encoded = tokenizer.batch_encode_plus(\n",
        "#         [orig_text],\n",
        "#         max_length=max_length,\n",
        "#         padding='max_length',\n",
        "#         truncation=True,\n",
        "#         return_attention_mask=True,\n",
        "#         return_tensors='pt'\n",
        "#     )\n",
        "\n",
        "#     orig_input_ids = orig_encoded['input_ids'][0]\n",
        "#     orig_attention_mask = orig_encoded['attention_mask'][0]\n",
        "    \n",
        "#     target_encoded = tokenizer.batch_encode_plus(\n",
        "#         [target_text],\n",
        "#         max_length=max_length,\n",
        "#         padding='max_length',\n",
        "#         truncation=True,\n",
        "#         return_attention_mask=True,\n",
        "#         return_tensors='pt'\n",
        "#     )\n",
        "    \n",
        "#     label_ids = target_encoded['input_ids'][0]\n",
        "    \n",
        "#     return {'input_ids': orig_input_ids,\n",
        "#             'attention_mask': orig_attention_mask,\n",
        "#             'labels': label_ids}"
      ],
      "metadata": {
        "id": "7JXS2Yr6C2h9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class TranslationDataIterator:\n",
        "    \n",
        "#     def __init__(self,\n",
        "#                  tokenizer,\n",
        "#                  n_examples,\n",
        "#                  max_load_at_once,\n",
        "#                  data_filename,\n",
        "#                  max_length=128,\n",
        "#                  shuffle=True):\n",
        "        \n",
        "#         self.tokenizer = tokenizer\n",
        "#         self.n_examples = n_examples\n",
        "#         self.max_load_at_once = max_load_at_once\n",
        "#         self.data_filename = data_filename\n",
        "#         self.max_length = max_length\n",
        "#         self.shuffle = shuffle\n",
        "        \n",
        "#         # Initialize row order, call on_epoch_end to shuffle row indices\n",
        "#         self.row_order = np.arange(1, self.n_examples+1)\n",
        "#         self.on_epoch_end()\n",
        "\n",
        "#         # Load first chunk of max_load_at_once examples\n",
        "#         self.df_curr_loaded = self._load_next_chunk(0)\n",
        "#         self.curr_idx_in_load = 0\n",
        "    \n",
        "#     def _load_next_chunk(self, idx):\n",
        "#         load_start = idx\n",
        "#         load_end = idx + self.max_load_at_once\n",
        "\n",
        "#         # Indices to skip are the ones in the shuffled row_order before and\n",
        "#         # after the chunk we'll use for this chunk\n",
        "#         load_idx_skip = self.row_order[:load_start] + self.row_order[load_end:]\n",
        "#         self.df_curr_loaded = pd.read_csv(self.data_filename, skiprows=load_idx_skip)\n",
        "#         self.df_curr_loaded = self.df_curr_loaded.sample(frac=1)\n",
        "    \n",
        "#     def __len__(self):\n",
        "#         return self.n_examples\n",
        "    \n",
        "#     def __getitem__(self, idx):\n",
        "#         if self.df_curr_loaded is None or self.curr_idx_in_load >= len(self.df_curr_loaded):\n",
        "#             self._load_next_chunk(idx)\n",
        "#             self.curr_idx_in_load = 0\n",
        "        \n",
        "#         text_pair = self.df_curr_loaded[['orig', 'target']].values.astype(str)[self.curr_idx_in_load]\n",
        "#         self.curr_idx_in_load += 1\n",
        "        \n",
        "#         item_data = preprocess_data(\n",
        "#             text_pair,\n",
        "#             self.tokenizer,\n",
        "#             self.max_length\n",
        "#         )\n",
        "        \n",
        "#         return item_data\n",
        "    \n",
        "#     def __call__(self):\n",
        "#         for i in range(self.__len__()):\n",
        "#             yield self.__getitem__(i)\n",
        "            \n",
        "#             if i == self.__len__()-1:\n",
        "#                 self.on_epoch_end()\n",
        "    \n",
        "#     def on_epoch_end(self):\n",
        "#         if self.shuffle:\n",
        "#             self.row_order = list(np.random.permutation(self.row_order))"
      ],
      "metadata": {
        "id": "oS527vUBC-y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Create the data iterators for train and validation data, pytorch version\n",
        "\n",
        "# max_length = 32\n",
        "# max_load_at_once = 100\n",
        "\n",
        "# train_data_iterator = TranslationDataIterator(\n",
        "#     tokenizer=t5_tokenizer,\n",
        "#     n_examples=len(train_pairs),\n",
        "#     max_load_at_once=max_load_at_once,\n",
        "#     data_filename=train_file,\n",
        "#     max_length=max_length\n",
        "# )\n",
        "\n",
        "# valid_data_iterator = TranslationDataIterator(\n",
        "#     tokenizer=t5_tokenizer,\n",
        "#     n_examples=len(valid_pairs),\n",
        "#     max_load_at_once=max_load_at_once,\n",
        "#     data_filename=valid_file,\n",
        "#     max_length=max_length\n",
        "# )\n",
        "\n",
        "# # Specify batch size and other training arguments\n",
        "\n",
        "# batch_size = 16\n",
        "\n",
        "# # Modify this filepath to where you want to save the model after fine-tuning\n",
        "# dir_path = 'drive/MyDrive/ISchool/MIDS/W266/2023_Spring/notebooks/'\n",
        "# file_path = dir_path + 't5base-finetuned-shakespeare-to-modern'\n",
        "\n",
        "# args = Seq2SeqTrainingArguments(\n",
        "#     file_path,\n",
        "#     evaluation_strategy='epoch',\n",
        "#     per_device_train_batch_size=batch_size,\n",
        "#     per_device_eval_batch_size=batch_size,\n",
        "#     num_train_epochs=1,\n",
        "# )\n",
        "\n",
        "# # Define the trainer, passing in the model, training args, and data generators\n",
        "\n",
        "# trainer = Seq2SeqTrainer(\n",
        "#     t5_model,\n",
        "#     args,\n",
        "#     train_dataset=train_data_iterator,\n",
        "#     eval_dataset=valid_data_iterator\n",
        "# )\n",
        "\n",
        "# trainer.train()"
      ],
      "metadata": {
        "id": "bHXVmNmgDCe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Works but out of memory"
      ],
      "metadata": {
        "id": "_euqPqAkCfbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## this seems to be working  but out of memory\n",
        "for epoch in range(5):\n",
        "  optimizer.zero_grad()\n",
        "  predicted = []\n",
        "  for sent in X_train:\n",
        "    encoded_sent = retribert_tokenizer.encode_plus(sent, \n",
        "                                                   add_special_tokens=True, \n",
        "                                                   truncation=True, \n",
        "                                                   padding=True, \n",
        "                                                   return_attention_mask=True, \n",
        "                                                   return_tensors='pt', \n",
        "                                                   max_length=510)\n",
        "    outputs_1 = retribert_model(encoded_sent[\"input_ids\"].to(\"cuda\"), encoded_sent[\"attention_mask\"].to(\"cuda\"))\n",
        "    outputs_1\n",
        "    final_outputs = torch.nn.functional.log_softmax(outputs_1, dim=1)\n",
        "  # # print(final_outputs)\n",
        "    final_outputs_max = torch.max(final_outputs)\n",
        "    predicted.append(final_outputs_max)\n",
        "  # print(predicted)\n",
        "  # print(final_outputs_2)\n",
        "        # input_ids = encoding['input_ids']\n",
        "        # attention_mask = encoding['attention_mask']\n",
        "  loss = criterion(final_outputs, targets)\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "id": "jEkeUxYxtiI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Does not work"
      ],
      "metadata": {
        "id": "ICD3hvi0CaUY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftdF-3pK1xgu"
      },
      "outputs": [],
      "source": [
        "# ## trying with dataloader\n",
        "# # len(X_train_tokens) #3128\n",
        "# # len(y_train_cohesion) #33128\n",
        "# cohesion_dict = {\"X_train_tokens\":X_train_tokens,\n",
        "#                  \"y_train_cohesion\": y_train_cohesion}\n",
        "# cohesion_df = pd.DataFrame(cohesion_dict)\n",
        "\n",
        "# class customDataset:\n",
        "#   def __init__(self):\n",
        "#     xy = cohesion_df\n",
        "#     self.len = xy.shape[0]\n",
        "#     self.x_data = torch.from_numpy(xy[:,0:-1])\n",
        "#     self.y_data = torch.from_numpy(xy.iloc[:,[-1]])\n",
        "#   def __getitem__(self,index):\n",
        "#     return self.x_data[index], self.y_data[index]\n",
        "#   def __len__(self):\n",
        "#     return self.len\n",
        "\n",
        "# cohesion_ds = customDataset()\n",
        "# training_data = torchvision.datasets.cohesion_ds(\n",
        "#     root=\"data\",\n",
        "#     train=True,\n",
        "#     download=True,\n",
        "#     transform=torchvision.transformsToTensor()\n",
        "# )\n",
        "\n",
        "# # train_dataloader = torch.utils.data.DataLoader(cohesion_df, batch_size=8, shuffle=True)\n",
        "# # train_dataloader\n",
        "\n",
        "# # train_features, train_labels = iter(train_dataloader)\n",
        "# # print(f\"Feature batch shape: {train_features.size()}\")\n",
        "# # print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "# # img = train_features[0].squeeze()\n",
        "# # label = train_labels[0]\n",
        "# # plt.imshow(img, cmap=\"gray\")\n",
        "# # plt.show()\n",
        "# # print(f\"Label: {label}\")\n",
        "# # test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True)\n",
        "## from dataset\n",
        "class pyDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, X,y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "  def __getitem__(self,idx):\n",
        "    return self.X[idx], self.y[idx]\n",
        "train_loader = torch.utils.data.DataLoader(dataset=pyDataset(X_train, y_train_cohesion), batch_size=8, shuffle=T)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for epoch in epochs:\n",
        "#     for batch in data_loader: ## If you have a DataLoader()  object to get the data.\n",
        "\n",
        "#         data = batch[0]\n",
        "#         targets = batch[1] ## assuming that data loader returns a tuple of data and its targets\n",
        "        \n",
        "#         optimizer.zero_grad()   \n",
        "#         encoding = tokenizer.batch_encode_plus(data, return_tensors='pt', padding=True, truncation=True,max_length=510, add_special_tokens = True)\n",
        "        # outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        # outputs = F.log_softmax(outputs, dim=1)\n",
        "        # input_ids = encoding['input_ids']\n",
        "        # attention_mask = encoding['attention_mask']\n",
        "        # loss = criterion(outputs, targets)\n",
        "        # loss.backward()\n",
        "        # optimizer.step()"
      ],
      "metadata": {
        "id": "QCePFL8wteIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2t3c-HtCffw"
      },
      "outputs": [],
      "source": [
        "# use MCRMSE as loss metric\n",
        "\n",
        "# https://stackoverflow.com/questions/61990363/rmse-loss-for-multi-output-regression-problem-in-pytorch\n",
        "# def loss_function (predicted_x , target):\n",
        "#     loss = torch.sum(torch.square(predicted_x - target) , axis= 1)/(predicted_x.size()[1])\n",
        "#     loss = torch.sum(loss)/loss.shape[0]\n",
        "#     return loss\n",
        "\n",
        "# loss_fn = nn.MSELoss()\n",
        "# RMSE_loss = torch.sqrt(loss_fn(prediction, target))\n",
        "# RMSE_loss.backward()\n",
        "\n",
        "# def MCRMSE(y_true, y_pred):\n",
        "#     colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis = 1)\n",
        "#     return tf.reduce_mean(tf.sqrt(colwise_mse), axis = -1, keepdims = True)\n",
        "     \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlP4F2WSXDLd"
      },
      "outputs": [],
      "source": [
        "### anothing thing\n",
        "### https://stackoverflow.com/questions/68115993/input-ids-torch-tensorinput-ids-valueerror-expected-sequence-of-length-133\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "# print(flaubert)\n",
        "for sent in X_train:\n",
        "    encoded_sent = retribert_tokenizer.encode_plus(sent, add_special_tokens=True, truncation=True, padding=True, return_attention_mask=True, return_tensors='pt', max_length=510)\n",
        "\n",
        "    # Add the outputs to the lists\n",
        "    # input_ids.append(encoded_sent.get('input_ids'))\n",
        "    # attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "\n",
        "# input_ids = torch.as_tensor(input_ids)\n",
        "# attention_masks = torch.as_tensor(attention_masks)\n",
        "\n",
        "hidden_state = retribert_model(input_ids=encoded_sent[\"input_ids\"].to(\"cuda\"), attention_mask=encoded_sent[\"attention_mask\"].to(\"cuda\"))\n",
        "hidden_state\n",
        "# # # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "last_hidden_state_cls = hidden_state[0][:, 0, :]\n",
        "\n",
        "retribert_model.linear1 = nn.Linear(768, 256)\n",
        "retribert_model.dropout1 = nn.Dropout(0.1)\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vImVYBNL56NB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd7c8a96-162c-426f-fed1-34e87698b0b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0186, -0.0166, -0.0154,  ...,  0.0220,  0.0171,  0.0076],\n",
              "        [ 0.0118,  0.0026,  0.0049,  ..., -0.0287,  0.0192,  0.0038],\n",
              "        ...,\n",
              "        [-0.0003, -0.0193, -0.0029,  ..., -0.0182, -0.0184, -0.0021],\n",
              "        [ 0.0355, -0.0214, -0.0174,  ..., -0.0083,  0.0015,  0.0047],\n",
              "        [-0.0179,  0.0016,  0.0094,  ..., -0.0528,  0.0078,  0.0255]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "list(retribert_model.parameters())[0] # model weights?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAY8GJHXZtKi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "a24c7e28-b4fc-4fce-c006-a0481836ae36"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-35ae434d271b>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretribert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_hidden_state_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    984\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m                 \u001b[0mbuffered_token_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m                 \u001b[0mbuffered_token_type_ids_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffered_token_type_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffered_token_type_ids_expanded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (768) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 768].  Tensor sizes: [1, 512]"
          ]
        }
      ],
      "source": [
        "# Set the manual seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# # Freeze all base layers in the \"features\" section of the model (the feature extractor) by setting requires_grad=False\n",
        "# for param in retribert_model.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "# retribert_model(last_hidden_state_cls)\n",
        "\n",
        "# ## from https://pypi.org/project/pytorch-pretrained-bert/\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     predictions = retribert_model(last_hidden_state_cls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thhTWuFiV1VN"
      },
      "outputs": [],
      "source": [
        "# results = torch.zeros((len(X_test_tokens), retri_cuda.config.hidden_size)).long()\n",
        "# results[0]\n",
        "# with torch.no_grad():\n",
        "#     for stidx in range(0, len(X_test_tokens), batch_size):\n",
        "#         X = X_test_tokens[stidx:stidx + batch_size]\n",
        "#         X = torch.LongTensor(X).cuda()\n",
        "#         embed, pooled_output = retri_cuda(X)\n",
        "#         results[stidx:stidx + batch_size,:] = embed.cpu()\n",
        "# torch.LongTensor(X)\n",
        "\n",
        "#### from https://machinelearningmastery.com/building-a-regression-model-in-pytorch/\n",
        "# X_train_torch = torch.tensor(X_train_tokens, dtype=torch.float32)\n",
        "# y_train_torch = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "# X_test_torch = torch.tensor(X_test, dtype=torch.float32)\n",
        "# y_test_torch = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
        " \n",
        "# # training parameters\n",
        "# n_epochs = 5   # number of epochs to run\n",
        "# batch_size = 8  # size of each batch\n",
        "# batch_start = torch.arange(0, len(X_train), batch_size)\n",
        " \n",
        "# # Hold the best model\n",
        "# best_mse = np.inf   # init to infinity\n",
        "# best_weights = None\n",
        "# history = []\n",
        " \n",
        "# # training loop\n",
        "# for epoch in range(n_epochs):\n",
        "#     retribert_model.train()\n",
        "#     with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
        "#         bar.set_description(f\"Epoch {epoch}\")\n",
        "#         for start in bar:\n",
        "#             # take a batch\n",
        "#             X_batch = X_train[start:start+batch_size]\n",
        "#             y_batch = y_train[start:start+batch_size]\n",
        "#             # forward pass\n",
        "#             y_pred = retribert_model(X_batch)\n",
        "#             loss = loss_fn(y_pred, y_batch)\n",
        "#             # backward pass\n",
        "#             optimizer.zero_grad()\n",
        "#             loss.backward()\n",
        "#             # update weights\n",
        "#             optimizer.step()\n",
        "#             # print progress\n",
        "#             bar.set_postfix(mse=float(loss))\n",
        "#     # evaluate accuracy at end of each epoch\n",
        "#     retribert_model.eval()\n",
        "#     y_pred = retribert_model(X_test)\n",
        "#     mse = loss_fn(y_pred, y_test)\n",
        "#     mse = float(mse)\n",
        "#     history.append(mse)\n",
        "#     if mse < best_mse:\n",
        "#         best_mse = mse\n",
        "#         best_weights = copy.deepcopy(retribert_model.state_dict())\n",
        " \n",
        "# # restore model and return best accuracy\n",
        "# retribert_model.load_state_dict(best_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hzAHU3_8oUl"
      },
      "outputs": [],
      "source": [
        "### evaluating the model\n",
        "# from https://discuss.pytorch.org/t/multi-class-bert-model-class-weights-and-where-to-use-them/176264\n",
        "# def evaluate():  \n",
        "#     model.eval()\n",
        "#     total_loss, total_accuracy = 0, 0\n",
        "#     total_preds = []\n",
        "#     for step,batch in enumerate(val_dataloader):\n",
        "#         if step % 50 == 0 and not step == 0:\n",
        "#             elapsed = format_time(time.time() - t0)\n",
        "#             print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "#         batch = [t.to(device) for t in batch]\n",
        "#         sent_id, mask, labels = batch\n",
        "#         with torch.no_grad():\n",
        "#             preds = model(sent_id, mask)\n",
        "#             loss = cross_entropy(preds,labels)  #<------- Here\n",
        "#             total_loss = total_loss + loss.item()\n",
        "#             preds = preds.detach().cpu().numpy()\n",
        "#             total_preds.append(preds)\n",
        "#     avg_loss = total_loss / len(val_dataloader) \n",
        "#     total_preds  = np.concatenate(total_preds, axis=0)\n",
        "#     return avg_loss, total_preds"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqgDr5o/lW2HnXftr9Bw6a",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "55386ad7964e416d81ae92730851ee48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b93146e5e274160859aab6f216d2b6e",
              "IPY_MODEL_caaad5949d8f4210bf5e50b5e85cb1a7",
              "IPY_MODEL_ded17492aa8b4da49f9b18e07c15d6e5"
            ],
            "layout": "IPY_MODEL_cd9e071c3f90472aaf8fc3162f9daf8f"
          }
        },
        "2b93146e5e274160859aab6f216d2b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef2fef90c9004d79a9b9875f1306ca33",
            "placeholder": "​",
            "style": "IPY_MODEL_04c3ffc4ca30446bae3271f33f330ad9",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "caaad5949d8f4210bf5e50b5e85cb1a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bce909e325024c9f9723d740371ae82f",
            "max": 487,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f1561aa513947c1b5e1b1bba1e9ed33",
            "value": 487
          }
        },
        "ded17492aa8b4da49f9b18e07c15d6e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9dc4f135fc847e2a5c84ff8c9ad333d",
            "placeholder": "​",
            "style": "IPY_MODEL_48abb91e7ff04205a2ba6817cedf9e6d",
            "value": " 487/487 [00:00&lt;00:00, 6.87kB/s]"
          }
        },
        "cd9e071c3f90472aaf8fc3162f9daf8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef2fef90c9004d79a9b9875f1306ca33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04c3ffc4ca30446bae3271f33f330ad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bce909e325024c9f9723d740371ae82f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f1561aa513947c1b5e1b1bba1e9ed33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9dc4f135fc847e2a5c84ff8c9ad333d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48abb91e7ff04205a2ba6817cedf9e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f02eb512cc34bfe883332ce3025bceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f45c9ada4b3429b934432cc14ba15d1",
              "IPY_MODEL_cc0fed33d6484eb597783e913290ff7a",
              "IPY_MODEL_61d9bf39bb18461e9b09701d60ec2ca3"
            ],
            "layout": "IPY_MODEL_dee05c237bb04f3abf39502acebed12f"
          }
        },
        "3f45c9ada4b3429b934432cc14ba15d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a910ce70354649579e4d87bba8e2f5dd",
            "placeholder": "​",
            "style": "IPY_MODEL_8ab21f044ac644848de9449fd7c3d31e",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "cc0fed33d6484eb597783e913290ff7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6565d9f185d74a17bb30261f58d9d6ee",
            "max": 325345269,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4da9515aea24a2492292029ba636387",
            "value": 325345269
          }
        },
        "61d9bf39bb18461e9b09701d60ec2ca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efe0b38b25584ca0814b4e8f1c771125",
            "placeholder": "​",
            "style": "IPY_MODEL_744dfbbb501a41c2aeb709dca6cabe6f",
            "value": " 325M/325M [00:08&lt;00:00, 40.2MB/s]"
          }
        },
        "dee05c237bb04f3abf39502acebed12f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a910ce70354649579e4d87bba8e2f5dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ab21f044ac644848de9449fd7c3d31e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6565d9f185d74a17bb30261f58d9d6ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4da9515aea24a2492292029ba636387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "efe0b38b25584ca0814b4e8f1c771125": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "744dfbbb501a41c2aeb709dca6cabe6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "deaf57fd355d41cfb8c0e12f0b107ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c15bdf26567f4292b23bbbaf66eda82a",
              "IPY_MODEL_402a9f1f49c64fe89a11c67e4bb885bf",
              "IPY_MODEL_7da0ec990c1448d4a6ad231f2450f42b"
            ],
            "layout": "IPY_MODEL_540c9d1e7b234a7fbb287a648e85901a"
          }
        },
        "c15bdf26567f4292b23bbbaf66eda82a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_183498dc4faa48a9a35f6ab218829f67",
            "placeholder": "​",
            "style": "IPY_MODEL_cdacd5d145ad492a9bf5ec920242f700",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "402a9f1f49c64fe89a11c67e4bb885bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c55a4f7b4bed4f9eb7ed6906fce267af",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85f604731b224aaa98bd99e1445e70ac",
            "value": 231508
          }
        },
        "7da0ec990c1448d4a6ad231f2450f42b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbddd1d878064369b04b6e16128350c0",
            "placeholder": "​",
            "style": "IPY_MODEL_2f4a1f8fb7714f15ae1b3d771683a1d8",
            "value": " 232k/232k [00:00&lt;00:00, 906kB/s]"
          }
        },
        "540c9d1e7b234a7fbb287a648e85901a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "183498dc4faa48a9a35f6ab218829f67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdacd5d145ad492a9bf5ec920242f700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c55a4f7b4bed4f9eb7ed6906fce267af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85f604731b224aaa98bd99e1445e70ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bbddd1d878064369b04b6e16128350c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f4a1f8fb7714f15ae1b3d771683a1d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}