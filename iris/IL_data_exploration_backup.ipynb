{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilamaiti/spring_2023_w266_final_project_heesuk_iris_srila/blob/main/iris/IL_data_exploration_backup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ9w2FlGlNDV"
      },
      "source": [
        "https://www.kaggle.com/competitions/feedback-prize-english-language-learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUehh9Tfk8rA"
      },
      "outputs": [],
      "source": [
        "# # install\n",
        "# !pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qNmUd_vinst-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pprint\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import copy\n",
        "import tensorflow as tf\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lXFJZt1KlRIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03098ed9-c6d3-4c36-d197-c9668d0507e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "# data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "%cd \"gdrive/MyDrive/Colab Notebooks/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdaPcHmjmlFS"
      },
      "outputs": [],
      "source": [
        "## only needed to run it once to download\n",
        "\n",
        "# os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Colab Notebooks/\"\n",
        "\n",
        "# !kaggle competitions download -c feedback-prize-english-language-learning \n",
        "# !unzip -q feedback-prize-english-language-learning.zip -d ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "x3sZG8BKnUTx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "9954c5bc-889f-44ce-c7d0-bdc266373cba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train shape: (3911, 8)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        text_id                                          full_text  cohesion  \\\n",
              "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
              "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
              "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
              "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
              "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
              "\n",
              "   syntax  vocabulary  phraseology  grammar  conventions  \n",
              "0     3.5         3.0          3.0      4.0          3.0  \n",
              "1     2.5         3.0          2.0      2.0          2.5  \n",
              "2     3.5         3.0          3.0      3.0          2.5  \n",
              "3     4.5         4.5          4.5      4.0          5.0  \n",
              "4     3.0         3.0          3.0      2.5          2.5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46266543-5051-4e8e-8fa4-49d3c339bc54\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>full_text</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0016926B079C</td>\n",
              "      <td>I think that students would benefit from learn...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0022683E9EA5</td>\n",
              "      <td>When a problem is a change you have to let it ...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00299B378633</td>\n",
              "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>003885A45F42</td>\n",
              "      <td>The best time in life is when you become yours...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0049B1DF5CCC</td>\n",
              "      <td>Small act of kindness can impact in other peop...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46266543-5051-4e8e-8fa4-49d3c339bc54')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46266543-5051-4e8e-8fa4-49d3c339bc54 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46266543-5051-4e8e-8fa4-49d3c339bc54');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "print(f\"train shape: {train.shape}\")\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ncsa5RK4n2EC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "f5b21027-69c7-4af7-f326-0576d4244127"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test shape: (3, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        text_id                                          full_text\n",
              "0  0000C359D63E  when a person has no experience on a job their...\n",
              "1  000BAD50D026  Do you think students would benefit from being...\n",
              "2  00367BB2546B  Thomas Jefferson once states that \"it is wonde..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73ece03c-7dce-4d1c-a36c-c2cc83bccb28\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>full_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000C359D63E</td>\n",
              "      <td>when a person has no experience on a job their...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000BAD50D026</td>\n",
              "      <td>Do you think students would benefit from being...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00367BB2546B</td>\n",
              "      <td>Thomas Jefferson once states that \"it is wonde...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73ece03c-7dce-4d1c-a36c-c2cc83bccb28')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73ece03c-7dce-4d1c-a36c-c2cc83bccb28 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73ece03c-7dce-4d1c-a36c-c2cc83bccb28');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "test = pd.read_csv(\"test.csv\")\n",
        "print(f\"test shape: {test.shape}\")\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYT9I1iToJpr"
      },
      "outputs": [],
      "source": [
        "train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgG43xnX8wkn"
      },
      "outputs": [],
      "source": [
        "# length of full_text\n",
        "pprint.pprint(train[\"full_text\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mm-WKueoUYxB"
      },
      "outputs": [],
      "source": [
        "len(train[\"full_text\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TX_R3R7U8xQ4"
      },
      "outputs": [],
      "source": [
        "# histogram with cohesion, syntax, vocabulary, phraseology, grammar, conventions \n",
        "for y in [\"cohesion\",\"syntax\",\"vocabulary\", \"phraseology\",\"grammar\", \"conventions\"]:\n",
        "  print(train[y].value_counts().sort_index())\n",
        "  print()\n",
        "  train[y].hist()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYjjR6n086-c"
      },
      "outputs": [],
      "source": [
        "# any collinearity?\n",
        "cm = train.corr()\n",
        "print(cm)\n",
        "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "sns.heatmap(cm, cmap=cmap)\n",
        "plt.show()\n",
        "# high correlation for all of them, especially phraseology+vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rhf00V0E9AV8"
      },
      "outputs": [],
      "source": [
        "# Any patterns of text? Head & tail has same topics? # range of topics with multiple paragraphs. pprint?\n",
        "[print(train[\"full_text\"][i]) for i in range(5)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_OBhpdB9D4L"
      },
      "outputs": [],
      "source": [
        "# [print(train[\"full_text\"][i]) for i in range(-5,-1,-1)]\n",
        "train[\"full_text\"][train.shape[1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfitgYXHib4D"
      },
      "outputs": [],
      "source": [
        "# any pattern for those who are high scorers in all of them?\n",
        "# [\"cohesion\",\"syntax\",\"vocabulary\", \"phraseology\",\"grammar\", \"conventions\"]\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "# high scorer for one is high scorer for the rest.\n",
        "train[(train[\"cohesion\"]==5) & (train[\"syntax\"]==5) & (train[\"vocabulary\"]==5) & (train[\"phraseology\"]==5) & (train[\"grammar\"]==5) & (train[\"conventions\"]==5)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEfXT6NfkUSH"
      },
      "outputs": [],
      "source": [
        "# any pattern for those who are low scorers in all of them?\n",
        "# [\"cohesion\",\"syntax\",\"vocabulary\", \"phraseology\",\"grammar\", \"conventions\"]\n",
        "\n",
        "# low scorer for one is low scorer for the rest.\n",
        "train[(train[\"cohesion\"]==1) & (train[\"syntax\"]==1) & (train[\"vocabulary\"]==1) & (train[\"phraseology\"]==1) & (train[\"grammar\"]==1) & (train[\"conventions\"]==1)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxgzZ5_yorIg"
      },
      "source": [
        "Notes:\n",
        "\n",
        "* test.csv only had 3 items. just discard and split by train.csv\n",
        "* high correlation, so high scorer in one is high scorer in rest and vice versa\n",
        "* hard to be any extreme\n",
        "* high scorers also tend to write more\n",
        "* low scorers have a lot of misspellings, suggesting a model with more casual language might be more appropriate\n",
        "* there are paragraphs so we need to take note of line separations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzB82PhPxEqX"
      },
      "source": [
        "# RetriBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLBV7TnUxCwv"
      },
      "outputs": [],
      "source": [
        "# RetriBERT tokenizer\n",
        "# class transformers.RetriBertTokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Hr_JUf8J7jyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cabbc0b-5df9-4eb8-8751-9197761a4966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ktrain\n",
            "  Downloading ktrain-0.34.0.tar.gz (25.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from ktrain) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from ktrain) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from ktrain) (1.4.4)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.9/dist-packages (from ktrain) (1.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from ktrain) (2.27.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from ktrain) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from ktrain) (23.0)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 KB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.9/dist-packages (from ktrain) (0.42.1)\n",
            "Collecting cchardet\n",
            "  Downloading cchardet-2.1.7-cp39-cp39-manylinux2010_x86_64.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.4/265.4 KB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.9/dist-packages (from ktrain) (4.0.0)\n",
            "Collecting syntok>1.3.3\n",
            "  Downloading syntok-1.4.4-py3-none-any.whl (24 kB)\n",
            "Collecting tika\n",
            "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers>=4.17.0 in /usr/local/lib/python3.9/dist-packages (from ktrain) (4.27.4)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras_bert>=0.86.0\n",
            "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting whoosh\n",
            "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.8/468.8 KB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from keras_bert>=0.86.0->ktrain) (1.22.4)\n",
            "Collecting keras-transformer==0.40.0\n",
            "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-pos-embd==0.13.0\n",
            "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-multi-head==0.29.0\n",
            "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-layer-normalization==0.16.0\n",
            "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-position-wise-feed-forward==0.8.0\n",
            "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-embed-sim==0.10.0\n",
            "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-self-attention==0.51.0\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (4.39.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (8.4.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (5.12.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->ktrain) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.1->ktrain) (2022.7.1)\n",
            "Requirement already satisfied: regex>2016 in /usr/local/lib/python3.9/dist-packages (from syntok>1.3.3->ktrain) (2022.10.31)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.17.0->ktrain) (0.13.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.17.0->ktrain) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.17.0->ktrain) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers>=4.17.0->ktrain) (3.10.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.17.0->ktrain) (4.65.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from langdetect->ktrain) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->ktrain) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->ktrain) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->ktrain) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->ktrain) (1.26.15)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->ktrain) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->ktrain) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tika->ktrain) (67.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=4.17.0->ktrain) (4.5.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.0.0->ktrain) (3.15.0)\n",
            "Building wheels for collected packages: ktrain, keras_bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, langdetect, tika\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.34.0-py3-none-any.whl size=25314865 sha256=a50da033fe139565639b2865a8002859ea4c5a38ac46cb9a17d94a3cf493fa6c\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/76/14/8295b3e0dbe6203199daea7c583f520778edb66844d6d5f901\n",
            "  Building wheel for keras_bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33517 sha256=ff0ae906b9526776d1e5a055ca85108cee1a1aa7e691f71658612b9d0e3ea097\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/26/24/14ecbc0166364db7f5500164b7d796263cf3cd10c57e892180\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12303 sha256=74490972f8c910b8a4ed503e2e71f4392962920b0e7ccce3a8cbc3ca9454041f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/d6/d1/c588c3b2b112c8f1173934995836ab2f2de8323cce99fa998f\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3959 sha256=6d44ac4afa7b914f3782316a175b703603adc066d5850a30963879af62438d6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/25/02/4bb438785ef9c10d07f6b3519f080b38917153fdac3108d738\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4666 sha256=7db51cc61bb6beff153afdf56b31f352e8c389937d86d73831e84acbf5b75657\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/df/15/a88cdf68ce687574649f65063a743123e1bee79932b6eea3b6\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14992 sha256=ae80059f533ff2031fd2f54c9450416ad3bcbab74c774ffad5ac1f083470ea1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/85/50/f232cac81ed1eb4dc20db31a9d1f4a8a1a8c696d4d27bff442\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6958 sha256=f30c750b73abab2fed41e17f7b8616ac26921cdc7f014c3717f67000d99324c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/8c/9a/917bf72d493e084ca1706a02679185789c2715f50770d8c987\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4983 sha256=b657ca0258396b314f8b49cb7888bcfe6f46ea4e35d37b9812995f75b3179e51\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/36/25/efb605ab1742a179274a6f7cb113da1c6758f45e212b59bb4d\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18910 sha256=2d0aa7f5dbe4cbc3bfd53a8b59341e78b7a9c2ff43daf5aee2f3ca2022e7bc1a\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/c1/84/b83a2fd6f1d63e136cba74bac4126bee3b8705eef6486635fd\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993243 sha256=c8199617a9d5c34643a3f29f34003a3a9dc43a23c36216740142924c8e2200f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/c1/d9/7e068de779d863bc8f8fc9467d85e25cfe47fa5051fff1a1bb\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32641 sha256=7e47a1035fc61f1fd6cec39e2b9ba5b05e1ab2297742c30fadf23c003f43f095\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/56/18/e752060632d32c39c9c4545e756dad281f8504dafcfac02b95\n",
            "Successfully built ktrain keras_bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention langdetect tika\n",
            "Installing collected packages: whoosh, sentencepiece, cchardet, syntok, langdetect, keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-layer-normalization, keras-embed-sim, tika, keras-multi-head, keras-transformer, keras_bert, ktrain\n",
            "Successfully installed cchardet-2.1.7 keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 keras_bert-0.89.0 ktrain-0.34.0 langdetect-1.0.9 sentencepiece-0.1.97 syntok-1.4.4 tika-2.6.0 whoosh-2.7.4\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install ktrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LC-BH85qy3lg"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from typing import Optional\n",
        "import transformers\n",
        "from ktrain import text\n",
        "\n",
        "import torch\n",
        "import torch.utils.checkpoint as checkpoint\n",
        "from torch import nn\n",
        "# from transformers import TFAutoModel, AutoTokenizer\n",
        "\n",
        "# from ...modeling_utils import PreTrainedModel\n",
        "# from ...utils import add_start_docstrings, logging\n",
        "# from ..bert.modeling_bert import BertModel\n",
        "# from .configuration_retribert import RetriBertConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUeVSs2z7Fhp"
      },
      "outputs": [],
      "source": [
        "# model_checkpoint = 'yjernite/retribert-base-uncased'\n",
        "# model = TFAutoModel.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiF9WJjLxtfa"
      },
      "outputs": [],
      "source": [
        "# # RetriBERT model\n",
        "# # class transformers.RetriBertModel\n",
        "# # coding=utf-8\n",
        "# # Copyright 2019-present, the HuggingFace Inc. team, The Google AI Language Team and Facebook, Inc.\n",
        "# #\n",
        "# # Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# # you may not use this file except in compliance with the License.\n",
        "# # You may obtain a copy of the License at\n",
        "# #\n",
        "# #     http://www.apache.org/licenses/LICENSE-2.0\n",
        "# #\n",
        "# # Unless required by applicable law or agreed to in writing, software\n",
        "# # distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# # See the License for the specific language governing permissions and\n",
        "# # limitations under the License.\n",
        "# \"\"\"\n",
        "# RetriBERT model\n",
        "# \"\"\"\n",
        "\n",
        "# logger = transformers.logging.get_logger(__name__)\n",
        "\n",
        "# RETRIBERT_PRETRAINED_MODEL_ARCHIVE_LIST = [\n",
        "#     \"yjernite/retribert-base-uncased\",\n",
        "#     # See all RetriBert models at https://huggingface.co/models?filter=retribert\n",
        "# ]\n",
        "\n",
        "\n",
        "# # INTERFACE FOR ENCODER AND TASK SPECIFIC MODEL #\n",
        "# class RetriBertPreTrainedModel(PreTrainedModel):\n",
        "#     \"\"\"\n",
        "#     An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained\n",
        "#     models.\n",
        "#     \"\"\"\n",
        "\n",
        "#     config_class = RetriBertConfig\n",
        "#     load_tf_weights = None\n",
        "#     base_model_prefix = \"retribert\"\n",
        "\n",
        "#     def _init_weights(self, module):\n",
        "#         \"\"\"Initialize the weights\"\"\"\n",
        "#         if isinstance(module, nn.Linear):\n",
        "#             module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "#             if module.bias is not None:\n",
        "#                 module.bias.data.zero_()\n",
        "#         elif isinstance(module, nn.Embedding):\n",
        "#             module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "#             if module.padding_idx is not None:\n",
        "#                 module.weight.data[module.padding_idx].zero_()\n",
        "#         elif isinstance(module, nn.LayerNorm):\n",
        "#             module.bias.data.zero_()\n",
        "#             module.weight.data.fill_(1.0)\n",
        "\n",
        "\n",
        "# RETRIBERT_START_DOCSTRING = r\"\"\"\n",
        "#     This model inherits from [`PreTrainedModel`]. Check the superclass documentation for the generic methods the\n",
        "#     library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads\n",
        "#     etc.)\n",
        "#     This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) subclass.\n",
        "#     Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage\n",
        "#     and behavior.\n",
        "#     Parameters:\n",
        "#         config ([`RetriBertConfig`]): Model configuration class with all the parameters of the model.\n",
        "#             Initializing with a config file does not load the weights associated with the model, only the\n",
        "#             configuration. Check out the [`~PreTrainedModel.from_pretrained`] method to load the model weights.\n",
        "# \"\"\"\n",
        "\n",
        "\n",
        "# @add_start_docstrings(\n",
        "#     \"\"\"Bert Based model to embed queries or document for document retrieval.\"\"\",\n",
        "#     RETRIBERT_START_DOCSTRING,\n",
        "# )\n",
        "# class RetriBertModel(RetriBertPreTrainedModel):\n",
        "#     def __init__(self, config: RetriBertConfig) -> None:\n",
        "#         super().__init__(config)\n",
        "#         self.projection_dim = config.projection_dim\n",
        "\n",
        "#         self.bert_query = BertModel(config)\n",
        "#         self.bert_doc = None if config.share_encoders else BertModel(config)\n",
        "#         self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "#         self.project_query = nn.Linear(config.hidden_size, config.projection_dim, bias=False)\n",
        "#         self.project_doc = nn.Linear(config.hidden_size, config.projection_dim, bias=False)\n",
        "\n",
        "#         self.ce_loss = nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "\n",
        "#         # Initialize weights and apply final processing\n",
        "#         self.post_init()\n",
        "\n",
        "#     def embed_sentences_checkpointed(\n",
        "#         self,\n",
        "#         input_ids,\n",
        "#         attention_mask,\n",
        "#         sent_encoder,\n",
        "#         checkpoint_batch_size=-1,\n",
        "#     ):\n",
        "#         # reproduces BERT forward pass with checkpointing\n",
        "#         if checkpoint_batch_size < 0 or input_ids.shape[0] < checkpoint_batch_size:\n",
        "#             return sent_encoder(input_ids, attention_mask=attention_mask)[1]\n",
        "#         else:\n",
        "#             # prepare implicit variables\n",
        "#             device = input_ids.device\n",
        "#             input_shape = input_ids.size()\n",
        "#             token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "#             head_mask = [None] * sent_encoder.config.num_hidden_layers\n",
        "#             extended_attention_mask: torch.Tensor = sent_encoder.get_extended_attention_mask(\n",
        "#                 attention_mask, input_shape\n",
        "#             )\n",
        "\n",
        "#             # define function for checkpointing\n",
        "#             def partial_encode(*inputs):\n",
        "#                 encoder_outputs = sent_encoder.encoder(\n",
        "#                     inputs[0],\n",
        "#                     attention_mask=inputs[1],\n",
        "#                     head_mask=head_mask,\n",
        "#                 )\n",
        "#                 sequence_output = encoder_outputs[0]\n",
        "#                 pooled_output = sent_encoder.pooler(sequence_output)\n",
        "#                 return pooled_output\n",
        "\n",
        "#             # run embedding layer on everything at once\n",
        "#             embedding_output = sent_encoder.embeddings(\n",
        "#                 input_ids=input_ids, position_ids=None, token_type_ids=token_type_ids, inputs_embeds=None\n",
        "#             )\n",
        "#             # run encoding and pooling on one mini-batch at a time\n",
        "#             pooled_output_list = []\n",
        "#             for b in range(math.ceil(input_ids.shape[0] / checkpoint_batch_size)):\n",
        "#                 b_embedding_output = embedding_output[b * checkpoint_batch_size : (b + 1) * checkpoint_batch_size]\n",
        "#                 b_attention_mask = extended_attention_mask[b * checkpoint_batch_size : (b + 1) * checkpoint_batch_size]\n",
        "#                 pooled_output = checkpoint.checkpoint(partial_encode, b_embedding_output, b_attention_mask)\n",
        "#                 pooled_output_list.append(pooled_output)\n",
        "#             return torch.cat(pooled_output_list, dim=0)\n",
        "\n",
        "#     def embed_questions(\n",
        "#         self,\n",
        "#         input_ids,\n",
        "#         attention_mask=None,\n",
        "#         checkpoint_batch_size=-1,\n",
        "#     ):\n",
        "#         q_reps = self.embed_sentences_checkpointed(\n",
        "#             input_ids,\n",
        "#             attention_mask,\n",
        "#             self.bert_query,\n",
        "#             checkpoint_batch_size,\n",
        "#         )\n",
        "#         return self.project_query(q_reps)\n",
        "\n",
        "#     def embed_answers(\n",
        "#         self,\n",
        "#         input_ids,\n",
        "#         attention_mask=None,\n",
        "#         checkpoint_batch_size=-1,\n",
        "#     ):\n",
        "#         a_reps = self.embed_sentences_checkpointed(\n",
        "#             input_ids,\n",
        "#             attention_mask,\n",
        "#             self.bert_query if self.bert_doc is None else self.bert_doc,\n",
        "#             checkpoint_batch_size,\n",
        "#         )\n",
        "#         return self.project_doc(a_reps)\n",
        "\n",
        "#     def forward(\n",
        "#         self,\n",
        "#         input_ids_query: torch.LongTensor,\n",
        "#         attention_mask_query: Optional[torch.FloatTensor],\n",
        "#         input_ids_doc: torch.LongTensor,\n",
        "#         attention_mask_doc: Optional[torch.FloatTensor],\n",
        "#         checkpoint_batch_size: int = -1,\n",
        "#     ) -> torch.FloatTensor:\n",
        "#         r\"\"\"\n",
        "#         Args:\n",
        "#             input_ids_query (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\n",
        "#                 Indices of input sequence tokens in the vocabulary for the queries in a batch.\n",
        "#                 Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n",
        "#                 [`PreTrainedTokenizer.__call__`] for details.\n",
        "#                 [What are input IDs?](../glossary#input-ids)\n",
        "#             attention_mask_query (`torch.FloatTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
        "#                 Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:\n",
        "#                 - 1 for tokens that are **not masked**,\n",
        "#                 - 0 for tokens that are **masked**.\n",
        "#                 [What are attention masks?](../glossary#attention-mask)\n",
        "#             input_ids_doc (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\n",
        "#                 Indices of input sequence tokens in the vocabulary for the documents in a batch.\n",
        "#             attention_mask_doc (`torch.FloatTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
        "#                 Mask to avoid performing attention on documents padding token indices.\n",
        "#             checkpoint_batch_size (`int`, *optional*, defaults to `-1`):\n",
        "#                 If greater than 0, uses gradient checkpointing to only compute sequence representation on\n",
        "#                 `checkpoint_batch_size` examples at a time on the GPU. All query representations are still compared to\n",
        "#                 all document representations in the batch.\n",
        "#         Return:\n",
        "#             `torch.FloatTensor``: The bidirectional cross-entropy loss obtained while trying to match each query to its\n",
        "#             corresponding document and each document to its corresponding query in the batch\n",
        "#         \"\"\"\n",
        "#         device = input_ids_query.device\n",
        "#         q_reps = self.embed_questions(input_ids_query, attention_mask_query, checkpoint_batch_size)\n",
        "#         a_reps = self.embed_answers(input_ids_doc, attention_mask_doc, checkpoint_batch_size)\n",
        "#         compare_scores = torch.mm(q_reps, a_reps.t())\n",
        "#         loss_qa = self.ce_loss(compare_scores, torch.arange(compare_scores.shape[1]).to(device))\n",
        "#         loss_aq = self.ce_loss(compare_scores.t(), torch.arange(compare_scores.shape[0]).to(device))\n",
        "#         loss = (loss_qa + loss_aq) / 2\n",
        "#         return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "saSRFRT_Vvqy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "6dc8af802b374dd8a25a5a9fd43c1bcd",
            "f059853f0caa413484e9d499bf763cfa",
            "beea827bcc954e03878cf2be9cc05621",
            "1545a8f8432c41569952fdd5afa4351c",
            "ba75c9b6afda49d8913152bc2a7817ac",
            "655acf950dbc4a23a5f135ef5fe494bd",
            "d7e50a2249924fac93a62fd05f627622",
            "1b5a917142a841e6a5a791e4c4dc2c78",
            "52e9c9595477445791d7b1f557f15a92",
            "20b66e9d5ccb44c3b2dce7d9822debb3",
            "c6ad6bf897d549a296bb49efbddf6943",
            "8fcac3ae1c094b6989a1477424f58696",
            "dae12c065a1c44d79baf2073240846b3",
            "0da5ff9b59374534a5e0af1b885331ad",
            "a4350431ed934ebe9005245f00e46226",
            "e846202a5f974f519ad560a42c61ba4f",
            "4fa0e8ce3b8f405681f67ecad3d8e720",
            "81fb70df37154c15a3d498061463fb4b",
            "8b419016c94949ad9a5ffdeeaf681d95",
            "d1e1307c51ea4911b488f64b528f1f17",
            "2f7888aa9ded43bc84f4ef28215806f1",
            "e19068632b9346b8bd361f40737fd625",
            "31912bc42285487b80c97f8d973486c3",
            "868b02184e5640039962f41ef28dd171",
            "e63944610f90487780ba7f64058ed3b8",
            "2df5ee198a6343e5b0812e90d6e4ddc9",
            "75402ca002274b40956357a3d53e9070",
            "95c0032d01134e6ba9ec52b4c9c40f23",
            "af81a4c377f646f3b98900f33442e237",
            "3c93e97b39b24f45b44fb5500503c847",
            "ace6e7d8311744a383f75b8c1cd9fbb0",
            "cc917ef4281c43f48ce8a3d187360281",
            "14b03f3827ad400cbbcf8303d7c4573d"
          ]
        },
        "outputId": "907bd3c2-2210-4858-ea63-7b503c8ca380"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/487 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6dc8af802b374dd8a25a5a9fd43c1bcd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/325M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fcac3ae1c094b6989a1477424f58696"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31912bc42285487b80c97f8d973486c3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# retribert_model = transformers.TFAutoModel.from_pretrained(\"yjernite/retribert-base-uncased\")\n",
        "# text.Transformer(\"yjernite/retribert-base-uncased/\")\n",
        "# transformers.AutoConfig.from_pretrained(\"yjernite/retribert-base-uncased/\")\n",
        "\n",
        "# retriconfig = transformers.RetriBertConfig(vocab_size=30522, \n",
        "#                              hidden_size=768, \n",
        "#                              num_hidden_layers=8, \n",
        "#                              num_attention_heads=12, \n",
        "#                              intermediate_size=3072, \n",
        "#                              hidden_act='gelu', \n",
        "#                              hidden_dropout_prob=0.1, \n",
        "#                              attention_probs_dropout_prob=0.1, \n",
        "#                              max_position_embeddings=512, \n",
        "#                              type_vocab_size=2, \n",
        "#                              initializer_range=0.02, \n",
        "#                              layer_norm_eps=1e-12, \n",
        "#                              share_encoders=True, \n",
        "#                              projection_dim=128, \n",
        "#                              pad_token_id=0)\n",
        "# # retribert_model = transformers.TFAutoModel.from_pretrained(retriconfig)\n",
        "# transformers.AutoConfig.from_pretrained(retriconfig) # tried using the config function\n",
        "\n",
        "retribert_model_checkpoints = \"yjernite/retribert-base-uncased\"\n",
        "retribert_model = transformers.BertModel.from_pretrained(retribert_model_checkpoints)\n",
        "# retribert_model\n",
        "\n",
        "# # Freeze all base layers in the \"features\" section of the model (the feature extractor) by setting requires_grad=False\n",
        "# for param in retribert_model.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "retribert_tokenizer = transformers.BertTokenizer.from_pretrained(retribert_model_checkpoints)\n",
        "# retribert_tokenizer = transformers.AutoTokenizer.from_pretrained(retribert_model_checkpoints, use_fast=False, normalization = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "osrK4zpiryVZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f2ff503-e49b-48a4-ef7d-4b5a1a2ca8d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "retri_cuda = retribert_model.cuda()\n",
        "retri_cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QG6hNNysrmyU"
      },
      "outputs": [],
      "source": [
        "input_train_df = train\n",
        "input_test_df = test\n",
        "label_cols = input_train_df.columns[2:]\n",
        "orig_train_df = copy.deepcopy(input_train_df)\n",
        "orig_train_df.head()\n",
        "     \n",
        "shuffle = np.random.permutation(np.arange(orig_train_df.shape[0]))\n",
        "orig_train_df = orig_train_df.iloc[shuffle]\n",
        "split=(0.8,0.1,0.1)\n",
        "splits = np.multiply(len(orig_train_df), split).astype(int)\n",
        "df_train, df_val, df_test = np.split(orig_train_df, [splits[0], splits[0] + splits[1]])\n",
        "\n",
        "X_train, X_val, X_test = df_train['full_text'], df_val['full_text'], df_test['full_text']\n",
        "y_train, y_val, y_test = np.array(df_train[label_cols]), np.array(df_val[label_cols]), np.array(df_test[label_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "j20twVVktlZY"
      },
      "outputs": [],
      "source": [
        "def set_config_param(seed = 99):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    tf.keras.backend.clear_session()\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Kaggle\"\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    \n",
        "    \n",
        "# set_config_param(20230214)\n",
        "set_config_param()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "k6dKVou5uMo5"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 512\n",
        "epochs = 5\n",
        "batch_size = 8\n",
        "dropout = .1\n",
        "learning_rate = .00005\n",
        "number_of_hidden_layer = 1\n",
        "hidden_layer_node_count = 256\n",
        "trainable_flag = False\n",
        "retrain_layer_count = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DLosOxRss8B2"
      },
      "outputs": [],
      "source": [
        "def MCRMSE(y_true, y_pred):\n",
        "    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n",
        "    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=-1, keepdims=True)\n",
        "\n",
        "def plot_loss_accuracy(history, col_list):\n",
        "    fig, ax = plt.subplots(2, 6, figsize=(16, 6), sharex='col', sharey='row')\n",
        "    fig.tight_layout(pad=5.0)\n",
        "    for idx, col in enumerate(col_list):\n",
        "\n",
        "        ax[0, idx].plot(history[col + '_loss'], lw=2, color='darkgoldenrod')\n",
        "        ax[0, idx].plot(history['val_' + col + '_loss'], lw=2, color='indianred')\n",
        "        #ax[0, idx].legend(loc='center left')\n",
        "        ax[0, idx].legend(['Train', 'Validation'], fontsize=5)\n",
        "        ax[0, idx].set_xlabel('Epochs', size=10)\n",
        "        ax[0, idx].set_title('Loss: ' + col)\n",
        "\n",
        "        ax[1, idx].plot(history[col + '_accuracy'], lw=2, color='darkgoldenrod')\n",
        "        ax[1, idx].plot(history['val_' + col + '_accuracy'], lw=2, color='indianred')\n",
        "        #ax[0, idx].legend(loc='center left')\n",
        "        ax[1, idx].legend(['Train', 'Validation'], fontsize=5)\n",
        "        ax[1, idx].set_xlabel('Epochs', size=10)\n",
        "        ax[1, idx].set_title('Accuracy: ' + col)\n",
        "\n",
        "def encode_text(text, tokenizer):\n",
        "    \n",
        "    encoded = tokenizer.batch_encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=MAX_LENGTH,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors=\"tf\",\n",
        "    )\n",
        "\n",
        "    input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n",
        "    attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_masks\": attention_masks\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XKTyGEb7wRwo"
      },
      "outputs": [],
      "source": [
        "train_encodings = encode_text(df_train['full_text'].tolist(), retribert_tokenizer)\n",
        "val_encodings = encode_text(df_val['full_text'].tolist(), retribert_tokenizer)\n",
        "test_encodings = encode_text(df_test['full_text'].tolist(), retribert_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwu_HuGqzvCG"
      },
      "outputs": [],
      "source": [
        "# double check encodings and length=512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Am8IcOsF0Y4s"
      },
      "outputs": [],
      "source": [
        "#### from BERT TF\n",
        "# def create_retribert_classification_model(retribert_model,\n",
        "#                                           num_train_layers=0,\n",
        "#                                           hidden_size = 200,\n",
        "#                                           dropout=0.3,\n",
        "#                                           learning_rate=0.00005):\n",
        "#     \"\"\"\n",
        "#     Build a simple classification model with BERT. Use the CLS Output for classification purposes\n",
        "#     \"\"\"\n",
        "#     if num_train_layers == 0:\n",
        "#         # Freeze all layers of pre-trained BERT model\n",
        "#         retribert_model.trainable = False\n",
        "\n",
        "#     elif num_train_layers == 12: ##### NUMBER OF RETRIBERT MODELS. NEED TO UPDATE.\n",
        "#         # Train all layers of the BERT model\n",
        "#         retribert_model.trainable = True\n",
        "\n",
        "#     else:\n",
        "#         # Restrict training to the num_train_layers outer transformer layers\n",
        "#         retrain_layers = []\n",
        "\n",
        "#         for retrain_layer_number in range(num_train_layers):\n",
        "\n",
        "#             layer_code = '_' + str(11 - retrain_layer_number)\n",
        "#             retrain_layers.append(layer_code)\n",
        "          \n",
        "        \n",
        "#         print('retrain layers: ', retrain_layers)\n",
        "\n",
        "#         for w in retribert_model.weights:\n",
        "#             if not any([x in w.name for x in retrain_layers]):\n",
        "#                 #print('freezing: ', w)\n",
        "#                 w._trainable = False\n",
        "\n",
        "#     input_ids = tf.keras.layers.Input(shape=(MAX_LENGTH,), dtype=tf.int64, name='input_ids_layer')\n",
        "#     token_type_ids = tf.keras.layers.Input(shape=(MAX_LENGTH,), dtype=tf.int64, name='token_type_ids_layer')\n",
        "#     attention_mask = tf.keras.layers.Input(shape=(MAX_LENGTH,), dtype=tf.int64, name='attention_mask_layer')\n",
        "\n",
        "#     retribert_inputs = {'input_ids': input_ids,\n",
        "#                         'token_type_ids': token_type_ids,\n",
        "#                         'attention_mask': attention_mask}      \n",
        "\n",
        "#     retribert_out = retribert_model(retribert_inputs)\n",
        "\n",
        "#     cls_token = retribert_out[0][:, 0, :]\n",
        "\n",
        "#     hidden = tf.keras.layers.Dense(hidden_size, activation='relu', name='hidden_layer')(cls_token)\n",
        "\n",
        "\n",
        "#     hidden = tf.keras.layers.Dropout(dropout)(hidden)\n",
        "\n",
        "\n",
        "#     classification = tf.keras.layers.Dense(1, activation='sigmoid',name='classification_layer')(hidden)\n",
        "    \n",
        "#     classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[classification])\n",
        "    \n",
        "#     classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "#                                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n",
        "#                                  metrics='accuracy')\n",
        "    \n",
        "#     return classification_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kiw3dT5U0rjI"
      },
      "outputs": [],
      "source": [
        "# retribert_classification_model = create_retribert_classification_model(retribert_model, num_train_layers=0)\n",
        "# retribert_classification_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "eXEi1T5WBmpv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5291f894-cc41-4d52-8611-ce26b16b9d76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Couldn't find torchinfo... installing it.\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries/code\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "     \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_CpwOxtEIQ0"
      },
      "outputs": [],
      "source": [
        "# from torch.utils.data import Dataset\n",
        "\n",
        "# class PandasDataset(Dataset):\n",
        "#     def __init__(self, dataframe):\n",
        "#         self.dataframe = dataframe\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.dataframe)\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         return self.dataframe.iloc[index]\n",
        "\n",
        "# from torch.utils.data import DataLoader\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# train, test = train_test_split(orig_train_df, test_size=0.2, random_state=0)\n",
        "# train_dataset = PandasDataset(train)\n",
        "# test_dataset = PandasDataset(test)\n",
        "# train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16)\n",
        "# test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# train_dataloader = torch.utils.data.DataLoader(X_train, batch_size=64, shuffle=True)\n",
        "# test_dataloader = torch.utils.data.DataLoader(X_test, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "um1mFaPz7shm"
      },
      "outputs": [],
      "source": [
        "# # Set the manual seeds\n",
        "# torch.manual_seed(42)\n",
        "# torch.cuda.manual_seed(42)\n",
        "# class_names = [1.0,1.5,2.0,2.5,3.0,3.5,4.0,4.5,5.0]\n",
        "# # Get the length of class_names (one output unit for each class)\n",
        "# output_shape = len(class_names)\n",
        "\n",
        "\n",
        "# # Recreate the classifier layer and seed it to the target device\n",
        "# retribert_model.classifier = torch.nn.Sequential(\n",
        "#     torch.nn.Dropout(p=0.2, inplace=True), \n",
        "#     torch.nn.Linear(in_features=1280, \n",
        "#                     out_features=output_shape, # same number of output units as our number of classes\n",
        "#                     bias=True)).to(device)\n",
        "\n",
        "\n",
        "# # Define loss and optimizer\n",
        "# loss_fn = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.Adam(retribert_model.parameters(), lr=0.001)\n",
        "\n",
        "# # retribert_model_results = engine.train(model=retribert_model,\n",
        "# #                                        train_dataloader=train_dataloader,\n",
        "# #                                        test_dataloader=test_dataloader,\n",
        "# #                                        optimizer=optimizer,\n",
        "# #                                        loss_fn=loss_fn,\n",
        "# #                                        epochs=5,\n",
        "# #                                        device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O710Kp2ClQpP"
      },
      "outputs": [],
      "source": [
        "## copy of code above\n",
        "X_train, X_val, X_test = df_train['full_text'], df_val['full_text'], df_test['full_text']\n",
        "y_train, y_val, y_test = np.array(df_train[label_cols]), np.array(df_val[label_cols]), np.array(df_test[label_cols])\n",
        "\n",
        "#### from\n",
        "# https://stackoverflow.com/questions/55369821/how-to-train-a-neural-network-model-with-bert-embeddings-instead-of-static-embed\n",
        "retribert_tokenizer = transformers.BertTokenizer.from_pretrained(retribert_model_checkpoints)\n",
        "# retribert_tokenizer = transformers.AutoTokenizer.from_pretrained(retribert_model_checkpoints, use_fast=False, normalization = True)\n",
        "\n",
        "X_train = [retribert_tokenizer.tokenize('[CLS] ' + sent + ' [SEP]', padding=512) for sent in X_train] \n",
        "X_train_tokens = [retribert_tokenizer.convert_tokens_to_ids(sent) for sent in X_train]\n",
        "# # X_train[0]\n",
        "# # X_train_tokens[0]\n",
        "X_test = [retribert_tokenizer.tokenize('[CLS] ' + sent + ' [SEP]', padding=512) for sent in X_test] \n",
        "X_test_tokens = [retribert_tokenizer.convert_tokens_to_ids(sent) for sent in X_test]\n",
        "# y_train_tensor = torch.from_numpy(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "7lIKdSf6rkyQ"
      },
      "outputs": [],
      "source": [
        "### train individual tensors\n",
        "y_train_cohesion = [y_train[i][0] for i in range(len(y_train))]\n",
        "y_train_syntax = [y_train[i][1] for i in range(len(y_train))]\n",
        "y_train_vocabulary = [y_train[i][2] for i in range(len(y_train))]\n",
        "y_train_phraseology = [y_train[i][3] for i in range(len(y_train))]\n",
        "y_train_grammar = [y_train[i][4] for i in range(len(y_train))]\n",
        "y_train_convention = [y_train[i][5] for i in range(len(y_train))]\n",
        "\n",
        "y_train_cohesion_tensor = torch.Tensor(y_train_cohesion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "ftdF-3pK1xgu"
      },
      "outputs": [],
      "source": [
        "# ## trying with dataloader\n",
        "# # len(X_train_tokens) #3128\n",
        "# # len(y_train_cohesion) #33128\n",
        "# cohesion_dict = {\"X_train_tokens\":X_train_tokens,\n",
        "#                  \"y_train_cohesion\": y_train_cohesion}\n",
        "# cohesion_df = pd.DataFrame(cohesion_dict)\n",
        "\n",
        "# class customDataset:\n",
        "#   def __init__(self):\n",
        "#     xy = cohesion_df\n",
        "#     self.len = xy.shape[0]\n",
        "#     self.x_data = torch.from_numpy(xy[:,0:-1])\n",
        "#     self.y_data = torch.from_numpy(xy.iloc[:,[-1]])\n",
        "#   def __getitem__(self,index):\n",
        "#     return self.x_data[index], self.y_data[index]\n",
        "#   def __len__(self):\n",
        "#     return self.len\n",
        "\n",
        "# cohesion_ds = customDataset()\n",
        "# training_data = torchvision.datasets.cohesion_ds(\n",
        "#     root=\"data\",\n",
        "#     train=True,\n",
        "#     download=True,\n",
        "#     transform=torchvision.transformsToTensor()\n",
        "# )\n",
        "\n",
        "# # train_dataloader = torch.utils.data.DataLoader(cohesion_df, batch_size=8, shuffle=True)\n",
        "# # train_dataloader\n",
        "\n",
        "# # train_features, train_labels = iter(train_dataloader)\n",
        "# # print(f\"Feature batch shape: {train_features.size()}\")\n",
        "# # print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "# # img = train_features[0].squeeze()\n",
        "# # label = train_labels[0]\n",
        "# # plt.imshow(img, cmap=\"gray\")\n",
        "# # plt.show()\n",
        "# # print(f\"Label: {label}\")\n",
        "# # test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True)\n",
        "\n",
        "class pyDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, X,y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "  def __getitem__(self,idx):\n",
        "    return self.X[idx], self.y[idx]\n",
        "train_loader = torch.utils.data.DataLoader(dataset=pyDataset(X_train, y_train_cohesion_tensor), batch_size=8, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=pyDataset(X_test, y_test), batch_size=8, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_train_cohesion_tensor)"
      ],
      "metadata": {
        "id": "PPzytzm8dIXT",
        "outputId": "db9affe7-5dcc-4f01-aa08-66750b2812e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3128"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "f4k7Cqm3CFLw"
      },
      "outputs": [],
      "source": [
        "# https://stackoverflow.com/questions/64156202/add-dense-layer-on-top-of-huggingface-bert-model\n",
        "### this seems to be working  but out of memory\n",
        "class CustomBERTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "          super(CustomBERTModel, self).__init__()\n",
        "          self.retribert = transformers.BertModel.from_pretrained(retribert_model_checkpoints)\n",
        "          # for param in self.retribert.parameters():\n",
        "            # param.requires_grad = False\n",
        "          self.linear1 = nn.Linear(768, 9)\n",
        "          self.dropout1 = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, ids, mask):\n",
        "          outputs = self.retribert(ids,attention_mask=mask)\n",
        "          last_hidden_state = outputs[0]\n",
        "\n",
        "          # sequence_output has the following shape: (batch_size, sequence_length, 768)\n",
        "          linear1_output = self.linear1(last_hidden_state[:,0,:].view(-1,768)) ## extract the 1st token's embeddings\n",
        "          # ### New layers:\n",
        "          linear2_dropout_output = self.dropout1(linear1_output)\n",
        "\n",
        "          return linear2_dropout_output\n",
        "\n",
        "retribert_model = CustomBERTModel() # You can pass the parameters if required to have more flexible model\n",
        "retribert_model.to(torch.device(\"cuda\")) ## can be gpu\n",
        "criterion = nn.CrossEntropyLoss() ## If required define your own criterion\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, retribert_model.parameters()))\n",
        "\n",
        "# out of memory method\n",
        "# for epoch in range(5):\n",
        "#   optimizer.zero_grad()\n",
        "#   predicted = []\n",
        "#   for sent in X_train:\n",
        "#     encoded_sent = retribert_tokenizer.encode_plus(sent, \n",
        "#                                                    add_special_tokens=True, \n",
        "#                                                    truncation=True, \n",
        "#                                                    padding=True, \n",
        "#                                                    return_attention_mask=True, \n",
        "#                                                    return_tensors='pt', \n",
        "#                                                    max_length=510)\n",
        "#     outputs_1 = retribert_model(encoded_sent[\"input_ids\"].to(\"cuda\"), encoded_sent[\"attention_mask\"].to(\"cuda\"))\n",
        "#     outputs_1\n",
        "  #   final_outputs = torch.nn.functional.log_softmax(outputs_1, dim=1)\n",
        "  # # print(final_outputs)\n",
        "  #   final_outputs_max = torch.max(final_outputs)\n",
        "  #   predicted.append(final_outputs_max)\n",
        "  # print(predicted)\n",
        "  # print(final_outputs_2)\n",
        "        # input_ids = encoding['input_ids']\n",
        "        # attention_mask = encoding['attention_mask']\n",
        "  # loss = criterion(final_outputs, targets)\n",
        "        # loss.backward()\n",
        "        # optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_loader:\n",
        "  print(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "y6yDf70QQwZB",
        "outputId": "061bb5bc-3592-4554-c771-755c38dd1dd7"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-ef9a69ae6daa>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0melem_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0melem_size\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# It may be accessed twice, so we use a list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: each element in list of batch should be of equal size"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    for batch in train_loader: ## If you have a DataLoader()  object to get the data.\n",
        "        data = batch[0]\n",
        "        targets = batch[1] ## assuming that data loader returns a tuple of data and its targets\n",
        "        optimizer.zero_grad()   \n",
        "        encoding = retribert_tokenizer.batch_encode_plus(data, return_tensors='pt', padding=True, truncation=True,max_length=510, add_special_tokens = True)\n",
        "        outputs = retribert_model(input_ids, attention_mask=attention_mask)\n",
        "        outputs = torch.nn.functional.log_softmax(outputs, dim=1)\n",
        "        input_ids = encoding['input_ids']\n",
        "        attention_mask = encoding['attention_mask']\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "A2_WunOSPm8f",
        "outputId": "505cd2ab-0b8d-43b5-a37e-8f804963ffc8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-c9e94a7bfc37>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m## If you have a DataLoader()  object to get the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m## assuming that data loader returns a tuple of data and its targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0melem_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0melem_size\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# It may be accessed twice, so we use a list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: each element in list of batch should be of equal size"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2t3c-HtCffw"
      },
      "outputs": [],
      "source": [
        "# use MCRMSE as loss metric\n",
        "\n",
        "# def MCRMSE(y_true, y_pred):\n",
        "#     colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis = 1)\n",
        "#     return tf.reduce_mean(tf.sqrt(colwise_mse), axis = -1, keepdims = True)\n",
        "     \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlP4F2WSXDLd"
      },
      "outputs": [],
      "source": [
        "### anothing thing\n",
        "### https://stackoverflow.com/questions/68115993/input-ids-torch-tensorinput-ids-valueerror-expected-sequence-of-length-133\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "# print(flaubert)\n",
        "for sent in X_train:\n",
        "    encoded_sent = retribert_tokenizer.encode_plus(sent, add_special_tokens=True, truncation=True, padding=True, return_attention_mask=True, return_tensors='pt', max_length=510)\n",
        "\n",
        "    # Add the outputs to the lists\n",
        "    # input_ids.append(encoded_sent.get('input_ids'))\n",
        "    # attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "\n",
        "# input_ids = torch.as_tensor(input_ids)\n",
        "# attention_masks = torch.as_tensor(attention_masks)\n",
        "\n",
        "hidden_state = retribert_model(input_ids=encoded_sent[\"input_ids\"].to(\"cuda\"), attention_mask=encoded_sent[\"attention_mask\"].to(\"cuda\"))\n",
        "hidden_state\n",
        "# # # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "last_hidden_state_cls = hidden_state[0][:, 0, :]\n",
        "\n",
        "retribert_model.linear1 = nn.Linear(768, 256)\n",
        "retribert_model.dropout1 = nn.Dropout(0.1)\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vImVYBNL56NB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd7c8a96-162c-426f-fed1-34e87698b0b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0186, -0.0166, -0.0154,  ...,  0.0220,  0.0171,  0.0076],\n",
              "        [ 0.0118,  0.0026,  0.0049,  ..., -0.0287,  0.0192,  0.0038],\n",
              "        ...,\n",
              "        [-0.0003, -0.0193, -0.0029,  ..., -0.0182, -0.0184, -0.0021],\n",
              "        [ 0.0355, -0.0214, -0.0174,  ..., -0.0083,  0.0015,  0.0047],\n",
              "        [-0.0179,  0.0016,  0.0094,  ..., -0.0528,  0.0078,  0.0255]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "list(retribert_model.parameters())[0] # model weights?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAY8GJHXZtKi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "a24c7e28-b4fc-4fce-c006-a0481836ae36"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-35ae434d271b>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretribert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_hidden_state_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    984\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m                 \u001b[0mbuffered_token_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m                 \u001b[0mbuffered_token_type_ids_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffered_token_type_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffered_token_type_ids_expanded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (768) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 768].  Tensor sizes: [1, 512]"
          ]
        }
      ],
      "source": [
        "# Set the manual seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# # Freeze all base layers in the \"features\" section of the model (the feature extractor) by setting requires_grad=False\n",
        "# for param in retribert_model.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "# retribert_model(last_hidden_state_cls)\n",
        "\n",
        "# ## from https://pypi.org/project/pytorch-pretrained-bert/\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     predictions = retribert_model(last_hidden_state_cls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thhTWuFiV1VN"
      },
      "outputs": [],
      "source": [
        "# results = torch.zeros((len(X_test_tokens), retri_cuda.config.hidden_size)).long()\n",
        "# results[0]\n",
        "# with torch.no_grad():\n",
        "#     for stidx in range(0, len(X_test_tokens), batch_size):\n",
        "#         X = X_test_tokens[stidx:stidx + batch_size]\n",
        "#         X = torch.LongTensor(X).cuda()\n",
        "#         embed, pooled_output = retri_cuda(X)\n",
        "#         results[stidx:stidx + batch_size,:] = embed.cpu()\n",
        "# torch.LongTensor(X)\n",
        "\n",
        "#### from https://machinelearningmastery.com/building-a-regression-model-in-pytorch/\n",
        "# X_train_torch = torch.tensor(X_train_tokens, dtype=torch.float32)\n",
        "# y_train_torch = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "# X_test_torch = torch.tensor(X_test, dtype=torch.float32)\n",
        "# y_test_torch = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
        " \n",
        "# # training parameters\n",
        "# n_epochs = 5   # number of epochs to run\n",
        "# batch_size = 8  # size of each batch\n",
        "# batch_start = torch.arange(0, len(X_train), batch_size)\n",
        " \n",
        "# # Hold the best model\n",
        "# best_mse = np.inf   # init to infinity\n",
        "# best_weights = None\n",
        "# history = []\n",
        " \n",
        "# # training loop\n",
        "# for epoch in range(n_epochs):\n",
        "#     retribert_model.train()\n",
        "#     with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
        "#         bar.set_description(f\"Epoch {epoch}\")\n",
        "#         for start in bar:\n",
        "#             # take a batch\n",
        "#             X_batch = X_train[start:start+batch_size]\n",
        "#             y_batch = y_train[start:start+batch_size]\n",
        "#             # forward pass\n",
        "#             y_pred = retribert_model(X_batch)\n",
        "#             loss = loss_fn(y_pred, y_batch)\n",
        "#             # backward pass\n",
        "#             optimizer.zero_grad()\n",
        "#             loss.backward()\n",
        "#             # update weights\n",
        "#             optimizer.step()\n",
        "#             # print progress\n",
        "#             bar.set_postfix(mse=float(loss))\n",
        "#     # evaluate accuracy at end of each epoch\n",
        "#     retribert_model.eval()\n",
        "#     y_pred = retribert_model(X_test)\n",
        "#     mse = loss_fn(y_pred, y_test)\n",
        "#     mse = float(mse)\n",
        "#     history.append(mse)\n",
        "#     if mse < best_mse:\n",
        "#         best_mse = mse\n",
        "#         best_weights = copy.deepcopy(retribert_model.state_dict())\n",
        " \n",
        "# # restore model and return best accuracy\n",
        "# retribert_model.load_state_dict(best_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hzAHU3_8oUl"
      },
      "outputs": [],
      "source": [
        "### evaluating the model\n",
        "# from https://discuss.pytorch.org/t/multi-class-bert-model-class-weights-and-where-to-use-them/176264\n",
        "# def evaluate():  \n",
        "#     model.eval()\n",
        "#     total_loss, total_accuracy = 0, 0\n",
        "#     total_preds = []\n",
        "#     for step,batch in enumerate(val_dataloader):\n",
        "#         if step % 50 == 0 and not step == 0:\n",
        "#             elapsed = format_time(time.time() - t0)\n",
        "#             print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "#         batch = [t.to(device) for t in batch]\n",
        "#         sent_id, mask, labels = batch\n",
        "#         with torch.no_grad():\n",
        "#             preds = model(sent_id, mask)\n",
        "#             loss = cross_entropy(preds,labels)  #<------- Here\n",
        "#             total_loss = total_loss + loss.item()\n",
        "#             preds = preds.detach().cpu().numpy()\n",
        "#             total_preds.append(preds)\n",
        "#     avg_loss = total_loss / len(val_dataloader) \n",
        "#     total_preds  = np.concatenate(total_preds, axis=0)\n",
        "#     return avg_loss, total_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting to TensorFlow?"
      ],
      "metadata": {
        "id": "28DHlMfOymrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow\n",
        "# !pip install tensorflow-addons\n",
        "# !pip install onnx\n",
        "# !git clone https://github.com/onnx/onnx-tensorflow.git && cd onnx-tensorflow && pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYiC0VJBtznL",
        "outputId": "88b97afd-e8f9-4ef9-b947-c1f201c3d97c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (2.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow) (67.6.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.53.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (0.0.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (6.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.9/dist-packages (0.19.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.9/dist-packages (from tensorflow-addons) (3.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow-addons) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.7->tensorflow-addons) (4.5.0)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.7->tensorflow-addons) (6.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=3.6->typeguard>=2.7->tensorflow-addons) (3.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.9/dist-packages (1.13.1)\n",
            "Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/lib/python3.9/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.9/dist-packages (from onnx) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/dist-packages (from onnx) (1.22.4)\n",
            "fatal: destination path 'onnx-tensorflow' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# import torch.optim as optim\n",
        "# from torchvision import datasets, transforms\n",
        "# from torch.autograd import Variable\n",
        "# import onnx\n",
        "# from onnx_tf.backend import prepare"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtVoQdW3t7g0",
        "outputId": "6a719768-50e9-425f-8d75-8d98985300c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# retribert_model = transformers.BertModel.from_pretrained(retribert_model_checkpoints)\n",
        "# torch.save(retribert_model.state_dict(), './retribert.pt')"
      ],
      "metadata": {
        "id": "NBDgFT8LuHxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_pytorch = retribert_model()\n",
        "# model_pytorch.load_state_dict('./retribert.pt')\n",
        "\n",
        "# dummy_input = torch.from_numpy(X_train_tokens.to(\"cuda\"))\n",
        "# dummy_output = model_pytorch(dummy_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "bMCLMKCqxrjz",
        "outputId": "e53819a9-3fa2-4a14-b5df-61d26b27b870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-8f55201d1509>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_pytorch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretribert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_pytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./retribert.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdummy_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdummy_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_pytorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    970\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have to specify either input_ids or inputs_embeds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You have to specify either input_ids or inputs_embeds"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6dc8af802b374dd8a25a5a9fd43c1bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f059853f0caa413484e9d499bf763cfa",
              "IPY_MODEL_beea827bcc954e03878cf2be9cc05621",
              "IPY_MODEL_1545a8f8432c41569952fdd5afa4351c"
            ],
            "layout": "IPY_MODEL_ba75c9b6afda49d8913152bc2a7817ac"
          }
        },
        "f059853f0caa413484e9d499bf763cfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_655acf950dbc4a23a5f135ef5fe494bd",
            "placeholder": "​",
            "style": "IPY_MODEL_d7e50a2249924fac93a62fd05f627622",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "beea827bcc954e03878cf2be9cc05621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b5a917142a841e6a5a791e4c4dc2c78",
            "max": 487,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52e9c9595477445791d7b1f557f15a92",
            "value": 487
          }
        },
        "1545a8f8432c41569952fdd5afa4351c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20b66e9d5ccb44c3b2dce7d9822debb3",
            "placeholder": "​",
            "style": "IPY_MODEL_c6ad6bf897d549a296bb49efbddf6943",
            "value": " 487/487 [00:00&lt;00:00, 4.14kB/s]"
          }
        },
        "ba75c9b6afda49d8913152bc2a7817ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "655acf950dbc4a23a5f135ef5fe494bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7e50a2249924fac93a62fd05f627622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b5a917142a841e6a5a791e4c4dc2c78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52e9c9595477445791d7b1f557f15a92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20b66e9d5ccb44c3b2dce7d9822debb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6ad6bf897d549a296bb49efbddf6943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fcac3ae1c094b6989a1477424f58696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dae12c065a1c44d79baf2073240846b3",
              "IPY_MODEL_0da5ff9b59374534a5e0af1b885331ad",
              "IPY_MODEL_a4350431ed934ebe9005245f00e46226"
            ],
            "layout": "IPY_MODEL_e846202a5f974f519ad560a42c61ba4f"
          }
        },
        "dae12c065a1c44d79baf2073240846b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fa0e8ce3b8f405681f67ecad3d8e720",
            "placeholder": "​",
            "style": "IPY_MODEL_81fb70df37154c15a3d498061463fb4b",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "0da5ff9b59374534a5e0af1b885331ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b419016c94949ad9a5ffdeeaf681d95",
            "max": 325345269,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1e1307c51ea4911b488f64b528f1f17",
            "value": 325345269
          }
        },
        "a4350431ed934ebe9005245f00e46226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f7888aa9ded43bc84f4ef28215806f1",
            "placeholder": "​",
            "style": "IPY_MODEL_e19068632b9346b8bd361f40737fd625",
            "value": " 325M/325M [00:03&lt;00:00, 152MB/s]"
          }
        },
        "e846202a5f974f519ad560a42c61ba4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fa0e8ce3b8f405681f67ecad3d8e720": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81fb70df37154c15a3d498061463fb4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b419016c94949ad9a5ffdeeaf681d95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1e1307c51ea4911b488f64b528f1f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f7888aa9ded43bc84f4ef28215806f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e19068632b9346b8bd361f40737fd625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31912bc42285487b80c97f8d973486c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_868b02184e5640039962f41ef28dd171",
              "IPY_MODEL_e63944610f90487780ba7f64058ed3b8",
              "IPY_MODEL_2df5ee198a6343e5b0812e90d6e4ddc9"
            ],
            "layout": "IPY_MODEL_75402ca002274b40956357a3d53e9070"
          }
        },
        "868b02184e5640039962f41ef28dd171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95c0032d01134e6ba9ec52b4c9c40f23",
            "placeholder": "​",
            "style": "IPY_MODEL_af81a4c377f646f3b98900f33442e237",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "e63944610f90487780ba7f64058ed3b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c93e97b39b24f45b44fb5500503c847",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ace6e7d8311744a383f75b8c1cd9fbb0",
            "value": 231508
          }
        },
        "2df5ee198a6343e5b0812e90d6e4ddc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc917ef4281c43f48ce8a3d187360281",
            "placeholder": "​",
            "style": "IPY_MODEL_14b03f3827ad400cbbcf8303d7c4573d",
            "value": " 232k/232k [00:00&lt;00:00, 2.26MB/s]"
          }
        },
        "75402ca002274b40956357a3d53e9070": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95c0032d01134e6ba9ec52b4c9c40f23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af81a4c377f646f3b98900f33442e237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c93e97b39b24f45b44fb5500503c847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ace6e7d8311744a383f75b8c1cd9fbb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc917ef4281c43f48ce8a3d187360281": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14b03f3827ad400cbbcf8303d7c4573d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}