{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilamaiti/spring_2023_w266_final_project_heesuk_iris_srila/blob/main/iris/W266_essay_evaluation_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lhf_T8cMjGsp"
      },
      "source": [
        "# **Installing new libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fD4BChywisTm",
        "outputId": "c2c02934-3529-4579-ba27-eba6fb4bf6dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.27.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji==0.6.0\n",
            "  Downloading emoji-0.6.0.tar.gz (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.6.0-py3-none-any.whl size=49732 sha256=5c67c1fcb9ebb874b3e869404e79a298f96b4eeb57d5c90c190d02e4da16e329\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/2a/7f/1a0012c86b1061c6ee2ed9568b1f830f857a51e8e416452af2\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting iterative-stratification\n",
            "  Downloading iterative_stratification-0.1.7-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from iterative-stratification) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from iterative-stratification) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from iterative-stratification) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->iterative-stratification) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->iterative-stratification) (3.1.0)\n",
            "Installing collected packages: iterative-stratification\n",
            "Successfully installed iterative-stratification-0.1.7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (1.14.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (1.16.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (23.3.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (1.22.4)\n",
            "Collecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<3.20,>=3.9.2\n",
            "  Downloading protobuf-3.19.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (23.0)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (16.0.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (0.32.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (4.5.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (1.53.0)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (67.6.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (1.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (2.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow==2.11.0) (0.40.0)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.2.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.17.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.4.3)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.27.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (6.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard-data-server, protobuf, keras, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.0\n",
            "    Uninstalling tensorboard-data-server-0.7.0:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.1\n",
            "    Uninstalling tensorboard-2.12.1:\n",
            "      Successfully uninstalled tensorboard-2.12.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "Successfully installed google-auth-oauthlib-0.4.6 keras-2.11.0 protobuf-3.19.6 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: yellowbrick in /usr/local/lib/python3.9/dist-packages (1.5)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from yellowbrick) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from yellowbrick) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from yellowbrick) (1.10.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from yellowbrick) (3.7.1)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from yellowbrick) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (4.39.3)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (5.12.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.0.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (8.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (23.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->yellowbrick) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->yellowbrick) (1.1.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib!=3.0.0,>=2.0.2->yellowbrick) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow_gpu==1.15.5 (from versions: 2.5.0, 2.5.1, 2.5.2, 2.5.3, 2.6.0, 2.6.1, 2.6.2, 2.6.3, 2.6.4, 2.6.5, 2.7.0rc0, 2.7.0rc1, 2.7.0, 2.7.1, 2.7.2, 2.7.3, 2.7.4, 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.12.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow_gpu==1.15.5\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install emoji==0.6.0\n",
        "!pip install scikit-multilearn\n",
        "!pip install iterative-stratification\n",
        "!pip install tensorflow==2.11.0\n",
        "!pip install yellowbrick\n",
        "!pip install tensorflow_gpu==1.15.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC3s_6EZjMBt"
      },
      "source": [
        "# **Importing libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaPH5XqxjU_z",
        "outputId": "1477bedc-1402-44ee-fb57-bbca2ee8c5f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers version: 4.27.4\n",
            "2.11.0\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "print(f'transformers version: {transformers.__version__}')\n",
        "from transformers import logging as hf_logging\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "hf_logging.set_verbosity_error()\n",
        "'''\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import spacy      \n",
        "from spacy import displacy\n",
        "from wordcloud import WordCloud\n",
        "from wordcloud import STOPWORDS\n",
        "from wordcloud import ImageColorGenerator\n",
        "nltk.download('punkt')\n",
        "'''\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from transformers import RobertaTokenizer, TFRobertaModel\n",
        "ROBERTA_MODEL_CHKPT = \"roberta-base\"\n",
        "BERTWEET_MODEL_CHKPT = \"vinai/bertweet-base\"\n",
        "BERT_MODEL_CHKPT = 'bert-base-cased'\n",
        "\n",
        "# Other required libraries\n",
        "import math\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import copy\n",
        "import sys\n",
        "import gc\n",
        "import pprint\n",
        "import statistics\n",
        "\n",
        "# data visualization\n",
        "from matplotlib import cm\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "\n",
        "# others\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "from scipy.cluster.hierarchy import set_link_color_palette\n",
        "from scipy.cluster.hierarchy import linkage\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "from yellowbrick.cluster import SilhouetteVisualizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# distances\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Data visualization libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Tensorflow libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils.layer_utils import count_params\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.losses import mae\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.regularizers import l1\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "\n",
        "import torch\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fjpBUG5jbmt"
      },
      "source": [
        "# **General functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahNGWcMIFD8u"
      },
      "source": [
        "## **Rounding Off to Custom Decimal Places**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5opWTwwnFLLP"
      },
      "outputs": [],
      "source": [
        "def roundPartial(value, resolution):\n",
        "    return round (value / resolution) * resolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYfihW3Mjgkf"
      },
      "source": [
        "## **Set parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pr1-rS8tjiqn"
      },
      "outputs": [],
      "source": [
        "def set_config_param(seed = 99):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    tf.keras.backend.clear_session()\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Colab Notebooks\"\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    \n",
        "    \n",
        "set_config_param(20230214)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yYB47Gdjo0L"
      },
      "source": [
        "## **Plot loss and accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BE9NqiNWjrPy"
      },
      "outputs": [],
      "source": [
        "def plot_loss_accuracy(history, col_list):\n",
        "    fig, ax = plt.subplots(2, 6, figsize=(16, 6), sharex='col', sharey='row')\n",
        "    fig.tight_layout(pad=5.0)\n",
        "    for idx, col in enumerate(col_list):\n",
        "\n",
        "        ax[0, idx].plot(history[col + '_loss'], lw=2, color='darkgoldenrod')\n",
        "        ax[0, idx].plot(history['val_' + col + '_loss'], lw=2, color='indianred')\n",
        "        #ax[0, idx].legend(loc='center left')\n",
        "        ax[0, idx].legend(['Train', 'Validation'], fontsize=5)\n",
        "        ax[0, idx].set_xlabel('Epochs', size=10)\n",
        "        ax[0, idx].set_title('Loss: ' + col)\n",
        "\n",
        "        ax[1, idx].plot(history[col + '_accuracy'], lw=2, color='darkgoldenrod')\n",
        "        ax[1, idx].plot(history['val_' + col + '_accuracy'], lw=2, color='indianred')\n",
        "        #ax[0, idx].legend(loc='center left')\n",
        "        ax[1, idx].legend(['Train', 'Validation'], fontsize=5)\n",
        "        ax[1, idx].set_xlabel('Epochs', size=10)\n",
        "        ax[1, idx].set_title('Accuracy: ' + col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dII35P-P_J_t"
      },
      "source": [
        "## **Plot Loss and other KPI specified**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQgOGDu6_PVK"
      },
      "outputs": [],
      "source": [
        "def custom_plot(df, model_name, kpi_name, kpi_string):\n",
        "    x_arr = np.arange(len(df['loss'])) + 1\n",
        "    fig = plt.figure(figsize=(12, 4))\n",
        "    ax = fig.add_subplot(1, 2, 1)\n",
        "    ax.plot(x_arr, df['loss'], '-o', label = model_name + ' : Train loss')\n",
        "    ax.plot(x_arr, df['val_loss'], '--<', label = model_name + ' :  Validation loss')\n",
        "    ax.legend(fontsize = 15)\n",
        "    ax.set_xlabel('Epoch', size = 15)\n",
        "    ax.set_ylabel('Loss', size = 15)\n",
        "\n",
        "    ax = fig.add_subplot(1, 2, 2)\n",
        "    ax.plot(x_arr, df[kpi_name], '-o', label = model_name + ' : Train ' + kpi_string)\n",
        "    ax.plot(x_arr, df['val_' + kpi_name], '--<', label = model_name + ' : Validation ' + kpi_string)\n",
        "    ax.legend(fontsize = 15)\n",
        "    ax.set_xlabel('Epoch', size = 15)\n",
        "    ax.set_ylabel(kpi_name, size = 15)\n",
        "    #ax.set_ylim(0,1)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3y3byq0Fk9P"
      },
      "source": [
        "## **Text Encode**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSxlBmVZFm2n"
      },
      "outputs": [],
      "source": [
        "def text_encode(texts, tokenizer, max_len):\n",
        "    input_ids = []\n",
        "    # token_type_ids = []\n",
        "    attention_mask = []\n",
        "    \n",
        "    for text in texts:\n",
        "        token = tokenizer(text, \n",
        "                          max_length = max_len, \n",
        "                          truncation = True, \n",
        "                          padding = 'max_length',\n",
        "                          add_special_tokens = True)\n",
        "        input_ids.append(token['input_ids'])\n",
        "        # token_type_ids.append(token['token_type_ids'])\n",
        "        attention_mask.append(token['attention_mask'])\n",
        "    \n",
        "    return np.array(input_ids), np.array(attention_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJw9YpJXjwSv"
      },
      "source": [
        "## **Custom metric**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VCdZF9ZjzN6"
      },
      "outputs": [],
      "source": [
        "def MCRMSE(y_true, y_pred):\n",
        "    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis = 1)\n",
        "    return tf.reduce_mean(tf.sqrt(colwise_mse), axis = -1, keepdims = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdYaqDeEGJE-"
      },
      "source": [
        "## **Build Base Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brWkfFsUk0wl"
      },
      "outputs": [],
      "source": [
        "def build_regression_model(loss = 'MCRMSE',\n",
        "                           model_name = 'Roberta', \n",
        "                           dense_dim = 6, \n",
        "                           MAX_LEN = 512,\n",
        "                           learning_rate = 1e-5,\n",
        "                           dropout = .1,\n",
        "                           number_of_hidden_layers = 1,\n",
        "                           hidden_layer_node_count = 64,\n",
        "                           retrain_layer_count = 0):\n",
        "    \n",
        "    # Define inputs\n",
        "    input_ids = tf.keras.Input(shape = (MAX_LEN ,), dtype = 'int64', name = 'input_ids')\n",
        "    attention_masks = tf.keras.Input(shape = (MAX_LEN ,), dtype = 'int64', name = 'attention_masks')\n",
        "    \n",
        "    if model_name == 'Roberta':\n",
        "        model_tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_MODEL_CHKPT)\n",
        "        model = TFRobertaModel.from_pretrained(ROBERTA_MODEL_CHKPT)\n",
        "    elif model_name == 'Bertweet':\n",
        "        model_tokenizer = AutoTokenizer.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "        model = TFRobertaModel.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "    elif model_name == 'Bert':\n",
        "        model_tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_CHKPT)\n",
        "        model = TFBertModel.from_pretrained(BERT_MODEL_CHKPT)  \n",
        "\n",
        "    # Adjust the trainable layer weights based on retrain_layer_count\n",
        "    # If retrain_layer_count is 0, then base model is frozen.\n",
        "    # If retrain_layer_count is 12, then the entire base model is trainable.\n",
        "    # And that implies that all the pretrained weights are lost and it relearns\n",
        "    # from the input data.\n",
        "    # If retrain_layer_count is between 1 and 11, then the last n layers of\n",
        "    # the pretrained model retrained.\n",
        "    if retrain_layer_count == 0:\n",
        "        # The pretained model is frozen\n",
        "        model.trainable = False           \n",
        "\n",
        "    elif retrain_layer_count == 12:  \n",
        "        # The pretrained model is retrained thru all layers.       \n",
        "        model.trainable = True     \n",
        "\n",
        "    else:    \n",
        "        # Restrict training to the num_train_layers outer transformer layers\n",
        "        retrain_layer_list = []\n",
        "        model.trainable = False  \n",
        "        for retrain_layer_number in range(retrain_layer_count):\n",
        "\n",
        "            layer_code = '_' + str(11 - retrain_layer_number)\n",
        "            retrain_layer_list.append(layer_code)\n",
        "        \n",
        "        print('Retrain layers: \\n', retrain_layer_list)\n",
        "        #model.compile()\n",
        "        print(f\"Number of trainable parameters : {count_params(model.trainable_weights)}\")\n",
        "        print(f\"Number of non-trainable parameters : {count_params(model.non_trainable_variables)}\")\n",
        "        for weight in model.weights:\n",
        "            weight._trainable = False\n",
        "            #print(\"***\", layer.name, layer._trainable)\n",
        "            if 'layer_' in weight.name and weight.name.split(\".\")[1].split(\"/\")[0] in retrain_layer_list:\n",
        "                weight._trainable = True\n",
        "                # print(\"$$$\", weight.name, weight._trainable)\n",
        "            elif 'layer_' not in weight.name :\n",
        "                weight._trainable = True\n",
        "                # print(\"###\", weight.name, weight._trainable)\n",
        "        model.compile()\n",
        "\n",
        "        for weight_details in model.weights:\n",
        "            print(weight_details.name, weight_details.trainable)\n",
        "    print(f\"Number of trainable parameters : {count_params(model.trainable_weights)}\")\n",
        "    print(f\"Number of non-trainable parameters : {count_params(model.non_trainable_variables)}\")\n",
        "                \n",
        "    # Insert pretrained model layer\n",
        "    pretrained_transformer = model([input_ids, attention_masks])\n",
        "\n",
        "    # Get the CLS output off the pretrained model\n",
        "    cls_token = pretrained_transformer[0][:, 0, :]\n",
        "\n",
        "    # Append the hidden layer and dropout layer\n",
        "    layer_list = []\n",
        "    for layer in range(number_of_hidden_layers):\n",
        "        if layer == 0:\n",
        "            hidden_layer = tf.keras.layers.Dense(units      = hidden_layer_node_count\n",
        "                                               , activation = 'relu'\n",
        "                                               , name       = 'hidden_layer_' + str(layer + 1)\n",
        "                                                )(cls_token)\n",
        "        else:\n",
        "            hidden_layer = tf.keras.layers.Dense(units      = hidden_layer_node_count\n",
        "                                               , activation = 'relu'\n",
        "                                               , name       = 'hidden_layer_' + str(layer + 1)\n",
        "                                            )(layer_list[-1])\n",
        "        layer_list.append(hidden_layer)\n",
        "        dropout_layer = tf.keras.layers.Dropout(dropout, \n",
        "                                                name = 'dropout_layer_' + str(layer + 1)\n",
        "                                               )(hidden_layer) \n",
        "        layer_list.append(dropout_layer)\n",
        "\n",
        "    # Add the output layer\n",
        "    output = tf.keras.layers.Dense(6,)(layer_list[-1])\n",
        "\n",
        "    # Build the final model\n",
        "    regression_model = tf.keras.Model(inputs = [input_ids, attention_masks], outputs = output)\n",
        "    \n",
        "    # Model compile\n",
        "    if loss == 'MCRMSE':\n",
        "        regression_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n",
        "                                 loss      = MCRMSE,\n",
        "                                 metrics   = MCRMSE\n",
        "                                )\n",
        "    \n",
        "    print(regression_model.summary())\n",
        "    keras.utils.plot_model(regression_model, \n",
        "                           show_shapes = False, \n",
        "                           show_dtype = False, \n",
        "                           show_layer_names = True, \n",
        "                           dpi = 90)\n",
        "    return regression_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzxEshCMv3Te"
      },
      "outputs": [],
      "source": [
        "def model_fit(model, \n",
        "              df_train, \n",
        "              train_indices,\n",
        "              val_indices,\n",
        "              model_name = 'Roberta', \n",
        "              MAX_LEN = 512,\n",
        "              epochs = 5,\n",
        "              batch_size = 4,\n",
        "              validation_split = .2):\n",
        "  \n",
        "    # Building the tokenizer for the given model\n",
        "    if model_name == 'Roberta':\n",
        "        tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_MODEL_CHKPT)\n",
        "    elif model_name == 'Bertweet':\n",
        "        tokenizer = AutoTokenizer.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "    elif model_name == 'Bert':\n",
        "        tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_CHKPT)\n",
        "        \n",
        "    train_encoded_input_ids, train_encoded_attention_masks = text_encode(df_train.iloc[list(train_indices)]['full_text'], tokenizer, MAX_LEN)\n",
        "    val_encoded_input_ids, val_encoded_attention_masks = text_encode(df_train.iloc[list(val_indices)]['full_text'], tokenizer, MAX_LEN)\n",
        "\n",
        "    y_train = np.array(df_train.iloc[list(train_indices)][label_cols], dtype = \"float32\")\n",
        "    y_val = np.array(df_train.iloc[list(val_indices)][label_cols], dtype = \"float32\")\n",
        "    \n",
        "    hist = model.fit([train_encoded_input_ids, train_encoded_attention_masks],\n",
        "                     y_train,\n",
        "                     validation_data = ([val_encoded_input_ids, val_encoded_attention_masks], \n",
        "                                        y_val\n",
        "                                       ),\n",
        "                     batch_size = batch_size,        \n",
        "                     epochs = epochs\n",
        "                    )\n",
        "\n",
        "    df_history = pd.DataFrame(hist.history)\n",
        "    return df_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "202ecOu4GLFG"
      },
      "outputs": [],
      "source": [
        "def build_base_model(model_layer, learning_rate, dense_dim = 6):\n",
        "    \n",
        "    #define inputs\n",
        "    input_ids = tf.keras.Input(shape = (MAX_LEN ,), dtype = 'int64', name = 'input_ids')\n",
        "    attention_masks = tf.keras.Input(shape = (MAX_LEN ,), dtype = 'int64', name = 'attention_masks')\n",
        "    \n",
        "    #insert BERT layer\n",
        "    transformer_layer = model_layer([input_ids, attention_masks])\n",
        "    \n",
        "    #choose only last hidden-state\n",
        "    x = transformer_layer[1]\n",
        "    output = tf.keras.layers.Dense(dense_dim)(x)\n",
        "    #output = tf.keras.layers.Rescaling(scale=4.0, offset=1.0)(x)\n",
        "    model = tf.keras.models.Model(inputs = [input_ids, attention_masks], outputs = output)\n",
        "\n",
        "    model.compile(tf.keras.optimizers.Adam(learning_rate), loss = mse_loss, metrics = mse_metrics)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmCPltuehyyQ"
      },
      "source": [
        "## **Build a model with custom loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnaCwE2Uhx-4"
      },
      "outputs": [],
      "source": [
        "def build_base_model_with_custom_loss(model_layer, learning_rate, dense_dim = 6):\n",
        "    \n",
        "    #define inputs\n",
        "    input_ids = tf.keras.Input(shape = (MAX_LEN ,), dtype = 'int64', name = 'input_ids')\n",
        "    attention_masks = tf.keras.Input(shape = (MAX_LEN ,), dtype = 'int64', name = 'attention_masks')\n",
        "    \n",
        "    #insert BERT layer\n",
        "    transformer_layer = model_layer([input_ids, attention_masks])\n",
        "    \n",
        "    #choose only last hidden-state\n",
        "    x = transformer_layer[1]\n",
        "    output = tf.keras.layers.Dense(dense_dim)(x)\n",
        "    #output = tf.keras.layers.Rescaling(scale=4.0, offset=1.0)(x)\n",
        "    model = tf.keras.models.Model(inputs = [input_ids, attention_masks], outputs = output)\n",
        "\n",
        "    model.compile(tf.keras.optimizers.Adam(learning_rate), loss = MCRMSE, metrics = MCRMSE)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96pZ-IUrCD30"
      },
      "source": [
        "##**Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ1hLAW2CGm4"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, y_test, test_encoded_input_ids, test_encoded_attention_masks):\n",
        "    score = model.evaluate([test_encoded_input_ids, test_encoded_attention_masks], \n",
        "                           y_test\n",
        "                          ) \n",
        "    print('\\nTest Loss : {:.2f}%'.format(score[0]))\n",
        "    print('\\nTest Accuracy :  {:.2f}%'.format(score[1]))\n",
        "    return score[0], score[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJV4COxjCc9j"
      },
      "source": [
        "## **Predict**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJsH7HXpCiAT"
      },
      "outputs": [],
      "source": [
        "def predict_model(model, df_test, test_encoded_input_ids, test_encoded_attention_masks, label_cols):\n",
        "    predictions = model.predict([test_encoded_input_ids, test_encoded_attention_masks])\n",
        "    df_predictions = pd.DataFrame(predictions, columns=['pred_' + c for c in label_cols])\n",
        "    for col in label_cols:\n",
        "        df_predictions['transformed_pred_' + col] = df_predictions['pred_' + col].apply(lambda x : roundPartial(x, .5))\n",
        "    df_comparison = pd.merge(df_test, df_predictions, left_index = True, right_index = True)\n",
        "    return df_predictions, df_comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CGFbdlnFEMs"
      },
      "source": [
        "## **Plot Model Structure**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmSoWa7kFHCc"
      },
      "outputs": [],
      "source": [
        "def plot_model_structure(model):\n",
        "    keras.utils.plot_model(model, show_shapes = False, show_dtype = False, show_layer_names = True, dpi = 90)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N73w6RpFsbPx"
      },
      "source": [
        "## **Samples of predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sP5jgL0fsmpV"
      },
      "outputs": [],
      "source": [
        "def hall_of_fame(df, component, num):\n",
        "  samp = df.query(\"transformed_pred_\"+component+\"==\"+component).sample(num)\n",
        "  samp = samp.reset_index()\n",
        "  for index, row in samp.iterrows():\n",
        "      print(\"predicted: \",row[\"transformed_pred_\"+component])\n",
        "      print(\"original: \",row[component])\n",
        "      pprint.pprint(row[\"full_text\"])\n",
        "      print(\"**********\")\n",
        "\n",
        "def hall_of_shame(df, component, num):\n",
        "  samp = df.query(\"transformed_pred_\"+component+\"!=\"+component).sample(num)\n",
        "  samp = samp.reset_index()\n",
        "  for index, row in samp.iterrows():\n",
        "      print(\"predicted: \",row[\"transformed_pred_\"+component])\n",
        "      print(\"original: \",row[component])\n",
        "      pprint.pprint(row[\"full_text\"])\n",
        "      print(\"**********\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP0n_Dd8j26W"
      },
      "source": [
        "# **Read input files**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLDHxYTxjxVl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "736e4e37-a2d7-4c43-de95-9cbbc9fa78b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "# data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "%cd \"gdrive/MyDrive/Colab Notebooks/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Le5HU_86j4-9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8114874b-b152-439f-a9a4-ff29d17578fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        text_id                                          full_text  cohesion  \\\n",
              "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
              "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
              "2  00299B378633  Dear, Principal  If u change the school policy...       3.0   \n",
              "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
              "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
              "\n",
              "   syntax  vocabulary  phraseology  grammar  conventions  score_sum  \n",
              "0     3.5         3.0          3.0      4.0          3.0       20.0  \n",
              "1     2.5         3.0          2.0      2.0          2.5       14.5  \n",
              "2     3.5         3.0          3.0      3.0          2.5       18.0  \n",
              "3     4.5         4.5          4.5      4.0          5.0       27.0  \n",
              "4     3.0         3.0          3.0      2.5          2.5       16.5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-56874f52-3207-4f72-9bba-4a4a96c97976\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>full_text</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "      <th>score_sum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0016926B079C</td>\n",
              "      <td>I think that students would benefit from learn...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0022683E9EA5</td>\n",
              "      <td>When a problem is a change you have to let it ...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>14.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00299B378633</td>\n",
              "      <td>Dear, Principal  If u change the school policy...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>003885A45F42</td>\n",
              "      <td>The best time in life is when you become yours...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0049B1DF5CCC</td>\n",
              "      <td>Small act of kindness can impact in other peop...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>16.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56874f52-3207-4f72-9bba-4a4a96c97976')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-56874f52-3207-4f72-9bba-4a4a96c97976 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-56874f52-3207-4f72-9bba-4a4a96c97976');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "input_train_df = pd.read_csv('train.csv')\n",
        "input_test_df = pd.read_csv('test.csv')\n",
        "# Cleaning up full_text : Removing tabl and carriage return characters\n",
        "input_train_df['full_text'] = input_train_df[\"full_text\"].replace(re.compile(r'[\\n\\r\\t]'), ' ', regex = True)\n",
        "input_test_df['full_text'] = input_test_df[\"full_text\"].replace(re.compile(r'[\\n\\r\\t]'), ' ', regex = True)\n",
        "\n",
        "label_cols = input_train_df.columns[2:]\n",
        "input_train_df['score_sum'] = np.sum(input_train_df[label_cols], axis = 1)\n",
        "pred_col_list = ['transformed_pred_' + col for col in label_cols]\n",
        "\n",
        "orig_train_df = copy.deepcopy(input_train_df)\n",
        "orig_train_df.to_csv(\"orig_train_df.csv\", index=False) \n",
        "orig_train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B51vr1w3upZy"
      },
      "source": [
        "# **Model building**\n",
        "\n",
        "As we do not have labels for our test data, we are repurposing our training data by splitting it into 80:20 ratio of training to split. We will only run this split once.\n",
        "\n",
        "The train part is then going thru k fold cross validation and get tested on validation set and final test is done on the test set. Final test accuracy will be the average MCRMSE score across k-folds.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9c7XpOGZi46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d28f685-b2d3-4083-aa56-667a6cc62a30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train data : 3128\n",
            "Length of test data : 783\n"
          ]
        }
      ],
      "source": [
        "# shuffling them back again\n",
        "shuffle = np.random.permutation(np.arange(orig_train_df.shape[0]))\n",
        "orig_train_df = orig_train_df.iloc[shuffle]\n",
        "\n",
        "# Splitting the data in 80:20 split\n",
        "split = (0.8, 0.2)\n",
        "splits = np.multiply(len(orig_train_df), split).astype(int)\n",
        "df_train, df_test = orig_train_df[ : splits[0]], orig_train_df[splits[0] : ]\n",
        "df_train.to_csv(\"df_train_split.csv\", index=False)\n",
        "df_test.to_csv(\"df_test_split.csv\", index=False)\n",
        "\n",
        "print(f\"Length of train data : {len(df_train)}\")\n",
        "print(f\"Length of test data : {len(df_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3dExc7WuXWn"
      },
      "source": [
        "BERT-base-cased with all its layers frozen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed parameters\n",
        "dense_dim = 6\n",
        "number_of_splits = 2\n",
        "random_state = 2023\n",
        "mse_loss = MCRMSE\n",
        "mse_metrics = MCRMSE\n",
        "model_name_list = ['Bert', 'Bertweet'] # Roberta\n",
        "\n",
        "df_train = pd.read_csv('df_train_split.csv')\n",
        "df_test = pd.read_csv('df_test_split.csv')\n",
        "print(f\"Length of train data : {len(df_train)}\")\n",
        "print(f\"Length of test data : {len(df_test)}\")\n",
        "y_test = np.array(df_test[label_cols], dtype = \"float32\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ8SJdvbBZy_",
        "outputId": "593608ac-1fd1-4af5-9b77-1abaab175f81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train data : 3128\n",
            "Length of test data : 783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable parameter dictionary\n",
        "param_list = [   # Completely frozen base layer\n",
        "                 {'epochs'                  : 10,\n",
        "                  'batch_size'              : 8,\n",
        "                  'learning_rate'           : 1e-5,\n",
        "                  'validation_split'        : .2,\n",
        "                  'dropout'                 : .1,\n",
        "                  'number_of_hidden_layers' : 2,\n",
        "                  'hidden_layer_node_count' : 64,\n",
        "                  'retrain_layer_count'     : 0\n",
        "                 }\n",
        "             ]"
      ],
      "metadata": {
        "id": "qx_nk6VzP-9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, param_entry in enumerate(param_list):\n",
        "    MAX_LEN = 512\n",
        "    epoch_val = param_entry['epochs']\n",
        "    batch_size_val = param_entry['batch_size']\n",
        "    learning_rate_val = param_entry['learning_rate']\n",
        "    validation_split_val = param_entry['validation_split']\n",
        "    dropout_val = param_entry['dropout']\n",
        "    number_of_hidden_layers_val = param_entry['number_of_hidden_layers']\n",
        "    hidden_layer_node_count_val = param_entry['hidden_layer_node_count']\n",
        "    retrain_layer_count_val = param_entry['retrain_layer_count']\n",
        "\n",
        "    print(\"************************\")\n",
        "    print(f\"Iteration : {idx + 1}\")\n",
        "    print(\"Parameters...\")\n",
        "    print(f\"Epochs : {epoch_val}\")\n",
        "    print(f\"Batch size : {batch_size_val}\")\n",
        "    print(f\"Learning rate : {learning_rate_val}\")\n",
        "    print(f\"Validation split : {validation_split_val}\")\n",
        "    print(f\"Dropout : {dropout_val}\")\n",
        "    print(f\"Number of hidden layers : {number_of_hidden_layers_val}\")\n",
        "    print(f\"Hidden layer node count : {hidden_layer_node_count_val}\")\n",
        "    print(f\"Retrain layer count : {retrain_layer_count_val}\")\n",
        "    print(\"************************\")\n",
        "    set_config_param(20230214)\n",
        "\n",
        "    model_tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_CHKPT)\n",
        "    model = TFRobertaModel.from_pretrained(BERT_MODEL_CHKPT)\n",
        "\n",
        "    train_input_ids, train_attention_masks = text_encode(df_train['full_text'], model_tokenizer, MAX_LEN)\n",
        "    test_input_ids, test_attention_masks = text_encode(df_test['full_text'], model_tokenizer, MAX_LEN)\n",
        "\n",
        "    y_train = np.array(df_train[label_cols], dtype = \"float32\")\n",
        "\n",
        "    bert = build_regression_model(loss= \"MCRMSE\", \n",
        "                                      model_name = \"Bert\",\n",
        "                                      dense_dim = 6, \n",
        "                                      MAX_LEN = 512,\n",
        "                                      learning_rate = learning_rate_val,\n",
        "                                      dropout=dropout_val,\n",
        "                                      number_of_hidden_layers = number_of_hidden_layers_val,\n",
        "                                      hidden_layer_node_count = hidden_layer_node_count_val,\n",
        "                                      retrain_layer_count = retrain_layer_count_val)\n",
        "    bert.summary()\n",
        "\n",
        "    history_v1 = bert.fit((train_input_ids, train_attention_masks),\n",
        "                  y_train,\n",
        "                  batch_size = batch_size_val,     \n",
        "                  epochs = epoch_val,\n",
        "                  validation_split = validation_split_val\n",
        "                  )\n",
        "\n",
        "    history_v1_df = pd.DataFrame(history_v1.history)\n",
        "\n",
        "    score_v1 = bert.evaluate([test_input_ids, test_attention_masks], \n",
        "                    y_test\n",
        "                  ) \n",
        "\n",
        "    predictions_v1 = bert.predict([test_input_ids, test_attention_masks])\n",
        "    df_pred_v1 = pd.DataFrame(predictions_v1, columns=['pred_' + c for c in label_cols])\n",
        "\n",
        "    for col in label_cols:\n",
        "      df_pred_v1['transformed_pred_' + col] = df_pred_v1['pred_' + col].apply(lambda x : roundPartial(x, .5))\n",
        "    \n",
        "    df_compare_v1= pd.merge(df_test, df_pred_v1, left_index = True, right_index = True)\n",
        "    df_compare_v1.to_csv(\"predict_bert_0.csv\", index=False)\n",
        "    all = []\n",
        "    for col in label_cols:\n",
        "      all.append(((df_compare_v1[col]-df_compare_v1[\"transformed_pred_\"+col]).pow(2).mean())**(0.5))\n",
        "    RMSE_scaled = statistics.fmean(all)\n",
        "    print(f\"RMSE_scaled: {RMSE_scaled}\")\n",
        "    \n",
        "    for label in label_cols:\n",
        "      print(label)\n",
        "      hall_of_fame(df_compare_v1,label,1)\n",
        "      print(\"************************\")\n",
        "      hall_of_shame(df_compare_v1,label,1)\n",
        "      print(\"************************\")\n",
        "    for component in label_cols:\n",
        "      print(component)\n",
        "      print(\"% Predicting too high: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\">\"+component))/len(df_compare_v1)))\n",
        "      print(\"% Predicted correctly: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"==\"+component))/len(df_compare_v1)))\n",
        "      print(\"% Predicting too low: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"<\"+component))/len(df_compare_v1)))\n",
        "      print(\"****\")\n",
        "    # Predicting too high or low for every score? \n",
        "    # for component in label_cols:\n",
        "    #   print(component)\n",
        "\n",
        "    #   for score in [1.0,1.5,2.0,2.5,3.0,3.5,4.0,4.5,5.0]:\n",
        "    #     if len(df_compare_v1[df_compare_v1[component]==score])==0:\n",
        "    #       print(component+\"==\"+str(score)+\" has 0 rows\")\n",
        "    #     else:\n",
        "    #       print(f'length: {len(df_compare_v1[df_compare_v1[component]==score])}')\n",
        "    #       print(\"% Predicting the above (\"+str(score)+\"): \" +\n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) &\n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]>score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #       print(\"% Predicting the same (\"+str(score)+\"): \" +\n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) & \n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]==score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #       print(\"% Predicting the below (\"+str(score)+\"): \" + \n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) & \n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]<score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #     print(\"****\")\n",
        "\n",
        "    for component in label_cols:\n",
        "      print(component)\n",
        "      print(\"% Predicting within .5: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"<=(\"+component+\"+.5) and transformed_pred_\"+component+\">=(\"+component+\"-.5)\"))/len(df_compare_v1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bafbe3e4c46641d09650ae650268da7c",
            "92bbe263eb214720a2e61bdcb05b82ee",
            "4f77ca6ca3164d199bf472827a428b4a",
            "33c7ec509a514b96b018195748f780d6",
            "dfd52916440d43e68a03933bf67b6d93",
            "ae90991b2d1a48fdb0ca9647833594bb",
            "fe9be27d56324efabc68a6592926fe6c",
            "2ee555e528ef4876b1b2e9957eacb968",
            "16a5123e234841fc9b1af753016a3157",
            "98eec0369bb7438badc698387cf2bdc6",
            "756dff02b4d14011a67de76e4e27fbec",
            "8c2f5329b7a04ac8af043a86fa72953a",
            "a2bcde8ba533441d95b3d4d6bfc036df",
            "fff74475351d454e885af623a9107993",
            "fcd7c8db8968483ca39f30bb7a37343c",
            "bed6c529bf8047b4b9875ca8fa89bce3",
            "dbf076bcc4124fac913621711addb0e6",
            "d4793f4f974b4cedb365f91a3d504815",
            "4ddc5eb1d2e449c0a570be470f9d7fe5",
            "c2638dcdc6a94e939780ffbc3b59e708",
            "899d91409a1f4d91bda5da7e20ced404",
            "cb97fdb2c5b54dd6afa6a9965ec7a977",
            "901a74da4949445da3b7960b02773824",
            "21c4d96df4524184a5ea3f72fcb5717b",
            "6944ac2666c3419b85db52280345c1b9",
            "d0d7e684052540fbbe493aa13013d208",
            "b60b38513a3e43f19a9f65dc2881b29b",
            "3bc25cfec28b4b92a591e8957515866c",
            "4a621de3ed10426d96a902b434f82d8b",
            "75b7fdf395f64453b8682eead2fa7d31",
            "39a526c91f644e96b3671bebbcf0ed05",
            "5f3eb465557f4378a01d296195bd7171",
            "6b58e83ba65a40bf84bfca6b0a100729",
            "63ec69e49a624ffcb4e733d172a21590",
            "a0dba75b62904b47930442def8a1f35a",
            "09867eb6e50743fcaa528ab6e4e95c92",
            "a5d3dcd42ca346ecaae7905f314313bd",
            "e72154f7f0a442f8962b14efe93aa07f",
            "e13e67c80f5049d89c09229668bcf5f8",
            "2e429bd842b64341abfb610662e036b4",
            "15ae65572cc843178ff6307b2b12a58b",
            "a46063ad1bf84ecba6700da44bfc836c",
            "591ddf1919b14d7f82a9c7f4a232c6d2",
            "9797be97bebc4c718d25ef0990e90b5a",
            "0e872febea2e42a68edcd97be0eb7092",
            "19c9bab4b2084f46aae17b96f1745ad4",
            "cfe57bc361ac4860858217e747353320",
            "cf832384db734b43822319cf5d4987e2",
            "8ed4b760a4b54925b20b5d7d6dbcd343",
            "0c1ece91fe5b44bf9e06fc565dcc65bc",
            "f76aab1a234c4515b9ac0d84a4bd3873",
            "0e885f2e875e4b31b3514000a3d11ee7",
            "11a6e4047b3a45ad9464e27a465e257b",
            "31ef51ab826b4b069b67eea158bcb1ab",
            "317f5cb48ccd4f40810cb3cfcfaf1631"
          ]
        },
        "id": "_oBQigtnjgWT",
        "outputId": "ee53f60f-3207-4dae-e4f0-c74027e8cea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************************\n",
            "Iteration : 1\n",
            "Parameters...\n",
            "Epochs : 10\n",
            "Batch size : 8\n",
            "Learning rate : 1e-05\n",
            "Validation split : 0.2\n",
            "Dropout : 0.1\n",
            "Number of hidden layers : 2\n",
            "Hidden layer node count : 64\n",
            "Retrain layer count : 0\n",
            "************************\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bafbe3e4c46641d09650ae650268da7c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c2f5329b7a04ac8af043a86fa72953a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "901a74da4949445da3b7960b02773824"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63ec69e49a624ffcb4e733d172a21590"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/527M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e872febea2e42a68edcd97be0eb7092"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters : 0\n",
            "Number of non-trainable parameters : 108310272\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " hidden_layer_1 (Dense)         (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_layer_1 (Dropout)      (None, 64)           0           ['hidden_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            " hidden_layer_2 (Dense)         (None, 64)           4160        ['dropout_layer_1[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_layer_2 (Dropout)      (None, 64)           0           ['hidden_layer_2[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 6)            390         ['dropout_layer_2[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,364,038\n",
            "Trainable params: 53,766\n",
            "Non-trainable params: 108,310,272\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " hidden_layer_1 (Dense)         (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_layer_1 (Dropout)      (None, 64)           0           ['hidden_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            " hidden_layer_2 (Dense)         (None, 64)           4160        ['dropout_layer_1[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_layer_2 (Dropout)      (None, 64)           0           ['hidden_layer_2[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 6)            390         ['dropout_layer_2[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,364,038\n",
            "Trainable params: 53,766\n",
            "Non-trainable params: 108,310,272\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "313/313 [==============================] - 156s 448ms/step - loss: 2.9008 - MCRMSE: 2.9004 - val_loss: 2.2972 - val_MCRMSE: 2.3025\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 156s 499ms/step - loss: 1.8674 - MCRMSE: 1.8670 - val_loss: 1.2046 - val_MCRMSE: 1.2096\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 141s 450ms/step - loss: 1.1287 - MCRMSE: 1.1286 - val_loss: 0.6779 - val_MCRMSE: 0.6814\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 156s 500ms/step - loss: 0.9515 - MCRMSE: 0.9515 - val_loss: 0.6084 - val_MCRMSE: 0.6109\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 156s 500ms/step - loss: 0.9137 - MCRMSE: 0.9139 - val_loss: 0.5971 - val_MCRMSE: 0.5993\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 156s 499ms/step - loss: 0.8855 - MCRMSE: 0.8857 - val_loss: 0.5886 - val_MCRMSE: 0.5908\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 156s 500ms/step - loss: 0.8802 - MCRMSE: 0.8800 - val_loss: 0.5833 - val_MCRMSE: 0.5855\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 156s 500ms/step - loss: 0.8610 - MCRMSE: 0.8609 - val_loss: 0.5779 - val_MCRMSE: 0.5801\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 156s 500ms/step - loss: 0.8555 - MCRMSE: 0.8555 - val_loss: 0.5718 - val_MCRMSE: 0.5740\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 156s 500ms/step - loss: 0.8157 - MCRMSE: 0.8158 - val_loss: 0.5658 - val_MCRMSE: 0.5680\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.5682 - MCRMSE: 0.5690\n",
            "25/25 [==============================] - 35s 1s/step\n",
            "RMSE_scaled: 0.6425438504406898\n",
            "cohesion\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('Do we choose our own behavior or is it controlled by other influences. Well '\n",
            " 'it all has to depend on the type of person you are. For example if you are '\n",
            " 'somebody who gets influenced by other people then you are going to act like '\n",
            " 'those people. And usually those people are bad influences, but if you are '\n",
            " 'somebody that chooses to be who they are then that is really who they are. '\n",
            " 'And mostly it is to be nice to others, and those are some reasons why it can '\n",
            " 'go either way, but for me i personally think you have a choice to be who you '\n",
            " 'desire to be without any influeces.  When you get to be who you want to be '\n",
            " 'life is easier. You are going to be true to yourself and people will have '\n",
            " 'respect for you. And many people all over the world are scared to be '\n",
            " 'themselfs, and would rather get controlled by other people. And because of '\n",
            " 'those type of people they spread that nagative influence off to other people '\n",
            " 'that get controlled easily. But in the end it depends on who you hang around '\n",
            " 'with.  Choosing the way you act is very important not just for you but for '\n",
            " 'your future. Because your future is what matters at the end of the day. And '\n",
            " 'because of that reason is because if you want to find a good job you have to '\n",
            " \"be respectful and kind. But if you didn't have a good attitude then nobody \"\n",
            " \"won't hire you. It's reasonable too, because nobody wants a bad attitude \"\n",
            " 'person in their jobs.  Many people who have chose their characters have been '\n",
            " 'successful because of it. And cause they have confedenced they can achieve '\n",
            " 'anything they want in the world. And all that just because they went on to '\n",
            " 'be themselfs. Meanwhile those who have been influenced by others have been '\n",
            " 'stuck like that their whole lifes.  Depending on what type of influences '\n",
            " 'they get, because some are good and they get to high places in life.  So at '\n",
            " 'the end of the day as long as you choose something that is good for you and '\n",
            " \"won't take you to bad places you will be great in life. But unfortunally it \"\n",
            " 'usually ends in bad places for those who are weak and would rather take '\n",
            " 'influences by others who are in bad situations. And thats why for me it is '\n",
            " 'better to choose to be yourself then to follow others. But if you are '\n",
            " 'somebody that likes the influences then choose people who are good. That is '\n",
            " 'how i see it in my eyes.     ')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  4.5\n",
            "('Technology has had the biggest impact on human interaction. Most people '\n",
            " \"might say it's made a positive impact on people's lives while others may \"\n",
            " \"disagree and say it's had a negative impact on people's lives. There may be \"\n",
            " 'some pros and there may be some cons to this situation. Can the impact of '\n",
            " \"technology be a good or bad outcome?  Let's start off with the pros or the \"\n",
            " \"positive effects technology has had on people's lives, now technology has \"\n",
            " \"made people's lives easier. Some may say because it's easier to access what \"\n",
            " 'they need easier online instead of heading to the market. Some may also say '\n",
            " \"it's easier and faster to call your friends or parents, any family member \"\n",
            " 'really, instead of driving all the way to them, which is true. Watching '\n",
            " 'movies on your phone instead of going all the way to the movie theater and '\n",
            " 'pay for your ticket and it only being a one time thing. There are countless '\n",
            " 'positives outcomes of how technology has increased over the years. The '\n",
            " \"technology nowadays makes everything faster and easier on people's lives. \"\n",
            " 'Unfortunately, all these great, glamorous, fast, and easy ways have some '\n",
            " \"downfall to them.  Now, technology definitely has it's flaws and negative \"\n",
            " \"impacts on people's lives. Most can say there's not as much human \"\n",
            " 'interactions since technology has been brought upon people. Communication is '\n",
            " 'key when interacting with one another. Today most people are also glued to '\n",
            " 'their cellular device, not physically but you get the point. Especially '\n",
            " 'teenagers, they have a bad habit of not being able to put down their '\n",
            " \"cellphone. Whether that being during school hours, at home when you're \"\n",
            " 'supposed to be doing work, and maybe even at work. The generation we have '\n",
            " 'today is usually all about social media, and just being on their cellphone '\n",
            " \"in general 24/7. Point blank there's just no physical, verbal communication \"\n",
            " 'anymore between one another. It may be causing a lot of students to slack in '\n",
            " \"school, and it may not only go for students and teenagers, they're not the \"\n",
            " 'only victims. Some particular parents may be also glued to their cellphone '\n",
            " \"just as teenagers. It's not their fault nor do the teenagers have any fault \"\n",
            " \"in this. All this is because of the evolution of technology. It's not \"\n",
            " 'pleasant to live in a world with not so much communication and everyone '\n",
            " 'being constantly glued to their cellphone nor is it pleasant to do awful in '\n",
            " \"school because you can't put your cellular device down. Now, these are just \"\n",
            " \"some reasons and examples why technology has a negative impact on people's \"\n",
            " 'lives. Can you imagine how many more scenarios like this happen daily?  '\n",
            " 'Though technology has evolved drastically through out the years and is still '\n",
            " \"evolving now as we speak, there's always going going to be positive and \"\n",
            " 'negative impacts. Technology does help and allow people to complete tasks '\n",
            " \"without having contact with others. There's the problem right there, there's \"\n",
            " 'no communication. Even though there are some positive effects of technology '\n",
            " \"that doesn't change the fact that there are more negative effects than \"\n",
            " 'positive. Technology effects each person a different way, whether that being '\n",
            " \"in a positive way or whether that being in a negative way. It's all a mix, \"\n",
            " 'and by mix I refer to positive effects and negative effects all over the '\n",
            " \"place. Some people may disagree or may agree whether it's a bad mixture or a \"\n",
            " 'good mixture. Cell phones and all technology can make it easier or harder '\n",
            " 'for certain people.  Whether if it truly is a positive or negative impact it '\n",
            " \"will not change what people think or at what position they're in. Some \"\n",
            " 'people just like taking the easy way out and not cope with what they are '\n",
            " 'losing and missing out on, communication. Human communication and '\n",
            " \"interactions are not it anymore. Everyone's opinion and saying on this \"\n",
            " \"dilemma is different, people's mindsets are different even their actions are \"\n",
            " \"different from everyone else's,but this is my opinion. In conclusion, that \"\n",
            " 'is why I strongly, and genuinely believe technology has a negative effect on '\n",
            " \"people's lives.            \")\n",
            "**********\n",
            "************************\n",
            "syntax\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('I do agree with Prime Minister Winston Churchill. My first reason is because '\n",
            " 'most of the people in this world will think that is really easy to be '\n",
            " 'successful, but time will get difficult as you and your self are growing up, '\n",
            " 'for you to be failing over and over again is just a meaning that life at '\n",
            " \"some point will be easier, Most people if they keep failing they won't know \"\n",
            " \"what to do, Keeping your hope and thoughts on your mind that's how you will \"\n",
            " 'succeed. keep on following that dream no matter how hard time will. Sometime '\n",
            " \"you will feel like you're not getiing answer or at least a signal.  My \"\n",
            " 'second reason is that failure is going to come at some point in your life '\n",
            " 'for example; teenager come at school, adult come at work, money wise, '\n",
            " 'housing. failure is something that we all should learn how to over come that '\n",
            " 'problem we should think for a solution make a plan in our life. how are we '\n",
            " 'goinf to fix this part and find a solution to over come that problem if we '\n",
            " 'need help from somebody.  My third reason is that as soon as you over come '\n",
            " \"failure you start learning thing about themselve, that they didn't know \"\n",
            " \"before, most people find ways to stop going back failing, that's when you \"\n",
            " 'start gaining the believe on keep going on practicing every single method to '\n",
            " 'do not fail again.  In my conclusion most of the people have those hard time '\n",
            " 'and is bext to talk to someone about a look for answer, in way to find the '\n",
            " 'solution and fix this problem by yourself or with someone important in your '\n",
            " 'life.')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  4.0\n",
            "('Adding another hour and thirty minutes to the school schedule is just a '\n",
            " 'waste of time! It means having to miss time with my family. It also means '\n",
            " 'having to wake up earlier to get to school. Teachers would have to stay back '\n",
            " 'and work longer but probably get paid the same amount for ten hours. So I '\n",
            " 'disagree with having to add another hour and thirty minutes.  First of all I '\n",
            " \"don't think kids would like to wake up extra early and get ready for school. \"\n",
            " 'Once the students get to the school they would be half asleep and it would '\n",
            " 'be harder for them to focus. The students would have trouble staying awake '\n",
            " 'and they would have more attitude then what they have now. More students '\n",
            " 'would be marked tardy and there would more students skipping classes just to '\n",
            " 'get some sleep. Not every student would stay awake through out the day and '\n",
            " 'finish there work.  Adding an hour and thirty minutes would also have an '\n",
            " 'impact on teachers. They already have to wake up extra early in order to be '\n",
            " 'here on time and stay late to work on grading papers, going to meetings, '\n",
            " \"etc. It would be harder for them to stay awake and teach. Teachers don't \"\n",
            " 'even get paid enough. So why would they want to stay back and serve more '\n",
            " 'time.  Some after school activities would get canceled and student that '\n",
            " 'would need those after school activities would get mad. Complaints would '\n",
            " 'start coming in and parents would get mad and ask why their child is '\n",
            " 'failing. Some sports would be canceled and and athletes would get frustrated '\n",
            " \"because they won't be motivated or asked to go to a certain collage. \"\n",
            " 'Students would get low grades if after school activities were to get '\n",
            " 'canceled. The school would become a laughing stock.  Adding an hour and '\n",
            " 'thirty minutes would have a bad effect on the school and the people in it. '\n",
            " \"There would be more trouble then there is now and students wouldn't get \"\n",
            " \"motivated. Grade levels would go down and students won't focus. Teachers \"\n",
            " 'would have trouble staying up for ten hours. Family time would be shortened '\n",
            " 'as well.')\n",
            "**********\n",
            "************************\n",
            "vocabulary\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('No i do not think that we should add one hour and a half to school. I think '\n",
            " 'it is bad anough that we have to stay for about 7 hours i have a lot of '\n",
            " 'reasons why i think they should not add an hour to school. One of the '\n",
            " 'reasons i would not want them to add an hour to school is because if they '\n",
            " 'add an hour to school they would have to add class to the chool to. but one '\n",
            " 'of the main resons that i would not want another hour at school is becuase '\n",
            " 'kids just want to go home and adding an hour would just get kids and parents '\n",
            " 'mad for there kids getting home late.  For example if it was day light '\n",
            " 'savings time it would be very dark once every one to go home. Or if a '\n",
            " 'teacher staff memeber or student plays a sport they would be late or unbkle '\n",
            " 'to go for the late releas at the school. In addition if there where to be a '\n",
            " 'lockdown at that hour and a half that the school bored had added the parents '\n",
            " 'of the students might want to sue the school bored for putting there '\n",
            " 'children in danger at the time they added to the day. Another example is if '\n",
            " 'ther is a fire they could get sued for the same thing that is why i feel '\n",
            " 'like the school bored should not add an hour and a half to the school day.')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  3.5\n",
            "('Our cell phones could help us in many situation, but they can also distract '\n",
            " 'us in many ways. Some teachers thinks that they should let their student use '\n",
            " \"their cell phones for educational purposes while other don't. Cell phones \"\n",
            " 'could affect a student in their process of learning.  A cell phone can be a '\n",
            " 'distraction for anybody specifically for a student. If students are allow to '\n",
            " 'use their phone in their classroom for educational purposes they could get '\n",
            " 'distracted with the other apps on their phone. For example: Sanpchat, '\n",
            " 'Instagram, Facebook, or even a text message. All of this apps could distract '\n",
            " 'the student from doing what he or she is supposed to be doing in the class.  '\n",
            " 'All students most do their own work at all time to show the teacher what he '\n",
            " 'or has learned in class. Having access to a cell phone in class could tempt '\n",
            " 'the student to cheat on their class work or test. Also students could send '\n",
            " 'each other answer through a text. Classroom should be a red zone at all time '\n",
            " \"so students won't have the chance to cheat in their work.  Every student \"\n",
            " 'should be focus on one specific thing thing while they are in school which '\n",
            " 'is to have good grades in their class. By being able to have access to their '\n",
            " \"cell phone in class the student won't try as hard to keep their grade up. \"\n",
            " 'Not having their phone would push them to do better in the class. The '\n",
            " 'student will have all their attention on getting their assignment done in '\n",
            " \"time.  Some students know how to control them self while others can't. Cell \"\n",
            " \"phones are a big distraction for teenagers now days. Most of them can't go \"\n",
            " 'anywhere without their phone in their hands. All classroom should be a red '\n",
            " 'zone just so students could put all their focus in school work. ')\n",
            "**********\n",
            "************************\n",
            "phraseology\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('Career is the most important in people life. if people do not have a career, '\n",
            " 'then will become a unemployed vagrant. People do not have work, so they do '\n",
            " 'not have money. As the saying goes,if you do not have money then you can not '\n",
            " 'do anything. therefore career is most important.  At a young age,students '\n",
            " 'thought is more brisk. student will thing about the career that they will do '\n",
            " 'in the future. At that time people have a illusion,visualize a bright '\n",
            " 'future, have a expect on the career in the future. At this time, if the '\n",
            " 'teacher gave student guide to selected towards a specific carreer. students '\n",
            " 'will fiem and unshakable their thought. they will do the best one can to '\n",
            " 'achieve the goals. Student will bring pressure on thierself. if do not have '\n",
            " 'pressure,then do not have improve. In the high school, should provide the '\n",
            " 'courses of select to guide them towards a specific career. For the reason: '\n",
            " 'first ,by do this can develop good habits on the student, in the school. '\n",
            " 'Second, student not only can study hard but also can get skills. Third '\n",
            " 'students will be good at their class that they choose to be a career. In the '\n",
            " 'school,develop the courses of specific career has more advantage. For '\n",
            " 'example,student graduate on the university, they are not face with on the '\n",
            " 'obtain employment. I think it is a good idea for student to gain the skill '\n",
            " 'for the career.  On the another way, develop the career courses early, it '\n",
            " 'will give student more pressure, because in this time student are still '\n",
            " 'immature. if gave they more pressure,can not make students students but can '\n",
            " \"make students fell repugnant. This way just run counter to student's \"\n",
            " 'intentions. Not all students need pressure to improve thierself. But some '\n",
            " 'students do not need pressure. They do not engage in honest work and have '\n",
            " 'neither learning nor skill in the school. sometimes students are not sure '\n",
            " 'that they work on something in the future. This career class may gave this '\n",
            " 'student more pressure,they should choose a career that they want to be in '\n",
            " 'the future. Therefore,this ways just make students fell disturbed.  In '\n",
            " 'short,the courses of study in high school are selected to guide to a '\n",
            " 'specific career it is a good idea for students to commit to a career. Career '\n",
            " 'is important. students should plan it early. In order to, can be batter able '\n",
            " 'to work in the future. So can not face with obtain employment.    ')\n",
            "**********\n",
            "************************\n",
            "predicted:  2.5\n",
            "original:  3.0\n",
            "('Technology had positives effects in people lives, it helps them in many ways '\n",
            " 'like emergency, transport, and security.  Technology helps people in case of '\n",
            " 'emergency, it helps them to comunicate with emergencies. It helps keep '\n",
            " 'people alive in the way to the hospital. Also technology can help doctors, '\n",
            " 'to determinate what is wrong with the patient. It helps doctors when they '\n",
            " 'make an peration.  Technology helps people with transportation, people can '\n",
            " 'travel around the country from place to place. People use transportation '\n",
            " 'when they have to work. Also helps people in case of emergency, by taking '\n",
            " 'them to the hospital. if someone wants to travel to others country, they can '\n",
            " 'take a airplane or a helicopter.  Technology helps people in education, '\n",
            " 'teachers use technology to teach. In schools they use technology to teach '\n",
            " 'student how our first genaration was, how they dress and how hard was to '\n",
            " 'live in the time. Student can find any information about projects in the '\n",
            " 'internet. After school students can do their homework instead going to other '\n",
            " 'places like in the pass.  Technology helps people with security, people use '\n",
            " 'cameras to keep secure places. They use cameras in places like shopping '\n",
            " 'store, food markets, restaurants and other places. Technology also helps '\n",
            " 'with the traffic security, like lights in the road to see where are you '\n",
            " 'going, see if the car infront of you stops, and cars have cameras to see '\n",
            " 'when you are going back.  In conclusion technology had a great impact on '\n",
            " 'peoples lieves, because it helps alot with transport, emergency, education '\n",
            " 'and other. People will have more avanced technology in the future. ')\n",
            "**********\n",
            "************************\n",
            "grammar\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('Wednesday 03, 20, 2019  Generic_Name  Working in Groups or Alone  In school '\n",
            " 'sometimes we work in groups and sometimes we work alone. Working alone is '\n",
            " \"fine because we don't get headaches from classmates; however, working in in \"\n",
            " 'groups is better because we get extra help from classmates. Working in '\n",
            " 'groups is better because we get extra help from classmates, we get more '\n",
            " 'opinions, and it takes less time doing the assignment.  First, working in '\n",
            " 'groups is better because we get extra help from classmates. For example, we '\n",
            " 'divide the assignment with our classmates. Each person has their own part to '\n",
            " 'do and we finish it faster than do it alone. Working in groups is better '\n",
            " 'because we will have more contribution from classamtes.  Second, working in '\n",
            " 'groups is better because we get more opinions. For example, every person in '\n",
            " 'the group give opinions. We get more ideas if we are more than only one '\n",
            " \"person. We don't have to think everything about the assignment because we \"\n",
            " 'will have thinking help. Working in groups is better because we get more '\n",
            " 'ideas.  Finally, working in group is better because the assignment will take '\n",
            " 'less time to be completed. It will take less time because we will get more '\n",
            " \"support and all the work don't will be completed just by one person. There \"\n",
            " 'will be more help and each person will do a little work what means that we '\n",
            " 'will finish faster because it will take us less time doing the assignment '\n",
            " 'than do it alone. Working in groups is better because the assignment will '\n",
            " 'take less time to be completed.  In conclusion, working in groups is better '\n",
            " \"because we divide the work with our classmates, we don't have to think \"\n",
            " 'everything about the assignment because we will have thinking help, and the '\n",
            " 'assignment will take less time to be completed. Working in groups is a '\n",
            " 'gift. ')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  3.5\n",
            "('People almost always credit their success by having a good attitude because '\n",
            " 'they treat people the way they want to get treated, it makes other people '\n",
            " 'happy and it makes the them happier. Having a good attitude to another '\n",
            " 'person makes that same person give you that same attitude back, and to other '\n",
            " 'people. They spread good vibes, and it makes them feel happier. Giving a '\n",
            " 'complement to someone every day can lead them to doing the same thing. '\n",
            " 'Having a good attitude can lead to having good karma so next someone says '\n",
            " '\"nice shoes\" to a random person. That someone will get treated with good '\n",
            " 'karma like passing their test the next day.  Having a good attitude to '\n",
            " 'people at school can lead to having more friends, and getting treated '\n",
            " 'better. By treating the teacher with respect, and kindness. It can make the '\n",
            " 'teacher do you same thing back. Good attitude is the key to success, and '\n",
            " 'every famous person you see on TV always has a good attitude. Maybe thats '\n",
            " 'why there successesful and famous all that hard work they put into their '\n",
            " \"job. When someone has a good attitude it's most likely thier happy, or \"\n",
            " \"everyone they talked with was happy.  But sometimes there's a sad person and \"\n",
            " 'to make thier day or cheer them up a complemant can help. By saying their '\n",
            " 'outfit looks good, or their hair cut looks better than last time. It can '\n",
            " \"cause them to feel better and do the same thing back to someone else that's \"\n",
            " \"having a bad day. There's also people that have good attitudes to make them \"\n",
            " \"selfs feel better It's like leaving chruch you fell happier. But coming to \"\n",
            " \"church it's just feels good.  Having a bad attitude can effect other peoples \"\n",
            " 'mood it can make them happy or sad. Having a good attitude makes more people '\n",
            " 'happier and feel calm. Attitude effects almost all of the day and other '\n",
            " \"peoples day including your family and pets. If your mad all day it's because \"\n",
            " \"someone was mad to you or just got effected by it from someone eles.  It's \"\n",
            " 'just better to have a good attitude all day than being mad all day and '\n",
            " 'causing other people to be mad insted of being happy. Being happy in the '\n",
            " 'worst times in your life is a good thing and can change your fellings '\n",
            " 'somehow. I would rather have a good day in a bad day than have a bad day. If '\n",
            " 'half of the world had a good attitude next thing you now the whole world has '\n",
            " \"a good attitude. But people don't like doing that they rather be mean to \"\n",
            " \"other people and that's why the whole world is violent and wars start and \"\n",
            " \"people die Because people don't have good attitudes.  Good attitude effects \"\n",
            " \"a lot of people like in music and in movies sometimes it's good and \"\n",
            " \"sometimes it's bad. People that are famous and have bad attitudes are really \"\n",
            " 'common they get mad at their fans but the fans is the only reason why their '\n",
            " 'famous and rich. Rich people are usually the sad ones and the poor are '\n",
            " 'usually the happier ones because they have better attitudes.  Good attitudes '\n",
            " \"effect a lot and so do bad ones that's why thiers all types of people in the \"\n",
            " 'world. Good ones and bad ones the ones with good attitude and the ones with '\n",
            " \"bad attitude. Good attitudes effect friends and family and that's why people \"\n",
            " 'should always have good attitudes. One time I was testing and I had a good '\n",
            " 'attitude but when I saw my score I had a bad attitude for the rest of the '\n",
            " 'day. And the same things happens when my parents are mad at each other it '\n",
            " 'gives me a bad attitude for the rest of the day in school and in soccer. But '\n",
            " 'when someone is nice to me or gives me a complement I feel better about '\n",
            " 'myself and it chages my attitude.  Sometimes having a good attitude in the '\n",
            " 'worst times is bad like having a good attitude in a funaral or at a sad '\n",
            " \"movie. But sometimes it's best to be happy and have a good attitude to \"\n",
            " \"spread good energy to other people and family. It's sometimes good to have a \"\n",
            " 'bad attitude so people can know your sad and be happier near you to cheer '\n",
            " 'you up. Being nice and having a good attitudes can really change someones '\n",
            " 'day so try it and complement people so they will do the same thing back.  I '\n",
            " 'usually have a good attitude even when I have a really bad headache or am '\n",
            " 'sick because having a bad attitude is not fun. and it makes other people '\n",
            " \"have bad days or feel bad so that's why I always have a Good attitude. To \"\n",
            " \"other people and my family so they will all have a good attitude and that's \"\n",
            " \"why having a bad attitude is bad because it causes bad thing and we don't \"\n",
            " 'need that we need to be nice and help other people. Thats why people are so '\n",
            " \"mean and don't care.  And that's why problems start and people get mad and \"\n",
            " \"that's why you should have a good attitude everyday to make other people \"\n",
            " 'happier.        ')\n",
            "**********\n",
            "************************\n",
            "conventions\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('Students should participate in extracurricular activity because it can help '\n",
            " 'them find new friends and skills or talent moreover helps them out of '\n",
            " 'trouble.  First and foremost, it can help students get out of trouble like '\n",
            " 'getting into fight or getting detention. Students can also get away from '\n",
            " 'being a bully. Like other students they show you bad influence. Students '\n",
            " 'makes you do it to other people is like your adopting it from them and it '\n",
            " \"makes you think that it's ok to do bad stuff like bullying or trash talking \"\n",
            " 'to other students. Students can also be out of trouble in social media by '\n",
            " 'poser. posers use your name and picture in social media to get a lot of '\n",
            " 'followers or to get someone in a relationship.  Secondly, students can '\n",
            " 'socialize like meet new people of friends. Students can also find their new '\n",
            " 'skills and talent by participating in any activities like sports or being a '\n",
            " 'students council. Moreover students can also share their interest in sports '\n",
            " 'like playing soccer they can show you what part of that game their '\n",
            " 'interested in. Sharing your interest to others makes other people people '\n",
            " 'share what their interest. Also sharing each others interest can lead you '\n",
            " 'you guys to be a good friends.  Thirdly, students can have better future by '\n",
            " 'getting their resume. Resume help students get a good job in the future. '\n",
            " 'Students can be a doctor when they grow up and they can also be teacher or '\n",
            " 'coach. Students can have better life, they can buy a big house and a nice '\n",
            " 'car. students can also help their family.  Lastly, students should '\n",
            " 'participate in extracurricular activity because it can help them get out of '\n",
            " 'trouble, socialize, and have better future.  In conclusion students should '\n",
            " 'participate in extracurricular activity because they can meet new people, '\n",
            " 'get out of trouble and they can also get their resume to get better job and '\n",
            " 'be successful in life.')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  2.5\n",
            "('So we heard that our principal is going to let all the students to '\n",
            " 'participate in one activity of their choice. But I have both reasons that '\n",
            " 'might go alright or not. Lets just say if I agree or disagree with the '\n",
            " 'principal decision and hopefully that our principal has a good feeling about '\n",
            " 'this decision.  Lets start with a positive reasons. First responsibility, if '\n",
            " 'the students get a activity that takes a lot of serious responsibility like '\n",
            " 'for example serve on the student council or working on the yearbook, '\n",
            " 'activity like that those have real responsibility to take care of. Next is '\n",
            " 'not knowing it was the students talent, all activity will fill up very '\n",
            " 'quickly and if any teacher puts a student that is not their favorite class '\n",
            " \"they will notice that their very talented on a activity that they didn't \"\n",
            " 'like. Last positive reason overwhelmed, the student will get overwhelmed and '\n",
            " 'sometimes is alright but at the end they still love the class.  Second, '\n",
            " \"start with the negative reasons. It won't be their favorite if a student \"\n",
            " 'want to be a class so bad but then a teacher decides to put him/her to '\n",
            " \"different class it's likely that the student wont be liking the class not a \"\n",
            " \"bit. Overwhelming, it's going to the same thing but the opposite its almost \"\n",
            " 'the same topic as the last reason of not liking the class and overwhelmed is '\n",
            " 'the part cause of not liking the class which lead to our third last negative '\n",
            " 'reason, dropping out its most likely that they gonna drop out the class it '\n",
            " 'will get so stress and overwhelmed that the student decides to quit and that '\n",
            " 'lead to have a no responsiblilty in life.  So I do agree with principal '\n",
            " 'student or people need to have responsibility in life and without it theres '\n",
            " 'going to be no job for that person who decided to drop of the activity they '\n",
            " 'got asigned.  ')\n",
            "**********\n",
            "************************\n",
            "cohesion\n",
            "% Predicting too high: 0.3116219667943806\n",
            "% Predicted correctly: 0.2784163473818646\n",
            "% Predicting too low: 0.4099616858237548\n",
            "****\n",
            "syntax\n",
            "% Predicting too high: 0.2950191570881226\n",
            "% Predicted correctly: 0.3384418901660281\n",
            "% Predicting too low: 0.3665389527458493\n",
            "****\n",
            "vocabulary\n",
            "% Predicting too high: 0.29118773946360155\n",
            "% Predicted correctly: 0.37292464878671777\n",
            "% Predicting too low: 0.33588761174968074\n",
            "****\n",
            "phraseology\n",
            "% Predicting too high: 0.28607918263090676\n",
            "% Predicted correctly: 0.30268199233716475\n",
            "% Predicting too low: 0.4112388250319285\n",
            "****\n",
            "grammar\n",
            "% Predicting too high: 0.3269476372924649\n",
            "% Predicted correctly: 0.26053639846743293\n",
            "% Predicting too low: 0.4125159642401022\n",
            "****\n",
            "conventions\n",
            "% Predicting too high: 0.3167305236270754\n",
            "% Predicted correctly: 0.30140485312899107\n",
            "% Predicting too low: 0.3818646232439336\n",
            "****\n",
            "cohesion\n",
            "length: 2\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 6\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 64\n",
            "% Predicting the above (2.0): 1.0\n",
            "% Predicting the same (2.0): 0.0\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 162\n",
            "% Predicting the above (2.5): 0.9567901234567902\n",
            "% Predicting the same (2.5): 0.043209876543209874\n",
            "% Predicting the below (2.5): 0.0\n",
            "****\n",
            "length: 219\n",
            "% Predicting the above (3.0): 0.0776255707762557\n",
            "% Predicting the same (3.0): 0.8949771689497716\n",
            "% Predicting the below (3.0): 0.0273972602739726\n",
            "****\n",
            "length: 198\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.07575757575757576\n",
            "% Predicting the below (3.5): 0.9242424242424242\n",
            "****\n",
            "length: 93\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.0\n",
            "% Predicting the below (4.0): 1.0\n",
            "****\n",
            "length: 35\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 4\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "syntax\n",
            "length: 4\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 5\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 96\n",
            "% Predicting the above (2.0): 1.0\n",
            "% Predicting the same (2.0): 0.0\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 149\n",
            "% Predicting the above (2.5): 0.7583892617449665\n",
            "% Predicting the same (2.5): 0.24161073825503357\n",
            "% Predicting the below (2.5): 0.0\n",
            "****\n",
            "length: 257\n",
            "% Predicting the above (3.0): 0.05058365758754864\n",
            "% Predicting the same (3.0): 0.8287937743190662\n",
            "% Predicting the below (3.0): 0.12062256809338522\n",
            "****\n",
            "length: 170\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.09411764705882353\n",
            "% Predicting the below (3.5): 0.9058823529411765\n",
            "****\n",
            "length: 81\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.0\n",
            "% Predicting the below (4.0): 1.0\n",
            "****\n",
            "length: 19\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 2\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "vocabulary\n",
            "vocabulary==1.0 has 0 rows\n",
            "****\n",
            "length: 4\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 26\n",
            "% Predicting the above (2.0): 1.0\n",
            "% Predicting the same (2.0): 0.0\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 101\n",
            "% Predicting the above (2.5): 1.0\n",
            "% Predicting the same (2.5): 0.0\n",
            "% Predicting the below (2.5): 0.0\n",
            "****\n",
            "length: 305\n",
            "% Predicting the above (3.0): 0.3180327868852459\n",
            "% Predicting the same (3.0): 0.6786885245901639\n",
            "% Predicting the below (3.0): 0.003278688524590164\n",
            "****\n",
            "length: 194\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.4381443298969072\n",
            "% Predicting the below (3.5): 0.5618556701030928\n",
            "****\n",
            "length: 122\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.0\n",
            "% Predicting the below (4.0): 1.0\n",
            "****\n",
            "length: 24\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 7\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "phraseology\n",
            "length: 3\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 3\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 74\n",
            "% Predicting the above (2.0): 1.0\n",
            "% Predicting the same (2.0): 0.0\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 152\n",
            "% Predicting the above (2.5): 0.9144736842105263\n",
            "% Predicting the same (2.5): 0.08552631578947369\n",
            "% Predicting the below (2.5): 0.0\n",
            "****\n",
            "length: 242\n",
            "% Predicting the above (3.0): 0.02066115702479339\n",
            "% Predicting the same (3.0): 0.9214876033057852\n",
            "% Predicting the below (3.0): 0.05785123966942149\n",
            "****\n",
            "length: 180\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.005555555555555556\n",
            "% Predicting the below (3.5): 0.9944444444444445\n",
            "****\n",
            "length: 107\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.0\n",
            "% Predicting the below (4.0): 1.0\n",
            "****\n",
            "length: 18\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 4\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "grammar\n",
            "length: 3\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 6\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 95\n",
            "% Predicting the above (2.0): 1.0\n",
            "% Predicting the same (2.0): 0.0\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 181\n",
            "% Predicting the above (2.5): 0.8397790055248618\n",
            "% Predicting the same (2.5): 0.16022099447513813\n",
            "% Predicting the below (2.5): 0.0\n",
            "****\n",
            "length: 193\n",
            "% Predicting the above (3.0): 0.0\n",
            "% Predicting the same (3.0): 0.9015544041450777\n",
            "% Predicting the below (3.0): 0.09844559585492228\n",
            "****\n",
            "length: 176\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.005681818181818182\n",
            "% Predicting the below (3.5): 0.9943181818181818\n",
            "****\n",
            "length: 96\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.0\n",
            "% Predicting the below (4.0): 1.0\n",
            "****\n",
            "length: 25\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 8\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "conventions\n",
            "length: 1\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 5\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 85\n",
            "% Predicting the above (2.0): 1.0\n",
            "% Predicting the same (2.0): 0.0\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 155\n",
            "% Predicting the above (2.5): 0.9612903225806452\n",
            "% Predicting the same (2.5): 0.03870967741935484\n",
            "% Predicting the below (2.5): 0.0\n",
            "****\n",
            "length: 240\n",
            "% Predicting the above (3.0): 0.03333333333333333\n",
            "% Predicting the same (3.0): 0.9333333333333333\n",
            "% Predicting the below (3.0): 0.03333333333333333\n",
            "****\n",
            "length: 168\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.03571428571428571\n",
            "% Predicting the below (3.5): 0.9642857142857143\n",
            "****\n",
            "length: 96\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.0\n",
            "% Predicting the below (4.0): 1.0\n",
            "****\n",
            "length: 26\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 7\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "cohesion\n",
            "% Predicting within .5: 0.7535121328224776\n",
            "syntax\n",
            "% Predicting within .5: 0.7739463601532567\n",
            "vocabulary\n",
            "% Predicting within .5: 0.8173690932311622\n",
            "phraseology\n",
            "% Predicting within .5: 0.7573435504469987\n",
            "grammar\n",
            "% Predicting within .5: 0.7100893997445722\n",
            "conventions\n",
            "% Predicting within .5: 0.7420178799489144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_compare_v1 = pd.read_csv(\"predict_bert_0.csv\")\n",
        "for component in label_cols:\n",
        "  print(pd.crosstab(df_compare_v1[component], df_compare_v1[\"transformed_pred_\"+component], margins=True))\n",
        "  print()"
      ],
      "metadata": {
        "id": "eFAPhe1LKsYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT-base-cased with its first 6 layers unfrozen"
      ],
      "metadata": {
        "id": "xV2k32ZKDMq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed parameters\n",
        "dense_dim = 6\n",
        "number_of_splits = 2\n",
        "random_state = 2023\n",
        "mse_loss = MCRMSE\n",
        "mse_metrics = MCRMSE\n",
        "model_name_list = ['Bert', 'Bertweet'] # Roberta\n",
        "\n",
        "df_train = pd.read_csv('df_train_split.csv')\n",
        "df_test = pd.read_csv('df_test_split.csv')\n",
        "print(f\"Length of train data : {len(df_train)}\")\n",
        "print(f\"Length of test data : {len(df_test)}\")\n",
        "y_test = np.array(df_test[label_cols], dtype = \"float32\")"
      ],
      "metadata": {
        "id": "kLUL0--ADHKL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae5c3fbe-51bd-4e51-a786-0f30fef9648e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train data : 3128\n",
            "Length of test data : 783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable parameter dictionary\n",
        "param_list = [   # Partially frozen base layer\n",
        "                 {'epochs'                  : 10,\n",
        "                  'batch_size'              : 8,\n",
        "                  'learning_rate'           : 1e-5,\n",
        "                  'validation_split'        : .2,\n",
        "                  'dropout'                 : .1,\n",
        "                  'number_of_hidden_layers' : 2,\n",
        "                  'hidden_layer_node_count' : 64,\n",
        "                  'retrain_layer_count'     : 6\n",
        "                 }\n",
        "             ]"
      ],
      "metadata": {
        "id": "VlW3K8Y6QJXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, param_entry in enumerate(param_list):\n",
        "    MAX_LEN = 512\n",
        "    epoch_val = param_entry['epochs']\n",
        "    batch_size_val = param_entry['batch_size']\n",
        "    learning_rate_val = param_entry['learning_rate']\n",
        "    validation_split_val = param_entry['validation_split']\n",
        "    dropout_val = param_entry['dropout']\n",
        "    number_of_hidden_layers_val = param_entry['number_of_hidden_layers']\n",
        "    hidden_layer_node_count_val = param_entry['hidden_layer_node_count']\n",
        "    retrain_layer_count_val = param_entry['retrain_layer_count']\n",
        "\n",
        "    print(\"************************\")\n",
        "    print(f\"Iteration : {idx + 1}\")\n",
        "    print(\"Parameters...\")\n",
        "    print(f\"Epochs : {epoch_val}\")\n",
        "    print(f\"Batch size : {batch_size_val}\")\n",
        "    print(f\"Learning rate : {learning_rate_val}\")\n",
        "    print(f\"Validation split : {validation_split_val}\")\n",
        "    print(f\"Dropout : {dropout_val}\")\n",
        "    print(f\"Number of hidden layers : {number_of_hidden_layers_val}\")\n",
        "    print(f\"Hidden layer node count : {hidden_layer_node_count_val}\")\n",
        "    print(f\"Retrain layer count : {retrain_layer_count_val}\")\n",
        "    print(\"************************\")\n",
        "    set_config_param(20230214)\n",
        "\n",
        "    model_tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_CHKPT)\n",
        "    model = TFRobertaModel.from_pretrained(BERT_MODEL_CHKPT)\n",
        "\n",
        "    train_input_ids, train_attention_masks = text_encode(df_train['full_text'], model_tokenizer, MAX_LEN)\n",
        "    test_input_ids, test_attention_masks = text_encode(df_test['full_text'], model_tokenizer, MAX_LEN)\n",
        "\n",
        "    y_train = np.array(df_train[label_cols], dtype = \"float32\")\n",
        "\n",
        "    bert = build_regression_model(loss= \"MCRMSE\", \n",
        "                                      model_name = \"Bert\",\n",
        "                                      dense_dim = 6, \n",
        "                                      MAX_LEN = 512,\n",
        "                                      learning_rate = learning_rate_val,\n",
        "                                      dropout=dropout_val,\n",
        "                                      number_of_hidden_layers = number_of_hidden_layers_val,\n",
        "                                      hidden_layer_node_count = hidden_layer_node_count_val,\n",
        "                                      retrain_layer_count = retrain_layer_count_val)\n",
        "    bert.summary()\n",
        "\n",
        "    history_v1 = bert.fit((train_input_ids, train_attention_masks),\n",
        "                  y_train,\n",
        "                  batch_size = batch_size_val,     \n",
        "                  epochs = epoch_val,\n",
        "                  validation_split = validation_split_val\n",
        "                  )\n",
        "\n",
        "    history_v1_df = pd.DataFrame(history_v1.history)\n",
        "\n",
        "    score_v1 = bert.evaluate([test_input_ids, test_attention_masks], \n",
        "                    y_test\n",
        "                  ) \n",
        "\n",
        "    predictions_v1 = bert.predict([test_input_ids, test_attention_masks])\n",
        "    df_pred_v1 = pd.DataFrame(predictions_v1, columns=['pred_' + c for c in label_cols])\n",
        "\n",
        "    for col in label_cols:\n",
        "      df_pred_v1['transformed_pred_' + col] = df_pred_v1['pred_' + col].apply(lambda x : roundPartial(x, .5))\n",
        "    \n",
        "    df_compare_v1= pd.merge(df_test, df_pred_v1, left_index = True, right_index = True)\n",
        "    df_compare_v1.to_csv(\"predict_bert_6.csv\", index=False)\n",
        "    all = []\n",
        "    for col in label_cols:\n",
        "      all.append(((df_compare_v1[col]-df_compare_v1[\"transformed_pred_\"+col]).pow(2).mean())**(0.5))\n",
        "    RMSE_scaled = statistics.fmean(all)\n",
        "    print(f\"RMSE_scaled: {RMSE_scaled}\")\n",
        "    \n",
        "    for label in label_cols:\n",
        "      print(label)\n",
        "      hall_of_fame(df_compare_v1,label,1)\n",
        "      print(\"************************\")\n",
        "      hall_of_shame(df_compare_v1,label,1)\n",
        "      print(\"************************\")\n",
        "    for component in label_cols:\n",
        "      print(component)\n",
        "      print(\"% Predicting too high: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\">\"+component))/len(df_compare_v1)))\n",
        "      print(\"% Predicted correctly: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"==\"+component))/len(df_compare_v1)))\n",
        "      print(\"% Predicting too low: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"<\"+component))/len(df_compare_v1)))\n",
        "      print(\"****\")\n",
        "    # Predicting too high or low for every score? \n",
        "    # for component in label_cols:\n",
        "    #   print(component)\n",
        "\n",
        "    #   for score in [1.0,1.5,2.0,2.5,3.0,3.5,4.0,4.5,5.0]:\n",
        "    #     if len(df_compare_v1[df_compare_v1[component]==score])==0:\n",
        "    #       print(component+\"==\"+str(score)+\" has 0 rows\")\n",
        "    #     else:\n",
        "    #       print(f'length: {len(df_compare_v1[df_compare_v1[component]==score])}')\n",
        "    #       print(\"% Predicting the above (\"+str(score)+\"): \" +\n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) &\n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]>score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #       print(\"% Predicting the same (\"+str(score)+\"): \" +\n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) & \n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]==score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #       print(\"% Predicting the below (\"+str(score)+\"): \" + \n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) & \n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]<score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #     print(\"****\")\n",
        "\n",
        "    for component in label_cols:\n",
        "      print(component)\n",
        "      print(\"% Predicting within .5: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"<=(\"+component+\"+.5) and transformed_pred_\"+component+\">=(\"+component+\"-.5)\"))/len(df_compare_v1)))"
      ],
      "metadata": {
        "id": "ri_zkHoCQJj8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6308854cf2aa4c8bbfe6135f15de39ca",
            "f688cb89165c489c8e5fb2ec4670f31b",
            "537c4b5bd6f449e1802fe999ad913a3a",
            "a4d4ba6063234549a183f5c7c82d6682",
            "1f8bb93c150a4908bac723af047c512d",
            "b9e7b866791c426d8106c63f2c9804ee",
            "20d6a17275464462b85e5d5156030036",
            "25bf8560ba834bc0af23e7a0b8190bc3",
            "ca424cbd85284861903b2cb991b60423",
            "5584a104c9a541ce885efddfeb933ecd",
            "1098570da60d456a95504654951d79b9",
            "9fd50d63943a4c09bb01d93099b1e541",
            "63da958fcb444e9a989ef476932656e5",
            "e2c03e048bde430ca1eab7d989e2a062",
            "16fc1bc897a843afa256628321eda644",
            "ab5d3ddeee4e4be49c0e9288897af115",
            "cdab9fcfda9b458490286b26edb51aa8",
            "e0ae38deb7024708a2998231e3c73bbe",
            "3a18f88f130b4a1ebbd463dfeeedb4ac",
            "de9ea2b44ca14e93abee1ace7e82d8bd",
            "3fc6950e29cc401182f79d397e0a9849",
            "2683d70e0b7243649c59544c12023c48",
            "af625878ca814014ac8b853ff1ed69e3",
            "6fc042bb266448a09d6e50a8d6085e07",
            "de4b71c543644894bb0b9f08545d8fb5",
            "bd03501ca168474681db04eaff7ee2b4",
            "e70f9f8bd21a4517bbbd37618e8eae50",
            "ceff53c1582848ae85b4374e26034661",
            "292184e323e147748933dc83f8cff702",
            "d86d0cda83554311bbdb3149d4ef2675",
            "45bceea3d6da4730b759f1c3bbc1e167",
            "80160e685b99485193ae8c164295cf68",
            "f73f563c4a214952b457b11b7e582503",
            "3885a3401fd34118a961eb60a0793fe4",
            "705fd9571662413c8aa5f4db31bd827e",
            "7a20999f4be84f0198b48126880d4f55",
            "280a88204258436c9f844215d018fcb3",
            "bd2ac54e2bf14984b47720de98054c85",
            "811dfcb024034297b512327b89a8bf57",
            "d8648b0c6522488086bb120fb1875932",
            "409f0cc38e834cdeba3cb091db1aa8ab",
            "0c04b59358fd4346b44fd61a94c111c0",
            "24319cc218b64ce4a1d3c0ea8aed6d16",
            "0df4943da1ce4680bd7db10e98edd381",
            "e96b351438fc4ff480f95df1426e08e2",
            "9d84cd638b264e4f9cc64904368d2f23",
            "c8ffda0aa8944f9ba0e167948748a360",
            "342776199ac146d697b1f24b370c4362",
            "4536c16ddd5c42c0b25d11a5e10524dc",
            "e7444a0b08f842dcb465e1d6059bacce",
            "4379a16364bc48ecadf5548bf75ac221",
            "921332b0abc148f7aafacf97beb3044d",
            "06e4f8b236634ea5a17d6823f2b43d07",
            "e2d818ae9b344a1a9946ba7c989f4e8f",
            "1cba373e7ec540328f956455cdb2c123"
          ]
        },
        "outputId": "b3061d6a-735f-4383-bc38-27083d3a617a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************************\n",
            "Iteration : 1\n",
            "Parameters...\n",
            "Epochs : 10\n",
            "Batch size : 8\n",
            "Learning rate : 1e-05\n",
            "Validation split : 0.2\n",
            "Dropout : 0.1\n",
            "Number of hidden layers : 2\n",
            "Hidden layer node count : 64\n",
            "Retrain layer count : 6\n",
            "************************\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6308854cf2aa4c8bbfe6135f15de39ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9fd50d63943a4c09bb01d93099b1e541"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af625878ca814014ac8b853ff1ed69e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3885a3401fd34118a961eb60a0793fe4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/527M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e96b351438fc4ff480f95df1426e08e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrain layers: \n",
            " ['_11', '_10', '_9', '_8', '_7', '_6']\n",
            "Number of trainable parameters : 0\n",
            "Number of non-trainable parameters : 108310272\n",
            "tf_bert_model/bert/embeddings/word_embeddings/weight:0 True\n",
            "tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0 True\n",
            "tf_bert_model/bert/embeddings/position_embeddings/embeddings:0 True\n",
            "tf_bert_model/bert/embeddings/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/embeddings/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/attention/self/value/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/attention/self/value/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/attention/output/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/attention/output/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/intermediate/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/intermediate/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/output/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/output/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/gamma:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/beta:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/attention/self/query/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/attention/self/query/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/attention/self/key/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/attention/self/key/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/attention/self/value/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/attention/self/value/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/attention/output/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/attention/output/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/intermediate/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/intermediate/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/output/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/output/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/gamma:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/beta:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/attention/self/query/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/attention/self/query/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/attention/self/key/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/attention/self/key/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/attention/self/value/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/attention/self/value/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/attention/output/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/attention/output/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/intermediate/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/intermediate/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/output/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/output/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/gamma:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/beta:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/attention/self/query/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/attention/self/query/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/attention/self/key/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/attention/self/key/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/attention/self/value/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/attention/self/value/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/attention/output/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/attention/output/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/intermediate/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/intermediate/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/output/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/output/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/gamma:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/beta:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/attention/self/query/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/attention/self/query/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/attention/self/key/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/attention/self/key/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/attention/self/value/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/attention/self/value/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/attention/output/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/attention/output/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/intermediate/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/intermediate/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/output/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/output/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/gamma:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/beta:0 False\n",
            "tf_bert_model/bert/encoder/layer_._6/attention/self/query/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/attention/self/query/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/attention/self/key/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/attention/self/key/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/attention/self/value/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/attention/self/value/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/attention/output/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/attention/output/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/intermediate/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/intermediate/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/output/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/output/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/attention/self/query/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/attention/self/query/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/attention/self/key/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/attention/self/key/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/attention/self/value/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/attention/self/value/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/attention/output/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/attention/output/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/intermediate/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/intermediate/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/output/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/output/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/attention/self/query/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/attention/self/query/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/attention/self/key/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/attention/self/key/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/attention/self/value/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/attention/self/value/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/attention/output/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/attention/output/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/intermediate/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/intermediate/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/output/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/output/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/attention/self/query/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/attention/self/query/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/attention/self/key/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/attention/self/key/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/attention/self/value/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/attention/self/value/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/attention/output/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/attention/output/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/intermediate/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/intermediate/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/output/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/output/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/attention/self/query/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/attention/self/query/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/attention/self/key/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/attention/self/key/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/attention/self/value/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/attention/self/value/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/attention/output/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/attention/output/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/intermediate/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/intermediate/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/output/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/output/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/attention/self/query/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/attention/self/query/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/attention/self/key/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/attention/self/key/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/attention/self/value/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/attention/self/value/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/attention/output/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/attention/output/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/intermediate/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/intermediate/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/output/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/output/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/pooler/dense/kernel:0 True\n",
            "tf_bert_model/bert/pooler/dense/bias:0 True\n",
            "Number of trainable parameters : 0\n",
            "Number of non-trainable parameters : 108310272\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " hidden_layer_1 (Dense)         (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_layer_1 (Dropout)      (None, 64)           0           ['hidden_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            " hidden_layer_2 (Dense)         (None, 64)           4160        ['dropout_layer_1[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_layer_2 (Dropout)      (None, 64)           0           ['hidden_layer_2[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 6)            390         ['dropout_layer_2[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,364,038\n",
            "Trainable params: 53,766\n",
            "Non-trainable params: 108,310,272\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " hidden_layer_1 (Dense)         (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_layer_1 (Dropout)      (None, 64)           0           ['hidden_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            " hidden_layer_2 (Dense)         (None, 64)           4160        ['dropout_layer_1[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_layer_2 (Dropout)      (None, 64)           0           ['hidden_layer_2[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 6)            390         ['dropout_layer_2[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,364,038\n",
            "Trainable params: 53,766\n",
            "Non-trainable params: 108,310,272\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "313/313 [==============================] - 175s 506ms/step - loss: 3.0412 - MCRMSE: 3.0408 - val_loss: 2.5215 - val_MCRMSE: 2.5272\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 146s 467ms/step - loss: 2.1701 - MCRMSE: 2.1698 - val_loss: 1.5060 - val_MCRMSE: 1.5115\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 162s 517ms/step - loss: 1.2890 - MCRMSE: 1.2887 - val_loss: 0.7137 - val_MCRMSE: 0.7179\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 161s 515ms/step - loss: 0.9671 - MCRMSE: 0.9671 - val_loss: 0.6008 - val_MCRMSE: 0.6033\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 161s 514ms/step - loss: 0.9235 - MCRMSE: 0.9236 - val_loss: 0.5891 - val_MCRMSE: 0.5913\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 161s 514ms/step - loss: 0.8935 - MCRMSE: 0.8935 - val_loss: 0.5829 - val_MCRMSE: 0.5851\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 161s 514ms/step - loss: 0.8828 - MCRMSE: 0.8828 - val_loss: 0.5765 - val_MCRMSE: 0.5787\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 161s 514ms/step - loss: 0.8670 - MCRMSE: 0.8669 - val_loss: 0.5704 - val_MCRMSE: 0.5725\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 161s 514ms/step - loss: 0.8443 - MCRMSE: 0.8442 - val_loss: 0.5664 - val_MCRMSE: 0.5687\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 161s 515ms/step - loss: 0.8313 - MCRMSE: 0.8312 - val_loss: 0.5604 - val_MCRMSE: 0.5627\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.5612 - MCRMSE: 0.5618\n",
            "25/25 [==============================] - 35s 1s/step\n",
            "RMSE_scaled: 0.6330000155257528\n",
            "cohesion\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('Yes I identify with churchill and his statement that for us to reach what we '\n",
            " 'want, we have to pass for a lot of things.  For us to be able to achieve our '\n",
            " 'goal, it doesnt matter if our goal is a short goal or a long goal, first of '\n",
            " 'all we have to pass some difficulties to be able to reach the goal that we '\n",
            " 'want. If we want to see the results of success in our life we never have to '\n",
            " 'loss the enthusiasm on it to be where we want it to be.  To reach the '\n",
            " 'porpose that we want is something fantastic because only the person that '\n",
            " 'fight for them know what they have had to pass to reach the goal. How can we '\n",
            " 'be a support for does people that need help to reach their achievements, but '\n",
            " 'for our on self is difficult to give us a impulse to reach our own goals. '\n",
            " 'The things in this life are hard nothing is easy, but not impossible. What '\n",
            " 'can we do for us, so we can always have the the enthusiasm high, so we can '\n",
            " 'have the decisition to tell our self we got this. Sometimes there have to be '\n",
            " 'a person to give us a shove to undestand that we got it. In my opinion and I '\n",
            " 'say this because this happen to me all the time, I give out advice , I help '\n",
            " 'those people that dont believe on there selfs no more, give them a word to '\n",
            " 'push them to keep goinginto the get it and tell themnever put there self '\n",
            " 'down.  Every single one that have complete a goal have had to pass on '\n",
            " 'problems, that you have problemts doesnt mean that you are on the way to '\n",
            " 'give up, to throw everything you have done at this point. Those problems, '\n",
            " 'those failure you have had are helping you to bild your character, to change '\n",
            " 'the way you see life to see the things with other prespective. I never heard '\n",
            " 'someone saying that reaching something is easy, fast or simple. To be '\n",
            " 'successful is something hard, its a huge feeling to get your own respect '\n",
            " 'that you can do it. Being successful is something difficult to overcome, the '\n",
            " 'reward is amazing. It is a nice thing to see everything whta we had go over '\n",
            " 'to get where you at is just for the effort that you put on it. Is a bless to '\n",
            " 'go forward in life tellingpeople how to do, what to do so they can get a '\n",
            " 'advice from you to be a successful person, to try very hard to achieve their '\n",
            " 'goals.  In conclusion to be a winner require to pass all difficulties that '\n",
            " 'life give out. Those failure are horrible but at the end of the day of the '\n",
            " 'day you will understand why did it happen. Whene you get along very well you '\n",
            " 'would say now I understand how to haddle out this problems. Like i said '\n",
            " 'before to achieve something is like get out of the something and enter to '\n",
            " 'other failure. when the years pass out you will have create anew version of '\n",
            " 'your character, personality that you construct, this new person will have '\n",
            " 'the capacity to make the hard esay. In my opinion I believe that getting or '\n",
            " 'achieving our goals consist on a route of failure, problems, difficulties, '\n",
            " 'ect. The things that are up on the hill those that are hard to reach are the '\n",
            " 'great ones, the right ones. ')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  2.5\n",
            "('Some students think that summer break is good for students because its long '\n",
            " 'break and students always like a long break so they can spend time with '\n",
            " 'there friends . Actually, i think that there should be year-round schools, '\n",
            " 'where there would be a 3-4 week break in the summer, a longer winter break, '\n",
            " 'and a week off in the spring and fall because students get bored to doing '\n",
            " 'same think like a study so and they can have more rest.  Some students think '\n",
            " 'that students should get a summer long break because its long break and '\n",
            " 'students always enjoy long break . If students get long break and there '\n",
            " 'parents are not in the country where student living s so they can go to out '\n",
            " 'of country for example; they can go to there hometown country to meet there '\n",
            " 'parents, friends and relatives.  I think students should get a year-round '\n",
            " 'schools, where there would be a 3-4 week break in the summer, a longer '\n",
            " 'winter break, and a week off in the spring and fall because if the students '\n",
            " 'keep coming school without break so they will be more stressful to doing '\n",
            " 'some think again and again without break. Also,  Also, if students have a '\n",
            " 'year-round schools, where there would be a 3-4 week break in the summer, a '\n",
            " 'longer winter break, and a week off in the spring and fall so they will get '\n",
            " \"a short - short break so they will be don't have so much load in there \"\n",
            " \"brains. Moreover, after a long break students don't like to come school so \"\n",
            " 'shorts break are better than long breaks.  Finally, i think a year-round '\n",
            " 'schools, where there would be a 3-4 week break in the summer, a longer '\n",
            " 'winter break, and a week off in the spring and fall is a good idea because '\n",
            " 'students get bored to doing same think like a study so and they can have '\n",
            " \"more rest. Also, after a long break students don't like to come school and \"\n",
            " 'they get more lazy, so shorts break are better than long breaks.  ')\n",
            "**********\n",
            "************************\n",
            "syntax\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('First, I would like to visit the place Spain because I want to go and see a '\n",
            " \"real Madrid. Real Madrid Is a team that it's really famous in soccer, and \"\n",
            " 'many people watch them play.  Also,I want to go with my friends to the beach '\n",
            " 'and have some fun by eating a lot of food that we never try before and '\n",
            " 'playing with the water in the beach with all my friends.  Third, my friends '\n",
            " 'and I will like to go, and visit one of the famous soccer players in the '\n",
            " 'history of soccer, and take a picture with them and there team. After, will '\n",
            " 'want to take a soccer player to come and eat with us and have some fun whit '\n",
            " 'the soccer player.  Finally, we would like to bring some family members to '\n",
            " 'the trip, and come have fun with us play a lot and take them to a park '\n",
            " \"that's great for family trip on Spain, and that we can all eat some ice \"\n",
            " 'cream at the same time and eat some great food and then go home.')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  2.5\n",
            "('I think, with that changing 4 days of work in a week have disadvantages and '\n",
            " 'some benefits. because people will not have time to live their normal life '\n",
            " 'or do work at home, they will use the same amount of energy and resources '\n",
            " 'and people will not support to work many hours in a day.  In addition, '\n",
            " 'people have already their own routine to work, even thought if some busines '\n",
            " 'try to change work days.  To began,  people will not have time to share with '\n",
            " 'their family, also working 4 day a week for 10 hours will cause problem in '\n",
            " 'your family, children in those time do not have enough responsibility to be '\n",
            " 'home by their self, even thought, people will not have time to do work at '\n",
            " 'home. For example; to clean their house, to go work after school and to '\n",
            " 'coexists their problems or thoughts with the family. And to do other works '\n",
            " 'at the end of the day.  Second, working 10 hours a day they will use the '\n",
            " 'same quantity of energy and resources because is the same sum of hours that '\n",
            " 'all people work, if they work 8 hours a day for 5 day, even that people may '\n",
            " 'use more energy, because the rest of the week people will need energy, as '\n",
            " 'well to work 10 hours a day will use the same amount of resources, to make '\n",
            " 'up all the works that you need to do.  Lastly, people will not support '\n",
            " 'working 10 hours a day, because many people have their routine to work, or '\n",
            " 'some of them have problems working to many hours, another reason why people '\n",
            " 'can not work 10 hours a day is that they have their own routine work, as '\n",
            " 'well student in school will not support to be in class. For example many '\n",
            " 'student gets bored in class juts been 8 hours in school and if we compare '\n",
            " 'there will be a lot if issue with their attendance. another point is many '\n",
            " 'student work to support their self, so in that occation they will not '\n",
            " 'available to work and make money.  To conclude, to work 10 hours a day is to '\n",
            " 'hard for many people and they will try to work less hours in a day, because '\n",
            " 'they can not have time to share with the family, also they can get sick for '\n",
            " 'being working to many hours. even thought on this times some people worked '\n",
            " '10 hours a day, but at the end of all that working to much can cause serious '\n",
            " 'problems with your health.        ')\n",
            "**********\n",
            "************************\n",
            "vocabulary\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('I think students can benefit if they are able to attend classes from home, '\n",
            " 'even know the distance but learning as a option for students who wants to '\n",
            " 'finish a carear or have a good job.  Take those classes online or videos '\n",
            " 'conferencing is not the same thing like to be able to go to classes. In '\n",
            " 'class students can ask about any question they have or get the information '\n",
            " 'they are looking for, and the schools teacher can see how they are learnig '\n",
            " \"but, online they don't have much oction like read a book or be able to ask \"\n",
            " 'any question they have to anybody.  Attend to classse is great is a oction '\n",
            " 'from student to choose but is the smart oction for for student who know what '\n",
            " 'they want to do in they future. Schools is a place where students have the '\n",
            " \"desition by you're own. There is where students can start makeing options \"\n",
            " 'and try finish what they really dream. Be able to atted classes from home is '\n",
            " 'hard thing to discuss but when students are able to go there is great '\n",
            " 'bacause is where they have to be and never give up during that time.  School '\n",
            " 'is not a principle to starts getting information about how thing are '\n",
            " 'working, or what options we can choose for be a porofessional after schools. '\n",
            " 'Prevent oction in schools is preposterous because that is not ducing, good '\n",
            " 'octions during school.  Students who rually have the decition to go to '\n",
            " 'schools even know the distace but they are benefit. that is a oction, but '\n",
            " 'when they get there is alot of information and option they can lissend from '\n",
            " 'teachers and other students. When they go to schools they are giving a step '\n",
            " 'more every day, to them life and they are benefit in school for the alot of '\n",
            " 'option they can have in schools.  Schools is a benifif for all yung people '\n",
            " 'to learnd how start life, when you get out from schools and have a good job. '\n",
            " 'for have the opportunite, students need finish school firts. Not matter the '\n",
            " 'distance or the skills they have during that period time. after that they '\n",
            " 'will see how everything is change to be better in they way.  For somo '\n",
            " 'students is hard to make that decition.  But when they have the oction and '\n",
            " 'they can do it is a good thing because they can learning more about and have '\n",
            " 'more opportunities when they graduate from schools thay have good jobs and '\n",
            " 'more oction to choose.  Some students think is preposterous to to make '\n",
            " 'decition in schools, bacause is alot of oction they can choose, and alot '\n",
            " 'thing they want to be but they only have somo octions. For somo of then is '\n",
            " 'hinder to go and pick that oportunities.  Instance when students live far '\n",
            " 'fom schools is hard to get there they need like a car to get there, but '\n",
            " 'parents are allways insist to students to go to schools not matter how hard '\n",
            " 'is all they wants is a good future for they childrens.  School is a '\n",
            " 'personality decition in life, butsmart decition for people who is looking '\n",
            " 'for good oction in life. Ertheless who finish school have more oction the '\n",
            " \"people who don't finish. During school students need have to be inmate \"\n",
            " 'because schools is a hard time.  For students in schools is like stairway, '\n",
            " 'because they walk aroung getting information, that is a good oction for '\n",
            " 'teachers, to stall information and try to preparate students to then life. '\n",
            " 'One way to be a perfectionist is graduste from schools.  Fanally when '\n",
            " 'students finish schools they did a good job and they have more option to '\n",
            " 'choose. More of they have good jods or go to college and finish a carear, '\n",
            " 'and they know how follow the the dreams, because when they was in chools '\n",
            " 'there was alot of skills and the crusts those over and over that was like '\n",
            " 'the firts hard thing they start with, that was alot of bad action they can '\n",
            " \"choose but they don't choose any of those. Finally finish with right thing, \"\n",
            " 'Now is fancy work and alot oction to choose in '\n",
            " 'life.                                                                                                          ')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.5\n",
            "original:  5.0\n",
            "(\"Imagination Over Mind  Imagination it's what sparks our creativity. Without \"\n",
            " \"imagination, knowledge means nothing because we wouldn't be able to come up \"\n",
            " 'with anything. How we create intricate characters and stories and how '\n",
            " 'incredible buildings stand tall. This is due to imagination and how we come '\n",
            " 'up with such things. Take a second and think of your favorite character from '\n",
            " 'any source of media. They were created because someone imagined them and '\n",
            " 'brought them to life. Imagination is all around us from our stories and '\n",
            " 'music to our basic everyday items. That pen on your desk was imagined up to '\n",
            " 'be able to write and pass along information.  For ages people imagined '\n",
            " 'stories and people listened. People and imagined plays,movies,books,TV and '\n",
            " 'video games all with different stories and design. These things may seem '\n",
            " 'insignificant, but people adore these stories and have been inspired. They '\n",
            " 'have been mesmerized by these worlds and characters. Imagination is what '\n",
            " 'leads people to create these stories. These stories have taught us messages '\n",
            " 'and life lessons also. They inspire us to be best version of our self and to '\n",
            " 'follow our dreams, as we see the characters do. We grow close to characters '\n",
            " 'and relate with them, making these stories more special to us. Imagination '\n",
            " 'gave us inspiring role models and heroes, they also gave us a childhood. How '\n",
            " 'we wait to see our favorite cartoon and smile with excitement waiting for '\n",
            " 'the next adventure to unfold. Imagination gave life to unforgettable '\n",
            " 'characters, how Walt Disney created Micky Mouse and countless other. These '\n",
            " \"characters and stories aren't just for children but adults as well. Stories \"\n",
            " 'of all genres exist to bring new experiences and worlds to the audience. '\n",
            " 'Imagination gave us stories to inspire,scare,to make us laugh or even cry '\n",
            " 'for the character. Imagination gave life to countless of stories something '\n",
            " 'knowledge could never do alone.  From the Eiffel Tower to an small little '\n",
            " \"house, people imagined buildings and ways to construct them. It's true you \"\n",
            " 'need to understand and know how to build but imagination is more important. '\n",
            " 'Imagination is what let us think of such designs. Even in ancient times '\n",
            " \"people put imagination and knowledge to build a house. Whether it's building \"\n",
            " 'a mud house or straw hut people imagined putting all of it together and put '\n",
            " 'it in action. How people designed cars for transportation and made it '\n",
            " 'function properly. Engineers are creative and imaginative to come up with '\n",
            " 'such intricate designs and models. Even everyday objects were imagined and '\n",
            " \"made to help you in everyday life. Whether it's a juicer to a wrench, people \"\n",
            " 'imagined these things to serve a purpose. How biomechanics creates '\n",
            " 'prosthetic arms and legs to help the disabled to move again. Theses things '\n",
            " 'all started as thought to help society and now are a vital part in today '\n",
            " 'society. Imagination is what led man kind to create items to help us in '\n",
            " 'everyday life.  Music is an form of art where people express their emotions '\n",
            " 'through song. Instruments were imagined for the sole purpose to create art. '\n",
            " 'Then playing the instrument led to more creative thinking, then songs were '\n",
            " 'imagined and instruments added to that. Songs are written with heart and '\n",
            " \"they express the artists' emotions. They are imagined and written down, \"\n",
            " 'sometimes using metaphors to express their emotions. People say that they '\n",
            " \"can say things through music that they couldn't say with words. Being able \"\n",
            " 'to imagine such meaningful songs that leave a such an impact on the listener '\n",
            " \"is incredible. Music speaks to people in a way words can't and the artist \"\n",
            " 'that make them are imaginative people.  Imagination led these artist to '\n",
            " 'produce such songs and music. Painting is an other form of imaginative art. '\n",
            " 'These artist express themselves by using strokes of paint to produce vibrant '\n",
            " 'works of art. Even though a painting is silent people speak through them to '\n",
            " 'show such meaningful works of art. Artists imagine what they want to paint '\n",
            " 'and execute and you can see such a passion in their works of art. '\n",
            " 'Imagination inspires artist to create outstanding pieces of art.  '\n",
            " 'Imagination also expresses itself in the way we dress and life style. For '\n",
            " 'the most part we choose the way we dress,where we work and what we do. When '\n",
            " 'not in uniform or work clothes we choose how we dress. We imagine ourselves '\n",
            " 'a certain way and choose to expresses ourselves that way. Our hair and how '\n",
            " \"we choose to style it also reflects our personality. Whether it's \"\n",
            " 'colored,straight,curly or even no hair at all. We also imagine what we want '\n",
            " 'in our lives and choose to study for that career. Our hobbies and interest '\n",
            " 'also show what kind of person you are. How you spend your free time is how '\n",
            " 'you reflect yourself. Our appearance and hobbies are a self reflection of '\n",
            " 'our imagination and who you are. Imagination makes you who you are, and '\n",
            " \"that's what makes everyone a different person.  Imagination might not seem \"\n",
            " \"important but it's what allows people to create stories, construct \"\n",
            " 'buildings, create items,produce music,to make art and makes you. We need '\n",
            " 'imagination even more than we need knowledge. Without imagination there '\n",
            " \"wouldn't be a way to put our knowledge to use. Imagination is the fuel of \"\n",
            " \"the world, it's what keeps everything going. It may seem insignificant at \"\n",
            " 'first but imagination is so such more. Without imagination no advancements '\n",
            " 'would be made. We need imagination to do almost everything life. Imagination '\n",
            " 'is what makes us human. Imagination over mind.        ')\n",
            "**********\n",
            "************************\n",
            "phraseology\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('Imagine that the school plans to add more time at school. I disagree of the '\n",
            " 'schools adding more time because it would be irritating,boring,stressed. and '\n",
            " 'kids do not want that to happen. The children wants to have a normal school '\n",
            " 'day. And they have to prove that they can do it,they believe in their self.  '\n",
            " 'First,It is boring because they want to have fun. And the reason why it is a '\n",
            " 'lot of fun because they want to have a good time. And thet can think about '\n",
            " 'what they want,What do they want to do when the schools are thjnking about '\n",
            " 'staying more longer at school. For example, Generic_Name went outside to '\n",
            " 'play after school.  Secondly,it is stressing because they would be crazy '\n",
            " 'about it. And the reason why it is stressing because the blood of the brian '\n",
            " 'would get bad. It would be horrible that they have blood pressure,haert '\n",
            " \"attacks,and they want to kill there self. They can't do that,but they can \"\n",
            " 'protect there self. For example,Generic_Name was taking a test but she got '\n",
            " 'nervous,Frustrated,lonly and upset.  Thirdly,it is irritating because kids '\n",
            " \"will get tired and dizzy at school. the reason why it's because their body \"\n",
            " 'do not have enough energy. For example,My best friend  Generic_Name studied '\n",
            " 'for a test,but she got tired. In my opinion it is not ok that a lot of '\n",
            " 'people get injured. And it is going to be difficult but it is worth a try,I '\n",
            " 'want a lot of people to be happy,not injured,not feeling down and feel '\n",
            " 'better about whats going on,or what is doing.  In closing,I disagree that '\n",
            " 'the school plans to add more time at school. And it is a bad idea,It would '\n",
            " 'get irritating,boring and stressed. In my opinion it is better for kids so '\n",
            " 'they can not worried about it. And it would be easier step by step and keep '\n",
            " 'going,Dont stop doing it.  I really think that it would be better if the '\n",
            " 'school would not have bullies,bad teachers back in the day because a lot of '\n",
            " 'teachers back in the they hit children because sometimes kids do not behave '\n",
            " 'and teachers think that the kids deserved it and i think that The kids do '\n",
            " 'not always get the right answer but In my opinion all teachers are different '\n",
            " 'because some teachers are nice,hardworking,sweet,mean,not inappropiate '\n",
            " 'aswell. And The teachers that i had or have from kindergarden to first '\n",
            " 'grade,second grade,third grade,fourth grade,fifith grade,sixth grade,Seventh '\n",
            " \"grade and 8th grade they're nice,helpful,caring too and thay dont hit us. \"\n",
            " 'They protect us,And i want for other kids have the same exciperence that i '\n",
            " 'have. And i want other kids or other people or everybody to be happy and '\n",
            " 'protected too. ')\n",
            "**********\n",
            "************************\n",
            "predicted:  2.5\n",
            "original:  3.0\n",
            "('It has been said that first impressions are almost impossible to change. '\n",
            " 'Some people think that are impossible to change, because they had been said '\n",
            " 'or think that you cannot change your first impression, when you at first '\n",
            " 'meet or start knowing someone, that is not true because clearly you can '\n",
            " 'change your first impression, even though it can be the same or different as '\n",
            " 'the first impression you had at the beginning of everything, but you may '\n",
            " 'also be insecure or confuse of your own thoughts and feelings.  I am in '\n",
            " 'disagreement with this prompt that it has been said that first impressions '\n",
            " 'are almost impossible to change, because just imagine clearly your first '\n",
            " 'impression it may not be the same when at first you start knowing someone, '\n",
            " 'when at first you meet someone, or even when at first you look someone by '\n",
            " 'the first time, people may also said that is impossible to assume your first '\n",
            " 'impression at someone, because your perspective of someone may be different '\n",
            " 'from another perspectives of others, you may have the same perspective or '\n",
            " 'also different from other people.  The day when at first came to United '\n",
            " 'States it was really hard for me and for my family from Mexico, I was really '\n",
            " 'nervous and also a little scared, it was one of my dreams that became real, '\n",
            " 'I was so impressed and surprised of everything, the first impression that I '\n",
            " 'used to have of United States changed, now that I am living in United '\n",
            " 'States, the impression is different because now I know how is to live in a '\n",
            " 'different country. Not always is going to be how you thought it would be, '\n",
            " 'but it can be even better, even thought your impression was different or was '\n",
            " 'the same at the beginning.  The day I came to this school Generic_School, my '\n",
            " 'impression from when I meet my counselor Generic_Name were different from my '\n",
            " 'impression after I meet her, I thought she was going to be really mad and '\n",
            " 'mean counselor or I even thought she was going to be a counselor that '\n",
            " \"doesn't like Hispanic people, but all my thoughts were wrong, my impression \"\n",
            " 'was really wrong because my thoughts about her were wrong, now that I know '\n",
            " 'how is my counselor, my first impression and perspective changed from the '\n",
            " 'one that I used to have and believe.  In conclusion, as the end of this '\n",
            " 'prompt that it has been first impressions are almost impossible to change is '\n",
            " 'wrong, that is not believable because your first impressions and your own '\n",
            " 'thoughts can be wrong, even though you thought it was going to be something '\n",
            " 'at the end is not how you thought it was going to be, first impressions are '\n",
            " 'possible to change because they can be wrong even though your perspective '\n",
            " \"can be true, or it can be also wrong. Don't let first impressions to trick \"\n",
            " 'you because they may be wrong, you can change them if you want, but make '\n",
            " 'sure to be secure.         ')\n",
            "**********\n",
            "************************\n",
            "grammar\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('Technology allows people to complete many tasks without having contact with '\n",
            " 'others. Today, people prefers to interact with technology than people. They '\n",
            " 'can check out books, shops, and play games without speaking to another '\n",
            " 'person. Some people thinks the limitation of human contact due to the use of '\n",
            " \"technology have positive effects on people's lives because technology makes \"\n",
            " 'more easy their lives, for example they not need to leave their houses for '\n",
            " 'buy or to joint with another person to play games. However, I think the '\n",
            " 'limitation of human contact due to the use of technology have negative '\n",
            " 'effects because people prefers to shop on online than stores, people use '\n",
            " 'more technology to talk, and also children plays with technology than with '\n",
            " 'another person or toys.  Today, people prefers to shop by online than '\n",
            " 'stores. I saw and lived this experience many times about buy by online but I '\n",
            " 'not feel comfortable as a store. Online shops makes feel lazy, alone, and '\n",
            " 'when you have questions obout the product nobody can answer you. I bought by '\n",
            " 'online many times but one day I understand that online shop is not healthy '\n",
            " \"for me because when I go to stores I'm practicing my English vocabulary, I \"\n",
            " 'walk alot that means that I doing a little exercise, and meet new places and '\n",
            " 'people. Shop by online avoid the human contact and gives negative effects on '\n",
            " \"people's lives.  People use more technology to talk, as facetime, facebook, \"\n",
            " 'whatssap or others applicationes. I agree to talk with this aplications with '\n",
            " 'people who lives far away but I prefer to join with my friends or family to '\n",
            " 'talk who lives close. Sometimes, I came out with my sister and their friends '\n",
            " 'who always are in their phones texting or taking pictures. In my '\n",
            " 'personality, use the phone when you are sharing with another person is not '\n",
            " 'respect and you are not enjoying the moment. The use of phones during a '\n",
            " 'meeting avoid the interaction with other human, and gives negative effects '\n",
            " \"on the people's live.  Finally, children more plays with technology than \"\n",
            " 'with another child or toys. In the past, children plays with toys or they '\n",
            " 'made their own toys. This helped to children to developed their imagination '\n",
            " 'or decover their skills. Also, children invented plays involving run, saltar '\n",
            " 'or make force; this plays helped to children to enjoy healthy and '\n",
            " 'socialiting with other child. But today, children prefers to play with '\n",
            " 'technology avoing come out and carring to be lazy, obesity, and addicting to '\n",
            " \"the technology. Children's break times likes to use their phones than talk \"\n",
            " 'with their friends or family. They think that interacting with family or '\n",
            " 'friends are old things and that is most enjoy use the phone in their break '\n",
            " 'times. The use of technology for children is a negative affect because they '\n",
            " 'not play or relationing with another people.  Today, people use more '\n",
            " 'technology than interact with another person, carring people to complete '\n",
            " 'taks wotout having contact with others. These limitation of human contact '\n",
            " \"due to the use of technology have negative effects on people's lives.\")\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  2.0\n",
            "('Schools were made for people who wants to learn and be a successful person '\n",
            " \"in life even though , there are some people who don't have the opportunity \"\n",
            " 'to be in school. Right now in some countries be on school until you are 18 '\n",
            " 'is a law but it other countries government those not care about children '\n",
            " 'future. Here in the United States they have the option for students to '\n",
            " 'attend classes from home by online or video conferencing. They have that '\n",
            " 'option specially on universities because some universities are out of the '\n",
            " 'city and a percentage of students with a bad economy may not be viable to '\n",
            " 'get transportation everyday. So In my opinion that is a great idea to have '\n",
            " 'that option on universities. They should have the same option in high school '\n",
            " 'but not to all the students because that may cause students to fail the '\n",
            " \"classes. High school 's should give that option to students with excellent \"\n",
            " 'notes and for students who live out of town. Attend classes from home by '\n",
            " 'online or videos has benefits, oneis you become more responsible,  second it '\n",
            " 'helps you to earned money, and gives you more opportunities to success.  In '\n",
            " 'one hand,Attend classes from home it may be a big responsibility because you '\n",
            " 'are doing it by your own no one is going to help you or push you to learn. '\n",
            " 'For example when you attend to class in a school or colleague there is '\n",
            " 'always a teacher ,who is there to help you,supports you ,and make sure you '\n",
            " \"don't fail your semester, they also make sure that you are learning and \"\n",
            " 'getting better everyday. Instead when you have to attend classes by yourself '\n",
            " 'you must be confident and responsible to make sure that you are going to '\n",
            " \"take classes everyday and don't waste the opportunity,because no one is \"\n",
            " 'going to be telling you more than 3threet times to do you work .There are '\n",
            " \"some students that don't know what be a responsible person means, does \"\n",
            " 'students may not be viable to get good greats by taking classes from home. '\n",
            " 'This kind of students need help from someone to push them and teach them to '\n",
            " 'be a responsible person. Be a responsible person is important because it '\n",
            " \"helps you to success in life gives more opportunities and you don't depend \"\n",
            " 'from nobody you learn how to do things by your own.  In the other hand one '\n",
            " 'more benefit to attend classes by home in online it helps you to earn money '\n",
            " 'specially if you live in large distance from school. A few houses are '\n",
            " 'located miles away from the city that means schools are located miles a way '\n",
            " 'from home. In that case attend classes from school it would be very helpful '\n",
            " 'and a big opportunity. Because take transportation everyday Monday to Friday '\n",
            " 'it may be expense because you may pay at mornings to get to school and pay '\n",
            " 'back in the afternoon to go back home. One more benefit is that it help you '\n",
            " 'to success,you may be a viable to find a job. For example you can do your '\n",
            " 'online classes in the mornings and find a part-time in the afternoon. Many '\n",
            " 'students do this they go to school on mornings and work for a couples of '\n",
            " 'hours at night. But if you could attend classes from home it would be so '\n",
            " 'much easier to work and study at the same time you would made your own '\n",
            " 'schedule withou a problem. Also make sure to give enough of time to do your '\n",
            " 'online classes and get good greats.  In conclusion  I do believe this potion '\n",
            " 'to attend classes from home in online or videos is a great opportunity. '\n",
            " 'Specially for students who live out of the city and for everyone who was to '\n",
            " 'success in life no matter what. School and universities should let students '\n",
            " 'know about this option. I am agree and I believe that I may not be the only '\n",
            " 'one who support this idea. Therefore this opportunity should give to '\n",
            " 'students who really needs it and no to those who would waste it .This kind '\n",
            " 'of option should be in all over the world to help people with bad economy '\n",
            " 'and help those who want to success and have a passion to learn. Students who '\n",
            " 'have the opportunity to attend school everyday without a problem should know '\n",
            " 'that there is people that live far from the city that they would love to be '\n",
            " 'seated in a classroom and attend school everyday.        ')\n",
            "**********\n",
            "************************\n",
            "conventions\n",
            "predicted:  3.5\n",
            "original:  3.5\n",
            "('Should students graduate in three years?  Some school offer programs that '\n",
            " 'allow students to graduate in three years. Students should graduate in three '\n",
            " 'years because, they have more time planing what they want to do, they have '\n",
            " 'more time to work and save money for college and they have more time to '\n",
            " 'spend time with their family. To have ideas who they can do during that '\n",
            " 'year.  Students should graduate from High school in three years because, '\n",
            " \"some students don't know what career they want or they don't know if work or \"\n",
            " 'continue studying. In that year they can think and choose what they want. '\n",
            " 'One of my friends graduated the last year of school and she stay at home '\n",
            " \"because she doesn't know what career choose, so she just stay at home \"\n",
            " \"because she doesn't know what to study and can't find a job yet.  Some \"\n",
            " 'students after four years in High School, they take one year more to think '\n",
            " 'and relax at home. That is why i think is a good idea just three years of '\n",
            " 'High School. They can take that year to work and save money for college, if '\n",
            " 'they want to. They can just start work to adapt to their new life or new '\n",
            " 'thing that are going to learn. In a fact, student can graduate in three '\n",
            " 'years of High School because is better for them. I think is better because '\n",
            " 'it help those student that are more than eighteen to graduate not too old.  '\n",
            " 'Some people think that students should not graduate from High school in '\n",
            " 'three years because, they have less time, but they are wrong because, '\n",
            " 'students can take the most important classes or they can take classes in the '\n",
            " 'evenings. Some students take courses during the summers. Some students want '\n",
            " 'to graduate early because have some goals that they want to complete. In the '\n",
            " 'future there can be online classes for those who need extra classes.  In '\n",
            " 'conclusion, graduate from High school in three years is a good idea because, '\n",
            " 'students can start college or the work force one year early. Students have '\n",
            " 'more time to search a good college and to prepare their thing. This is good '\n",
            " 'for parents too because, they can go to the college that their son or '\n",
            " 'daughter wants to go.  ')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.5\n",
            "original:  4.0\n",
            "('High school students should graduate in three years instead of traditional '\n",
            " 'four years. Most student who follows this plan should work hard and take '\n",
            " 'more courses in the summer or in the evening. Therefore, students will have '\n",
            " 'a good choice to work one year early or to enter the college early. Students '\n",
            " 'will finish high school early, work force one year early, achieve their '\n",
            " 'goals early. These reasons are why high school students should graduate in '\n",
            " 'three years instead of traditional four years.  Firstly, students have a '\n",
            " 'good idea to finish high school early. For example, some students take a '\n",
            " 'courses during the summers and some of them take courses during the '\n",
            " 'evenings. When students take the courses during summer and in the evening, '\n",
            " 'students will finish school early. In addition, some students may not be '\n",
            " 'able to take elective courses. When student not taking elective courses, '\n",
            " 'they will finish high school one year early. when students finish high '\n",
            " 'school early, they will have time to achieve their dreams.  Secondly, '\n",
            " 'students will have time to work force one year early. For example, some '\n",
            " 'students work hard for saving some money to pay the college. When students '\n",
            " 'enter the college, they need money to pay the college for the courses which '\n",
            " 'they will taking it. Therefore, some students like to finish high school '\n",
            " 'early for to have time to work one year early. When students work hard and '\n",
            " 'saving money for college, they will study without any worried about the '\n",
            " 'money that should pay to college.  Most importantly, students will have time '\n",
            " 'achieve their goals early. For example, some students want to achieve their '\n",
            " 'goals earl, for to have a good career. When students achieve their goals, '\n",
            " 'they will have a good life in the future, and they will have a jobs or '\n",
            " 'career to support their life. In addition, students who achieve their goals '\n",
            " 'early, they will opportunity to achieve another goals. When students achieve '\n",
            " 'another goals, they will make a future more better.  Some people argue that '\n",
            " 'high school students should not graduate in three years instead of the '\n",
            " 'traditional four years. They say students will not be able to take elective '\n",
            " 'courses. This may be true; however, when students will not be able to take '\n",
            " 'elective courses, they will achieve their dreams early. In addition, when '\n",
            " 'students graduate early they will have time to working and saving money for '\n",
            " 'college. In fact, students will have a good choice to work one year early or '\n",
            " 'to enter the college early.  In conclusion, students have a good idea to '\n",
            " 'finish high school early, have time to work force one year early, and '\n",
            " 'students will have time to achieve their goals early. These reasons are why '\n",
            " 'students should graduate in three years instead of the traditional four '\n",
            " 'years. Some students take a courses during the summers and some of them take '\n",
            " 'courses during the evenings, for graduate early. Some students work hard for '\n",
            " 'saving some money to pay the college. Some students want to achieve their '\n",
            " 'goals earl, for to have a good career.')\n",
            "**********\n",
            "************************\n",
            "cohesion\n",
            "% Predicting too high: 0.28607918263090676\n",
            "% Predicted correctly: 0.29757343550446996\n",
            "% Predicting too low: 0.4163473818646232\n",
            "****\n",
            "syntax\n",
            "% Predicting too high: 0.2656449553001277\n",
            "% Predicted correctly: 0.33588761174968074\n",
            "% Predicting too low: 0.39846743295019155\n",
            "****\n",
            "vocabulary\n",
            "% Predicting too high: 0.227330779054917\n",
            "% Predicted correctly: 0.3997445721583653\n",
            "% Predicting too low: 0.37292464878671777\n",
            "****\n",
            "phraseology\n",
            "% Predicting too high: 0.3269476372924649\n",
            "% Predicted correctly: 0.3065134099616858\n",
            "% Predicting too low: 0.3665389527458493\n",
            "****\n",
            "grammar\n",
            "% Predicting too high: 0.3116219667943806\n",
            "% Predicted correctly: 0.2822477650063857\n",
            "% Predicting too low: 0.4061302681992337\n",
            "****\n",
            "conventions\n",
            "% Predicting too high: 0.4125159642401022\n",
            "% Predicted correctly: 0.28991060025542786\n",
            "% Predicting too low: 0.29757343550446996\n",
            "****\n",
            "cohesion\n",
            "length: 2\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 6\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 64\n",
            "% Predicting the above (2.0): 1.0\n",
            "% Predicting the same (2.0): 0.0\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 162\n",
            "% Predicting the above (2.5): 0.8888888888888888\n",
            "% Predicting the same (2.5): 0.1111111111111111\n",
            "% Predicting the below (2.5): 0.0\n",
            "****\n",
            "length: 219\n",
            "% Predicting the above (3.0): 0.0365296803652968\n",
            "% Predicting the same (3.0): 0.91324200913242\n",
            "% Predicting the below (3.0): 0.0502283105022831\n",
            "****\n",
            "length: 198\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.07575757575757576\n",
            "% Predicting the below (3.5): 0.9242424242424242\n",
            "****\n",
            "length: 93\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.0\n",
            "% Predicting the below (4.0): 1.0\n",
            "****\n",
            "length: 35\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 4\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "syntax\n",
            "length: 4\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 5\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 96\n",
            "% Predicting the above (2.0): 1.0\n",
            "% Predicting the same (2.0): 0.0\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 149\n",
            "% Predicting the above (2.5): 0.6912751677852349\n",
            "% Predicting the same (2.5): 0.3087248322147651\n",
            "% Predicting the below (2.5): 0.0\n",
            "****\n",
            "length: 257\n",
            "% Predicting the above (3.0): 0.0\n",
            "% Predicting the same (3.0): 0.8287937743190662\n",
            "% Predicting the below (3.0): 0.17120622568093385\n",
            "****\n",
            "length: 170\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.023529411764705882\n",
            "% Predicting the below (3.5): 0.9764705882352941\n",
            "****\n",
            "length: 81\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.0\n",
            "% Predicting the below (4.0): 1.0\n",
            "****\n",
            "length: 19\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 2\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "vocabulary\n",
            "vocabulary==1.0 has 0 rows\n",
            "****\n",
            "length: 4\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 26\n",
            "% Predicting the above (2.0): 1.0\n",
            "% Predicting the same (2.0): 0.0\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 101\n",
            "% Predicting the above (2.5): 0.9702970297029703\n",
            "% Predicting the same (2.5): 0.0297029702970297\n",
            "% Predicting the below (2.5): 0.0\n",
            "****\n",
            "length: 305\n",
            "% Predicting the above (3.0): 0.16393442622950818\n",
            "% Predicting the same (3.0): 0.8163934426229508\n",
            "% Predicting the below (3.0): 0.019672131147540985\n",
            "****\n",
            "length: 194\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.31443298969072164\n",
            "% Predicting the below (3.5): 0.6855670103092784\n",
            "****\n",
            "length: 122\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.0\n",
            "% Predicting the below (4.0): 1.0\n",
            "****\n",
            "length: 24\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 7\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "phraseology\n",
            "length: 3\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 3\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 74\n",
            "% Predicting the above (2.0): 1.0\n",
            "% Predicting the same (2.0): 0.0\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 152\n",
            "% Predicting the above (2.5): 0.8947368421052632\n",
            "% Predicting the same (2.5): 0.10526315789473684\n",
            "% Predicting the below (2.5): 0.0\n",
            "****\n",
            "length: 242\n",
            "% Predicting the above (3.0): 0.1652892561983471\n",
            "% Predicting the same (3.0): 0.7851239669421488\n",
            "% Predicting the below (3.0): 0.049586776859504134\n",
            "****\n",
            "length: 180\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.18888888888888888\n",
            "% Predicting the below (3.5): 0.8111111111111111\n",
            "****\n",
            "length: 107\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.0\n",
            "% Predicting the below (4.0): 1.0\n",
            "****\n",
            "length: 18\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 4\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "grammar\n",
            "length: 3\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 6\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 95\n",
            "% Predicting the above (2.0): 1.0\n",
            "% Predicting the same (2.0): 0.0\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 181\n",
            "% Predicting the above (2.5): 0.7679558011049724\n",
            "% Predicting the same (2.5): 0.23204419889502761\n",
            "% Predicting the below (2.5): 0.0\n",
            "****\n",
            "length: 193\n",
            "% Predicting the above (3.0): 0.0051813471502590676\n",
            "% Predicting the same (3.0): 0.9119170984455959\n",
            "% Predicting the below (3.0): 0.08290155440414508\n",
            "****\n",
            "length: 176\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.017045454545454544\n",
            "% Predicting the below (3.5): 0.9829545454545454\n",
            "****\n",
            "length: 96\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.0\n",
            "% Predicting the below (4.0): 1.0\n",
            "****\n",
            "length: 25\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 8\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "conventions\n",
            "length: 1\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 5\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 85\n",
            "% Predicting the above (2.0): 1.0\n",
            "% Predicting the same (2.0): 0.0\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 155\n",
            "% Predicting the above (2.5): 0.9741935483870968\n",
            "% Predicting the same (2.5): 0.025806451612903226\n",
            "% Predicting the below (2.5): 0.0\n",
            "****\n",
            "length: 240\n",
            "% Predicting the above (3.0): 0.3375\n",
            "% Predicting the same (3.0): 0.6541666666666667\n",
            "% Predicting the below (3.0): 0.008333333333333333\n",
            "****\n",
            "length: 168\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.39285714285714285\n",
            "% Predicting the below (3.5): 0.6071428571428571\n",
            "****\n",
            "length: 96\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.0\n",
            "% Predicting the below (4.0): 1.0\n",
            "****\n",
            "length: 26\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 7\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "cohesion\n",
            "% Predicting within .5: 0.7496807151979565\n",
            "syntax\n",
            "% Predicting within .5: 0.7675606641123882\n",
            "vocabulary\n",
            "% Predicting within .5: 0.8339719029374202\n",
            "phraseology\n",
            "% Predicting within .5: 0.7803320561941252\n",
            "grammar\n",
            "% Predicting within .5: 0.7318007662835249\n",
            "conventions\n",
            "% Predicting within .5: 0.7445721583652618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_compare_v1 = pd.read_csv(\"predict_bert_6.csv\")\n",
        "for component in label_cols:\n",
        "  print(pd.crosstab(df_compare_v1[component], df_compare_v1[\"transformed_pred_\"+component], margins=True))\n",
        "  print()"
      ],
      "metadata": {
        "id": "OVOPBW0OK1Z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT-base-cased with all 12 layers unfrozen"
      ],
      "metadata": {
        "id": "nqdHzmdaDSGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed parameters\n",
        "dense_dim = 6\n",
        "number_of_splits = 2\n",
        "random_state = 2023\n",
        "mse_loss = MCRMSE\n",
        "mse_metrics = MCRMSE\n",
        "model_name_list = ['Bert', 'Bertweet'] # Roberta\n",
        "\n",
        "df_train = pd.read_csv('df_train_split.csv')\n",
        "df_test = pd.read_csv('df_test_split.csv')\n",
        "print(f\"Length of train data : {len(df_train)}\")\n",
        "print(f\"Length of test data : {len(df_test)}\")\n",
        "y_test = np.array(df_test[label_cols], dtype = \"float32\")"
      ],
      "metadata": {
        "id": "_tm-53JKDWJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d9332de-8997-4269-d438-0bf618d80afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train data : 3128\n",
            "Length of test data : 783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable parameter dictionary\n",
        "param_list = [   # Completely unfrozen base layer\n",
        "                 {'epochs'                  : 10,\n",
        "                  'batch_size'              : 8,\n",
        "                  'learning_rate'           : 1e-5,\n",
        "                  'validation_split'        : .2,\n",
        "                  'dropout'                 : .1,\n",
        "                  'number_of_hidden_layers' : 2,\n",
        "                  'hidden_layer_node_count' : 64,\n",
        "                  'retrain_layer_count'     : 12\n",
        "                 },\n",
        "             ]"
      ],
      "metadata": {
        "id": "hHIjC1XYQKAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, param_entry in enumerate(param_list):\n",
        "    MAX_LEN = 512\n",
        "    epoch_val = param_entry['epochs']\n",
        "    batch_size_val = param_entry['batch_size']\n",
        "    learning_rate_val = param_entry['learning_rate']\n",
        "    validation_split_val = param_entry['validation_split']\n",
        "    dropout_val = param_entry['dropout']\n",
        "    number_of_hidden_layers_val = param_entry['number_of_hidden_layers']\n",
        "    hidden_layer_node_count_val = param_entry['hidden_layer_node_count']\n",
        "    retrain_layer_count_val = param_entry['retrain_layer_count']\n",
        "\n",
        "    print(\"************************\")\n",
        "    print(f\"Iteration : {idx + 1}\")\n",
        "    print(\"Parameters...\")\n",
        "    print(f\"Epochs : {epoch_val}\")\n",
        "    print(f\"Batch size : {batch_size_val}\")\n",
        "    print(f\"Learning rate : {learning_rate_val}\")\n",
        "    print(f\"Validation split : {validation_split_val}\")\n",
        "    print(f\"Dropout : {dropout_val}\")\n",
        "    print(f\"Number of hidden layers : {number_of_hidden_layers_val}\")\n",
        "    print(f\"Hidden layer node count : {hidden_layer_node_count_val}\")\n",
        "    print(f\"Retrain layer count : {retrain_layer_count_val}\")\n",
        "    print(\"************************\")\n",
        "    set_config_param(20230214)\n",
        "\n",
        "    model_tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_CHKPT)\n",
        "    model = TFRobertaModel.from_pretrained(BERT_MODEL_CHKPT)\n",
        "\n",
        "    train_input_ids, train_attention_masks = text_encode(df_train['full_text'], model_tokenizer, MAX_LEN)\n",
        "    test_input_ids, test_attention_masks = text_encode(df_test['full_text'], model_tokenizer, MAX_LEN)\n",
        "\n",
        "    y_train = np.array(df_train[label_cols], dtype = \"float32\")\n",
        "\n",
        "    bert = build_regression_model(loss= \"MCRMSE\", \n",
        "                                      model_name = \"Bert\",\n",
        "                                      dense_dim = 6, \n",
        "                                      MAX_LEN = 512,\n",
        "                                      learning_rate = learning_rate_val,\n",
        "                                      dropout=dropout_val,\n",
        "                                      number_of_hidden_layers = number_of_hidden_layers_val,\n",
        "                                      hidden_layer_node_count = hidden_layer_node_count_val,\n",
        "                                      retrain_layer_count = retrain_layer_count_val)\n",
        "    bert.summary()\n",
        "\n",
        "    history_v1 = bert.fit((train_input_ids, train_attention_masks),\n",
        "                  y_train,\n",
        "                  batch_size = batch_size_val,     \n",
        "                  epochs = epoch_val,\n",
        "                  validation_split = validation_split_val\n",
        "                  )\n",
        "\n",
        "    history_v1_df = pd.DataFrame(history_v1.history)\n",
        "\n",
        "    score_v1 = bert.evaluate([test_input_ids, test_attention_masks], \n",
        "                    y_test\n",
        "                  ) \n",
        "\n",
        "    predictions_v1 = bert.predict([test_input_ids, test_attention_masks])\n",
        "    df_pred_v1 = pd.DataFrame(predictions_v1, columns=['pred_' + c for c in label_cols])\n",
        "\n",
        "    for col in label_cols:\n",
        "      df_pred_v1['transformed_pred_' + col] = df_pred_v1['pred_' + col].apply(lambda x : roundPartial(x, .5))\n",
        "    \n",
        "    df_compare_v1= pd.merge(df_test, df_pred_v1, left_index = True, right_index = True)\n",
        "    df_compare_v1.to_csv(\"predict_bert_12.csv\", index=False)\n",
        "    all = []\n",
        "    for col in label_cols:\n",
        "      all.append(((df_compare_v1[col]-df_compare_v1[\"transformed_pred_\"+col]).pow(2).mean())**(0.5))\n",
        "    RMSE_scaled = statistics.fmean(all)\n",
        "    print(f\"RMSE_scaled: {RMSE_scaled}\")\n",
        "    \n",
        "    for label in label_cols:\n",
        "      print(label)\n",
        "      hall_of_fame(df_compare_v1,label,1)\n",
        "      print(\"************************\")\n",
        "      hall_of_shame(df_compare_v1,label,1)\n",
        "      print(\"************************\")\n",
        "    for component in label_cols:\n",
        "      print(component)\n",
        "      print(\"% Predicting too high: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\">\"+component))/len(df_compare_v1)))\n",
        "      print(\"% Predicted correctly: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"==\"+component))/len(df_compare_v1)))\n",
        "      print(\"% Predicting too low: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"<\"+component))/len(df_compare_v1)))\n",
        "      print(\"****\")\n",
        "    # Predicting too high or low for every score? \n",
        "    # for component in label_cols:\n",
        "    #   print(component)\n",
        "\n",
        "    #   for score in [1.0,1.5,2.0,2.5,3.0,3.5,4.0,4.5,5.0]:\n",
        "    #     if len(df_compare_v1[df_compare_v1[component]==score])==0:\n",
        "    #       print(component+\"==\"+str(score)+\" has 0 rows\")\n",
        "    #     else:\n",
        "    #       print(f'length: {len(df_compare_v1[df_compare_v1[component]==score])}')\n",
        "    #       print(\"% Predicting the above (\"+str(score)+\"): \" +\n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) &\n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]>score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #       print(\"% Predicting the same (\"+str(score)+\"): \" +\n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) & \n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]==score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #       print(\"% Predicting the below (\"+str(score)+\"): \" + \n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) & \n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]<score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #     print(\"****\")\n",
        "\n",
        "    for component in label_cols:\n",
        "      print(component)\n",
        "      print(\"% Predicting within .5: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"<=(\"+component+\"+.5) and transformed_pred_\"+component+\">=(\"+component+\"-.5)\"))/len(df_compare_v1)))"
      ],
      "metadata": {
        "id": "fLLxEQE3QKHd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e5063f5-4de6-4426-8815-a8dd0430f4b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************************\n",
            "Iteration : 1\n",
            "Parameters...\n",
            "Epochs : 10\n",
            "Batch size : 8\n",
            "Learning rate : 1e-05\n",
            "Validation split : 0.2\n",
            "Dropout : 0.1\n",
            "Number of hidden layers : 2\n",
            "Hidden layer node count : 64\n",
            "Retrain layer count : 12\n",
            "************************\n",
            "Number of trainable parameters : 108310272\n",
            "Number of non-trainable parameters : 0\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " hidden_layer_1 (Dense)         (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_layer_1 (Dropout)      (None, 64)           0           ['hidden_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            " hidden_layer_2 (Dense)         (None, 64)           4160        ['dropout_layer_1[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_layer_2 (Dropout)      (None, 64)           0           ['hidden_layer_2[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 6)            390         ['dropout_layer_2[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,364,038\n",
            "Trainable params: 108,364,038\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " hidden_layer_1 (Dense)         (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_layer_1 (Dropout)      (None, 64)           0           ['hidden_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            " hidden_layer_2 (Dense)         (None, 64)           4160        ['dropout_layer_1[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_layer_2 (Dropout)      (None, 64)           0           ['hidden_layer_2[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 6)            390         ['dropout_layer_2[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,364,038\n",
            "Trainable params: 108,364,038\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 384s 1s/step - loss: 1.0622 - MCRMSE: 1.0622 - val_loss: 0.5243 - val_MCRMSE: 0.5280\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 361s 1s/step - loss: 0.8955 - MCRMSE: 0.8956 - val_loss: 0.4795 - val_MCRMSE: 0.4816\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 365s 1s/step - loss: 0.8518 - MCRMSE: 0.8517 - val_loss: 0.4736 - val_MCRMSE: 0.4755\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 365s 1s/step - loss: 0.8302 - MCRMSE: 0.8300 - val_loss: 0.4629 - val_MCRMSE: 0.4644\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 364s 1s/step - loss: 0.7934 - MCRMSE: 0.7934 - val_loss: 0.4836 - val_MCRMSE: 0.4844\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 351s 1s/step - loss: 0.7694 - MCRMSE: 0.7695 - val_loss: 0.4994 - val_MCRMSE: 0.5011\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 351s 1s/step - loss: 0.7456 - MCRMSE: 0.7458 - val_loss: 0.4764 - val_MCRMSE: 0.4786\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 352s 1s/step - loss: 0.7370 - MCRMSE: 0.7368 - val_loss: 0.4669 - val_MCRMSE: 0.4680\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 353s 1s/step - loss: 0.7034 - MCRMSE: 0.7032 - val_loss: 0.4865 - val_MCRMSE: 0.4870\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 339s 1s/step - loss: 0.6931 - MCRMSE: 0.6931 - val_loss: 0.4757 - val_MCRMSE: 0.4773\n",
            "25/25 [==============================] - 33s 1s/step - loss: 0.4708 - MCRMSE: 0.4701\n",
            "25/25 [==============================] - 36s 1s/step\n",
            "RMSE_scaled: 0.5267901151738109\n",
            "cohesion\n",
            "predicted:  3.5\n",
            "original:  3.5\n",
            "('Being true to yourself in a world so cruel is the best to accomplishment. '\n",
            " 'The most important lessons life can give is stand your ground, be more '\n",
            " 'forward with certain individuals, cut what seems to be negative. '\n",
            " 'Individuality can always be a good, sometimes you never need that helping '\n",
            " 'hand because not everyone is helpful. Some try to be the bad person by '\n",
            " 'stepping over you.  Most experiences, I myself have gone through were never '\n",
            " 'the best. Everyone might seem like the good person, but we never know what '\n",
            " 'is really behind them. First off, you should simply just stand your ground. '\n",
            " 'Show them that not everything is meant to be worked within two people.  '\n",
            " 'Another reason, achieving things on your own shows you a lot of things you '\n",
            " 'never knew before. One of those might be you have made through school by '\n",
            " 'yourself and got your diploma. Accomplishment comes with many struggles and '\n",
            " 'steps. Not just anyone makes it through; some give up because maybe others '\n",
            " 'told them that not everything is for them.  Lastly, cut out certain people '\n",
            " 'that you know never got you anywhere. Everyday is a lesson if we recognize '\n",
            " 'it or not. Some days are harder than others, but there is never a day you '\n",
            " 'should give. Every job can be easy with a positive mindset.  In conclusion, '\n",
            " 'my reasons to accomplishment to stand your ground, move forward, and to '\n",
            " 'leave negativity behind can lead to bigger success and open '\n",
            " 'opportunity.      ')\n",
            "**********\n",
            "************************\n",
            "predicted:  2.5\n",
            "original:  3.0\n",
            "('taking online clases is one of the best option, for many student who has '\n",
            " 'problem to attendace in the school.  taking online clases can help to '\n",
            " 'student, who need to work full time because they are having many '\n",
            " 'responsability in there home some of the students are living by themself, '\n",
            " 'people who have to pay bills and work extra hours and they are not having '\n",
            " 'time for going to school decide to giving up and not finish there education '\n",
            " \".  many student don't have money for getting lunch or can not apply for get \"\n",
            " 'free lunch.  and they don t want to spend more money in the school or '\n",
            " 'students who has childrens are paying babysitting the time when there are in '\n",
            " 'the school, and want to continue studing.  Student can have better grades.  '\n",
            " 'they can access online any time during the day, they can focus in clases '\n",
            " 'they having more time to work in assigment, they can add extra time to check '\n",
            " 'test, homeworks, vocabularies, etc they can memorise more easily, because '\n",
            " 'they can repeat the information many times they want. access online clases, '\n",
            " 'student do not have another student to interrup the clases least problem '\n",
            " 'between of students, getting online education , people will not skip clases '\n",
            " 'becauses. they think be in a classroom is to bore and they decide to leaving '\n",
            " 'the classroom. a big problem is a lot student s are missing the buss, '\n",
            " 'because there a late for minutes them the a lossing a day of school .  '\n",
            " 'people are getting sick easily the food from the school is not healthy, '\n",
            " 'people pefer to not eat than eat the food from the cafeteria that is '\n",
            " 'affecting attends .  this idea to have clases online it going to make '\n",
            " 'students feels they are getting enoght help from the school, having online '\n",
            " 'education is a great idea for student it will increseasing the attendance ')\n",
            "**********\n",
            "************************\n",
            "syntax\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('I think its a good idea to ask people for other people opinion because '\n",
            " 'people might have better thought on something, they can have different '\n",
            " 'options for you, and it also can help you later in life.  I think we should '\n",
            " 'ask people for there opinion because they might have a better thought. For '\n",
            " 'example if you wanted to go shopping for cloths and you dont know which one '\n",
            " 'to pick. People will give options of what they think and they can tell you '\n",
            " 'which one they prefer more. There are variety options you can pick from. You '\n",
            " 'can choose your own and ask people if they like it or not. If you dont know '\n",
            " 'which one to pick between two options. You can ask friends, family, or '\n",
            " 'anyone you feel comfuterble with you can get an idea which one you want '\n",
            " 'more. Its always a good thing to ask for people opinion.  Asking for people '\n",
            " 'opinion is good they can have different options for you. You can ask on '\n",
            " 'different flavor of ice cream you can get as many options as you want . '\n",
            " 'People can give you differnt opionions on what they think which ice cream '\n",
            " 'taste better than other ones. different options is always a good thing to '\n",
            " 'use. Its bad sometimes haveing only one option the more options the better. '\n",
            " 'The more options you get you wont have problems with picking things of what '\n",
            " 'you want. It is easier to to pick and and you can have what you want.  All '\n",
            " 'these opinions can help us out later in life. In the future you might need '\n",
            " 'help on which flavor ice cream is good. You can ask someone and they can '\n",
            " 'give you an opinion which one is good. Its good to have opinion some of them '\n",
            " 'you might not like. Everyone dont have the same opinion which is okay '\n",
            " 'everyone can have different opinion on different types of things. over time '\n",
            " 'you might need an opinion on something and you can thing what people have '\n",
            " 'said before or you can ask someone to help you out.  Different opinions and '\n",
            " 'thoughts can help you more in life and you wont have problems with picking '\n",
            " 'things. its good to have different opinions on different things that people '\n",
            " 'give you. All these opinions people give you can help you later in the '\n",
            " 'future and different kinda of opinions. I think it is better choice to ask '\n",
            " 'someone on thier opinions and get an idea of what other people think about '\n",
            " 'different things.                                                ')\n",
            "**********\n",
            "************************\n",
            "predicted:  2.5\n",
            "original:  3.5\n",
            "('Well I want to start saying that the first impressions about people can '\n",
            " \"change but if the impressions change is because something happen. I'm saying \"\n",
            " 'it because of some of my experiences with other people that I met and change '\n",
            " \"my impressions about them. Sometimes people don't change,instead of saying \"\n",
            " 'that people change your impressions about them maybe you need to know your '\n",
            " 'self first and see what is happening also you need to known why that person '\n",
            " 'change your impressions because maybe something sad or bad is happening on '\n",
            " \"their life and you don't know it.  So let me tell you an experience that \"\n",
            " 'happen to me a few moths ago so I met this girl and she was very nice with '\n",
            " 'me and I start thinking that she was that nice with everyone and no I was '\n",
            " 'wrong she only was that nice with me so I decide to date her so I tell her '\n",
            " 'if she want go to see a movie next weekend and she tell me, yes! and I say '\n",
            " 'great so like 3 days before going to see the movie she start acting weird '\n",
            " 'and I ask her if she was OK? and she tell me yes,so the next day I start '\n",
            " 'talking with her and she tell me what was happening and she tell me that her '\n",
            " 'mother was sick and she was sad,so she tell me everything that was happening '\n",
            " 'and I understand why she was acting weird.  In conclusion my impressions '\n",
            " 'about her it was starting to change but I decide to talk with her to see '\n",
            " 'what was happening, before that I start saying that she change and my '\n",
            " 'impressions about her change. is bad to change the impressions about a '\n",
            " \"person without knowing what is happening in their life,because you don't \"\n",
            " 'know if that person is waiting for you to ask them what is happening. So I '\n",
            " 'think you should ask that person what is happening and then you decide what '\n",
            " 'are you going to do. These are some of the many reason why I disagree with '\n",
            " 'the statement.')\n",
            "**********\n",
            "************************\n",
            "vocabulary\n",
            "predicted:  4.0\n",
            "original:  4.0\n",
            "(\"I really need to find a career path. With your help, I think we'll be able \"\n",
            " 'to come up with a solution. You should come my school not just to help me, '\n",
            " 'but to help others too. Students need to gain experience to at least '\n",
            " 'understand what to do, and how to act in the work place. They can really '\n",
            " 'benefit by finding a new career. Their interest can take them a long way. '\n",
            " 'Your help can take them a long way, and they can potentially help you too. '\n",
            " 'Coming to my school would help me gain experience, find an interest, and '\n",
            " 'gain something beneficial.  Experience is key in finding a job that '\n",
            " 'interests you. If I join an internship I can potentially gain a lot of '\n",
            " 'experience. An internship helps you to prepare for whats to come later on in '\n",
            " 'your career. Work ethic and how to do your job are things you might learn. I '\n",
            " 'really need to learn whats the wrong thing to do, and whats the right thing '\n",
            " 'to do in the work place. For example, you need to learn how to address your '\n",
            " 'boss in a polite way. If you mess that up, it could possibly cost you your '\n",
            " 'career. I really need to learn this stuff to improve my career later down '\n",
            " 'the line. I know you would be capable to help me with that.  Benefits are '\n",
            " 'things you gain out of a situation. If you help me I will benefit from this, '\n",
            " 'and you could benefit from this too. I can gain a lot if you help me. I '\n",
            " 'could pursue an amazing career that would help me out a lot. My career would '\n",
            " 'help me pay for bills, rent, and my car. If your internship helps me find a '\n",
            " \"good career, that career can help me financially. It's like a domino affect. \"\n",
            " 'It can also benefit me emotionally. If I really like my job, that makes me '\n",
            " \"happy. Don't forget that this could benefit you too. You could potentially \"\n",
            " 'gain knowledge about what your doing wrong and what your doing right. You '\n",
            " 'can improve as a manager of your business; possibly changing your work style '\n",
            " 'or business style. I can help you with certain things too if I join your '\n",
            " 'internship.  You have to be interested in something to start a good career. '\n",
            " \"What is your career going to be based around? You can help me find a job I'm \"\n",
            " \"interested in or lead me down a path where I can start the job I'm \"\n",
            " 'interested in. In my opinion, you have to like your job to succeed in your '\n",
            " \"career. If you don't, It could lead to quitting. If I know what I want to \"\n",
            " \"do, you can point me in the right direction and I'll work hard in order to \"\n",
            " \"reach my goal. If I don't know what I want to do, you can help me find \"\n",
            " \"something. You can see what I'm good at and what I'm not good at, what my \"\n",
            " 'likes and dislikes are, and from there you can help me find a career I want '\n",
            " \"to pursue. I know you will help me find a career I'm interested in.  In \"\n",
            " 'conclusion, experience is something I want to gain in order to know how to '\n",
            " 'do other things. I want to gain a lot of benefits, because they will lead to '\n",
            " \"good and better things. I really want to find a good career that I'm \"\n",
            " 'interested in so I can manage myself. I know if you were to come to my '\n",
            " 'school and talk to me, and let me join your internship, I would be able to '\n",
            " 'gain all these things. ')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.5\n",
            "original:  3.0\n",
            "('Being yourself is being true to yourself and to others for example. When '\n",
            " \"you're hanging out with a group of people. Don't act like someone else but \"\n",
            " \"yourself because you will get caught for trying to be someone that you're \"\n",
            " \"not and get made fun of for being something that you're not. It's better to \"\n",
            " 'be yourself because you want people to like who you really are. Not someone '\n",
            " \"you ain't your just lying to yourself and others.  Ralph Waldo Emerson was a \"\n",
            " \"Author who believe ''to be yourself in a world that is constantly trying to \"\n",
            " \"make you something else is the greatest accomplishment''. I agree with that \"\n",
            " 'statement but not so many could say the same. There is many human on this '\n",
            " 'planet who cant accomplishment being their self than being someone else than '\n",
            " 'their self .  Many people struggle to be their self because of society. '\n",
            " 'Society brain washes people to be someone else than being their self.  '\n",
            " 'Nowadays being yourself is lame and being someone else is Amazing to some '\n",
            " 'people. Their is con on being someone else like lying to people until they '\n",
            " 'fine out who you really are. Than they might not like who you really are '\n",
            " 'then your feelings are hurt . Therefore your friendless and hurt ,But you '\n",
            " 'could always pick yourself up by being yourself. Than by over time people '\n",
            " 'will start to notice how you change and they will want to have relationship '\n",
            " \"with you.  It's healthy to have relationships with you being yourself than \"\n",
            " 'being someone else. The reason why i am saying that is because you dont want '\n",
            " 'to be lying to the other person the whole time during the relationship . It '\n",
            " 'will bring problems to the relationships .However its always a good idea to '\n",
            " 'talk it out and come clean.  Being yourself make a huge impacts in people '\n",
            " 'daily life. It could go for the good or the worse its all up to the person. '\n",
            " 'Therefore its important to be yourself always no matter what or whats the '\n",
            " 'cost of it . Also make sure to take pride of being yourself.        ')\n",
            "**********\n",
            "************************\n",
            "phraseology\n",
            "predicted:  3.5\n",
            "original:  3.5\n",
            "('Your principal has decided all students must participate in at least one '\n",
            " 'extracurricular activity. I agree because now days all kids do is stay home '\n",
            " 'and be on there phones and do nothing. I know that because I used to do the '\n",
            " \"same thing before and i didn't like to do anything at all but then I started \"\n",
            " 'playing a sport and it help a lot but i think that. Participating in a '\n",
            " 'extracurricular activity may help you by staying healthy, get you out of '\n",
            " 'trouble,and get you in a good college.  one example is staying healthy by '\n",
            " 'playing a sport you can help prevent a lot of things like maintain a good '\n",
            " 'weight, and keep you from getting sick. Keeping a good weight is good for '\n",
            " 'your health because it keeps you from getting other diseases,more than 1/4 '\n",
            " 'of the people in the U.S. are obese. Why not start at a young age and '\n",
            " 'prevent from being sick and other things. Another thing that can help is '\n",
            " 'eating healthy, we can prevent sickness to in order to do that you might '\n",
            " 'want to think about trying out a new sport.  Another example is getting you '\n",
            " 'out of trouble you can avoid a lot of drama. I learned that social media can '\n",
            " 'get you into a lot of trouble, half of the time a lot of the drama comes '\n",
            " 'from social media. Maybe if you join a club or a sports team you can think '\n",
            " 'before doing something that can get you in trouble. One time my friend made '\n",
            " 'the soccer team but she got in trouble so they kicked her off the team and '\n",
            " 'she learned from her mistake and never got in trouble again. When in your in '\n",
            " \"a cub or playing a sports half of the time you don't have time to be in \"\n",
            " 'drama get in trouble.  Last example is joining a club, working on the year '\n",
            " 'book,serve in the student council and, playing a sport can get you into a '\n",
            " 'good college now a days colleges are looking to see if you have participated '\n",
            " 'in any sports or clubs. When i graduate high school i want to go to college '\n",
            " 'and a study to be a general surgeon and participating in a sport or joining '\n",
            " 'a club can help me get into a college. You meed new people when you join new '\n",
            " 'clubs and make new friend ships. When you want to go into a club or in '\n",
            " 'sports do something that you like not something your friends like or '\n",
            " 'something that can help you in life with.  In conclusion staying '\n",
            " 'healthy,getting out of trouble,and going into a new college can help you '\n",
            " 'when you participate in a extracurricular activity. staying healthy by '\n",
            " 'playing a sports and eating healthy can prevent you from getting sick. '\n",
            " 'Staying out of trouble can avoid a lot of drama from school and social media '\n",
            " 'think before you do something your going to regret . Joining a club or '\n",
            " 'participating in a sport can help you get into the college you want and you '\n",
            " 'can meet new people and make new friend ships.')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.5\n",
            "original:  4.0\n",
            "('Technology has had positive effects on people because you can use cellphones '\n",
            " 'to interact people, you can also be shopping at home without having to leave '\n",
            " 'your house, and also if you are a gamer you can also play with people from '\n",
            " \"around the world. That's why technology has had a positive effects on \"\n",
            " 'people.  Technology is a big impact on people because phones can do '\n",
            " 'anything. You can be in video call with friends and family without having to '\n",
            " 'leave your house. You can also call your family with just your phone. One '\n",
            " 'last thing you can do with phones is that you can make group chats with your '\n",
            " 'friends and family. You can be playing games with your friends or you can '\n",
            " 'just chat with them.  With the important of technology you can also do '\n",
            " 'shopping. You can shop without having to leave your home at all. If you are '\n",
            " 'from another country you can shop from around the world and you can buy '\n",
            " 'things that represent your country and feel like home. One last thing you '\n",
            " 'can do with shopping online is that can order food from any restaurant and '\n",
            " 'it will get sent right to your home. you can also send stuff to your friends '\n",
            " 'and family by just sending it to them  With technology if your a gamer like '\n",
            " 'myself you can play with anyone from around the world. With gaming you can '\n",
            " 'play with your friends and you can be talking and playing at the same time. '\n",
            " 'Also with your gaming system you can also watch hulu, and with hulu can '\n",
            " 'watch movies without having to go to the movie theater. Also with gaming '\n",
            " 'with friends is that you can just have a blast while gaming. The '\n",
            " 'counterclaim will be what if your not a gamer? If your not a gamer then you '\n",
            " 'can take school at home without having to leave your house.  In conclusion i '\n",
            " 'agree that technology has had positive effects on people because it has '\n",
            " 'brought us cellphones to connect people from around the world. You can also '\n",
            " 'shop online without having to leave your home. You can also be gaming with '\n",
            " \"people from around the world. That's why technology has had a positive \"\n",
            " 'impact on peoples lives.             ')\n",
            "**********\n",
            "************************\n",
            "grammar\n",
            "predicted:  3.5\n",
            "original:  3.5\n",
            "('Students chould not be required to take a music, a drama or an art class. '\n",
            " 'Student should only be required to take classes that they actually need. '\n",
            " 'Having to take those classes just adds classes you need to graduate. It is '\n",
            " 'also all a waist of time if the students are not actually in to it.  '\n",
            " 'Firstly, these classes are just extra classes that we dont really need. In '\n",
            " 'my opnion, I believe that student should be able to graduate highschool with '\n",
            " 'the classes they need. English, Math, History and Science are all classes '\n",
            " \"that can support them when they go to college. If student don't take these \"\n",
            " 'classes they may also graduate ealier then they are supposed to. For '\n",
            " 'example, I go to a highschool where I get the credits I need and I am able '\n",
            " 'to graduate a year earlier. Which I think everyone should have the chance '\n",
            " 'too.  Lastly, if a student is not interested in one of these classes they '\n",
            " \"won't try. Even if they do try and fail then its just holding them back. \"\n",
            " \"They will start stressing over it when they won't actually end up needing \"\n",
            " 'it. Student will also consume most of their time bringing up their grade in '\n",
            " 'these classes that they will not work on other classes. Then they will end '\n",
            " 'up failing.  On the other hand, some might say these classes should be '\n",
            " 'required because student might find interest in one of those and would like '\n",
            " 'to persue it after graduating. I think that if a student is interested then '\n",
            " 'they should be allowed to take the class of your choice. However, if your '\n",
            " 'not then you should not be pushed to take them when you dont want to.  In '\n",
            " 'conclusion, student should not be forced to take elcective classes. If they '\n",
            " 'want to they should but if not then they shouldnt need it to graduate. '\n",
            " 'Electives are just extra classes needed to graduate and they also have no '\n",
            " 'pont if the student are not actually interested. po p')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  4.0\n",
            "('By extending the school day two hours, students and teachers will have more '\n",
            " 'advantages to learn and to teach.  I agree to follow this model by extending '\n",
            " 'the school day two hours. There are many reasons of why it will be better '\n",
            " 'and will benefit us as students. One of the reasons is that we will have '\n",
            " 'more time in the weekend to review our notes, homework, and things that we '\n",
            " 'need help with. Another reason is that we will be doing the same forty hours '\n",
            " 'of school even if we will have a four-day school week. It also will benefit '\n",
            " 'teachers by increasing their time to review test or projects made by the '\n",
            " 'students.  Most of the time there are things at school that we do not really '\n",
            " 'understand, and a four-day school week will give us more time to study and '\n",
            " 'review these things at home. We the students have the opportunity to go to '\n",
            " 'school and graduate, but also some of us have obligations and '\n",
            " 'responsibilities. For example in my personal life, I have to work after '\n",
            " 'school everyday. And most of the time when I get home, I feel tired and I '\n",
            " 'just go to sleep, I forget if I have homework or not. Therefore this model '\n",
            " 'will give us more time to work and being less worry about going to school '\n",
            " 'five-day week. We can concentrate at school four days and the other day we '\n",
            " 'can work and do homework or projects when we have to.  Also a four-day '\n",
            " 'school week will benefit us because we will be doing the same forty hours. '\n",
            " 'Therefore our grades and education would not change. And I do not think that '\n",
            " 'is necessary to study all five days, it is not about how many days do you go '\n",
            " 'to school, is about how you take advantages from it. For example if you go '\n",
            " 'to school everyday just to talk with your teammates, is like you were '\n",
            " 'absent. For that reason I agree to extend the two hours of school, that way '\n",
            " 'we can concentrate four days and having in mind that we will have three days '\n",
            " 'to study or to keep learning at home.  Another reason of why I agree to '\n",
            " 'extend the school day, is because it will benefit the teachers also. It will '\n",
            " 'benefit the teachers by giving them more time to review and grade homework, '\n",
            " 'projects or test that students took in the class. It also will give us the '\n",
            " 'opportunity to spend more time with our families and people around us. For '\n",
            " 'example, I work with my father in construction, and I almost do not see him '\n",
            " 'all day until the night. This four-day school week, will give me the '\n",
            " 'opportunity to spend a entire day working with him without being worry about '\n",
            " 'the school for a day. And just like me, there is a lot of people who will be '\n",
            " 'benefit from it.  Finally, school should be extended two hours day, that way '\n",
            " 'we can have more time in the weekend to prepare for tests, teachers will '\n",
            " 'have more time to grade them. And we will have three days to spend with our '\n",
            " 'families.                     ')\n",
            "**********\n",
            "************************\n",
            "conventions\n",
            "predicted:  2.5\n",
            "original:  2.5\n",
            "('Can we accomplish more if we are always doing something ?  Sometimes we are '\n",
            " \"lazy and we don't want to do nothing, but if we are doing always something \"\n",
            " 'we can be more stronger and helpful to the citizen.  Sometimes we are lazy, '\n",
            " 'but that is bad in our life because we has to learn about this life and '\n",
            " 'prepare for the future and other things. One day we would grow up and we '\n",
            " \"would does not know anything and we're gonna fall in our life, therefor i \"\n",
            " 'told them this advice.  Thomas Jefferson wrote, \"Determine never to be '\n",
            " 'idle...it is wonderful how much may be done if we are always doing.\"  we can '\n",
            " 'be stronger if we are always doing something because we can learn about '\n",
            " 'everything that we did and we can get strength to be better, also we can be '\n",
            " 'a adviser to other peoples for example: Kids, Teenager, also Adults.  We can '\n",
            " 'be helpful if we are always doing something because one day that we fall '\n",
            " 'down, also we can stand up more stronger and healthy. We can help person '\n",
            " 'with our experiences, also we can help kids give them a advise because we '\n",
            " 'want a good, strong citizen in this world and they can make it better, and '\n",
            " 'help each other.  In conclusion we can be stronger, healthy for people that '\n",
            " \"don't know anything in this life. We can do better things for our future, \"\n",
            " 'furthermore kids will be our future, therefore we are gonna fight for them, '\n",
            " \"and their future because if we are lazy and we don't do anything we are \"\n",
            " 'gonna fail. We need more activities in our life and do something all the '\n",
            " 'time because for that we can learn ah be adviser, also we need a break but '\n",
            " 'we has to continue learning and to be success in our life, and complete our '\n",
            " 'dreams.')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  3.5\n",
            "(\"The school board shouldn't add one and half hours to school each day. To \"\n",
            " \"begin one reason i think they shouldn't is that a lot of kids who play \"\n",
            " \"sports or clubs after school might not be able to because they don't have \"\n",
            " \"time to learn about how life is and how difficult it is and people's life \"\n",
            " 'difficulties. One example is that some kids play videos and since they dont '\n",
            " 'have lots of time out side of school they might just play video game instead '\n",
            " 'of sports and if you give them more time out of school more opportunities '\n",
            " 'students will have. secondly Students will be more tired and less focus '\n",
            " 'because if students have more time in school the more earlier they will have '\n",
            " \"to sleep and most students don't fall asleep early also students have \"\n",
            " 'homework since they well most likely be tired from school they might take a '\n",
            " 'nap and there might either wake up to late to do homework or not have time '\n",
            " 'to finish all there homework. Thirdly more students will not want to be in '\n",
            " \"school and may drop out from either too much stress or they just don't want \"\n",
            " 'to be in school because the longer time there in school the more tired they '\n",
            " 'are and less time they have to do what makes them feel relaxed or not have '\n",
            " 'time to do what they love to do. students also might not have time to make '\n",
            " 'friends because there focusing on school and it might ruin there social '\n",
            " 'skill and conversation with strangers out side of school. Lastly less amount '\n",
            " 'of time they have to spend with there families because they would have to go '\n",
            " 'to school for extra time and as soon as they get home they have to do '\n",
            " 'homework and honestly by the time there done there going to be most likely '\n",
            " 'tired to do anything beside resting or sleeping. Also some students have '\n",
            " 'younger siblings to take care of after school so that would put more stress '\n",
            " 'on a student and either a family would have to pay for a baby sitter or some '\n",
            " \"families don't have money to pay for one so parents might take there student \"\n",
            " 'out of school just to take care of there sibling and so the extra time in '\n",
            " \"school wouldn't help him. To conclude those are the main reasons why I think \"\n",
            " \"we shouldn't have more school hours in school.  \")\n",
            "**********\n",
            "************************\n",
            "cohesion\n",
            "% Predicting too high: 0.2222222222222222\n",
            "% Predicted correctly: 0.31800766283524906\n",
            "% Predicting too low: 0.45977011494252873\n",
            "****\n",
            "syntax\n",
            "% Predicting too high: 0.194125159642401\n",
            "% Predicted correctly: 0.384418901660281\n",
            "% Predicting too low: 0.421455938697318\n",
            "****\n",
            "vocabulary\n",
            "% Predicting too high: 0.24393358876117496\n",
            "% Predicted correctly: 0.44316730523627074\n",
            "% Predicting too low: 0.3128991060025543\n",
            "****\n",
            "phraseology\n",
            "% Predicting too high: 0.2669220945083014\n",
            "% Predicted correctly: 0.40485312899106\n",
            "% Predicting too low: 0.3282247765006386\n",
            "****\n",
            "grammar\n",
            "% Predicting too high: 0.25925925925925924\n",
            "% Predicted correctly: 0.37292464878671777\n",
            "% Predicting too low: 0.367816091954023\n",
            "****\n",
            "conventions\n",
            "% Predicting too high: 0.14942528735632185\n",
            "% Predicted correctly: 0.3665389527458493\n",
            "% Predicting too low: 0.4840357598978289\n",
            "****\n",
            "cohesion\n",
            "length: 2\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 6\n",
            "% Predicting the above (1.5): 0.8333333333333334\n",
            "% Predicting the same (1.5): 0.16666666666666666\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 64\n",
            "% Predicting the above (2.0): 0.734375\n",
            "% Predicting the same (2.0): 0.234375\n",
            "% Predicting the below (2.0): 0.03125\n",
            "****\n",
            "length: 162\n",
            "% Predicting the above (2.5): 0.4691358024691358\n",
            "% Predicting the same (2.5): 0.41975308641975306\n",
            "% Predicting the below (2.5): 0.1111111111111111\n",
            "****\n",
            "length: 219\n",
            "% Predicting the above (3.0): 0.182648401826484\n",
            "% Predicting the same (3.0): 0.45662100456621\n",
            "% Predicting the below (3.0): 0.3607305936073059\n",
            "****\n",
            "length: 198\n",
            "% Predicting the above (3.5): 0.020202020202020204\n",
            "% Predicting the same (3.5): 0.30303030303030304\n",
            "% Predicting the below (3.5): 0.6767676767676768\n",
            "****\n",
            "length: 93\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.053763440860215055\n",
            "% Predicting the below (4.0): 0.946236559139785\n",
            "****\n",
            "length: 35\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 4\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "syntax\n",
            "length: 4\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 5\n",
            "% Predicting the above (1.5): 0.6\n",
            "% Predicting the same (1.5): 0.4\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 96\n",
            "% Predicting the above (2.0): 0.7083333333333334\n",
            "% Predicting the same (2.0): 0.2708333333333333\n",
            "% Predicting the below (2.0): 0.020833333333333332\n",
            "****\n",
            "length: 149\n",
            "% Predicting the above (2.5): 0.28187919463087246\n",
            "% Predicting the same (2.5): 0.610738255033557\n",
            "% Predicting the below (2.5): 0.10738255033557047\n",
            "****\n",
            "length: 257\n",
            "% Predicting the above (3.0): 0.1245136186770428\n",
            "% Predicting the same (3.0): 0.5252918287937743\n",
            "% Predicting the below (3.0): 0.35019455252918286\n",
            "****\n",
            "length: 170\n",
            "% Predicting the above (3.5): 0.01764705882352941\n",
            "% Predicting the same (3.5): 0.24705882352941178\n",
            "% Predicting the below (3.5): 0.7352941176470589\n",
            "****\n",
            "length: 81\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.06172839506172839\n",
            "% Predicting the below (4.0): 0.9382716049382716\n",
            "****\n",
            "length: 19\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 2\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "vocabulary\n",
            "vocabulary==1.0 has 0 rows\n",
            "****\n",
            "length: 4\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 26\n",
            "% Predicting the above (2.0): 0.8076923076923077\n",
            "% Predicting the same (2.0): 0.19230769230769232\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 101\n",
            "% Predicting the above (2.5): 0.6336633663366337\n",
            "% Predicting the same (2.5): 0.3465346534653465\n",
            "% Predicting the below (2.5): 0.019801980198019802\n",
            "****\n",
            "length: 305\n",
            "% Predicting the above (3.0): 0.29180327868852457\n",
            "% Predicting the same (3.0): 0.580327868852459\n",
            "% Predicting the below (3.0): 0.12786885245901639\n",
            "****\n",
            "length: 194\n",
            "% Predicting the above (3.5): 0.061855670103092786\n",
            "% Predicting the same (3.5): 0.5309278350515464\n",
            "% Predicting the below (3.5): 0.4072164948453608\n",
            "****\n",
            "length: 122\n",
            "% Predicting the above (4.0): 0.00819672131147541\n",
            "% Predicting the same (4.0): 0.20491803278688525\n",
            "% Predicting the below (4.0): 0.7868852459016393\n",
            "****\n",
            "length: 24\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.08333333333333333\n",
            "% Predicting the below (4.5): 0.9166666666666666\n",
            "****\n",
            "length: 7\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "phraseology\n",
            "length: 3\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 3\n",
            "% Predicting the above (1.5): 0.6666666666666666\n",
            "% Predicting the same (1.5): 0.3333333333333333\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 74\n",
            "% Predicting the above (2.0): 0.7027027027027027\n",
            "% Predicting the same (2.0): 0.2702702702702703\n",
            "% Predicting the below (2.0): 0.02702702702702703\n",
            "****\n",
            "length: 152\n",
            "% Predicting the above (2.5): 0.5263157894736842\n",
            "% Predicting the same (2.5): 0.4407894736842105\n",
            "% Predicting the below (2.5): 0.03289473684210526\n",
            "****\n",
            "length: 242\n",
            "% Predicting the above (3.0): 0.256198347107438\n",
            "% Predicting the same (3.0): 0.5495867768595041\n",
            "% Predicting the below (3.0): 0.19421487603305784\n",
            "****\n",
            "length: 180\n",
            "% Predicting the above (3.5): 0.05\n",
            "% Predicting the same (3.5): 0.42777777777777776\n",
            "% Predicting the below (3.5): 0.5222222222222223\n",
            "****\n",
            "length: 107\n",
            "% Predicting the above (4.0): 0.009345794392523364\n",
            "% Predicting the same (4.0): 0.17757009345794392\n",
            "% Predicting the below (4.0): 0.8130841121495327\n",
            "****\n",
            "length: 18\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 4\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "grammar\n",
            "length: 3\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 6\n",
            "% Predicting the above (1.5): 0.6666666666666666\n",
            "% Predicting the same (1.5): 0.3333333333333333\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 95\n",
            "% Predicting the above (2.0): 0.6947368421052632\n",
            "% Predicting the same (2.0): 0.28421052631578947\n",
            "% Predicting the below (2.0): 0.021052631578947368\n",
            "****\n",
            "length: 181\n",
            "% Predicting the above (2.5): 0.43646408839779005\n",
            "% Predicting the same (2.5): 0.4585635359116022\n",
            "% Predicting the below (2.5): 0.10497237569060773\n",
            "****\n",
            "length: 193\n",
            "% Predicting the above (3.0): 0.22279792746113988\n",
            "% Predicting the same (3.0): 0.49740932642487046\n",
            "% Predicting the below (3.0): 0.27979274611398963\n",
            "****\n",
            "length: 176\n",
            "% Predicting the above (3.5): 0.045454545454545456\n",
            "% Predicting the same (3.5): 0.42045454545454547\n",
            "% Predicting the below (3.5): 0.5340909090909091\n",
            "****\n",
            "length: 96\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.10416666666666667\n",
            "% Predicting the below (4.0): 0.8958333333333334\n",
            "****\n",
            "length: 25\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 8\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "conventions\n",
            "length: 1\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 5\n",
            "% Predicting the above (1.5): 0.8\n",
            "% Predicting the same (1.5): 0.2\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 85\n",
            "% Predicting the above (2.0): 0.5058823529411764\n",
            "% Predicting the same (2.0): 0.4\n",
            "% Predicting the below (2.0): 0.09411764705882353\n",
            "****\n",
            "length: 155\n",
            "% Predicting the above (2.5): 0.34838709677419355\n",
            "% Predicting the same (2.5): 0.5612903225806452\n",
            "% Predicting the below (2.5): 0.09032258064516129\n",
            "****\n",
            "length: 240\n",
            "% Predicting the above (3.0): 0.0625\n",
            "% Predicting the same (3.0): 0.5416666666666666\n",
            "% Predicting the below (3.0): 0.3958333333333333\n",
            "****\n",
            "length: 168\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.19642857142857142\n",
            "% Predicting the below (3.5): 0.8035714285714286\n",
            "****\n",
            "length: 96\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.020833333333333332\n",
            "% Predicting the below (4.0): 0.9791666666666666\n",
            "****\n",
            "length: 26\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 7\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "cohesion\n",
            "% Predicting within .5: 0.8288633461047255\n",
            "syntax\n",
            "% Predicting within .5: 0.8646232439335888\n",
            "vocabulary\n",
            "% Predicting within .5: 0.9195402298850575\n",
            "phraseology\n",
            "% Predicting within .5: 0.8710089399744572\n",
            "grammar\n",
            "% Predicting within .5: 0.8212005108556832\n",
            "conventions\n",
            "% Predicting within .5: 0.8250319284802043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_compare_v1 = pd.read_csv(\"predict_bert_12.csv\")\n",
        "for component in label_cols:\n",
        "  print(pd.crosstab(df_compare_v1[component], df_compare_v1[\"transformed_pred_\"+component], margins=True))\n",
        "  print()"
      ],
      "metadata": {
        "id": "soKr77IRK5Lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zN5pnfXQua0e"
      },
      "source": [
        "BERTweet with all layers frozen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed parameters\n",
        "dense_dim = 6\n",
        "number_of_splits = 2\n",
        "random_state = 2023\n",
        "mse_loss = MCRMSE\n",
        "mse_metrics = MCRMSE\n",
        "model_name_list = ['Bert', 'Bertweet'] # Roberta\n",
        "\n",
        "df_train = pd.read_csv('df_train_split.csv')\n",
        "df_test = pd.read_csv('df_test_split.csv')\n",
        "print(f\"Length of train data : {len(df_train)}\")\n",
        "print(f\"Length of test data : {len(df_test)}\")\n",
        "y_test = np.array(df_test[label_cols], dtype = \"float32\")"
      ],
      "metadata": {
        "id": "osNV7GVVDk2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4339e907-b116-41d5-aa00-183de8ecd3fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train data : 3128\n",
            "Length of test data : 783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable parameter dictionary\n",
        "param_list = [   # Completely frozen base layer\n",
        "                 {'epochs'                  : 10,\n",
        "                  'batch_size'              : 8,\n",
        "                  'learning_rate'           : 1e-5,\n",
        "                  'validation_split'        : .2,\n",
        "                  'dropout'                 : .1,\n",
        "                  'number_of_hidden_layers' : 2,\n",
        "                  'hidden_layer_node_count' : 64,\n",
        "                  'retrain_layer_count'     : 0\n",
        "                 }\n",
        "             ]"
      ],
      "metadata": {
        "id": "_QPrhWegQZfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, param_entry in enumerate(param_list):\n",
        "    MAX_LEN = 512\n",
        "    epoch_val = param_entry['epochs']\n",
        "    batch_size_val = param_entry['batch_size']\n",
        "    learning_rate_val = param_entry['learning_rate']\n",
        "    validation_split_val = param_entry['validation_split']\n",
        "    dropout_val = param_entry['dropout']\n",
        "    number_of_hidden_layers_val = param_entry['number_of_hidden_layers']\n",
        "    hidden_layer_node_count_val = param_entry['hidden_layer_node_count']\n",
        "    retrain_layer_count_val = param_entry['retrain_layer_count']\n",
        "\n",
        "    print(\"************************\")\n",
        "    print(f\"Iteration : {idx + 1}\")\n",
        "    print(\"Parameters...\")\n",
        "    print(f\"Epochs : {epoch_val}\")\n",
        "    print(f\"Batch size : {batch_size_val}\")\n",
        "    print(f\"Learning rate : {learning_rate_val}\")\n",
        "    print(f\"Validation split : {validation_split_val}\")\n",
        "    print(f\"Dropout : {dropout_val}\")\n",
        "    print(f\"Number of hidden layers : {number_of_hidden_layers_val}\")\n",
        "    print(f\"Hidden layer node count : {hidden_layer_node_count_val}\")\n",
        "    print(f\"Retrain layer count : {retrain_layer_count_val}\")\n",
        "    print(\"************************\")\n",
        "    set_config_param(20230214)\n",
        "\n",
        "    model_tokenizer = AutoTokenizer.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "    model = TFRobertaModel.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "\n",
        "    train_input_ids, train_attention_masks = text_encode(df_train['full_text'], model_tokenizer, MAX_LEN)\n",
        "    test_input_ids, test_attention_masks = text_encode(df_test['full_text'], model_tokenizer, MAX_LEN)\n",
        "\n",
        "    y_train = np.array(df_train[label_cols], dtype = \"float32\")\n",
        "\n",
        "    bertweet = build_regression_model(loss= \"MCRMSE\", \n",
        "                                      model_name = \"Bertweet\",\n",
        "                                      dense_dim = 6, \n",
        "                                      MAX_LEN = 512,\n",
        "                                      learning_rate = learning_rate_val,\n",
        "                                      dropout=dropout_val,\n",
        "                                      number_of_hidden_layers = number_of_hidden_layers_val,\n",
        "                                      hidden_layer_node_count = hidden_layer_node_count_val,\n",
        "                                      retrain_layer_count = retrain_layer_count_val)\n",
        "    bertweet.summary()\n",
        "\n",
        "    history_v1 = bertweet.fit((train_input_ids, train_attention_masks),\n",
        "                  y_train,\n",
        "                  batch_size = batch_size_val,     \n",
        "                  epochs = epoch_val,\n",
        "                  validation_split = validation_split_val\n",
        "                  )\n",
        "\n",
        "    history_v1_df = pd.DataFrame(history_v1.history)\n",
        "\n",
        "    score_v1 = bertweet.evaluate([test_input_ids, test_attention_masks], \n",
        "                    y_test\n",
        "                  ) \n",
        "\n",
        "    predictions_v1 = bertweet.predict([test_input_ids, test_attention_masks])\n",
        "    df_pred_v1 = pd.DataFrame(predictions_v1, columns=['pred_' + c for c in label_cols])\n",
        "\n",
        "    for col in label_cols:\n",
        "      df_pred_v1['transformed_pred_' + col] = df_pred_v1['pred_' + col].apply(lambda x : roundPartial(x, .5))\n",
        "    \n",
        "    df_compare_v1= pd.merge(df_test, df_pred_v1, left_index = True, right_index = True)\n",
        "    df_compare_v1.to_csv(\"predict_bertweet_0.csv\", index=False)\n",
        "\n",
        "    all = []\n",
        "    for col in label_cols:\n",
        "      all.append(((df_compare_v1[col]-df_compare_v1[\"transformed_pred_\"+col]).pow(2).mean())**(0.5))\n",
        "    RMSE_scaled = statistics.fmean(all)\n",
        "    print(f\"RMSE_scaled: {RMSE_scaled}\")\n",
        "\n",
        "    for label in label_cols:\n",
        "      print(label)\n",
        "      hall_of_fame(df_compare_v1,label,1)\n",
        "      print(\"************************\")\n",
        "      hall_of_shame(df_compare_v1,label,1)\n",
        "      print(\"************************\")\n",
        "    for component in label_cols:\n",
        "      print(component)\n",
        "      print(\"% Predicting too high: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\">\"+component))/len(df_compare_v1)))\n",
        "      print(\"% Predicted correctly: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"==\"+component))/len(df_compare_v1)))\n",
        "      print(\"% Predicting too low: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"<\"+component))/len(df_compare_v1)))\n",
        "      print(\"****\")\n",
        "    # Predicting too high or low for every score? \n",
        "\n",
        "    # for component in label_cols:\n",
        "    #   print(component)\n",
        "\n",
        "    #   for score in [1.0,1.5,2.0,2.5,3.0,3.5,4.0,4.5,5.0]:\n",
        "    #     if len(df_compare_v1[df_compare_v1[component]==score])==0:\n",
        "    #       print(component+\"==\"+str(score)+\" has 0 rows\")\n",
        "    #     else:\n",
        "    #       print(f'length: {len(df_compare_v1[df_compare_v1[component]==score])}')\n",
        "    #       print(\"% Predicting the above (\"+str(score)+\"): \" +\n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) &\n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]>score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #       print(\"% Predicting the same (\"+str(score)+\"): \" +\n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) & \n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]==score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #       print(\"% Predicting the below (\"+str(score)+\"): \" + \n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) & \n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]<score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #     print(\"****\")\n",
        "    for component in label_cols:\n",
        "      print(component)\n",
        "      print(\"% Predicting within .5: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"<=(\"+component+\"+.5) and transformed_pred_\"+component+\">=(\"+component+\"-.5)\"))/len(df_compare_v1)))"
      ],
      "metadata": {
        "id": "9ldRv4D6QZ1o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0f99a5ce99684adcb74b6d997dd4f6b6",
            "63e3ad6b2f714d83a9371224fc036969",
            "841c04a5892848feaccb9c5f8db87714",
            "15c166dfb76a4c778e078f4a798a1667",
            "1ba6bc91c94a439f811d817a996a3f89",
            "f5be82c8821c48d3b1cb9017841f0d77",
            "2d7c191b35fa4f10be56e5d6ea621584",
            "9719939c3b0946748256bd92fd9534c6",
            "28f0f0f927aa4d6d80a45e4bf15f1cfc",
            "8cc709c0cbe2412d8d281ab9f84463b1",
            "444d03ee8b4e4cb5a2ee62e769bc01a1",
            "0e7917045672490b88288cc47fb111e8",
            "f06b3a456911410e835a1ab4feca72e0",
            "28309e7c29b242aeb49361bf8b5127d8",
            "30719f59a4db452c939c3e8a54d30798",
            "85294c2326b64a748275411f5201e159",
            "9d92a01d03eb42098d864ef0bc145add",
            "a8ba13da20be4372810a8a1359ca557c",
            "5a1a84d5368e4a85bc2c5f3de605b20f",
            "fd26e87afb974ebdbfa5f67460712499",
            "37234288af2a444f9317d1a53376cde4",
            "4393074977724b5d9c7514e6212b25e8",
            "0c72c905ae934db2b34b4ab00ac577d8",
            "0a7b38b0978c41f3acd74bc82be39def",
            "b6edc4817bf3431c991d8d923a89ff1e",
            "f68553ac3b3b4ccfb4cdc67dc1a931cd",
            "10cc1b639ff04b5d823e04b6ba32c668",
            "e3e7fe0be36140889edc96805cdd3f9a",
            "b400ff9e85084e168d7a5d9e28b3f3b5",
            "b19cdfc0d0c149b4a7b873f5da0b5ba5",
            "e84ed1195b234049818f31377d9afaf6",
            "3fa790ed2e894e888bbeb3e9013770b8",
            "13993572354848a4b2c3b9317ebc4faa",
            "5876ad8f5e74428ca6002e0ae9097745",
            "c4936d6bed14436a88931c7775e18ff7",
            "6a6a2a8153224a94a0476b164bde2b13",
            "ea446597da424b29a15cddad8b6e0ae2",
            "901ee533fc4147fd94a01cf6d0710e65",
            "234fef11af4a4d5d9c1da7b50bcead21",
            "2965235ba8cb4a8abaafb19e5195ce01",
            "304b52a248364e85adf8ad5f64505313",
            "c5610672da1f4f7987ee84d17f0b3665",
            "a682d41932d54145a2802a4a47ba920e",
            "3a1461733a2f4d9ab2d5123f73c4718a"
          ]
        },
        "outputId": "96312c46-0930-4cb3-f37c-9a199d9d125f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************************\n",
            "Iteration : 1\n",
            "Parameters...\n",
            "Epochs : 10\n",
            "Batch size : 8\n",
            "Learning rate : 1e-05\n",
            "Validation split : 0.2\n",
            "Dropout : 0.1\n",
            "Number of hidden layers : 2\n",
            "Hidden layer node count : 64\n",
            "Retrain layer count : 0\n",
            "************************\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/558 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f99a5ce99684adcb74b6d997dd4f6b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/843k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e7917045672490b88288cc47fb111e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/bpe.codes:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c72c905ae934db2b34b4ab00ac577d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/740M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5876ad8f5e74428ca6002e0ae9097745"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters : 0\n",
            "Number of non-trainable parameters : 134899968\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_roberta_model_1 (TFRobertaM  TFBaseModelOutputWi  134899968  ['input_ids[0][0]',              \n",
            " odel)                          thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_roberta_model_1[0][0]']     \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " hidden_layer_1 (Dense)         (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_layer_1 (Dropout)      (None, 64)           0           ['hidden_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            " hidden_layer_2 (Dense)         (None, 64)           4160        ['dropout_layer_1[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_layer_2 (Dropout)      (None, 64)           0           ['hidden_layer_2[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 6)            390         ['dropout_layer_2[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 134,953,734\n",
            "Trainable params: 53,766\n",
            "Non-trainable params: 134,899,968\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_roberta_model_1 (TFRobertaM  TFBaseModelOutputWi  134899968  ['input_ids[0][0]',              \n",
            " odel)                          thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_roberta_model_1[0][0]']     \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " hidden_layer_1 (Dense)         (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_layer_1 (Dropout)      (None, 64)           0           ['hidden_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            " hidden_layer_2 (Dense)         (None, 64)           4160        ['dropout_layer_1[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_layer_2 (Dropout)      (None, 64)           0           ['hidden_layer_2[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 6)            390         ['dropout_layer_2[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 134,953,734\n",
            "Trainable params: 53,766\n",
            "Non-trainable params: 134,899,968\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "313/313 [==============================] - 177s 515ms/step - loss: 3.0059 - MCRMSE: 3.0057 - val_loss: 2.7446 - val_MCRMSE: 2.7494\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 159s 508ms/step - loss: 2.4625 - MCRMSE: 2.4624 - val_loss: 2.1009 - val_MCRMSE: 2.1056\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 161s 513ms/step - loss: 1.7884 - MCRMSE: 1.7881 - val_loss: 1.3632 - val_MCRMSE: 1.3672\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 162s 518ms/step - loss: 1.2083 - MCRMSE: 1.2080 - val_loss: 0.8587 - val_MCRMSE: 0.8614\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 163s 522ms/step - loss: 0.9832 - MCRMSE: 0.9832 - val_loss: 0.6731 - val_MCRMSE: 0.6747\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 149s 476ms/step - loss: 0.9135 - MCRMSE: 0.9135 - val_loss: 0.6302 - val_MCRMSE: 0.6317\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 148s 474ms/step - loss: 0.8971 - MCRMSE: 0.8970 - val_loss: 0.6178 - val_MCRMSE: 0.6192\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 163s 520ms/step - loss: 0.8905 - MCRMSE: 0.8905 - val_loss: 0.6102 - val_MCRMSE: 0.6118\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 163s 522ms/step - loss: 0.8614 - MCRMSE: 0.8614 - val_loss: 0.6044 - val_MCRMSE: 0.6062\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 163s 522ms/step - loss: 0.8428 - MCRMSE: 0.8427 - val_loss: 0.5995 - val_MCRMSE: 0.6012\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.6029 - MCRMSE: 0.6030\n",
            "25/25 [==============================] - 34s 1s/step\n",
            "RMSE_scaled: 0.6875804283199073\n",
            "cohesion\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('although former British minister Winston Churchill says \"success consists of '\n",
            " 'going from failure to failure without loss of enthusiasm.\" actually to get '\n",
            " 'to success sometimes does take failure to get it. actually this is very true '\n",
            " 'for people who never give and work hard even after they fail time and time '\n",
            " 'and again. for example when you fail at something to keep trying after till '\n",
            " \"you succeed. some people think if you fail you won't be successful that is \"\n",
            " 'not true. if you never give up you will be successful. another example when '\n",
            " 'you fall you always get back up and keep going and pushing forward. only you '\n",
            " \"can decide if you want to always fail or try harder. to get success it ain't \"\n",
            " 'easy. there is a saying nothing that is easy to get is wroth having. this '\n",
            " 'relates to what Churchill said. Winston Churchill is a wise man and i would '\n",
            " 'agree with him. everything he said about failing and being successful after '\n",
            " 'is true. they are so many successful people who have failed plenty of times '\n",
            " 'in their life. it happens to all people no can be perfect at what they want '\n",
            " 'or do in their life. inconclousion Winston Churchill is a wise man for his '\n",
            " 'saying. his saying can motivate many people who feel like giving up after '\n",
            " 'failing. ')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  2.5\n",
            "('A local workplace that you would like to pursue convince employer include '\n",
            " 'why you like this job .  My First, reason is allowing students to explore '\n",
            " 'the local bakery exploreing the local bakery can help students see what a '\n",
            " 'person dose in the a local bakery. The students can learn new things in a '\n",
            " 'local bakery for example my friend learn new things in the local bakery. '\n",
            " 'This can help students learn better things in the local bakery here is my '\n",
            " 'second reason.  My Next, reason is working at a local pursue bakery working '\n",
            " 'at a local bakery is helpful for me because I can make new friends and talk '\n",
            " 'with others. I can learn new stuff and do better in the local bakery.  for '\n",
            " 'an example I made new friends and talk with others at the local bakery. Here '\n",
            " 'are my other reason of allowing the exmployer a visit .  My Last,  reason is '\n",
            " 'allowing the employer for a visit at the local bakery allowing the employer '\n",
            " 'to come and visit. This would be very helpfull for me because the employer '\n",
            " 'can come see the bakery. And see how the students can also learn what a '\n",
            " 'bakery can do inside. I chose this job becuase it was a creativ job for me . '\n",
            " 'For an example this job help me in learning things and stuff . In closing '\n",
            " 'this is what a local workplace I chose . ')\n",
            "**********\n",
            "************************\n",
            "syntax\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('I am not agree with those educators that say, the summer break is too long '\n",
            " \"and the students can't retain imformation as easily when they return in the \"\n",
            " \"fall. The summer break is made to a students's benefit, it help the students \"\n",
            " 'as a relajation during the summer. The students have to spend time with '\n",
            " 'their family a lot as possible they can. Some of them need to make money, '\n",
            " 'and they take the summer break to make it. That is why I am not agree the '\n",
            " \"educators that does't wants the summer break long.  One reason,the students \"\n",
            " 'are in the school almost a whole year, and all that time they are stressed '\n",
            " 'by all the work they have to do in the school. Caming the summer break the '\n",
            " \"students wait it with antusiasm, and work hard to finish the school's work \"\n",
            " \"and enjoy summer break, it help them as a relajation after a school's \"\n",
            " 'stress, they have to forget the school by a mommet, and relax their brains. '\n",
            " \"Second reason, during the school's time the students does't have a lot of \"\n",
            " 'time to spend with their family, and the summer break is a good time of the '\n",
            " 'year to spend it with their dear, persons, friends, classmate, girlfriend, '\n",
            " \"and family. After it, the students are more prepared to star the school's \"\n",
            " 'year concentred at what they have to focus in the school with a clean brain '\n",
            " \",and do all the school's work. Third reason, some students have some \"\n",
            " 'obligations in their homes, for example some of those are: pay cellphone, '\n",
            " 'pay room, buy food, and pay car, so some student take advantages of the '\n",
            " 'summer break to make some money to helps them to pay all their obligations '\n",
            " \"in their homes, and don't take the school's time to spend it in other \"\n",
            " 'obligations, and take their time just to teh schools. Finally, the student '\n",
            " \"does't need the summer break shorter, they have a lot of things to do during \"\n",
            " \"the summer break, and it would't be justly to them, I am againt to the \"\n",
            " 'educators that feel the summer break is too long.')\n",
            "**********\n",
            "************************\n",
            "predicted:  2.0\n",
            "original:  3.5\n",
            "('\"Determine never to be idle...it is wonderful how much may be done if we are '\n",
            " 'always doing,\" a quote from Thomas Jefferson, meaning the more active we '\n",
            " 'are, the more we are able to accomplish. Although many would believe being '\n",
            " 'active would be the obvious answer, there are reasons as to why being '\n",
            " 'inactive may allow us to achieve more. By being inactive, we have plenty of '\n",
            " 'time on our hands to accomplish things, we have the energy to accomplish '\n",
            " 'more, rather than constantly being worked up and doing something, and we '\n",
            " 'also have time to brainstorm ideas.  Constantly doing something does not '\n",
            " 'give us the time we need to accomplish goals. By always have a fixed '\n",
            " 'schedule or always having to do something, we feel as though we connot risk '\n",
            " 'wasting any time by trying to achieve something. Having those few extra '\n",
            " 'minutes out of the day can allow us to create or focus on our hobbies, which '\n",
            " 'then can get us to accomplish things. For example, over the summer, my dad '\n",
            " 'decided to take time out of his job to focus on his love for plants. He then '\n",
            " 'decided to make it his goal to bulid a garden, by taking time out of his '\n",
            " 'very fixed work schedule to do it. By the end on the summer, he had '\n",
            " 'accomplished his goal; just from taking some time off.  Always doing '\n",
            " 'something causes us to lack the energy we need to accomplish things. When '\n",
            " 'constantly doing things and working, we are too tired to achieve anything, '\n",
            " 'because we put all our energy into everthing else we do. We become fatigue '\n",
            " 'and restless when constantly doing something. For example, my mother is '\n",
            " 'always doing something; she goes to class, goes to work, then comes home to '\n",
            " 'clean and cook. She is never able to accomplish anything because she does '\n",
            " 'not have enough energy. When we constantly work, all we want to do after is '\n",
            " 'sleep, rather than causing us to want to accomplish things.  By not always '\n",
            " 'having to do things, we are able to new brainstorm ideas. We can brainstorm '\n",
            " 'goals that we would like to accomplish. When always doing something our '\n",
            " 'minds are focused on other things, rather than focusing on acheiving goals. '\n",
            " 'We dont have time to sit and brainstorm when we are constantly working. Our '\n",
            " 'minds cannot focus on multiple things at once, meaning it does not have '\n",
            " 'space for other thoughts of accomplishments.  Even though many people think '\n",
            " 'that constantly being active helps accomplish more, it is not always true. '\n",
            " 'We can accomplish just as much, or even more when being inactive than always '\n",
            " 'doing something. By being inactive we have the time to accomplish things, we '\n",
            " 'have the energy to achieve more goals, rathan than being tired and restless, '\n",
            " 'and we are able to brainstorm ideas without other thoughts in our minds to '\n",
            " 'distract us.')\n",
            "**********\n",
            "************************\n",
            "vocabulary\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('Though most people think the inactivity serve a purpose however, the people '\n",
            " 'always need to doing things in their lives. All the people need to have '\n",
            " 'something to do in their life. Most people in the world think an inactivity '\n",
            " 'person can have in effect to other people, so the people need to always do '\n",
            " 'something in their life. The people need to have more activity in their '\n",
            " 'life. A activity person can have many success things can change their life '\n",
            " 'and the future a new generation in their families. A person with more '\n",
            " 'activity can be more successful .The inactivity is a person lazy can do not '\n",
            " 'care about doing something their life so, they may be do not care about '\n",
            " 'other people too.  Many people in the world does not have a job , but they '\n",
            " 'do not look for it. The people feels lazy to move around looking for work '\n",
            " 'and they only waste their time doing nothing. The people pass their time '\n",
            " 'without a work so, they are not doing nothing for their future for that many '\n",
            " 'people in the world are very poor. They can have a good future if they do '\n",
            " 'not waste their times doing nothing. In many countries there are people who '\n",
            " 'are very lazy for work, so they going to streets to ask other people give '\n",
            " 'money to them. The people have many opportunities in their life but , they '\n",
            " 'do not think about it. An inactivity person do not care about if they can '\n",
            " 'have a job or not. That kind of people just think have a free times. To be a '\n",
            " 'lazy person do not have any purpose in the life. Many children in the world '\n",
            " 'suffer with their parents because, they do not have a job .The children with '\n",
            " 'young age have to work because, their parents are very inactivity in the '\n",
            " 'their jobs. The inactivity can have a effect in the children because they '\n",
            " 'have to go to streets with parents ask for money to other person.  Most '\n",
            " 'people in world are very lazy. Some students have inactivity in the schools '\n",
            " '.The students when they have to do a work in group, they want to the easy '\n",
            " 'part of the work for that some students have problem when they become '\n",
            " 'adults. Most the students are very lazy so, they want all the things easy. '\n",
            " 'When the students become in adults they think all are going to be easy for '\n",
            " 'them like student years. Sometimes the work is next to them, but they are so '\n",
            " 'lazy for doing any work, so they only avoid the work. The people want to '\n",
            " 'waste their time in easy ways like spend time in home. Sometimes the people '\n",
            " 'want to find a job with easy ways to do it for that many people do not have '\n",
            " 'a job. The students need to be more activity person. To be a inactivity '\n",
            " 'person in young age can have a big a effect in the future. The students need '\n",
            " 'to have a purpose do not have to be inactivity person.  In the world many '\n",
            " 'people are unemployment, so they think that can be better for them. The '\n",
            " 'people can spend more time with their families,but they not need to be lazy. '\n",
            " 'They need to doing something for their country or their families. Many '\n",
            " 'people says if the world have less unemployment the economic can change for '\n",
            " 'a good way. The economic is very important for a future of the countries. If '\n",
            " 'the world can have less inactivity person the economic can change, so the '\n",
            " 'countries can have less poor people.  In conclusion, to be an inactivity '\n",
            " 'person does not have a purpose in life. The people need to always do '\n",
            " 'somethings for their life. If the people always do somethings, that people '\n",
            " 'can change the ways how can be their future life. An activity person always '\n",
            " 'are doing things with a purpose, so the person can be successful in '\n",
            " 'anythings they done. If the people are an inactivity person that mean they '\n",
            " 'can not have any purpose, so the people never has to be an inactivity '\n",
            " 'person. The people never need to act lazy around. Any people need to act '\n",
            " 'like more a activity person so, they can be more succesful in '\n",
            " 'life.                  ')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  4.0\n",
            "('Should the city council adoption the curfew of a 10 p. m weekday and a '\n",
            " 'midnight weekend curfew for teenagers?  You often hear people say that '\n",
            " 'teenagers are costing more problem to other people and for the around them '\n",
            " 'environment. The city council should adoption the 10 p. m midnight curfew '\n",
            " 'for teenagers because teens would stay out of problems, and they would have '\n",
            " 'more time to do school work.  To start, the curfew would avoid teenagers '\n",
            " 'being in problem with the law. For example,teens with the curfew would not '\n",
            " 'be in gangs or cost problem to others. Lets say that teens had the curfew it '\n",
            " 'would expand beyond the level of doing good to others and staying out of '\n",
            " 'gangs or doing bad stuff. They would be able to achieve their goals fast and '\n",
            " 'force on what is next in life. Even though, this curfew sounds bad its not '\n",
            " 'bad because teens would learn that the curfew is just to help them and help '\n",
            " 'the environment around them.  Secondly, the curfew would allow teens with '\n",
            " 'more time on their schools work and have time to force on their work. For '\n",
            " 'example, teens would have more time to focus on their schools work than '\n",
            " 'being on the streets with gangs. With that being said teens would have a '\n",
            " 'chance of achieving their dreams and being successful in live without a bad '\n",
            " 'influences. In this scenario, it show that a curfew is not bad because it '\n",
            " 'has some good way in live and it allow people to do good stuff for others. '\n",
            " 'Ultimately, with this curfew it allows young people to see the better side '\n",
            " 'in life and it would help them to stay focus in schools by achieving their '\n",
            " 'work and doing the right things.  Some people may say that having a curfew '\n",
            " 'is unfairly interfere in young people lives. For example, young people have '\n",
            " 'the right to choose the way they want to be. Therefor, being later in night '\n",
            " 'dose not meant that young people are doing bad stuff or their are in gangs '\n",
            " 'also they are just having fun in their way. Thus, being in a curfew it show '\n",
            " 'young people that their are controlling by other people just because they '\n",
            " 'have a different way of having fun. In this scenario, it show that having a '\n",
            " 'curfew is just unfairly for teenagers just because other teens got in '\n",
            " 'trouble it dose not means that all of the young people needs to have a '\n",
            " 'curfew.  In conclusion, the city council would just being helpful to the '\n",
            " 'young people by add a time limit. And it would help the environment around '\n",
            " 'them and it would give more time and focus to the young people. All in all, '\n",
            " 'it is a good thing to put a curfew because teens would have more time to '\n",
            " 'spent with their family and doing good stuff for the environment.    ')\n",
            "**********\n",
            "************************\n",
            "phraseology\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('I think, with that changing 4 days of work in a week have disadvantages and '\n",
            " 'some benefits. because people will not have time to live their normal life '\n",
            " 'or do work at home, they will use the same amount of energy and resources '\n",
            " 'and people will not support to work many hours in a day.  In addition, '\n",
            " 'people have already their own routine to work, even thought if some busines '\n",
            " 'try to change work days.  To began,  people will not have time to share with '\n",
            " 'their family, also working 4 day a week for 10 hours will cause problem in '\n",
            " 'your family, children in those time do not have enough responsibility to be '\n",
            " 'home by their self, even thought, people will not have time to do work at '\n",
            " 'home. For example; to clean their house, to go work after school and to '\n",
            " 'coexists their problems or thoughts with the family. And to do other works '\n",
            " 'at the end of the day.  Second, working 10 hours a day they will use the '\n",
            " 'same quantity of energy and resources because is the same sum of hours that '\n",
            " 'all people work, if they work 8 hours a day for 5 day, even that people may '\n",
            " 'use more energy, because the rest of the week people will need energy, as '\n",
            " 'well to work 10 hours a day will use the same amount of resources, to make '\n",
            " 'up all the works that you need to do.  Lastly, people will not support '\n",
            " 'working 10 hours a day, because many people have their routine to work, or '\n",
            " 'some of them have problems working to many hours, another reason why people '\n",
            " 'can not work 10 hours a day is that they have their own routine work, as '\n",
            " 'well student in school will not support to be in class. For example many '\n",
            " 'student gets bored in class juts been 8 hours in school and if we compare '\n",
            " 'there will be a lot if issue with their attendance. another point is many '\n",
            " 'student work to support their self, so in that occation they will not '\n",
            " 'available to work and make money.  To conclude, to work 10 hours a day is to '\n",
            " 'hard for many people and they will try to work less hours in a day, because '\n",
            " 'they can not have time to share with the family, also they can get sick for '\n",
            " 'being working to many hours. even thought on this times some people worked '\n",
            " '10 hours a day, but at the end of all that working to much can cause serious '\n",
            " 'problems with your health.        ')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  3.5\n",
            "('Can a positive attitude take you to the life that you always have '\n",
            " 'dreamed?.There are so many reasons to support that a positive attitude is '\n",
            " 'the key to open the doors of succesful!!!. Being positive, anyone acquire '\n",
            " 'the capacity of be smart to make good decisions. For example a negative '\n",
            " 'person never going to take risk to make a hard decision because always going '\n",
            " 'to think in that everything goes to be bad. Positive attitude must be in the '\n",
            " 'mind of everybody because is the only way to be succesful in this world. '\n",
            " 'Positive person eventhough sometimes make mistakes never going to give up '\n",
            " 'and always going to keep trying to achive anything, no matter the negative '\n",
            " 'commentaries of the people. A positive attitude bring the happiness that '\n",
            " \"everyone is looking, it's like be a super man with super powers. A lot of \"\n",
            " 'famous people like actors, singers,entrepreneurs, and others recomend be '\n",
            " 'positive even upon a pouring rain all of them are a good example to say '\n",
            " 'that. All these things prove that be positive always going to be the step '\n",
            " 'that everyone should take to be someone in this life.  All these things that '\n",
            " 'positive always going to be the step that everyone should take to be someone '\n",
            " 'in this life there are a lot of famous like actors, singers, entrepreneurs, '\n",
            " 'and others recomend be positive even upon a pouring rain because a positive '\n",
            " \"attitude bring the happiness that everyone is looking, it's like be a super \"\n",
            " 'man with super powers, always a Positive person eventhough sometimes make '\n",
            " 'mistakes never going to give up and always going to keep trying to achive '\n",
            " 'anything, no matter the negative commentaries of the people that is why a '\n",
            " 'positive attitude must be in the mind of everybody because is the only way '\n",
            " 'to be succesful in this world, for example a negative person never going to '\n",
            " 'take risk to make a hard decision because always going to think in that '\n",
            " 'everything goes to be bad the only way to make it is being positive, anyone '\n",
            " 'acquire the capacity of be smart to make good decisions think about this '\n",
            " 'cuestion, Can a positive attitude take you to the life that you always have '\n",
            " 'dreamed?.There are so many reasons to support that a positive attitude is '\n",
            " 'the key to open the doors of succesful.')\n",
            "**********\n",
            "************************\n",
            "grammar\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('So i think it we should do the four day school week here at Generic_School.  '\n",
            " 'Because here are one advantage and one disadvantage. The one advantage is '\n",
            " 'that the student will get a three day week end. And then here is a another '\n",
            " 'advantage is that the student would have enough time to finish their '\n",
            " 'homework and project. And then for the one disadvantage is that the student '\n",
            " 'would have a longer school day because they are adding the eight hour that '\n",
            " 'we are going to miss for Friday school day. they would be dividing that '\n",
            " 'eight hour of school for the four day of school that we are going to have. '\n",
            " 'and then here is a another disadvantage like would the student who play '\n",
            " 'sport have short practice because of this like if we do in real life would '\n",
            " 'that actually happen.  So here is my first reason why it is a good reason '\n",
            " 'for this to happen because it would save the school a bunch of money on '\n",
            " 'electric bill. And then here is another good reason that we should do this '\n",
            " 'is that it would help the teacher teach to student understand the material a '\n",
            " 'little bit better. And then here is second reason why it is a bad reason to '\n",
            " 'do this and school like this will give student who play sport a short time '\n",
            " 'to do homework at home because they have school then after school they have '\n",
            " 'practice  So in conclusion we should try this for a month and then after '\n",
            " 'that month we can see if we should keep this thing going on for the rest of '\n",
            " 'the school year. like we can ask the student if they want it to stay. Or we '\n",
            " 'can back the regular secudule like we go the regular time that we get school '\n",
            " 'and then we go back to the five day school week. like in my opinion we '\n",
            " 'should try this out and see how this turn out like would most of the student '\n",
            " 'like this or would most of them hate like i think this is going to be like a '\n",
            " '50 50  chance of this working and not working. like i feel like most of the '\n",
            " 'student would like and the rest of student hating this because the extending '\n",
            " 'hour of the school day but the student who are going to love this is because '\n",
            " 'of the three day weekend and then for the teacher they all would love this '\n",
            " 'idea for the school year')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  2.0\n",
            "('Working with group is more beneficial because, if a person work in group '\n",
            " 'then he/she can share thought and ideas before start working. Also, it helps '\n",
            " 'student to learn how to communicate with other team member because team work '\n",
            " 'is very important and necessary to learn before students start working '\n",
            " 'professionally.  I believe that working in group will gives student more '\n",
            " 'ideas and everyone in group can share their thoughts with each other. It '\n",
            " 'also helps students to finish their work on time and the most important is '\n",
            " 'that not only one person have burden to do all work. Communication is the '\n",
            " 'key of working in group because, group working is also helps students to '\n",
            " 'learn how to communicate and how people should behave when they work as a '\n",
            " 'team.  Team work and communication is very important to learn before a '\n",
            " 'person go to college or before start working professionally because, if a '\n",
            " 'person does not have ability to work in team then it would be very hard to '\n",
            " 'adjust in college or professional work environment. There are many '\n",
            " 'advantages of working in group for instance, student can plan and share '\n",
            " 'ideas with their group, they can discuss the work with each other before the '\n",
            " 'start work on any project and they can also help each other if any of the '\n",
            " 'group member is confused in anything. The most important part of the any '\n",
            " 'project or any other work is finish on time and if not then no matter how '\n",
            " 'much hard work the person put is just useless. Group working is also save '\n",
            " 'time because everyone work together rather then only one person has burden '\n",
            " 'to complete all work.  To conclude, I just want to mention that I understand '\n",
            " 'that working alone is more beneficial for some people but, working in group '\n",
            " 'is much better more easier than working alone. For instance, working in '\n",
            " \"group gives more ideas from different people's sense of humor and people get \"\n",
            " 'chance to work with different people whose thoughts and working style is '\n",
            " 'different.   ')\n",
            "**********\n",
            "************************\n",
            "conventions\n",
            "predicted:  2.5\n",
            "original:  2.5\n",
            "('Today, in the actuality, a lot of people have a big dreams that we can to '\n",
            " 'complete have a better life for our future family or also to own self but a '\n",
            " 'many people be surrender becuase most of the time have the fuilures, when '\n",
            " 'they are doing something; I think that our life without the fuilures will be '\n",
            " \"bored and easy becuase we don't have the energies to work hard or fight for \"\n",
            " \"our goals or dreams. I agree with Churchill's statement about the important \"\n",
            " 'role that failure plays in the pursuit of success because you can help other '\n",
            " 'to complete their dreams or their goals, also you can have more spirit and a '\n",
            " 'positives attitudes than you have in the begging, also you can be a '\n",
            " 'successful and strong person.  You can help others to complete with their '\n",
            " 'dreams or their goals, because sometimes a lot of people who want to comply '\n",
            " \"their dreams or goals they don't have the motivation of their families or \"\n",
            " 'the economy necessary to buy all the studies or all the things that they '\n",
            " 'need, so when you finish all the goals that you make you, you can assist to '\n",
            " 'others. I know an experience of child from Mexico, his name was '\n",
            " 'Generic_Name. Generic_Name was a child with the low economy resources, I '\n",
            " 'remember that he toll us all the things that he was comply to get a better '\n",
            " 'life for his family and him self. So one day, Generic_Name received a big '\n",
            " 'notice from a presidency of Generic_City, the place were we live, that he '\n",
            " 'can have a opportunity to study whatever he want. He and his family were '\n",
            " 'happy for the big opportunity that Generic_Name have. At pass of the years, '\n",
            " 'when Generic_Name finished study the collage, I know that Generic_Name is a '\n",
            " 'big entrepreneur from a big company that he created after finished the '\n",
            " 'college. Today, also Generic_Name likes help other people who want to be a '\n",
            " 'successful in their life like the presidency help him. In my observation to '\n",
            " 'be a good person likes Generic_Name makes that you have a lot of open '\n",
            " 'opportunities to get the success or the things that Generic_Name every day '\n",
            " 'was dreamed.  Also you can be a successful and strong person because all '\n",
            " 'people knows that the life is not easy and less if you want to do something '\n",
            " 'hard or something that you need put a lot of time in it to pursuit of '\n",
            " 'success and if you think that your goals or dreams are difficult to '\n",
            " 'complete. Sometimes we need strive more that the people or your mind think. '\n",
            " 'Another of my experiences is when was in Mexico, I was little girl, I '\n",
            " 'remember that most of my days I talked with my family, my mother, my father '\n",
            " 'and also sometimes with my grandfathers; about that I want study the High '\n",
            " 'School in Untied States because I saw a TV Shows and movies shows all the '\n",
            " 'schools and also my father lived a lot of years in this country so, he talk '\n",
            " 'me about the schools, the teachers, the classmates, the classes and '\n",
            " 'classrooms that were to different form my country, the lunch time and I '\n",
            " 'think that the thing that was more exercise was with the lockers because in '\n",
            " \"my country don't have lockers or something to put our things likes books, \"\n",
            " 'pencils, notebooks and sometimes, the food. At the time that was grow up, I '\n",
            " 'was continue with the same mentality to come to this country to comply my '\n",
            " 'studies. I remember that have a lot of failures in the time to the arrival '\n",
            " 'to United States but,even if never let that my thoughts or the commentaries '\n",
            " 'of the negative people will be fell bad about my big dream. I think that was '\n",
            " 'a strong person because is hard to come to other place with different '\n",
            " 'culture and customers in everything and also is hard and sad separate to the '\n",
            " 'persons who love.  Other might say that the importance role that failure '\n",
            " 'plays in the pursuit of success does not matter or they are disagree because '\n",
            " 'you can lose your forces to continue and accomplish your goals and sometimes '\n",
            " 'this failure can make us fell sad. However, you can have more spirit and '\n",
            " 'positives attitudes than you have in the begging because when you have a '\n",
            " 'failure in something that you study a lot or put your all time in it, you '\n",
            " 'can have the mentality that you can to do well it, just you need strive a '\n",
            " 'little be more that you make before. This is one of my experiences in my '\n",
            " 'life; the last week, in my History class with Generic_Name, we have a quiz '\n",
            " 'form the first unit so, we did the quiz, but the majority of my classmates '\n",
            " \"and me, we don't pass the quiz, my teacher talked with us to give us a \"\n",
            " 'another opportunity to pass it. A lot of my classmates tell her that they do '\n",
            " 'not were think that they can pass it even though they study a lot before the '\n",
            " 'retake but, I have the spirit and the positives attitudes that I can passed '\n",
            " 'the quiz with a good grade and study well at home. I think that my '\n",
            " 'experience, it is good example because a lot of people who want to complete '\n",
            " 'their dreams does not matter the times that they need to try to get a good '\n",
            " 'result and a good recompense for the effort that they make.  In my opinion, '\n",
            " 'I think that Churchill\\'s statement \"success consists of going from failure '\n",
            " 'to failure without loss of enthusiasm\" it is important and I agree with it '\n",
            " 'because you can motive other people to be a good person with good feelings '\n",
            " 'and goals, another reason is because you can to be a successful and '\n",
            " 'respectful person and you can have a good attitudes through haved a bad '\n",
            " 'results, every time you need stay be happy. Most of the people we have the '\n",
            " 'big goals to comply something that always we dreaming.')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  2.0\n",
            "('FIRST, I CHOOSE TOHAVE THE LONGER SPRING BREAKS.SECOND ,THE STUDENT CAN '\n",
            " 'TRAVEL TO VISIT THEIR FAMILY.THIRD, ENJOYA THE BEACH FOR TIME THAT STUDENTS '\n",
            " \"WANTS.DOESN'T HAVE WORRY ABOUT GOING BACK TO SCHOOL.  FIRST I CHOSE THAT \"\n",
            " 'STUDENTS SHOULD HAVE LONGER BREAK BECAUSE THE STUDENT NEED TO FUN FOR THE '\n",
            " 'BREAK . II CHOSE THAT STUDENT HAVE THE LONGER SUMMER BREAK BECAUSE THE IS MY '\n",
            " 'FAVORITE BREAK IN MY ALL FAMILY STAY HOME OR SOMETIME WE ARE TRAVEL SOME '\n",
            " 'ANOTHER COUNTRY .  THE MOST OF THE STUDENT TRAVEL FOR ANOTHER PLACE .THE '\n",
            " 'SOME STUDENTS CAN TRAVEL TO VISIT THEIR FAMILY BECAUSE THERE FAMILY WAS A '\n",
            " 'DIFFERNT COUNTRY OR DIFFERENT PLACE .WE ARE VISIT HOME BECAUSE WE ARE ENJOYA '\n",
            " 'THEIR FAMILY.WE ARE TRAVEL THE THE FUN PLACE BECAUSE MY FAMILY WAS A LOVE '\n",
            " 'THERE .  WE ARE TRAVEL THE BEACH WE ARE ENJOY THE BEACH FOR MY FAMILY OR MY '\n",
            " 'FRIENDS BECAUSE MY FRIEND AND WE ARE PLAY THE SAND WE HAVE THE FUN .MY ALL '\n",
            " 'FAMILY WAS GOING THERE WE HAVE FUN. I CHOSE TONOT HAVE LONGER SPRING BREAK '\n",
            " \"BECAUSE WON'T CATCH COLD .MORE DIFFICULT FOR STUDENTS OF THE CANSANTRATE .I \"\n",
            " 'CHOSE THE BOTH SIDE BECAUSE THERE WAS A NOT HAVE LONGER SUMMER BECAUSE WE '\n",
            " 'CAN CATCH COLD MOVE DIFICULT FOR THE CONSANTRATE FOR THE STUDENTS .WE ARE '\n",
            " 'TAKING THE LONG BREAKBECAUSE WE ARE FORGET THE EVERYTHINGS . I THINKS ALL '\n",
            " 'STUDENT ENJOYA THE SUMMER BREAK BECAUSE THE SUMMER BREAK WAS THE FUN FOR THE '\n",
            " 'STUDENTS.  MOST OF THE STUDENTS TAKE THE LONG BREAK BECAUSE TNE STUDENTS '\n",
            " 'MOVE THE DIFFERENT PLACE .SUMMER BREAK TAKE THE 1WEAK FOR STUDENTS .THERE '\n",
            " 'WAS THE DIFFERENTS KINDS OF THE SEASON BECAUES MOST PEOPLE LOVE SUMMER OR '\n",
            " 'WINTER AND SPRINGS.SOME PEOPLE LOVE THE SUMMER OR SOME PEOPLE LOVE THE '\n",
            " 'WINTER OR PEOPLE THE SPRINGS. THE SUMMER BREAKS OR WINTER SOMST OF THE '\n",
            " 'PEOPLE ENJOY WINTER .THIS SPRING BREAK I WAS A TRAVEL TO MY COUNTRY BECAUSE '\n",
            " \"I'M VISIT TO MY FRIENDS .I LOVE TO VISIT MY FRENSD .I THINK I AM MOVING \"\n",
            " 'DIFFERENT PLACE FOR THREE DAY THIS PLACE WAS A BEAUTIFUL.THER WAS DIFFERENT '\n",
            " 'KINDS OF FLOWER OR DIFFERENT KINDS OF THE COLORS OR DIFFERENT FROOT OR '\n",
            " 'DIFFERENT DRESS  DIFFERENT KINDS OF FESTIBLE.MOST STUDENTS LOVE TAKE 4,4 '\n",
            " 'WEAK BREAKS THE SCHOOLS '\n",
            " '.                                                                                                      ')\n",
            "**********\n",
            "************************\n",
            "cohesion\n",
            "% Predicting too high: 0.2988505747126437\n",
            "% Predicted correctly: 0.2950191570881226\n",
            "% Predicting too low: 0.4061302681992337\n",
            "****\n",
            "syntax\n",
            "% Predicting too high: 0.2541507024265645\n",
            "% Predicted correctly: 0.2962962962962963\n",
            "% Predicting too low: 0.4495530012771392\n",
            "****\n",
            "vocabulary\n",
            "% Predicting too high: 0.26053639846743293\n",
            "% Predicted correctly: 0.3780332056194125\n",
            "% Predicting too low: 0.3614303959131545\n",
            "****\n",
            "phraseology\n",
            "% Predicting too high: 0.2669220945083014\n",
            "% Predicted correctly: 0.30268199233716475\n",
            "% Predicting too low: 0.43039591315453385\n",
            "****\n",
            "grammar\n",
            "% Predicting too high: 0.31928480204342274\n",
            "% Predicted correctly: 0.26436781609195403\n",
            "% Predicting too low: 0.4163473818646232\n",
            "****\n",
            "conventions\n",
            "% Predicting too high: 0.3167305236270754\n",
            "% Predicted correctly: 0.2937420178799489\n",
            "% Predicting too low: 0.3895274584929757\n",
            "****\n",
            "cohesion\n",
            "length: 2\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 6\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 64\n",
            "% Predicting the above (2.0): 1.0\n",
            "% Predicting the same (2.0): 0.0\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 162\n",
            "% Predicting the above (2.5): 0.8024691358024691\n",
            "% Predicting the same (2.5): 0.19135802469135801\n",
            "% Predicting the below (2.5): 0.006172839506172839\n",
            "****\n",
            "length: 219\n",
            "% Predicting the above (3.0): 0.1461187214611872\n",
            "% Predicting the same (3.0): 0.6940639269406392\n",
            "% Predicting the below (3.0): 0.1598173515981735\n",
            "****\n",
            "length: 198\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.24242424242424243\n",
            "% Predicting the below (3.5): 0.7575757575757576\n",
            "****\n",
            "length: 93\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.0\n",
            "% Predicting the below (4.0): 1.0\n",
            "****\n",
            "length: 35\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 4\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "syntax\n",
            "length: 4\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 5\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 96\n",
            "% Predicting the above (2.0): 0.9791666666666666\n",
            "% Predicting the same (2.0): 0.020833333333333332\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 149\n",
            "% Predicting the above (2.5): 0.610738255033557\n",
            "% Predicting the same (2.5): 0.3691275167785235\n",
            "% Predicting the below (2.5): 0.020134228187919462\n",
            "****\n",
            "length: 257\n",
            "% Predicting the above (3.0): 0.019455252918287938\n",
            "% Predicting the same (3.0): 0.6614785992217899\n",
            "% Predicting the below (3.0): 0.31906614785992216\n",
            "****\n",
            "length: 170\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.029411764705882353\n",
            "% Predicting the below (3.5): 0.9705882352941176\n",
            "****\n",
            "length: 81\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.0\n",
            "% Predicting the below (4.0): 1.0\n",
            "****\n",
            "length: 19\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 2\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "vocabulary\n",
            "vocabulary==1.0 has 0 rows\n",
            "****\n",
            "length: 4\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 26\n",
            "% Predicting the above (2.0): 1.0\n",
            "% Predicting the same (2.0): 0.0\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 101\n",
            "% Predicting the above (2.5): 0.9207920792079208\n",
            "% Predicting the same (2.5): 0.0594059405940594\n",
            "% Predicting the below (2.5): 0.019801980198019802\n",
            "****\n",
            "length: 305\n",
            "% Predicting the above (3.0): 0.26557377049180325\n",
            "% Predicting the same (3.0): 0.6983606557377049\n",
            "% Predicting the below (3.0): 0.036065573770491806\n",
            "****\n",
            "length: 194\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.39690721649484534\n",
            "% Predicting the below (3.5): 0.6030927835051546\n",
            "****\n",
            "length: 122\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.0\n",
            "% Predicting the below (4.0): 1.0\n",
            "****\n",
            "length: 24\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 7\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "phraseology\n",
            "length: 3\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 3\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 74\n",
            "% Predicting the above (2.0): 0.9864864864864865\n",
            "% Predicting the same (2.0): 0.013513513513513514\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 152\n",
            "% Predicting the above (2.5): 0.8355263157894737\n",
            "% Predicting the same (2.5): 0.16447368421052633\n",
            "% Predicting the below (2.5): 0.0\n",
            "****\n",
            "length: 242\n",
            "% Predicting the above (3.0): 0.012396694214876033\n",
            "% Predicting the same (3.0): 0.8553719008264463\n",
            "% Predicting the below (3.0): 0.1322314049586777\n",
            "****\n",
            "length: 180\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.022222222222222223\n",
            "% Predicting the below (3.5): 0.9777777777777777\n",
            "****\n",
            "length: 107\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.0\n",
            "% Predicting the below (4.0): 1.0\n",
            "****\n",
            "length: 18\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 4\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "grammar\n",
            "length: 3\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 6\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 95\n",
            "% Predicting the above (2.0): 1.0\n",
            "% Predicting the same (2.0): 0.0\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 181\n",
            "% Predicting the above (2.5): 0.7237569060773481\n",
            "% Predicting the same (2.5): 0.27071823204419887\n",
            "% Predicting the below (2.5): 0.0055248618784530384\n",
            "****\n",
            "length: 193\n",
            "% Predicting the above (3.0): 0.07772020725388601\n",
            "% Predicting the same (3.0): 0.7512953367875648\n",
            "% Predicting the below (3.0): 0.17098445595854922\n",
            "****\n",
            "length: 176\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.07386363636363637\n",
            "% Predicting the below (3.5): 0.9261363636363636\n",
            "****\n",
            "length: 96\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.0\n",
            "% Predicting the below (4.0): 1.0\n",
            "****\n",
            "length: 25\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 8\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "conventions\n",
            "length: 1\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 5\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 85\n",
            "% Predicting the above (2.0): 0.9882352941176471\n",
            "% Predicting the same (2.0): 0.011764705882352941\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 155\n",
            "% Predicting the above (2.5): 0.8580645161290322\n",
            "% Predicting the same (2.5): 0.12903225806451613\n",
            "% Predicting the below (2.5): 0.012903225806451613\n",
            "****\n",
            "length: 240\n",
            "% Predicting the above (3.0): 0.10416666666666667\n",
            "% Predicting the same (3.0): 0.7916666666666666\n",
            "% Predicting the below (3.0): 0.10416666666666667\n",
            "****\n",
            "length: 168\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.1130952380952381\n",
            "% Predicting the below (3.5): 0.8869047619047619\n",
            "****\n",
            "length: 96\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.0\n",
            "% Predicting the below (4.0): 1.0\n",
            "****\n",
            "length: 26\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 7\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "cohesion\n",
            "% Predicting within .5: 0.7241379310344828\n",
            "syntax\n",
            "% Predicting within .5: 0.7292464878671775\n",
            "vocabulary\n",
            "% Predicting within .5: 0.8071519795657727\n",
            "phraseology\n",
            "% Predicting within .5: 0.7343550446998723\n",
            "grammar\n",
            "% Predicting within .5: 0.6704980842911877\n",
            "conventions\n",
            "% Predicting within .5: 0.7049808429118773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_compare_v1 = pd.read_csv(\"predict_bertweet_0.csv\")\n",
        "for component in label_cols:\n",
        "  print(pd.crosstab(df_compare_v1[component], df_compare_v1[\"transformed_pred_\"+component], margins=True))\n",
        "  print()"
      ],
      "metadata": {
        "id": "oxUUt3tcK7vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERTweet with its first 6 layers unfrozen"
      ],
      "metadata": {
        "id": "dLWyqxG4Dnul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed parameters\n",
        "dense_dim = 6\n",
        "number_of_splits = 2\n",
        "random_state = 2023\n",
        "mse_loss = MCRMSE\n",
        "mse_metrics = MCRMSE\n",
        "model_name_list = ['Bert', 'Bertweet'] # Roberta\n",
        "\n",
        "df_train = pd.read_csv('df_train_split.csv')\n",
        "df_test = pd.read_csv('df_test_split.csv')\n",
        "print(f\"Length of train data : {len(df_train)}\")\n",
        "print(f\"Length of test data : {len(df_test)}\")\n",
        "y_test = np.array(df_test[label_cols], dtype = \"float32\")"
      ],
      "metadata": {
        "id": "JR7KuCt9Dqid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acc5d257-0fe9-4745-d6d3-ac3cf8346a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train data : 3128\n",
            "Length of test data : 783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable parameter dictionary\n",
        "param_list = [   # Partially frozen base layer\n",
        "                 {'epochs'                  : 10,\n",
        "                  'batch_size'              : 8,\n",
        "                  'learning_rate'           : 1e-5,\n",
        "                  'validation_split'        : .2,\n",
        "                  'dropout'                 : .1,\n",
        "                  'number_of_hidden_layers' : 2,\n",
        "                  'hidden_layer_node_count' : 64,\n",
        "                  'retrain_layer_count'     : 6\n",
        "                 }\n",
        "             ]"
      ],
      "metadata": {
        "id": "H3srUqj_QZ_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, param_entry in enumerate(param_list):\n",
        "    MAX_LEN = 512\n",
        "    epoch_val = param_entry['epochs']\n",
        "    batch_size_val = param_entry['batch_size']\n",
        "    learning_rate_val = param_entry['learning_rate']\n",
        "    validation_split_val = param_entry['validation_split']\n",
        "    dropout_val = param_entry['dropout']\n",
        "    number_of_hidden_layers_val = param_entry['number_of_hidden_layers']\n",
        "    hidden_layer_node_count_val = param_entry['hidden_layer_node_count']\n",
        "    retrain_layer_count_val = param_entry['retrain_layer_count']\n",
        "\n",
        "    print(\"************************\")\n",
        "    print(f\"Iteration : {idx + 1}\")\n",
        "    print(\"Parameters...\")\n",
        "    print(f\"Epochs : {epoch_val}\")\n",
        "    print(f\"Batch size : {batch_size_val}\")\n",
        "    print(f\"Learning rate : {learning_rate_val}\")\n",
        "    print(f\"Validation split : {validation_split_val}\")\n",
        "    print(f\"Dropout : {dropout_val}\")\n",
        "    print(f\"Number of hidden layers : {number_of_hidden_layers_val}\")\n",
        "    print(f\"Hidden layer node count : {hidden_layer_node_count_val}\")\n",
        "    print(f\"Retrain layer count : {retrain_layer_count_val}\")\n",
        "    print(\"************************\")\n",
        "    set_config_param(20230214)\n",
        "\n",
        "    model_tokenizer = AutoTokenizer.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "    model = TFRobertaModel.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "\n",
        "    train_input_ids, train_attention_masks = text_encode(df_train['full_text'], model_tokenizer, MAX_LEN)\n",
        "    test_input_ids, test_attention_masks = text_encode(df_test['full_text'], model_tokenizer, MAX_LEN)\n",
        "\n",
        "    y_train = np.array(df_train[label_cols], dtype = \"float32\")\n",
        "\n",
        "    bertweet = build_regression_model(loss= \"MCRMSE\", \n",
        "                                      model_name = \"Bertweet\",\n",
        "                                      dense_dim = 6, \n",
        "                                      MAX_LEN = 512,\n",
        "                                      learning_rate = learning_rate_val,\n",
        "                                      dropout=dropout_val,\n",
        "                                      number_of_hidden_layers = number_of_hidden_layers_val,\n",
        "                                      hidden_layer_node_count = hidden_layer_node_count_val,\n",
        "                                      retrain_layer_count = retrain_layer_count_val)\n",
        "    bertweet.summary()\n",
        "\n",
        "    history_v1 = bertweet.fit((train_input_ids, train_attention_masks),\n",
        "                  y_train,\n",
        "                  batch_size = batch_size_val,     \n",
        "                  epochs = epoch_val,\n",
        "                  validation_split = validation_split_val\n",
        "                  )\n",
        "\n",
        "    history_v1_df = pd.DataFrame(history_v1.history)\n",
        "\n",
        "    score_v1 = bertweet.evaluate([test_input_ids, test_attention_masks], \n",
        "                    y_test\n",
        "                  ) \n",
        "\n",
        "    predictions_v1 = bertweet.predict([test_input_ids, test_attention_masks])\n",
        "    df_pred_v1 = pd.DataFrame(predictions_v1, columns=['pred_' + c for c in label_cols])\n",
        "\n",
        "    for col in label_cols:\n",
        "      df_pred_v1['transformed_pred_' + col] = df_pred_v1['pred_' + col].apply(lambda x : roundPartial(x, .5))\n",
        "    \n",
        "    df_compare_v1= pd.merge(df_test, df_pred_v1, left_index = True, right_index = True)\n",
        "    df_compare_v1.to_csv(\"predict_bertweet_6.csv\", index=False)\n",
        "\n",
        "    all = []\n",
        "    for col in label_cols:\n",
        "      all.append(((df_compare_v1[col]-df_compare_v1[\"transformed_pred_\"+col]).pow(2).mean())**(0.5))\n",
        "    RMSE_scaled = statistics.fmean(all)\n",
        "    print(f\"RMSE_scaled: {RMSE_scaled}\")\n",
        "\n",
        "    for label in label_cols:\n",
        "      print(label)\n",
        "      hall_of_fame(df_compare_v1,label,1)\n",
        "      print(\"************************\")\n",
        "      hall_of_shame(df_compare_v1,label,1)\n",
        "      print(\"************************\")\n",
        "    for component in label_cols:\n",
        "      print(component)\n",
        "      print(\"% Predicting too high: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\">\"+component))/len(df_compare_v1)))\n",
        "      print(\"% Predicted correctly: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"==\"+component))/len(df_compare_v1)))\n",
        "      print(\"% Predicting too low: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"<\"+component))/len(df_compare_v1)))\n",
        "      print(\"****\")\n",
        "    # Predicting too high or low for every score? \n",
        "\n",
        "    # for component in label_cols:\n",
        "    #   print(component)\n",
        "\n",
        "    #   for score in [1.0,1.5,2.0,2.5,3.0,3.5,4.0,4.5,5.0]:\n",
        "    #     if len(df_compare_v1[df_compare_v1[component]==score])==0:\n",
        "    #       print(component+\"==\"+str(score)+\" has 0 rows\")\n",
        "    #     else:\n",
        "    #       print(f'length: {len(df_compare_v1[df_compare_v1[component]==score])}')\n",
        "    #       print(\"% Predicting the above (\"+str(score)+\"): \" +\n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) &\n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]>score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #       print(\"% Predicting the same (\"+str(score)+\"): \" +\n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) & \n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]==score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #       print(\"% Predicting the below (\"+str(score)+\"): \" + \n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) & \n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]<score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #     print(\"****\")\n",
        "    for component in label_cols:\n",
        "      print(component)\n",
        "      print(\"% Predicting within .5: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"<=(\"+component+\"+.5) and transformed_pred_\"+component+\">=(\"+component+\"-.5)\"))/len(df_compare_v1)))"
      ],
      "metadata": {
        "id": "sg5wOlghQaJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffaa4136-cf64-472f-ceec-fa7421e47056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************************\n",
            "Iteration : 1\n",
            "Parameters...\n",
            "Epochs : 10\n",
            "Batch size : 8\n",
            "Learning rate : 1e-05\n",
            "Validation split : 0.2\n",
            "Dropout : 0.1\n",
            "Number of hidden layers : 2\n",
            "Hidden layer node count : 64\n",
            "Retrain layer count : 6\n",
            "************************\n",
            "Retrain layers: \n",
            " ['_11', '_10', '_9', '_8', '_7', '_6']\n",
            "Number of trainable parameters : 0\n",
            "Number of non-trainable parameters : 134899968\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/attention/self/query/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/attention/self/query/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/attention/self/key/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/attention/self/key/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/attention/self/value/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/attention/self/value/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/attention/output/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/attention/output/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/attention/output/LayerNorm/gamma:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/attention/output/LayerNorm/beta:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/intermediate/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/intermediate/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/output/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/output/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/output/LayerNorm/gamma:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/output/LayerNorm/beta:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/attention/self/query/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/attention/self/query/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/attention/self/key/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/attention/self/key/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/attention/self/value/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/attention/self/value/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/attention/output/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/attention/output/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/attention/output/LayerNorm/gamma:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/attention/output/LayerNorm/beta:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/intermediate/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/intermediate/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/output/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/output/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/output/LayerNorm/gamma:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/output/LayerNorm/beta:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/attention/self/query/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/attention/self/query/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/attention/self/key/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/attention/self/key/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/attention/self/value/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/attention/self/value/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/attention/output/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/attention/output/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/attention/output/LayerNorm/gamma:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/attention/output/LayerNorm/beta:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/intermediate/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/intermediate/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/output/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/output/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/output/LayerNorm/gamma:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/output/LayerNorm/beta:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/attention/self/query/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/attention/self/query/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/attention/self/key/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/attention/self/key/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/attention/self/value/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/attention/self/value/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/attention/output/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/attention/output/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/attention/output/LayerNorm/gamma:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/attention/output/LayerNorm/beta:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/intermediate/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/intermediate/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/output/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/output/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/output/LayerNorm/gamma:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/output/LayerNorm/beta:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/attention/self/query/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/attention/self/query/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/attention/self/key/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/attention/self/key/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/attention/self/value/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/attention/self/value/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/attention/output/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/attention/output/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/attention/output/LayerNorm/gamma:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/attention/output/LayerNorm/beta:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/intermediate/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/intermediate/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/output/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/output/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/output/LayerNorm/gamma:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/output/LayerNorm/beta:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/attention/self/query/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/attention/self/query/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/attention/self/key/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/attention/self/key/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/attention/self/value/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/attention/self/value/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/attention/output/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/attention/output/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/attention/output/LayerNorm/gamma:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/attention/output/LayerNorm/beta:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/intermediate/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/intermediate/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/output/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/output/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/output/LayerNorm/gamma:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/output/LayerNorm/beta:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/attention/self/query/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/attention/self/query/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/attention/self/key/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/attention/self/key/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/attention/self/value/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/attention/self/value/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/attention/output/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/attention/output/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/attention/output/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/attention/output/LayerNorm/beta:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/intermediate/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/intermediate/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/output/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/output/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/output/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/output/LayerNorm/beta:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/attention/self/query/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/attention/self/query/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/attention/self/key/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/attention/self/key/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/attention/self/value/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/attention/self/value/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/attention/output/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/attention/output/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/attention/output/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/attention/output/LayerNorm/beta:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/intermediate/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/intermediate/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/output/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/output/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/output/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/output/LayerNorm/beta:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/attention/self/query/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/attention/self/query/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/attention/self/key/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/attention/self/key/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/attention/self/value/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/attention/self/value/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/attention/output/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/attention/output/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/attention/output/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/attention/output/LayerNorm/beta:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/intermediate/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/intermediate/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/output/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/output/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/output/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/output/LayerNorm/beta:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/attention/self/query/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/attention/self/query/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/attention/self/key/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/attention/self/key/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/attention/self/value/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/attention/self/value/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/attention/output/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/attention/output/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/attention/output/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/attention/output/LayerNorm/beta:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/intermediate/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/intermediate/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/output/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/output/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/output/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/output/LayerNorm/beta:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/attention/self/query/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/attention/self/query/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/attention/self/key/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/attention/self/key/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/attention/self/value/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/attention/self/value/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/attention/output/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/attention/output/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/attention/output/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/attention/output/LayerNorm/beta:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/intermediate/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/intermediate/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/output/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/output/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/output/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/output/LayerNorm/beta:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/attention/self/query/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/attention/self/query/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/attention/self/key/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/attention/self/key/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/attention/self/value/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/attention/self/value/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/attention/output/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/attention/output/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/attention/output/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/attention/output/LayerNorm/beta:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/intermediate/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/intermediate/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/output/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/output/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/output/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/output/LayerNorm/beta:0 True\n",
            "tf_roberta_model_1/roberta/pooler/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/pooler/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/embeddings/word_embeddings/weight:0 True\n",
            "tf_roberta_model_1/roberta/embeddings/token_type_embeddings/embeddings:0 True\n",
            "tf_roberta_model_1/roberta/embeddings/position_embeddings/embeddings:0 True\n",
            "tf_roberta_model_1/roberta/embeddings/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/embeddings/LayerNorm/beta:0 True\n",
            "Number of trainable parameters : 0\n",
            "Number of non-trainable parameters : 134899968\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_roberta_model_1 (TFRobertaM  TFBaseModelOutputWi  134899968  ['input_ids[0][0]',              \n",
            " odel)                          thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_roberta_model_1[0][0]']     \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " hidden_layer_1 (Dense)         (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_layer_1 (Dropout)      (None, 64)           0           ['hidden_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            " hidden_layer_2 (Dense)         (None, 64)           4160        ['dropout_layer_1[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_layer_2 (Dropout)      (None, 64)           0           ['hidden_layer_2[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 6)            390         ['dropout_layer_2[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 134,953,734\n",
            "Trainable params: 53,766\n",
            "Non-trainable params: 134,899,968\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_roberta_model_1 (TFRobertaM  TFBaseModelOutputWi  134899968  ['input_ids[0][0]',              \n",
            " odel)                          thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_roberta_model_1[0][0]']     \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " hidden_layer_1 (Dense)         (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_layer_1 (Dropout)      (None, 64)           0           ['hidden_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            " hidden_layer_2 (Dense)         (None, 64)           4160        ['dropout_layer_1[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_layer_2 (Dropout)      (None, 64)           0           ['hidden_layer_2[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 6)            390         ['dropout_layer_2[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 134,953,734\n",
            "Trainable params: 53,766\n",
            "Non-trainable params: 134,899,968\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "313/313 [==============================] - 160s 459ms/step - loss: 2.9545 - MCRMSE: 2.9542 - val_loss: 2.6879 - val_MCRMSE: 2.6926\n",
            "Epoch 2/10\n",
            "208/313 [==================>...........] - ETA: 39s - loss: 2.4793 - MCRMSE: 2.4793"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_compare_v1 = pd.read_csv(\"predict_bertweet_6.csv\")\n",
        "for component in label_cols:\n",
        "  print(pd.crosstab(df_compare_v1[component], df_compare_v1[\"transformed_pred_\"+component], margins=True))\n",
        "  print()"
      ],
      "metadata": {
        "id": "tapAn1G63Ncp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERTweet with all its layers unfrozen"
      ],
      "metadata": {
        "id": "cwZV561yDtp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed parameters\n",
        "dense_dim = 6\n",
        "number_of_splits = 2\n",
        "random_state = 2023\n",
        "mse_loss = MCRMSE\n",
        "mse_metrics = MCRMSE\n",
        "model_name_list = ['Bert', 'Bertweet'] # Roberta\n",
        "\n",
        "df_train = pd.read_csv('df_train_split.csv')\n",
        "df_test = pd.read_csv('df_test_split.csv')\n",
        "print(f\"Length of train data : {len(df_train)}\")\n",
        "print(f\"Length of test data : {len(df_test)}\")\n",
        "y_test = np.array(df_test[label_cols], dtype = \"float32\")"
      ],
      "metadata": {
        "id": "EK7jPfHeDsh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable parameter dictionary\n",
        "param_list = [   # Completely unfrozen base layer\n",
        "                 {'epochs'                  : 10,\n",
        "                  'batch_size'              : 8,\n",
        "                  'learning_rate'           : 1e-5,\n",
        "                  'validation_split'        : .2,\n",
        "                  'dropout'                 : .1,\n",
        "                  'number_of_hidden_layers' : 2,\n",
        "                  'hidden_layer_node_count' : 64,\n",
        "                  'retrain_layer_count'     : 12\n",
        "                 },\n",
        "             ]"
      ],
      "metadata": {
        "id": "Ug6ZH807QaVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, param_entry in enumerate(param_list):\n",
        "    MAX_LEN = 512\n",
        "    epoch_val = param_entry['epochs']\n",
        "    batch_size_val = param_entry['batch_size']\n",
        "    learning_rate_val = param_entry['learning_rate']\n",
        "    validation_split_val = param_entry['validation_split']\n",
        "    dropout_val = param_entry['dropout']\n",
        "    number_of_hidden_layers_val = param_entry['number_of_hidden_layers']\n",
        "    hidden_layer_node_count_val = param_entry['hidden_layer_node_count']\n",
        "    retrain_layer_count_val = param_entry['retrain_layer_count']\n",
        "\n",
        "    print(\"************************\")\n",
        "    print(f\"Iteration : {idx + 1}\")\n",
        "    print(\"Parameters...\")\n",
        "    print(f\"Epochs : {epoch_val}\")\n",
        "    print(f\"Batch size : {batch_size_val}\")\n",
        "    print(f\"Learning rate : {learning_rate_val}\")\n",
        "    print(f\"Validation split : {validation_split_val}\")\n",
        "    print(f\"Dropout : {dropout_val}\")\n",
        "    print(f\"Number of hidden layers : {number_of_hidden_layers_val}\")\n",
        "    print(f\"Hidden layer node count : {hidden_layer_node_count_val}\")\n",
        "    print(f\"Retrain layer count : {retrain_layer_count_val}\")\n",
        "    print(\"************************\")\n",
        "    set_config_param(20230214)\n",
        "\n",
        "    model_tokenizer = AutoTokenizer.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "    model = TFRobertaModel.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "\n",
        "    train_input_ids, train_attention_masks = text_encode(df_train['full_text'], model_tokenizer, MAX_LEN)\n",
        "    test_input_ids, test_attention_masks = text_encode(df_test['full_text'], model_tokenizer, MAX_LEN)\n",
        "\n",
        "    y_train = np.array(df_train[label_cols], dtype = \"float32\")\n",
        "\n",
        "    bertweet = build_regression_model(loss= \"MCRMSE\", \n",
        "                                      model_name = \"Bertweet\",\n",
        "                                      dense_dim = 6, \n",
        "                                      MAX_LEN = 512,\n",
        "                                      learning_rate = learning_rate_val,\n",
        "                                      dropout=dropout_val,\n",
        "                                      number_of_hidden_layers = number_of_hidden_layers_val,\n",
        "                                      hidden_layer_node_count = hidden_layer_node_count_val,\n",
        "                                      retrain_layer_count = retrain_layer_count_val)\n",
        "    bertweet.summary()\n",
        "\n",
        "    history_v1 = bertweet.fit((train_input_ids, train_attention_masks),\n",
        "                  y_train,\n",
        "                  batch_size = batch_size_val,     \n",
        "                  epochs = epoch_val,\n",
        "                  validation_split = validation_split_val\n",
        "                  )\n",
        "\n",
        "    history_v1_df = pd.DataFrame(history_v1.history)\n",
        "\n",
        "    score_v1 = bertweet.evaluate([test_input_ids, test_attention_masks], \n",
        "                    y_test\n",
        "                  ) \n",
        "\n",
        "    predictions_v1 = bertweet.predict([test_input_ids, test_attention_masks])\n",
        "    df_pred_v1 = pd.DataFrame(predictions_v1, columns=['pred_' + c for c in label_cols])\n",
        "\n",
        "    for col in label_cols:\n",
        "      df_pred_v1['transformed_pred_' + col] = df_pred_v1['pred_' + col].apply(lambda x : roundPartial(x, .5))\n",
        "    \n",
        "    df_compare_v1= pd.merge(df_test, df_pred_v1, left_index = True, right_index = True)\n",
        "    df_compare_v1.to_csv(\"predict_bertweet_12.csv\", index=False)\n",
        "\n",
        "    all = []\n",
        "    for col in label_cols:\n",
        "      all.append(((df_compare_v1[col]-df_compare_v1[\"transformed_pred_\"+col]).pow(2).mean())**(0.5))\n",
        "    RMSE_scaled = statistics.fmean(all)\n",
        "    print(f\"RMSE_scaled: {RMSE_scaled}\")\n",
        "\n",
        "    for label in label_cols:\n",
        "      print(label)\n",
        "      hall_of_fame(df_compare_v1,label,1)\n",
        "      print(\"************************\")\n",
        "      hall_of_shame(df_compare_v1,label,1)\n",
        "      print(\"************************\")\n",
        "    for component in label_cols:\n",
        "      print(component)\n",
        "      print(\"% Predicting too high: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\">\"+component))/len(df_compare_v1)))\n",
        "      print(\"% Predicted correctly: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"==\"+component))/len(df_compare_v1)))\n",
        "      print(\"% Predicting too low: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"<\"+component))/len(df_compare_v1)))\n",
        "      print(\"****\")\n",
        "    # Predicting too high or low for every score? \n",
        "\n",
        "    # for component in label_cols:\n",
        "    #   print(component)\n",
        "\n",
        "    #   for score in [1.0,1.5,2.0,2.5,3.0,3.5,4.0,4.5,5.0]:\n",
        "    #     if len(df_compare_v1[df_compare_v1[component]==score])==0:\n",
        "    #       print(component+\"==\"+str(score)+\" has 0 rows\")\n",
        "    #     else:\n",
        "    #       print(f'length: {len(df_compare_v1[df_compare_v1[component]==score])}')\n",
        "    #       print(\"% Predicting the above (\"+str(score)+\"): \" +\n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) &\n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]>score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #       print(\"% Predicting the same (\"+str(score)+\"): \" +\n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) & \n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]==score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #       print(\"% Predicting the below (\"+str(score)+\"): \" + \n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) & \n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]<score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #     print(\"****\")\n",
        "    for component in label_cols:\n",
        "      print(component)\n",
        "      print(\"% Predicting within .5: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"<=(\"+component+\"+.5) and transformed_pred_\"+component+\">=(\"+component+\"-.5)\"))/len(df_compare_v1)))"
      ],
      "metadata": {
        "id": "v2WHf9FO5mV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_compare_v1 = pd.read_csv(\"predict_bertweet_12.csv\")\n",
        "for component in label_cols:\n",
        "  print(pd.crosstab(df_compare_v1[component], df_compare_v1[\"transformed_pred_\"+component], margins=True))\n",
        "  print()"
      ],
      "metadata": {
        "id": "zQsAxB06LE7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_compare_v1)"
      ],
      "metadata": {
        "id": "y573G-r-HG33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_compare_v1[\"character_count\"] = df_compare_v1.full_text.str.len()"
      ],
      "metadata": {
        "id": "Vg4xRReLGqLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_compare_v1[df_compare_v1[\"character_count\"]<280])"
      ],
      "metadata": {
        "id": "XsevoYXxR96P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2ET_cAludgH"
      },
      "source": [
        "Concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LED6NugFs3Ec"
      },
      "outputs": [],
      "source": [
        "set_config_param(20230214)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tuz4PZrbh1vk"
      },
      "source": [
        "# **Clustering**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[\"score_sum\"].hist()\n",
        "plt.title(\"Train Dataset's Total Scores\")\n",
        "plt.xlabel(\"Total Score\")\n",
        "plt.ylabel(\"Number of Essays\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hWXYOWjpPEUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTMJpfp8YzNz"
      },
      "outputs": [],
      "source": [
        "df_rating = copy.deepcopy(df_train[label_cols])\n",
        "rating_values_array = np.array(df_rating[label_cols])\n",
        "\n",
        "# standardize\n",
        "sc = StandardScaler()\n",
        "rating_values_array_std = sc.fit(rating_values_array).transform(rating_values_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHFkIEq5Cgul"
      },
      "outputs": [],
      "source": [
        "km = KMeans(random_state=42)\n",
        "visualizer = KElbowVisualizer(km, k=(2,10))\n",
        " \n",
        "visualizer.fit(rating_values_array_std)        # Fit the data to the visualizer\n",
        "visualizer.show()        # Finalize and render the figure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLpAtecfC72h"
      },
      "source": [
        "Here is how the Elbow / SSE Plot would look like. As per the plot given below, for n_clusters = 3 that represents the elbow you start seeing diminishing returns by increasing k. The line starts looking linear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2cZ4AyoDOoU"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 3, figsize=(20,5))\n",
        "for idx, i in enumerate([2, 3, 4]):\n",
        "    '''\n",
        "    Create KMeans instance for different number of clusters\n",
        "    '''\n",
        "    km = KMeans(n_clusters=i, init='k-means++', n_init=10, max_iter=100, random_state=42)\n",
        "    #q, mod = divmod(i, 2)\n",
        "    '''\n",
        "    Create SilhouetteVisualizer instance with KMeans instance\n",
        "    Fit the visualizer\n",
        "    '''\n",
        "    visualizer = SilhouetteVisualizer(km, colors='yellowbrick', ax=ax[idx])\n",
        "    visualizer.fit(rating_values_array_std) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-e9bqdIGWnZ"
      },
      "source": [
        "Given above, the Silhouette plot for n_clusters = 3 looks to be most appropriate than others as it stands well against all the three measuring criteria (scores below average Silhouette score, Wide fluctuations in the size of the plot, and non-uniform thickness)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Spyt5ysCGSEp"
      },
      "outputs": [],
      "source": [
        "km_base = KMeans(n_clusters=3,\n",
        "           #init='random',\n",
        "           init='k-means++',\n",
        "           n_init=10,\n",
        "           max_iter=300,\n",
        "           tol=1e-04,\n",
        "           random_state=1234)\n",
        "\n",
        "# predict k-means classes\n",
        "y_km_base = km_base.fit_predict(rating_values_array_std)\n",
        "\n",
        "# Assigning cluster value to the datafarme\n",
        "df_train['cluster_id'] = y_km_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8Jlal-4bqri"
      },
      "outputs": [],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgY72Q0Qj5rF"
      },
      "source": [
        "We can see that an increase in *k* is associated with a decrease in the within-cluster SSE. \n",
        "\n",
        "This is because the examples are closer to the centroid they assigned to.\n",
        "\n",
        "**The elbow solution**: the optimal *k* is where the within-cluster SSE begings to increase most rapidly.\n",
        "\n",
        "For this particular example the elbow is at *k=2* so we started with a good number of clusters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2RZdPo215xy"
      },
      "outputs": [],
      "source": [
        "df_train_cluster0 = df_train[df_train.cluster_id == 0]\n",
        "df_train_cluster1 = df_train[df_train.cluster_id == 1]\n",
        "df_train_cluster2 = df_train[df_train.cluster_id == 2]\n",
        "\n",
        "print(f\"Length of cluster 0 : {len(df_train_cluster0)}\")\n",
        "print(f\"Length of cluster 1 : {len(df_train_cluster1)}\")\n",
        "print(f\"Length of cluster 2 : {len(df_train_cluster2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1Hd6zkQeqvc"
      },
      "outputs": [],
      "source": [
        "print(f\"Min and max score in cluster 0 are : {np.min(df_train_cluster0['score_sum'])} and {np.max(df_train_cluster0['score_sum'])}\")\n",
        "print(f\"Min and Max score in cluster 1 are : {np.min(df_train_cluster1['score_sum'])} and {np.max(df_train_cluster1['score_sum'])}\")\n",
        "print(f\"Min and Max score in cluster 2 are : {np.min(df_train_cluster2['score_sum'])} and {np.max(df_train_cluster2['score_sum'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61PU78V5HbuI"
      },
      "source": [
        "The cluster is divided based on the distribution of the data. Low-scores are in one bucket, medium scores are placed in another and top scrores are placed in the higher bucket."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kbjNbnOZGJi"
      },
      "source": [
        "# **Model parameter setup**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed parameters\n",
        "dense_dim = 6\n",
        "number_of_splits = 2\n",
        "random_state = 2023\n",
        "mse_loss = MCRMSE\n",
        "mse_metrics = MCRMSE"
      ],
      "metadata": {
        "id": "jdKR-L-1UjLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining the two clusters' data\n",
        "df_train = pd.concat([df_train_cluster0, df_train_cluster1, df_train_cluster2])\n",
        "\n",
        "# shuffling them back again\n",
        "shuffle = np.random.permutation(np.arange(df_train.shape[0]))\n",
        "df_train = df_train.iloc[shuffle]\n",
        "\n",
        "MCRMSE_list = []\n",
        "\n",
        "'''\n",
        "rating_cluster has two values 0 and 1.\n",
        "We are doing k fold with stratification using rating_cluster.\n",
        "We introduced this new column to split on as as our data ouput is multi class\n",
        "and multi label with continuous values and traditional k fold split does not\n",
        "support that.\n",
        "This new column will help us to see if our model is performing better for which \n",
        "group : above or below average.\n",
        "'''"
      ],
      "metadata": {
        "id": "H3QubIulTTw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_list = ['Bert'] # , 'Bertweet' Roberta\n",
        "# Variable parameter dictionary\n",
        "param_list = [   # Completely frozen base layer\n",
        "                 {'epochs'                  : 10,\n",
        "                  'batch_size'              : 8,\n",
        "                  'learning_rate'           : 1e-5,\n",
        "                  'validation_split'        : .2,\n",
        "                  'dropout'                 : .1,\n",
        "                  'number_of_hidden_layers' : 2,\n",
        "                  'hidden_layer_node_count' : 64,\n",
        "                  'retrain_layer_count'     : 0\n",
        "                 }\n",
        "             ]"
      ],
      "metadata": {
        "id": "ilTJLL1rTUE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHeyCiPxENqg"
      },
      "outputs": [],
      "source": [
        "for param_val_model_name in model_name_list:\n",
        "\n",
        "    for idx, param_entry in enumerate(param_list):\n",
        "    \n",
        "        param_val_epoch = param_entry['epochs']\n",
        "        param_val_batch_size = param_entry['batch_size']\n",
        "        param_val_learning_rate = param_entry['learning_rate']\n",
        "        param_val_validation_split = param_entry['validation_split']\n",
        "        param_val_dropout = param_entry['dropout']\n",
        "        param_val_number_of_hidden_layers = param_entry['number_of_hidden_layers']\n",
        "        param_val_hidden_layer_node_count = param_entry['hidden_layer_node_count']\n",
        "        param_val_retrain_layer_count = param_entry['retrain_layer_count']\n",
        "\n",
        "        for kfold, (train_indices, val_indices) in enumerate(StratifiedKFold(n_splits     = number_of_splits, \n",
        "                                                                             shuffle      = True, \n",
        "                                                                             random_state = random_state\n",
        "                                                                             ).split(df_train['cluster_id'].values.tolist(), \n",
        "                                                                                     df_train['cluster_id'].values.tolist()\n",
        "                                                                                    )\n",
        "                                                            ):\n",
        "            print(\"************************\")\n",
        "            print(f\"Model : {param_val_model_name}\")\n",
        "            print(f\"Iteration : {idx + 1}\")\n",
        "            print(\"Parameters...\")\n",
        "            print(f\"Epochs : {param_val_epoch}\")\n",
        "            print(f\"Batch size : {param_val_batch_size}\")\n",
        "            print(f\"Learning rate : {param_val_learning_rate}\")\n",
        "            print(f\"Validation split : {param_val_validation_split}\")\n",
        "            print(f\"Dropout : {param_val_dropout}\")\n",
        "            print(f\"Number of hidden layers : {param_val_number_of_hidden_layers}\")\n",
        "            print(f\"Hidden layer node count : {param_val_hidden_layer_node_count}\")\n",
        "            print(f\"Retrain layer count : {param_val_retrain_layer_count}\")\n",
        "            print(f\"k-fold : {kfold + 1}\")\n",
        "            print(f\"length of train data : {len(train_indices)}\")\n",
        "            print(f\"length of validation data : {len(val_indices)}\")\n",
        "            print(\"************************\")\n",
        "            set_config_param(20230214)\n",
        "\n",
        "            # Building the tokenizer for the given model\n",
        "            if param_val_model_name == 'Roberta':\n",
        "                tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_MODEL_CHKPT)\n",
        "            elif param_val_model_name == 'Bertweet':\n",
        "                tokenizer = AutoTokenizer.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "            elif param_val_model_name == 'Bert':\n",
        "                tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_CHKPT)\n",
        "            \n",
        "            # Model building\n",
        "            print(\"Building model...\")\n",
        "            regression_model = build_regression_model(loss                    = 'MCRMSE',\n",
        "                                                      model_name              = param_val_model_name, \n",
        "                                                      dense_dim               = dense_dim, \n",
        "                                                      MAX_LEN                 = MAX_LEN,\n",
        "                                                      learning_rate           = param_val_learning_rate,\n",
        "                                                      dropout                 = param_val_dropout,\n",
        "                                                      number_of_hidden_layers = param_val_number_of_hidden_layers,\n",
        "                                                      hidden_layer_node_count = param_val_hidden_layer_node_count,\n",
        "                                                      retrain_layer_count     = param_val_retrain_layer_count\n",
        "                                                     )\n",
        "        \n",
        "            # Model fitting\n",
        "            print(\"Fitting model...\")\n",
        "            df_history = model_fit(model            = regression_model, \n",
        "                                   df_train         = df_train, \n",
        "                                   train_indices    = train_indices,\n",
        "                                   val_indices      = val_indices,\n",
        "                                   model_name       = param_val_model_name, \n",
        "                                   MAX_LEN          = MAX_LEN,\n",
        "                                   epochs           = param_val_epoch,\n",
        "                                   batch_size       = param_val_batch_size,\n",
        "                                   validation_split = param_val_validation_split\n",
        "                                  )\n",
        "            print(df_history.T)\n",
        "\n",
        "            print(\"Plotting loss and MCRMSE...\")\n",
        "            custom_plot(df         = df_history, \n",
        "                        model_name = param_val_model_name, \n",
        "                        kpi_name   = 'MCRMSE', \n",
        "                        kpi_string = 'MCRMSE'\n",
        "                       )\n",
        "\n",
        "            # Prep for model evaluation with test data\n",
        "            print(\"Evaluating mode...\")\n",
        "            test_encoded_input_ids, test_encoded_attention_masks = text_encode(texts      = df_test['full_text'], \n",
        "                                                                               tokenizer = tokenizer, \n",
        "                                                                               max_len    = MAX_LEN\n",
        "                                                                              )\n",
        "            # Model evaluation\n",
        "            test_loss, test_accuracy = evaluate_model(regression_model, \n",
        "                                                      y_test, \n",
        "                                                      test_encoded_input_ids, \n",
        "                                                      test_encoded_attention_masks\n",
        "                                                     )\n",
        "\n",
        "            # Model prediction\n",
        "            print(\"Model prediction...\")\n",
        "            df_prediction, df_comparison = predict_model(regression_model, \n",
        "                                                         df_test, \n",
        "                                                         test_encoded_input_ids, \n",
        "                                                         test_encoded_attention_masks, \n",
        "                                                         label_cols\n",
        "                                                        )\n",
        "\n",
        "            print(\"Plotting model structure...\")\n",
        "            keras.utils.plot_model(regression_model, \n",
        "                                   show_shapes      = False, \n",
        "                                   show_dtype       = False, \n",
        "                                   show_layer_names = True, \n",
        "                                   dpi              = 90\n",
        "                                  )\n",
        "\n",
        "            print(\"Appending to kpi list...\")\n",
        "            temp_dict = {'model_name'                  : param_val_model_name,\n",
        "                         'iteration'                   : idx + 1,\n",
        "                         'epoch'                       : param_val_epoch,\n",
        "                         'batch_size'                  : param_val_batch_size,\n",
        "                         'learning_rate'               : param_val_learning_rate,\n",
        "                         'validation_split'            : param_val_validation_split,\n",
        "                         'dropout'                     : param_val_dropout,\n",
        "                         'number_of_hidden_layers'     : param_val_number_of_hidden_layers,\n",
        "                         'hidden_layer_node_count'     : param_val_hidden_layer_node_count,\n",
        "                         'retrain_layer_count'         : param_val_retrain_layer_count,\n",
        "                         'fold'                        : kfold + 1, \n",
        "                         'train_loss'                  : df_history.iloc[-1][0],\n",
        "                         'train_accuracy'              : df_history.iloc[-1][1],\n",
        "                         'val_loss'                    : df_history.iloc[-1][2],\n",
        "                         'val_accuracy'                : df_history.iloc[-1][3],\n",
        "                         'test_loss'                   : test_loss,\n",
        "                         'test_accuracy'               : test_accuracy\n",
        "                        }\n",
        "            MCRMSE_list.append(temp_dict)\n",
        "            \n",
        "            # # Saving the model\n",
        "            # print(\"Saving the model...\")\n",
        "            # model_file_name = 'regression_model_' + param_val_model_name.lower() + '_iter_' + str(idx + 1) + '_kfold_' + str(kfold + 1) + \".h5\"\n",
        "            # regression_model.save(model_file_name)\n",
        "\n",
        "            for label in label_cols:\n",
        "              print(label)\n",
        "              hall_of_fame(df_comparison,label,1)\n",
        "              print(\"************************\")\n",
        "              hall_of_shame(df_comparison,label,1)\n",
        "              print(\"************************\")\n",
        "            for component in label_cols:\n",
        "              print(component)\n",
        "              print(\"% Predicted too high: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\">\"+component))/len(df_comparison)))\n",
        "              print(\"% Predicted correctly: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\"==\"+component))/len(df_comparison)))\n",
        "              print(\"% Predicted too low: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\"<\"+component))/len(df_comparison)))\n",
        "              print(\"****\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_list = ['Bert'] # , 'Bertweet' Roberta\n",
        "# Variable parameter dictionary\n",
        "param_list = [   # Partially frozen base layer\n",
        "                 {'epochs'                  : 10,\n",
        "                  'batch_size'              : 8,\n",
        "                  'learning_rate'           : 1e-5,\n",
        "                  'validation_split'        : .2,\n",
        "                  'dropout'                 : .1,\n",
        "                  'number_of_hidden_layers' : 2,\n",
        "                  'hidden_layer_node_count' : 64,\n",
        "                  'retrain_layer_count'     : 6\n",
        "                 }\n",
        "             ]"
      ],
      "metadata": {
        "id": "7CbvW1-OWJcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param_val_model_name in model_name_list:\n",
        "\n",
        "    for idx, param_entry in enumerate(param_list):\n",
        "    \n",
        "        param_val_epoch = param_entry['epochs']\n",
        "        param_val_batch_size = param_entry['batch_size']\n",
        "        param_val_learning_rate = param_entry['learning_rate']\n",
        "        param_val_validation_split = param_entry['validation_split']\n",
        "        param_val_dropout = param_entry['dropout']\n",
        "        param_val_number_of_hidden_layers = param_entry['number_of_hidden_layers']\n",
        "        param_val_hidden_layer_node_count = param_entry['hidden_layer_node_count']\n",
        "        param_val_retrain_layer_count = param_entry['retrain_layer_count']\n",
        "\n",
        "        for kfold, (train_indices, val_indices) in enumerate(StratifiedKFold(n_splits     = number_of_splits, \n",
        "                                                                             shuffle      = True, \n",
        "                                                                             random_state = random_state\n",
        "                                                                             ).split(df_train['cluster_id'].values.tolist(), \n",
        "                                                                                     df_train['cluster_id'].values.tolist()\n",
        "                                                                                    )\n",
        "                                                            ):\n",
        "            print(\"************************\")\n",
        "            print(f\"Model : {param_val_model_name}\")\n",
        "            print(f\"Iteration : {idx + 1}\")\n",
        "            print(\"Parameters...\")\n",
        "            print(f\"Epochs : {param_val_epoch}\")\n",
        "            print(f\"Batch size : {param_val_batch_size}\")\n",
        "            print(f\"Learning rate : {param_val_learning_rate}\")\n",
        "            print(f\"Validation split : {param_val_validation_split}\")\n",
        "            print(f\"Dropout : {param_val_dropout}\")\n",
        "            print(f\"Number of hidden layers : {param_val_number_of_hidden_layers}\")\n",
        "            print(f\"Hidden layer node count : {param_val_hidden_layer_node_count}\")\n",
        "            print(f\"Retrain layer count : {param_val_retrain_layer_count}\")\n",
        "            print(f\"k-fold : {kfold + 1}\")\n",
        "            print(f\"length of train data : {len(train_indices)}\")\n",
        "            print(f\"length of validation data : {len(val_indices)}\")\n",
        "            print(\"************************\")\n",
        "            set_config_param(20230214)\n",
        "\n",
        "            # Building the tokenizer for the given model\n",
        "            if param_val_model_name == 'Roberta':\n",
        "                tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_MODEL_CHKPT)\n",
        "            elif param_val_model_name == 'Bertweet':\n",
        "                tokenizer = AutoTokenizer.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "            elif param_val_model_name == 'Bert':\n",
        "                tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_CHKPT)\n",
        "            \n",
        "            # Model building\n",
        "            print(\"Building model...\")\n",
        "            regression_model = build_regression_model(loss                    = 'MCRMSE',\n",
        "                                                      model_name              = param_val_model_name, \n",
        "                                                      dense_dim               = dense_dim, \n",
        "                                                      MAX_LEN                 = MAX_LEN,\n",
        "                                                      learning_rate           = param_val_learning_rate,\n",
        "                                                      dropout                 = param_val_dropout,\n",
        "                                                      number_of_hidden_layers = param_val_number_of_hidden_layers,\n",
        "                                                      hidden_layer_node_count = param_val_hidden_layer_node_count,\n",
        "                                                      retrain_layer_count     = param_val_retrain_layer_count\n",
        "                                                     )\n",
        "        \n",
        "            # Model fitting\n",
        "            print(\"Fitting model...\")\n",
        "            df_history = model_fit(model            = regression_model, \n",
        "                                   df_train         = df_train, \n",
        "                                   train_indices    = train_indices,\n",
        "                                   val_indices      = val_indices,\n",
        "                                   model_name       = param_val_model_name, \n",
        "                                   MAX_LEN          = MAX_LEN,\n",
        "                                   epochs           = param_val_epoch,\n",
        "                                   batch_size       = param_val_batch_size,\n",
        "                                   validation_split = param_val_validation_split\n",
        "                                  )\n",
        "            print(df_history.T)\n",
        "\n",
        "            print(\"Plotting loss and MCRMSE...\")\n",
        "            custom_plot(df         = df_history, \n",
        "                        model_name = param_val_model_name, \n",
        "                        kpi_name   = 'MCRMSE', \n",
        "                        kpi_string = 'MCRMSE'\n",
        "                       )\n",
        "\n",
        "            # Prep for model evaluation with test data\n",
        "            print(\"Evaluating mode...\")\n",
        "            test_encoded_input_ids, test_encoded_attention_masks = text_encode(texts      = df_test['full_text'], \n",
        "                                                                               tokenizer = tokenizer, \n",
        "                                                                               max_len    = MAX_LEN\n",
        "                                                                              )\n",
        "            # Model evaluation\n",
        "            test_loss, test_accuracy = evaluate_model(regression_model, \n",
        "                                                      y_test, \n",
        "                                                      test_encoded_input_ids, \n",
        "                                                      test_encoded_attention_masks\n",
        "                                                     )\n",
        "\n",
        "            # Model prediction\n",
        "            print(\"Model prediction...\")\n",
        "            df_prediction, df_comparison = predict_model(regression_model, \n",
        "                                                         df_test, \n",
        "                                                         test_encoded_input_ids, \n",
        "                                                         test_encoded_attention_masks, \n",
        "                                                         label_cols\n",
        "                                                        )\n",
        "\n",
        "            print(\"Plotting model structure...\")\n",
        "            keras.utils.plot_model(regression_model, \n",
        "                                   show_shapes      = False, \n",
        "                                   show_dtype       = False, \n",
        "                                   show_layer_names = True, \n",
        "                                   dpi              = 90\n",
        "                                  )\n",
        "\n",
        "            print(\"Appending to kpi list...\")\n",
        "            temp_dict = {'model_name'                  : param_val_model_name,\n",
        "                         'iteration'                   : idx + 1,\n",
        "                         'epoch'                       : param_val_epoch,\n",
        "                         'batch_size'                  : param_val_batch_size,\n",
        "                         'learning_rate'               : param_val_learning_rate,\n",
        "                         'validation_split'            : param_val_validation_split,\n",
        "                         'dropout'                     : param_val_dropout,\n",
        "                         'number_of_hidden_layers'     : param_val_number_of_hidden_layers,\n",
        "                         'hidden_layer_node_count'     : param_val_hidden_layer_node_count,\n",
        "                         'retrain_layer_count'         : param_val_retrain_layer_count,\n",
        "                         'fold'                        : kfold + 1, \n",
        "                         'train_loss'                  : df_history.iloc[-1][0],\n",
        "                         'train_accuracy'              : df_history.iloc[-1][1],\n",
        "                         'val_loss'                    : df_history.iloc[-1][2],\n",
        "                         'val_accuracy'                : df_history.iloc[-1][3],\n",
        "                         'test_loss'                   : test_loss,\n",
        "                         'test_accuracy'               : test_accuracy\n",
        "                        }\n",
        "            MCRMSE_list.append(temp_dict)\n",
        "            \n",
        "            # # Saving the model\n",
        "            # print(\"Saving the model...\")\n",
        "            # model_file_name = 'regression_model_' + param_val_model_name.lower() + '_iter_' + str(idx + 1) + '_kfold_' + str(kfold + 1) + \".h5\"\n",
        "            # regression_model.save(model_file_name)\n",
        "\n",
        "            for label in label_cols:\n",
        "              print(label)\n",
        "              hall_of_fame(df_comparison,label,1)\n",
        "              print(\"************************\")\n",
        "              hall_of_shame(df_comparison,label,1)\n",
        "              print(\"************************\")\n",
        "            for component in label_cols:\n",
        "              print(component)\n",
        "              print(\"% Predicted too high: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\">\"+component))/len(df_comparison)))\n",
        "              print(\"% Predicted correctly: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\"==\"+component))/len(df_comparison)))\n",
        "              print(\"% Predicted too low: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\"<\"+component))/len(df_comparison)))\n",
        "              print(\"****\")"
      ],
      "metadata": {
        "id": "dxSmMFd3XICM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_list = ['Bert'] # , 'Bertweet' Roberta\n",
        "# Variable parameter dictionary\n",
        "param_list = [   # Completely unfrozen base layer\n",
        "                 {'epochs'                  : 10,\n",
        "                  'batch_size'              : 8,\n",
        "                  'learning_rate'           : 1e-5,\n",
        "                  'validation_split'        : .2,\n",
        "                  'dropout'                 : .1,\n",
        "                  'number_of_hidden_layers' : 2,\n",
        "                  'hidden_layer_node_count' : 64,\n",
        "                  'retrain_layer_count'     : 12\n",
        "                 },\n",
        "             ]"
      ],
      "metadata": {
        "id": "tQR2U-dBWVM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param_val_model_name in model_name_list:\n",
        "\n",
        "    for idx, param_entry in enumerate(param_list):\n",
        "    \n",
        "        param_val_epoch = param_entry['epochs']\n",
        "        param_val_batch_size = param_entry['batch_size']\n",
        "        param_val_learning_rate = param_entry['learning_rate']\n",
        "        param_val_validation_split = param_entry['validation_split']\n",
        "        param_val_dropout = param_entry['dropout']\n",
        "        param_val_number_of_hidden_layers = param_entry['number_of_hidden_layers']\n",
        "        param_val_hidden_layer_node_count = param_entry['hidden_layer_node_count']\n",
        "        param_val_retrain_layer_count = param_entry['retrain_layer_count']\n",
        "\n",
        "        for kfold, (train_indices, val_indices) in enumerate(StratifiedKFold(n_splits     = number_of_splits, \n",
        "                                                                             shuffle      = True, \n",
        "                                                                             random_state = random_state\n",
        "                                                                             ).split(df_train['cluster_id'].values.tolist(), \n",
        "                                                                                     df_train['cluster_id'].values.tolist()\n",
        "                                                                                    )\n",
        "                                                            ):\n",
        "            print(\"************************\")\n",
        "            print(f\"Model : {param_val_model_name}\")\n",
        "            print(f\"Iteration : {idx + 1}\")\n",
        "            print(\"Parameters...\")\n",
        "            print(f\"Epochs : {param_val_epoch}\")\n",
        "            print(f\"Batch size : {param_val_batch_size}\")\n",
        "            print(f\"Learning rate : {param_val_learning_rate}\")\n",
        "            print(f\"Validation split : {param_val_validation_split}\")\n",
        "            print(f\"Dropout : {param_val_dropout}\")\n",
        "            print(f\"Number of hidden layers : {param_val_number_of_hidden_layers}\")\n",
        "            print(f\"Hidden layer node count : {param_val_hidden_layer_node_count}\")\n",
        "            print(f\"Retrain layer count : {param_val_retrain_layer_count}\")\n",
        "            print(f\"k-fold : {kfold + 1}\")\n",
        "            print(f\"length of train data : {len(train_indices)}\")\n",
        "            print(f\"length of validation data : {len(val_indices)}\")\n",
        "            print(\"************************\")\n",
        "            set_config_param(20230214)\n",
        "\n",
        "            # Building the tokenizer for the given model\n",
        "            if param_val_model_name == 'Roberta':\n",
        "                tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_MODEL_CHKPT)\n",
        "            elif param_val_model_name == 'Bertweet':\n",
        "                tokenizer = AutoTokenizer.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "            elif param_val_model_name == 'Bert':\n",
        "                tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_CHKPT)\n",
        "            \n",
        "            # Model building\n",
        "            print(\"Building model...\")\n",
        "            regression_model = build_regression_model(loss                    = 'MCRMSE',\n",
        "                                                      model_name              = param_val_model_name, \n",
        "                                                      dense_dim               = dense_dim, \n",
        "                                                      MAX_LEN                 = MAX_LEN,\n",
        "                                                      learning_rate           = param_val_learning_rate,\n",
        "                                                      dropout                 = param_val_dropout,\n",
        "                                                      number_of_hidden_layers = param_val_number_of_hidden_layers,\n",
        "                                                      hidden_layer_node_count = param_val_hidden_layer_node_count,\n",
        "                                                      retrain_layer_count     = param_val_retrain_layer_count\n",
        "                                                     )\n",
        "        \n",
        "            # Model fitting\n",
        "            print(\"Fitting model...\")\n",
        "            df_history = model_fit(model            = regression_model, \n",
        "                                   df_train         = df_train, \n",
        "                                   train_indices    = train_indices,\n",
        "                                   val_indices      = val_indices,\n",
        "                                   model_name       = param_val_model_name, \n",
        "                                   MAX_LEN          = MAX_LEN,\n",
        "                                   epochs           = param_val_epoch,\n",
        "                                   batch_size       = param_val_batch_size,\n",
        "                                   validation_split = param_val_validation_split\n",
        "                                  )\n",
        "            print(df_history.T)\n",
        "\n",
        "            print(\"Plotting loss and MCRMSE...\")\n",
        "            custom_plot(df         = df_history, \n",
        "                        model_name = param_val_model_name, \n",
        "                        kpi_name   = 'MCRMSE', \n",
        "                        kpi_string = 'MCRMSE'\n",
        "                       )\n",
        "\n",
        "            # Prep for model evaluation with test data\n",
        "            print(\"Evaluating mode...\")\n",
        "            test_encoded_input_ids, test_encoded_attention_masks = text_encode(texts      = df_test['full_text'], \n",
        "                                                                               tokenizer = tokenizer, \n",
        "                                                                               max_len    = MAX_LEN\n",
        "                                                                              )\n",
        "            # Model evaluation\n",
        "            test_loss, test_accuracy = evaluate_model(regression_model, \n",
        "                                                      y_test, \n",
        "                                                      test_encoded_input_ids, \n",
        "                                                      test_encoded_attention_masks\n",
        "                                                     )\n",
        "\n",
        "            # Model prediction\n",
        "            print(\"Model prediction...\")\n",
        "            df_prediction, df_comparison = predict_model(regression_model, \n",
        "                                                         df_test, \n",
        "                                                         test_encoded_input_ids, \n",
        "                                                         test_encoded_attention_masks, \n",
        "                                                         label_cols\n",
        "                                                        )\n",
        "\n",
        "            print(\"Plotting model structure...\")\n",
        "            keras.utils.plot_model(regression_model, \n",
        "                                   show_shapes      = False, \n",
        "                                   show_dtype       = False, \n",
        "                                   show_layer_names = True, \n",
        "                                   dpi              = 90\n",
        "                                  )\n",
        "\n",
        "            print(\"Appending to kpi list...\")\n",
        "            temp_dict = {'model_name'                  : param_val_model_name,\n",
        "                         'iteration'                   : idx + 1,\n",
        "                         'epoch'                       : param_val_epoch,\n",
        "                         'batch_size'                  : param_val_batch_size,\n",
        "                         'learning_rate'               : param_val_learning_rate,\n",
        "                         'validation_split'            : param_val_validation_split,\n",
        "                         'dropout'                     : param_val_dropout,\n",
        "                         'number_of_hidden_layers'     : param_val_number_of_hidden_layers,\n",
        "                         'hidden_layer_node_count'     : param_val_hidden_layer_node_count,\n",
        "                         'retrain_layer_count'         : param_val_retrain_layer_count,\n",
        "                         'fold'                        : kfold + 1, \n",
        "                         'train_loss'                  : df_history.iloc[-1][0],\n",
        "                         'train_accuracy'              : df_history.iloc[-1][1],\n",
        "                         'val_loss'                    : df_history.iloc[-1][2],\n",
        "                         'val_accuracy'                : df_history.iloc[-1][3],\n",
        "                         'test_loss'                   : test_loss,\n",
        "                         'test_accuracy'               : test_accuracy\n",
        "                        }\n",
        "            MCRMSE_list.append(temp_dict)\n",
        "            \n",
        "            # # Saving the model\n",
        "            # print(\"Saving the model...\")\n",
        "            # model_file_name = 'regression_model_' + param_val_model_name.lower() + '_iter_' + str(idx + 1) + '_kfold_' + str(kfold + 1) + \".h5\"\n",
        "            # regression_model.save(model_file_name)\n",
        "\n",
        "            for label in label_cols:\n",
        "              print(label)\n",
        "              hall_of_fame(df_comparison,label,1)\n",
        "              print(\"************************\")\n",
        "              hall_of_shame(df_comparison,label,1)\n",
        "              print(\"************************\")\n",
        "            for component in label_cols:\n",
        "              print(component)\n",
        "              print(\"% Predicted too high: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\">\"+component))/len(df_comparison)))\n",
        "              print(\"% Predicted correctly: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\"==\"+component))/len(df_comparison)))\n",
        "              print(\"% Predicted too low: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\"<\"+component))/len(df_comparison)))\n",
        "              print(\"****\")"
      ],
      "metadata": {
        "id": "JJbaEmqeWeSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_list = ['Bertweet'] # ,  Roberta\n",
        "# Variable parameter dictionary\n",
        "param_list = [   # Completely frozen base layer\n",
        "                 {'epochs'                  : 10,\n",
        "                  'batch_size'              : 8,\n",
        "                  'learning_rate'           : 1e-5,\n",
        "                  'validation_split'        : .2,\n",
        "                  'dropout'                 : .1,\n",
        "                  'number_of_hidden_layers' : 2,\n",
        "                  'hidden_layer_node_count' : 64,\n",
        "                  'retrain_layer_count'     : 0\n",
        "                 }\n",
        "             ]"
      ],
      "metadata": {
        "id": "XrxR2zQHWegL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param_val_model_name in model_name_list:\n",
        "\n",
        "    for idx, param_entry in enumerate(param_list):\n",
        "    \n",
        "        param_val_epoch = param_entry['epochs']\n",
        "        param_val_batch_size = param_entry['batch_size']\n",
        "        param_val_learning_rate = param_entry['learning_rate']\n",
        "        param_val_validation_split = param_entry['validation_split']\n",
        "        param_val_dropout = param_entry['dropout']\n",
        "        param_val_number_of_hidden_layers = param_entry['number_of_hidden_layers']\n",
        "        param_val_hidden_layer_node_count = param_entry['hidden_layer_node_count']\n",
        "        param_val_retrain_layer_count = param_entry['retrain_layer_count']\n",
        "\n",
        "        for kfold, (train_indices, val_indices) in enumerate(StratifiedKFold(n_splits     = number_of_splits, \n",
        "                                                                             shuffle      = True, \n",
        "                                                                             random_state = random_state\n",
        "                                                                             ).split(df_train['cluster_id'].values.tolist(), \n",
        "                                                                                     df_train['cluster_id'].values.tolist()\n",
        "                                                                                    )\n",
        "                                                            ):\n",
        "            print(\"************************\")\n",
        "            print(f\"Model : {param_val_model_name}\")\n",
        "            print(f\"Iteration : {idx + 1}\")\n",
        "            print(\"Parameters...\")\n",
        "            print(f\"Epochs : {param_val_epoch}\")\n",
        "            print(f\"Batch size : {param_val_batch_size}\")\n",
        "            print(f\"Learning rate : {param_val_learning_rate}\")\n",
        "            print(f\"Validation split : {param_val_validation_split}\")\n",
        "            print(f\"Dropout : {param_val_dropout}\")\n",
        "            print(f\"Number of hidden layers : {param_val_number_of_hidden_layers}\")\n",
        "            print(f\"Hidden layer node count : {param_val_hidden_layer_node_count}\")\n",
        "            print(f\"Retrain layer count : {param_val_retrain_layer_count}\")\n",
        "            print(f\"k-fold : {kfold + 1}\")\n",
        "            print(f\"length of train data : {len(train_indices)}\")\n",
        "            print(f\"length of validation data : {len(val_indices)}\")\n",
        "            print(\"************************\")\n",
        "            set_config_param(20230214)\n",
        "\n",
        "            # Building the tokenizer for the given model\n",
        "            if param_val_model_name == 'Roberta':\n",
        "                tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_MODEL_CHKPT)\n",
        "            elif param_val_model_name == 'Bertweet':\n",
        "                tokenizer = AutoTokenizer.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "            elif param_val_model_name == 'Bert':\n",
        "                tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_CHKPT)\n",
        "            \n",
        "            # Model building\n",
        "            print(\"Building model...\")\n",
        "            regression_model = build_regression_model(loss                    = 'MCRMSE',\n",
        "                                                      model_name              = param_val_model_name, \n",
        "                                                      dense_dim               = dense_dim, \n",
        "                                                      MAX_LEN                 = MAX_LEN,\n",
        "                                                      learning_rate           = param_val_learning_rate,\n",
        "                                                      dropout                 = param_val_dropout,\n",
        "                                                      number_of_hidden_layers = param_val_number_of_hidden_layers,\n",
        "                                                      hidden_layer_node_count = param_val_hidden_layer_node_count,\n",
        "                                                      retrain_layer_count     = param_val_retrain_layer_count\n",
        "                                                     )\n",
        "        \n",
        "            # Model fitting\n",
        "            print(\"Fitting model...\")\n",
        "            df_history = model_fit(model            = regression_model, \n",
        "                                   df_train         = df_train, \n",
        "                                   train_indices    = train_indices,\n",
        "                                   val_indices      = val_indices,\n",
        "                                   model_name       = param_val_model_name, \n",
        "                                   MAX_LEN          = MAX_LEN,\n",
        "                                   epochs           = param_val_epoch,\n",
        "                                   batch_size       = param_val_batch_size,\n",
        "                                   validation_split = param_val_validation_split\n",
        "                                  )\n",
        "            print(df_history.T)\n",
        "\n",
        "            print(\"Plotting loss and MCRMSE...\")\n",
        "            custom_plot(df         = df_history, \n",
        "                        model_name = param_val_model_name, \n",
        "                        kpi_name   = 'MCRMSE', \n",
        "                        kpi_string = 'MCRMSE'\n",
        "                       )\n",
        "\n",
        "            # Prep for model evaluation with test data\n",
        "            print(\"Evaluating mode...\")\n",
        "            test_encoded_input_ids, test_encoded_attention_masks = text_encode(texts      = df_test['full_text'], \n",
        "                                                                               tokenizer = tokenizer, \n",
        "                                                                               max_len    = MAX_LEN\n",
        "                                                                              )\n",
        "            # Model evaluation\n",
        "            test_loss, test_accuracy = evaluate_model(regression_model, \n",
        "                                                      y_test, \n",
        "                                                      test_encoded_input_ids, \n",
        "                                                      test_encoded_attention_masks\n",
        "                                                     )\n",
        "\n",
        "            # Model prediction\n",
        "            print(\"Model prediction...\")\n",
        "            df_prediction, df_comparison = predict_model(regression_model, \n",
        "                                                         df_test, \n",
        "                                                         test_encoded_input_ids, \n",
        "                                                         test_encoded_attention_masks, \n",
        "                                                         label_cols\n",
        "                                                        )\n",
        "\n",
        "            print(\"Plotting model structure...\")\n",
        "            keras.utils.plot_model(regression_model, \n",
        "                                   show_shapes      = False, \n",
        "                                   show_dtype       = False, \n",
        "                                   show_layer_names = True, \n",
        "                                   dpi              = 90\n",
        "                                  )\n",
        "\n",
        "            print(\"Appending to kpi list...\")\n",
        "            temp_dict = {'model_name'                  : param_val_model_name,\n",
        "                         'iteration'                   : idx + 1,\n",
        "                         'epoch'                       : param_val_epoch,\n",
        "                         'batch_size'                  : param_val_batch_size,\n",
        "                         'learning_rate'               : param_val_learning_rate,\n",
        "                         'validation_split'            : param_val_validation_split,\n",
        "                         'dropout'                     : param_val_dropout,\n",
        "                         'number_of_hidden_layers'     : param_val_number_of_hidden_layers,\n",
        "                         'hidden_layer_node_count'     : param_val_hidden_layer_node_count,\n",
        "                         'retrain_layer_count'         : param_val_retrain_layer_count,\n",
        "                         'fold'                        : kfold + 1, \n",
        "                         'train_loss'                  : df_history.iloc[-1][0],\n",
        "                         'train_accuracy'              : df_history.iloc[-1][1],\n",
        "                         'val_loss'                    : df_history.iloc[-1][2],\n",
        "                         'val_accuracy'                : df_history.iloc[-1][3],\n",
        "                         'test_loss'                   : test_loss,\n",
        "                         'test_accuracy'               : test_accuracy\n",
        "                        }\n",
        "            MCRMSE_list.append(temp_dict)\n",
        "            \n",
        "            # # Saving the model\n",
        "            # print(\"Saving the model...\")\n",
        "            # model_file_name = 'regression_model_' + param_val_model_name.lower() + '_iter_' + str(idx + 1) + '_kfold_' + str(kfold + 1) + \".h5\"\n",
        "            # regression_model.save(model_file_name)\n",
        "\n",
        "            for label in label_cols:\n",
        "              print(label)\n",
        "              hall_of_fame(df_comparison,label,1)\n",
        "              print(\"************************\")\n",
        "              hall_of_shame(df_comparison,label,1)\n",
        "              print(\"************************\")\n",
        "            for component in label_cols:\n",
        "              print(component)\n",
        "              print(\"% Predicted too high: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\">\"+component))/len(df_comparison)))\n",
        "              print(\"% Predicted correctly: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\"==\"+component))/len(df_comparison)))\n",
        "              print(\"% Predicted too low: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\"<\"+component))/len(df_comparison)))\n",
        "              print(\"****\")"
      ],
      "metadata": {
        "id": "c58WkBFSXB4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_list = ['Bertweet'] # ,  Roberta\n",
        "# Variable parameter dictionary\n",
        "param_list = [   # Partially frozen base layer\n",
        "                 {'epochs'                  : 10,\n",
        "                  'batch_size'              : 8,\n",
        "                  'learning_rate'           : 1e-5,\n",
        "                  'validation_split'        : .2,\n",
        "                  'dropout'                 : .1,\n",
        "                  'number_of_hidden_layers' : 2,\n",
        "                  'hidden_layer_node_count' : 64,\n",
        "                  'retrain_layer_count'     : 6\n",
        "                 }\n",
        "             ]"
      ],
      "metadata": {
        "id": "MtEZR1JSWmKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param_val_model_name in model_name_list:\n",
        "\n",
        "    for idx, param_entry in enumerate(param_list):\n",
        "    \n",
        "        param_val_epoch = param_entry['epochs']\n",
        "        param_val_batch_size = param_entry['batch_size']\n",
        "        param_val_learning_rate = param_entry['learning_rate']\n",
        "        param_val_validation_split = param_entry['validation_split']\n",
        "        param_val_dropout = param_entry['dropout']\n",
        "        param_val_number_of_hidden_layers = param_entry['number_of_hidden_layers']\n",
        "        param_val_hidden_layer_node_count = param_entry['hidden_layer_node_count']\n",
        "        param_val_retrain_layer_count = param_entry['retrain_layer_count']\n",
        "\n",
        "        for kfold, (train_indices, val_indices) in enumerate(StratifiedKFold(n_splits     = number_of_splits, \n",
        "                                                                             shuffle      = True, \n",
        "                                                                             random_state = random_state\n",
        "                                                                             ).split(df_train['cluster_id'].values.tolist(), \n",
        "                                                                                     df_train['cluster_id'].values.tolist()\n",
        "                                                                                    )\n",
        "                                                            ):\n",
        "            print(\"************************\")\n",
        "            print(f\"Model : {param_val_model_name}\")\n",
        "            print(f\"Iteration : {idx + 1}\")\n",
        "            print(\"Parameters...\")\n",
        "            print(f\"Epochs : {param_val_epoch}\")\n",
        "            print(f\"Batch size : {param_val_batch_size}\")\n",
        "            print(f\"Learning rate : {param_val_learning_rate}\")\n",
        "            print(f\"Validation split : {param_val_validation_split}\")\n",
        "            print(f\"Dropout : {param_val_dropout}\")\n",
        "            print(f\"Number of hidden layers : {param_val_number_of_hidden_layers}\")\n",
        "            print(f\"Hidden layer node count : {param_val_hidden_layer_node_count}\")\n",
        "            print(f\"Retrain layer count : {param_val_retrain_layer_count}\")\n",
        "            print(f\"k-fold : {kfold + 1}\")\n",
        "            print(f\"length of train data : {len(train_indices)}\")\n",
        "            print(f\"length of validation data : {len(val_indices)}\")\n",
        "            print(\"************************\")\n",
        "            set_config_param(20230214)\n",
        "\n",
        "            # Building the tokenizer for the given model\n",
        "            if param_val_model_name == 'Roberta':\n",
        "                tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_MODEL_CHKPT)\n",
        "            elif param_val_model_name == 'Bertweet':\n",
        "                tokenizer = AutoTokenizer.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "            elif param_val_model_name == 'Bert':\n",
        "                tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_CHKPT)\n",
        "            \n",
        "            # Model building\n",
        "            print(\"Building model...\")\n",
        "            regression_model = build_regression_model(loss                    = 'MCRMSE',\n",
        "                                                      model_name              = param_val_model_name, \n",
        "                                                      dense_dim               = dense_dim, \n",
        "                                                      MAX_LEN                 = MAX_LEN,\n",
        "                                                      learning_rate           = param_val_learning_rate,\n",
        "                                                      dropout                 = param_val_dropout,\n",
        "                                                      number_of_hidden_layers = param_val_number_of_hidden_layers,\n",
        "                                                      hidden_layer_node_count = param_val_hidden_layer_node_count,\n",
        "                                                      retrain_layer_count     = param_val_retrain_layer_count\n",
        "                                                     )\n",
        "        \n",
        "            # Model fitting\n",
        "            print(\"Fitting model...\")\n",
        "            df_history = model_fit(model            = regression_model, \n",
        "                                   df_train         = df_train, \n",
        "                                   train_indices    = train_indices,\n",
        "                                   val_indices      = val_indices,\n",
        "                                   model_name       = param_val_model_name, \n",
        "                                   MAX_LEN          = MAX_LEN,\n",
        "                                   epochs           = param_val_epoch,\n",
        "                                   batch_size       = param_val_batch_size,\n",
        "                                   validation_split = param_val_validation_split\n",
        "                                  )\n",
        "            print(df_history.T)\n",
        "\n",
        "            print(\"Plotting loss and MCRMSE...\")\n",
        "            custom_plot(df         = df_history, \n",
        "                        model_name = param_val_model_name, \n",
        "                        kpi_name   = 'MCRMSE', \n",
        "                        kpi_string = 'MCRMSE'\n",
        "                       )\n",
        "\n",
        "            # Prep for model evaluation with test data\n",
        "            print(\"Evaluating mode...\")\n",
        "            test_encoded_input_ids, test_encoded_attention_masks = text_encode(texts      = df_test['full_text'], \n",
        "                                                                               tokenizer = tokenizer, \n",
        "                                                                               max_len    = MAX_LEN\n",
        "                                                                              )\n",
        "            # Model evaluation\n",
        "            test_loss, test_accuracy = evaluate_model(regression_model, \n",
        "                                                      y_test, \n",
        "                                                      test_encoded_input_ids, \n",
        "                                                      test_encoded_attention_masks\n",
        "                                                     )\n",
        "\n",
        "            # Model prediction\n",
        "            print(\"Model prediction...\")\n",
        "            df_prediction, df_comparison = predict_model(regression_model, \n",
        "                                                         df_test, \n",
        "                                                         test_encoded_input_ids, \n",
        "                                                         test_encoded_attention_masks, \n",
        "                                                         label_cols\n",
        "                                                        )\n",
        "\n",
        "            print(\"Plotting model structure...\")\n",
        "            keras.utils.plot_model(regression_model, \n",
        "                                   show_shapes      = False, \n",
        "                                   show_dtype       = False, \n",
        "                                   show_layer_names = True, \n",
        "                                   dpi              = 90\n",
        "                                  )\n",
        "\n",
        "            print(\"Appending to kpi list...\")\n",
        "            temp_dict = {'model_name'                  : param_val_model_name,\n",
        "                         'iteration'                   : idx + 1,\n",
        "                         'epoch'                       : param_val_epoch,\n",
        "                         'batch_size'                  : param_val_batch_size,\n",
        "                         'learning_rate'               : param_val_learning_rate,\n",
        "                         'validation_split'            : param_val_validation_split,\n",
        "                         'dropout'                     : param_val_dropout,\n",
        "                         'number_of_hidden_layers'     : param_val_number_of_hidden_layers,\n",
        "                         'hidden_layer_node_count'     : param_val_hidden_layer_node_count,\n",
        "                         'retrain_layer_count'         : param_val_retrain_layer_count,\n",
        "                         'fold'                        : kfold + 1, \n",
        "                         'train_loss'                  : df_history.iloc[-1][0],\n",
        "                         'train_accuracy'              : df_history.iloc[-1][1],\n",
        "                         'val_loss'                    : df_history.iloc[-1][2],\n",
        "                         'val_accuracy'                : df_history.iloc[-1][3],\n",
        "                         'test_loss'                   : test_loss,\n",
        "                         'test_accuracy'               : test_accuracy\n",
        "                        }\n",
        "            MCRMSE_list.append(temp_dict)\n",
        "            \n",
        "            # # Saving the model\n",
        "            # print(\"Saving the model...\")\n",
        "            # model_file_name = 'regression_model_' + param_val_model_name.lower() + '_iter_' + str(idx + 1) + '_kfold_' + str(kfold + 1) + \".h5\"\n",
        "            # regression_model.save(model_file_name)\n",
        "\n",
        "            for label in label_cols:\n",
        "              print(label)\n",
        "              hall_of_fame(df_comparison,label,1)\n",
        "              print(\"************************\")\n",
        "              hall_of_shame(df_comparison,label,1)\n",
        "              print(\"************************\")\n",
        "            for component in label_cols:\n",
        "              print(component)\n",
        "              print(\"% Predicted too high: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\">\"+component))/len(df_comparison)))\n",
        "              print(\"% Predicted correctly: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\"==\"+component))/len(df_comparison)))\n",
        "              print(\"% Predicted too low: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\"<\"+component))/len(df_comparison)))\n",
        "              print(\"****\")"
      ],
      "metadata": {
        "id": "AsjCJKI-XBKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_list = ['Bertweet'] # ,  Roberta\n",
        "# Variable parameter dictionary\n",
        "param_list = [   # Completely unfrozen base layer\n",
        "                 {'epochs'                  : 10,\n",
        "                  'batch_size'              : 8,\n",
        "                  'learning_rate'           : 1e-5,\n",
        "                  'validation_split'        : .2,\n",
        "                  'dropout'                 : .1,\n",
        "                  'number_of_hidden_layers' : 2,\n",
        "                  'hidden_layer_node_count' : 64,\n",
        "                  'retrain_layer_count'     : 12\n",
        "                 },\n",
        "             ]"
      ],
      "metadata": {
        "id": "i40hO2kuWmVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param_val_model_name in model_name_list:\n",
        "\n",
        "    for idx, param_entry in enumerate(param_list):\n",
        "    \n",
        "        param_val_epoch = param_entry['epochs']\n",
        "        param_val_batch_size = param_entry['batch_size']\n",
        "        param_val_learning_rate = param_entry['learning_rate']\n",
        "        param_val_validation_split = param_entry['validation_split']\n",
        "        param_val_dropout = param_entry['dropout']\n",
        "        param_val_number_of_hidden_layers = param_entry['number_of_hidden_layers']\n",
        "        param_val_hidden_layer_node_count = param_entry['hidden_layer_node_count']\n",
        "        param_val_retrain_layer_count = param_entry['retrain_layer_count']\n",
        "\n",
        "        for kfold, (train_indices, val_indices) in enumerate(StratifiedKFold(n_splits     = number_of_splits, \n",
        "                                                                             shuffle      = True, \n",
        "                                                                             random_state = random_state\n",
        "                                                                             ).split(df_train['cluster_id'].values.tolist(), \n",
        "                                                                                     df_train['cluster_id'].values.tolist()\n",
        "                                                                                    )\n",
        "                                                            ):\n",
        "            print(\"************************\")\n",
        "            print(f\"Model : {param_val_model_name}\")\n",
        "            print(f\"Iteration : {idx + 1}\")\n",
        "            print(\"Parameters...\")\n",
        "            print(f\"Epochs : {param_val_epoch}\")\n",
        "            print(f\"Batch size : {param_val_batch_size}\")\n",
        "            print(f\"Learning rate : {param_val_learning_rate}\")\n",
        "            print(f\"Validation split : {param_val_validation_split}\")\n",
        "            print(f\"Dropout : {param_val_dropout}\")\n",
        "            print(f\"Number of hidden layers : {param_val_number_of_hidden_layers}\")\n",
        "            print(f\"Hidden layer node count : {param_val_hidden_layer_node_count}\")\n",
        "            print(f\"Retrain layer count : {param_val_retrain_layer_count}\")\n",
        "            print(f\"k-fold : {kfold + 1}\")\n",
        "            print(f\"length of train data : {len(train_indices)}\")\n",
        "            print(f\"length of validation data : {len(val_indices)}\")\n",
        "            print(\"************************\")\n",
        "            set_config_param(20230214)\n",
        "\n",
        "            # Building the tokenizer for the given model\n",
        "            if param_val_model_name == 'Roberta':\n",
        "                tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_MODEL_CHKPT)\n",
        "            elif param_val_model_name == 'Bertweet':\n",
        "                tokenizer = AutoTokenizer.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "            elif param_val_model_name == 'Bert':\n",
        "                tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_CHKPT)\n",
        "            \n",
        "            # Model building\n",
        "            print(\"Building model...\")\n",
        "            regression_model = build_regression_model(loss                    = 'MCRMSE',\n",
        "                                                      model_name              = param_val_model_name, \n",
        "                                                      dense_dim               = dense_dim, \n",
        "                                                      MAX_LEN                 = MAX_LEN,\n",
        "                                                      learning_rate           = param_val_learning_rate,\n",
        "                                                      dropout                 = param_val_dropout,\n",
        "                                                      number_of_hidden_layers = param_val_number_of_hidden_layers,\n",
        "                                                      hidden_layer_node_count = param_val_hidden_layer_node_count,\n",
        "                                                      retrain_layer_count     = param_val_retrain_layer_count\n",
        "                                                     )\n",
        "        \n",
        "            # Model fitting\n",
        "            print(\"Fitting model...\")\n",
        "            df_history = model_fit(model            = regression_model, \n",
        "                                   df_train         = df_train, \n",
        "                                   train_indices    = train_indices,\n",
        "                                   val_indices      = val_indices,\n",
        "                                   model_name       = param_val_model_name, \n",
        "                                   MAX_LEN          = MAX_LEN,\n",
        "                                   epochs           = param_val_epoch,\n",
        "                                   batch_size       = param_val_batch_size,\n",
        "                                   validation_split = param_val_validation_split\n",
        "                                  )\n",
        "            print(df_history.T)\n",
        "\n",
        "            print(\"Plotting loss and MCRMSE...\")\n",
        "            custom_plot(df         = df_history, \n",
        "                        model_name = param_val_model_name, \n",
        "                        kpi_name   = 'MCRMSE', \n",
        "                        kpi_string = 'MCRMSE'\n",
        "                       )\n",
        "\n",
        "            # Prep for model evaluation with test data\n",
        "            print(\"Evaluating mode...\")\n",
        "            test_encoded_input_ids, test_encoded_attention_masks = text_encode(texts      = df_test['full_text'], \n",
        "                                                                               tokenizer = tokenizer, \n",
        "                                                                               max_len    = MAX_LEN\n",
        "                                                                              )\n",
        "            # Model evaluation\n",
        "            test_loss, test_accuracy = evaluate_model(regression_model, \n",
        "                                                      y_test, \n",
        "                                                      test_encoded_input_ids, \n",
        "                                                      test_encoded_attention_masks\n",
        "                                                     )\n",
        "\n",
        "            # Model prediction\n",
        "            print(\"Model prediction...\")\n",
        "            df_prediction, df_comparison = predict_model(regression_model, \n",
        "                                                         df_test, \n",
        "                                                         test_encoded_input_ids, \n",
        "                                                         test_encoded_attention_masks, \n",
        "                                                         label_cols\n",
        "                                                        )\n",
        "\n",
        "            print(\"Plotting model structure...\")\n",
        "            keras.utils.plot_model(regression_model, \n",
        "                                   show_shapes      = False, \n",
        "                                   show_dtype       = False, \n",
        "                                   show_layer_names = True, \n",
        "                                   dpi              = 90\n",
        "                                  )\n",
        "\n",
        "            print(\"Appending to kpi list...\")\n",
        "            temp_dict = {'model_name'                  : param_val_model_name,\n",
        "                         'iteration'                   : idx + 1,\n",
        "                         'epoch'                       : param_val_epoch,\n",
        "                         'batch_size'                  : param_val_batch_size,\n",
        "                         'learning_rate'               : param_val_learning_rate,\n",
        "                         'validation_split'            : param_val_validation_split,\n",
        "                         'dropout'                     : param_val_dropout,\n",
        "                         'number_of_hidden_layers'     : param_val_number_of_hidden_layers,\n",
        "                         'hidden_layer_node_count'     : param_val_hidden_layer_node_count,\n",
        "                         'retrain_layer_count'         : param_val_retrain_layer_count,\n",
        "                         'fold'                        : kfold + 1, \n",
        "                         'train_loss'                  : df_history.iloc[-1][0],\n",
        "                         'train_accuracy'              : df_history.iloc[-1][1],\n",
        "                         'val_loss'                    : df_history.iloc[-1][2],\n",
        "                         'val_accuracy'                : df_history.iloc[-1][3],\n",
        "                         'test_loss'                   : test_loss,\n",
        "                         'test_accuracy'               : test_accuracy\n",
        "                        }\n",
        "            MCRMSE_list.append(temp_dict)\n",
        "            \n",
        "            # # Saving the model\n",
        "            # print(\"Saving the model...\")\n",
        "            # model_file_name = 'regression_model_' + param_val_model_name.lower() + '_iter_' + str(idx + 1) + '_kfold_' + str(kfold + 1) + \".h5\"\n",
        "            # regression_model.save(model_file_name)\n",
        "\n",
        "            for label in label_cols:\n",
        "              print(label)\n",
        "              hall_of_fame(df_comparison,label,1)\n",
        "              print(\"************************\")\n",
        "              hall_of_shame(df_comparison,label,1)\n",
        "              print(\"************************\")\n",
        "            for component in label_cols:\n",
        "              print(component)\n",
        "              print(\"% Predicted too high: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\">\"+component))/len(df_comparison)))\n",
        "              print(\"% Predicted correctly: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\"==\"+component))/len(df_comparison)))\n",
        "              print(\"% Predicted too low: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\"<\"+component))/len(df_comparison)))\n",
        "              print(\"****\")"
      ],
      "metadata": {
        "id": "MuGt3OWDXAgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pk6ZkXlSjt5B"
      },
      "outputs": [],
      "source": [
        "# kpi_col_list = ['model_name',\n",
        "#                 'iteration',\n",
        "#                 'epoch_val',\n",
        "#                 'batch_size_val',\n",
        "#                 'learning_rate_val',\n",
        "#                 'validation_split_val',\n",
        "#                 'dropout_val',\n",
        "#                 'number_of_hidden_layers_val',\n",
        "#                 'hidden_layer_node_count_val',\n",
        "#                 'retrain_layer_count_val',\n",
        "#                 'fold', \n",
        "#                 'train_loss', \n",
        "#                 'train_accuracy', \n",
        "#                 'val_loss', \n",
        "#                 'val_accuracy', \n",
        "#                 'test_loss', \n",
        "#                 'test_accuracy'\n",
        "#                ]\n",
        "# df_MCRMSE = pd.DataFrame(MCRMSE_list, columns = kpi_col_list)    \n",
        "# df_MCRMSE.to_csv(\"kpi_stats_bertweet.csv\", index = False)\n",
        "# df_MCRMSE    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDwRZh-7ENeh"
      },
      "outputs": [],
      "source": [
        "# print(\"Average test accuracy and loss...\")\n",
        "# df_MCRMSE.groupby(['model_name', 'iteration']).agg({'test_loss'      : [np.mean, np.min, np.max],  \n",
        "#                                                     'test_accuracy'  : [np.mean, np.min, np.max] \n",
        "#                                                    }\n",
        "#                                                   )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Appendix\n",
        "Other experiments with the hyper parameters"
      ],
      "metadata": {
        "id": "phqVvESQdeRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def regression_model_with_bert(num_classes=9,                  # [1, 1.5, 2, 2.5....4.5, 5]: 9 classes\n",
        "                               num_train_layers=0,\n",
        "                               num_hidden_layer=1,\n",
        "                               num_hidden_units=256,\n",
        "                               dropout=0.3,\n",
        "                               learning_rate=0.00005,\n",
        "                               activation = 'relu',\n",
        "                               optimizer='adam'):\n",
        "    \"\"\"\n",
        "    Build a simple regression model with BERT. Use the CLS Output for regression purposes.\n",
        "    \"\"\"\n",
        "    # =========== BEGIN generate \"input features\" using pre-trained model tokenizer ==================================\n",
        "    if num_train_layers == 0:\n",
        "        bert_model.trainable = False                 # Freeze all layers of pre-trained BERT model\n",
        "\n",
        "    elif num_train_layers == 12:         \n",
        "        bert_model.trainable = True                  # Train all layers of the BERT model\n",
        "\n",
        "    else:                                            # Restrict training to the num_train_layers outer transformer layers\n",
        "        retrain_layers = []\n",
        "        for retrain_layer_number in range(num_train_layers):\n",
        "            layer_code = '_' + str(11 - retrain_layer_number)\n",
        "            retrain_layers.append(layer_code) \n",
        "        # print('retrain layers: ', retrain_layers)\n",
        "\n",
        "        for w in bert_model.weights:\n",
        "            if not any([x in w.name for x in retrain_layers]):\n",
        "                #print('freezing: ', w)\n",
        "                w._trainable = False\n",
        "    \n",
        "    # Input Layer\n",
        "    input_ids = tf.keras.layers.Input(shape=(MAX_LENGTH), dtype=tf.int64, name='input_ids_layer')\n",
        "    attention_mask = tf.keras.layers.Input(shape=(MAX_LENGTH), dtype=tf.int64, name='attention_mask_layer')\n",
        "\n",
        "    bert_inputs = {'input_ids': input_ids,\n",
        "                  'attention_mask': attention_mask\n",
        "                  }\n",
        "                      \n",
        "    # Bert output: being used as an input feature in the classification model below\n",
        "    bert_out = bert_model(bert_inputs)        # full features as an input to the following classification model\n",
        "    # pooler_output = bert_out[1]             # one vector for each\n",
        "    cls_token = bert_out[0][:, 0, :]          # give us a raw CLS tokens\n",
        "\n",
        "\n",
        "    layer_list = []\n",
        "    for hidden_layer_number in range(num_hidden_layer):\n",
        "        if hidden_layer_number == 0:\n",
        "            hidden_layer = tf.keras.layers.Dense(units = num_hidden_units\n",
        "                                        , activation = activation\n",
        "                                        , name = 'hidden_layer_' + str(hidden_layer_number + 1)\n",
        "                                        )(cls_token)\n",
        "        else:\n",
        "            hidden_layer = tf.keras.layers.Dense(units = num_hidden_units\n",
        "                                        , activation = activation\n",
        "                                        , name = 'hidden_layer_' + str(hidden_layer_number + 1)\n",
        "                                        )(layer_list[-1])\n",
        "        layer_list.append(hidden_layer)\n",
        "        dropout_layer = tf.keras.layers.Dropout(dropout, name = 'dropout_layer_' + str(hidden_layer_number + 1))(hidden_layer) \n",
        "        layer_list.append(dropout_layer)\n",
        "\n",
        "    output = tf.keras.layers.Dense(6,)(layer_list[-1])\n",
        "    regression_model = tf.keras.Model(inputs = [input_ids, attention_mask], outputs = output)\n",
        "\n",
        "    def selected_optimizer(optimizer):\n",
        "      if optimizer.lower() == 'sgd':\n",
        "        return SGD(learning_rate=learning_rate)           \n",
        "      elif optimizer.lower() == 'adam':\n",
        "        return Adam(learning_rate=learning_rate)          \n",
        "\n",
        "    regression_model.compile(optimizer = selected_optimizer(optimizer),\n",
        "                             loss=MCRMSE,\n",
        "                             metrics=MCRMSE) \n",
        "\n",
        "    return regression_model, count_params(regression_model.trainable_weights), count_params(regression_model.non_trainable_weights)\n",
        "def train_regression(model, batch_size, epochs):  \n",
        "  checkpoint_filepath = '/content/gdrive/MyDrive/Kaggle/Model_Checkpoint'         #  Create a new directory, Model_Checkpoint, in my Google Drive first and navigate the path here\n",
        "  model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
        "                                                                  save_weights_only=True,\n",
        "                                                                  monitor='val_loss',\n",
        "                                                                  mode='min',\n",
        "                                                                  save_best_only=True)  \n",
        "  # The following parameters say: \"If there hasn't been at least an improvement of 0.001 in the validation loss over the previous 3 epochs, then stop the training and keep the best model you found.\"\n",
        "  early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', \n",
        "                                              min_delta=0.001, # minimium amount of change to count as an improvement\n",
        "                                              patience=3,      # how many epochs to wait before stopping\n",
        "                                              restore_best_weights=True)\n",
        "\n",
        "  print('Training Regression with BERT.....\\n====================================='  )\n",
        "  regression_model_history = model.fit([train_encodings.input_ids, \n",
        "                                        train_encodings.attention_mask\n",
        "                                        ], \n",
        "                                        y_train,   \n",
        "                                        validation_split = .1,\n",
        "                                        # validation_data =([val_encodings.input_ids, \n",
        "                                        #                     val_encodings.attention_mask], \n",
        "                                        #                   y_val\n",
        "                                        #                   ),    \n",
        "                                        batch_size = batch_size, \n",
        "                                        # callbacks=[callback, model_checkpoint_callback, tensorboard_callback],\n",
        "                                        callbacks=[early_stopping_callback, model_checkpoint_callback],\n",
        "                                        epochs = epochs \n",
        "                                        # verbose=0    # make output invisible\n",
        "                                        )    \n",
        "  df_regression_model_history = pd.DataFrame(regression_model_history.history)\n",
        "  display(df_regression_model_history.T)     \n",
        "  return df_regression_model_history\n",
        "def plot_loss_mcrmse(df, eval_metric):\n",
        "    x_arr = np.arange(len(df['loss'])) + 1\n",
        "    fig = plt.figure(figsize=(12, 4))\n",
        "    ax = fig.add_subplot(1, 2, 1)\n",
        "    ax.plot(x_arr, df['loss'], '-o', label = 'Train Loss')\n",
        "    ax.plot(x_arr, df['val_loss'], '--<', label = 'Validation Loss')\n",
        "    ax.legend(fontsize = 12)\n",
        "    ax.set_xlabel('Epoch', size = 12)\n",
        "    ax.set_ylabel('Loss', size = 12)\n",
        "\n",
        "    ax = fig.add_subplot(1, 2, 2)\n",
        "    ax.plot(x_arr, df[eval_metric], '-o', label = 'Train ' + eval_metric)\n",
        "    ax.plot(x_arr, df['val_' + eval_metric], '--<', label = 'Validation ' + eval_metric)\n",
        "    ax.legend(fontsize = 12)\n",
        "    ax.set_xlabel('Epoch', size = 12)\n",
        "    ax.set_ylabel('MCRMSE', size = 12)\n",
        "    #ax.set_ylim(0,1)\n",
        "    plt.show()\n",
        "def evaluate_test_labels(model):\n",
        "  score_regression = model.evaluate([test_encodings.input_ids, \n",
        "                                          test_encodings.attention_mask\n",
        "                                          ], \n",
        "                                          y_test\n",
        "                                          ) \n",
        "  print('\\nEvaluate Test Metrics:\\n=================================')\n",
        "  print('\\nTest loss: {:.4f}'.format(score_regression[0]))\n",
        "  print('\\nTest MCRMSE score: {:.4f}'.format(score_regression[1]),'\\n')\n",
        "  return score_regression\n",
        "def predict_test_labels(model):\n",
        "  predictions = model.predict([test_encodings.input_ids, test_encodings.attention_mask])    # -1 in reshape function is used when you don't know or want to explicitly tell the dimension of that axis.\n",
        "  df_pred = pd.DataFrame(predictions, columns=['pred_'+ col for col in label_cols])\n",
        "  return df_pred\n",
        "def scaled_pred(df):\n",
        "  pred_scaled = []\n",
        "  for col in df:\n",
        "    df[col + '_scaled'] = df[col].apply(lambda val: round(val/0.5) * 0.5)\n",
        "    pred_scaled.append(df[col + '_scaled'])\n",
        "  return pd.DataFrame(pred_scaled).T\n",
        "def run_regression_experiment(num_train_layers=0,\n",
        "                              num_hidden_layer=1,\n",
        "                              num_hidden_units=256,\n",
        "                              dropout=0.3,\n",
        "                              learning_rate=0.00005,\n",
        "                              batch_size=8,\n",
        "                              csv_filename='perf_summary_regression_w_BERT.csv',\n",
        "                              activation = 'relu',                                    # 'relu', 'leaky_relu', 'gelu'\n",
        "                              optimizer='adam',                                       # 'adam', 'sgd'\n",
        "                              epochs=1): ### UPDATE AT THE END\n",
        "  set_config_param(20230214)\n",
        "  df_perf_summary = pd.DataFrame()\n",
        "  \n",
        "  for layer in num_train_layers:  \n",
        "    print('\\n******************************************************')\n",
        "    print(f'Regression with BERT: Number of Unfrozen Layers = {layer}')\n",
        "    print('******************************************************\\n')\n",
        "\n",
        "    # build a regression model\n",
        "    regression_with_bert, num_trainable_params, num_non_trainable_params = regression_model_with_bert(num_classes = 9,                          # [1, 1.5, 2, 2.5....4.5, 5]: 9 classes\n",
        "                                                                                                      num_train_layers = layer,\n",
        "                                                                                                      num_hidden_layer = num_hidden_layer,\n",
        "                                                                                                      num_hidden_units = num_hidden_units,\n",
        "                                                                                                      dropout = dropout,\n",
        "                                                                                                      learning_rate = learning_rate,\n",
        "                                                                                                      activation = activation,\n",
        "                                                                                                      optimizer=optimizer)\n",
        "    # print(f'Parameter Values:\\n======================\\nnum_hidden_layer = {num_hidden_layer}\\nnum_hidden_units = {num_hidden_units}\\ndropout = {dropout}\\nlearning_rate = {learning_rate}\\nbatch_size = {batch_size}\\n')\n",
        "    \n",
        "    # model summary and plot model structure\n",
        "    display(regression_with_bert.summary())\n",
        "    display(keras.utils.plot_model(regression_with_bert, show_shapes=False, show_dtype=False, show_layer_names=True, dpi=90))\n",
        "\n",
        "    # train model\n",
        "    df_regression_model_history = train_regression(regression_with_bert, batch_size, epochs)\n",
        "    print(\"\\nPlotting loss and MCRMSE...\")\n",
        "    plot_loss_mcrmse(df_regression_model_history, 'MCRMSE')  \n",
        "    # print(\"\\nTensorBoard: Evolution of Loss and MCRMSE:\\n=============================================\")\n",
        "    # %tensorboard --logdir logs/fit\n",
        "\n",
        "    # Evaluate test set\n",
        "    score_regression = evaluate_test_labels(regression_with_bert)\n",
        "\n",
        "    # Predict test set\n",
        "    df_pred = predict_test_labels(regression_with_bert)\n",
        "    df_pred_scaled = scaled_pred(df_pred)\n",
        "    \n",
        "    # Create a final table with y_true, y_pred_raw, and y_pred_scaled\n",
        "    # display(generate_final_table(df_pred))\n",
        "\n",
        "    # ========== Performace metrics summary ===================================\n",
        "    perf_metrics = pd.DataFrame({'NLP Model':\"bert-base-cased\",\n",
        "                                'Num_Trainable_layers': layer,\n",
        "                                # 'Trainable_Params':  f'{num_trainable_params:,}',\n",
        "                                # 'Non-Trainable_Params':  f'{num_non_trainable_params:,}',\n",
        "                                'Epochs':epochs,                                                              \n",
        "                                'Test_MCRMSE':round(score_regression[1], 4), \n",
        "                                'Test_Loss':round(score_regression[0], 4), \n",
        "                                'Train_MCRMSE':round(df_regression_model_history.iloc[-1][1], 4), \n",
        "                                'Train_Loss':round(df_regression_model_history.iloc[-1][0], 4), \n",
        "                                'Val_MCRMSE':round(df_regression_model_history.iloc[-1][3], 4), \n",
        "                                'Val_Loss':round(df_regression_model_history.iloc[-1][2], 4),  \n",
        "                                'Optimizer': optimizer, \n",
        "                                'Activation': activation,  \n",
        "                                'Learning_Rate':learning_rate,                               \n",
        "                                'Num_Hidden_Layers':num_hidden_layer, \n",
        "                                'Num_hidden_Units':num_hidden_units,                                 \n",
        "                                'Dropout': dropout, \n",
        "                                'Batch_Size': batch_size}, index=[0])\n",
        "    df_perf_summary = df_perf_summary.append(perf_metrics)\n",
        "  df_perf_summary.to_csv(csv_filename, index=False)\n",
        "  display(df_perf_summary.reset_index(drop=True))\n",
        "def generate_final_table(df_pred):\n",
        "  print('\\nFinal Table: y_true vs. y_pred_raw vs. y_pred_scaled\\n======================================================')\n",
        "  df_final = pd.concat([df_test[['full_text']].reset_index(drop=True), df_test[label_cols].reset_index(drop=True), df_pred], axis=1)\n",
        "  display(df_final)\n",
        "  return df_final\n",
        "def run_regression_experiment_1(num_train_layers=0,\n",
        "                              num_hidden_layer=1,\n",
        "                              num_hidden_units=256,\n",
        "                              dropout=0.3,\n",
        "                              learning_rate=0.00005,\n",
        "                              batch_size=8,\n",
        "                              csv_filename='perf_summary_regression_w_BERT.csv',\n",
        "                              activation = 'relu',                                    # 'relu', 'leaky_relu', 'gelu'\n",
        "                              optimizer='adam',                                       # 'adam', 'sgd'\n",
        "                              epochs=10):\n",
        "\n",
        "  # df_perf_summary = pd.DataFrame()\n",
        "  # for layer in num_train_layers:  \n",
        "  print('\\n******************************************************')\n",
        "  print(f'Regression with BERT: Number of Unfrozen Layers = {num_train_layers}')\n",
        "  print('******************************************************\\n')\n",
        "\n",
        "\n",
        "  # build a regression model\n",
        "  regression_with_bert, num_trainable_params, num_non_trainable_params = regression_model_with_bert(num_classes = 9,                          # [1, 1.5, 2, 2.5....4.5, 5]: 9 classes\n",
        "                                                                                                    num_train_layers = num_train_layers,\n",
        "                                                                                                    num_hidden_layer = num_hidden_layer,\n",
        "                                                                                                    num_hidden_units = num_hidden_units,\n",
        "                                                                                                    dropout = dropout,\n",
        "                                                                                                    learning_rate = learning_rate,\n",
        "                                                                                                    activation = activation,\n",
        "                                                                                                    optimizer=optimizer)\n",
        "  # print(f'Parameter Values:\\n======================\\nnum_hidden_layer = {num_hidden_layer}\\nnum_hidden_units = {num_hidden_units}\\ndropout = {dropout}\\nlearning_rate = {learning_rate}\\nbatch_size = {batch_size}\\n')\n",
        "  \n",
        "  # model summary and plot model structure\n",
        "  display(regression_with_bert.summary())\n",
        "  display(keras.utils.plot_model(regression_with_bert, show_shapes=False, show_dtype=False, show_layer_names=True, dpi=90))\n",
        "\n",
        "  # train model\n",
        "  df_regression_model_history = train_regression(regression_with_bert, batch_size, epochs)\n",
        "  print(\"\\nPlotting loss and MCRMSE...\")\n",
        "  plot_loss_mcrmse(df_regression_model_history, 'MCRMSE')  \n",
        "  # print(\"\\nTensorBoard: Evolution of Loss and MCRMSE:\\n=============================================\")\n",
        "  # %tensorboard --logdir logs/fit\n",
        "\n",
        "  # Evaluate test set\n",
        "  score_regression = evaluate_test_labels(regression_with_bert)\n",
        "\n",
        "  # Predict test set\n",
        "  df_pred = predict_test_labels(regression_with_bert)\n",
        "  df_pred_scaled = scaled_pred(df_pred)\n",
        "  df_pred.to_csv('df_pred.csv', index=False)\n",
        "  \n",
        "  # Create a final table with y_true, y_pred_raw, and y_pred_scaled\n",
        "  df_final = generate_final_table(df_pred)\n",
        "  display(generate_final_table(df_pred))\n",
        "  df_final.to_csv('df_final.csv', index=False)\n",
        "\n",
        "  # ========== Performace metrics summary ===================================\n",
        "  perf_metrics = pd.DataFrame({'NLP Model':\"bert-base-cased\",\n",
        "                              'Num_Trainable_layers': num_train_layers,\n",
        "                              # 'Trainable_Params':  f'{num_trainable_params:,}',\n",
        "                              # 'Non-Trainable_Params':  f'{num_non_trainable_params:,}',\n",
        "                              'Epochs':epochs,                                                              \n",
        "                              'Test_MCRMSE':round(score_regression[1], 4), \n",
        "                              'Test_Loss':round(score_regression[0], 4), \n",
        "                              'Train_MCRMSE':round(df_regression_model_history.iloc[-1][1], 4), \n",
        "                              'Train_Loss':round(df_regression_model_history.iloc[-1][0], 4), \n",
        "                              'Val_MCRMSE':round(df_regression_model_history.iloc[-1][3], 4), \n",
        "                              'Val_Loss':round(df_regression_model_history.iloc[-1][2], 4),  \n",
        "                              'Optimizer': optimizer, \n",
        "                              'Activation': activation,  \n",
        "                              'Learning_Rate':learning_rate,                               \n",
        "                              'Num_Hidden_Layers':num_hidden_layer, \n",
        "                              'Num_hidden_Units':num_hidden_units,                                 \n",
        "                              'Dropout': dropout, \n",
        "                              'Batch_Size': batch_size}, index=[0])\n",
        "    # df_perf_summary = df_perf_summary.append(perf_metrics)\n",
        "  perf_metrics.to_csv(csv_filename, index=False)\n",
        "  display(perf_metrics.reset_index(drop=True))"
      ],
      "metadata": {
        "id": "X6fxpQJFlDH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_regression_experiment(num_train_layers=np.arange(0,13,6),\n",
        "                          activation='relu',\n",
        "                          optimizer='adam',                          \n",
        "                          csv_filename='perf_summary_regression_w_BERT_1.csv')"
      ],
      "metadata": {
        "id": "6PZfOmUGddGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_regression_experiment(num_train_layers=np.arange(0,13,2),\n",
        "                          num_hidden_layer=2,\n",
        "                          num_hidden_units=64,\n",
        "                          dropout=0.1,\n",
        "                          learning_rate=0.00001,\n",
        "                          batch_size=16,\n",
        "                          csv_filename='perf_summary_regression_w_BERT_2.csv',\n",
        "                          activation='relu',\n",
        "                          optimizer='adam',\n",
        "                          epochs=10)"
      ],
      "metadata": {
        "id": "akVSmP58v_We"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_regression_experiment(num_train_layers=np.arange(0,13,2),\n",
        "                          csv_filename='perf_summary_regression_w_BERT_5.csv')"
      ],
      "metadata": {
        "id": "5PeAFzQhv_eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_regression_experiment(num_train_layers=np.arange(0,13,6),\n",
        "                          # num_hidden_layer=1,\n",
        "                          # num_hidden_units=256,\n",
        "                          # dropout=0.3,\n",
        "                          # learning_rate=0.00005,\n",
        "                          batch_size=16,\n",
        "                          activation='relu',\n",
        "                          optimizer='adam',\n",
        "                          csv_filename='perf_summary_regression_w_BERT_4.csv')"
      ],
      "metadata": {
        "id": "ADKyWC2Dv_lK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_regression_experiment(num_train_layers=np.arange(0,13,6),\n",
        "                          # num_hidden_layer=1,\n",
        "                          # num_hidden_units=256,\n",
        "                          # dropout=0.3,\n",
        "                          # learning_rate=0.00005,\n",
        "                          batch_size=16,\n",
        "                          activation='gelu',\n",
        "                          optimizer='adam',\n",
        "                          csv_filename='perf_summary_regression_w_BERT_batch16_gelu.csv')"
      ],
      "metadata": {
        "id": "IQkEBRrEv5mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_regression_experiment(num_train_layers=np.arange(0,7,2),\n",
        "                          # num_hidden_layer=1,\n",
        "                          # num_hidden_units=256,\n",
        "                          # dropout=0.3,\n",
        "                          # learning_rate=0.00005,\n",
        "                          batch_size=16,\n",
        "                          activation='leaky_relu',\n",
        "                          optimizer='adam',\n",
        "                          csv_filename='perf_summary_regression_w_BERT_batch16_leakyRelu.csv')"
      ],
      "metadata": {
        "id": "9KsoMwRRv5pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_regression_experiment(num_train_layers=np.arange(2,5,2),\n",
        "# run_regression_experiment(num_train_layers=np.arange(0,9,2),\n",
        "                          # num_hidden_layer=1,\n",
        "                          # num_hidden_units=256,\n",
        "                          dropout=0.1,\n",
        "                          # learning_rate=0.00005,\n",
        "                          batch_size=16,\n",
        "                          activation='relu',\n",
        "                          optimizer='adam',\n",
        "                          csv_filename='perf_summary_regression_w_BERT_batch16_leakyRelu.csv')"
      ],
      "metadata": {
        "id": "h2-i0Bccv5wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_regression_experiment(num_train_layers=np.arange(0,7,2),\n",
        "                          # num_hidden_layer=1,\n",
        "                          # num_hidden_units=256,\n",
        "                          dropout=0.2,\n",
        "                          # learning_rate=0.00005,\n",
        "                          batch_size=16,\n",
        "                          activation='leaky_relu',\n",
        "                          optimizer='adam',\n",
        "                          csv_filename='perf_summary_regression_w_BERT_batch16_leakyRelu_sgd.csv')"
      ],
      "metadata": {
        "id": "dp1zCoQTvxAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " run_regression_experiment(num_train_layers=np.arange(0,7,2),\n",
        "                          # num_hidden_layer=1,\n",
        "                          # num_hidden_units=256,\n",
        "                          dropout=0.2,\n",
        "                          learning_rate=0.0001,\n",
        "                          batch_size=16,\n",
        "                          activation='leaky_relu',\n",
        "                          optimizer='adam',\n",
        "                          csv_filename='perf_summary_regression_w_BERT_batch16_leakyRelu_lowerLR.csv')"
      ],
      "metadata": {
        "id": "FieQsIpzvxC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_regression_experiment(num_train_layers=np.arange(0,13,4),\n",
        "                          # num_hidden_layer=1,\n",
        "                          num_hidden_units=128,\n",
        "                          dropout=0.2,\n",
        "                          learning_rate=0.0005,\n",
        "                          batch_size=16,\n",
        "                          activation='leaky_relu',\n",
        "                          optimizer='adam',\n",
        "                          csv_filename='perf_summary_regression_w_BERT_batch16_leakyRelu_lowerLR2.csv')"
      ],
      "metadata": {
        "id": "N5_xlwdavxFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " run_regression_experiment(num_train_layers=np.arange(0,13,4),\n",
        "                          # num_hidden_layer=1,\n",
        "                          num_hidden_units=64,\n",
        "                          dropout=0.2,\n",
        "                          learning_rate=0.0005,\n",
        "                          batch_size=16,\n",
        "                          activation='leaky_relu',\n",
        "                          optimizer='adam',\n",
        "                          csv_filename='perf_summary_regression_w_BERT_batch16_leakyRelu_lowerLR128.csv')"
      ],
      "metadata": {
        "id": "drc4AOITvxIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_regression_experiment_1(num_train_layers=12,\n",
        "                          num_hidden_layer=2,\n",
        "                          num_hidden_units=64,\n",
        "                          dropout=0.1,\n",
        "                          learning_rate=0.00001,\n",
        "                          batch_size=16,\n",
        "                          csv_filename='perf_summary_regression_w_BERT_final1.csv',\n",
        "                          activation='relu',\n",
        "                          optimizer='adam',\n",
        "                          epochs=10)"
      ],
      "metadata": {
        "id": "BDn1FN-ZvxLD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FYfihW3Mjgkf",
        "6yYB47Gdjo0L",
        "dII35P-P_J_t"
      ],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bafbe3e4c46641d09650ae650268da7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92bbe263eb214720a2e61bdcb05b82ee",
              "IPY_MODEL_4f77ca6ca3164d199bf472827a428b4a",
              "IPY_MODEL_33c7ec509a514b96b018195748f780d6"
            ],
            "layout": "IPY_MODEL_dfd52916440d43e68a03933bf67b6d93"
          }
        },
        "92bbe263eb214720a2e61bdcb05b82ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae90991b2d1a48fdb0ca9647833594bb",
            "placeholder": "​",
            "style": "IPY_MODEL_fe9be27d56324efabc68a6592926fe6c",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "4f77ca6ca3164d199bf472827a428b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ee555e528ef4876b1b2e9957eacb968",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16a5123e234841fc9b1af753016a3157",
            "value": 29
          }
        },
        "33c7ec509a514b96b018195748f780d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98eec0369bb7438badc698387cf2bdc6",
            "placeholder": "​",
            "style": "IPY_MODEL_756dff02b4d14011a67de76e4e27fbec",
            "value": " 29.0/29.0 [00:00&lt;00:00, 819B/s]"
          }
        },
        "dfd52916440d43e68a03933bf67b6d93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae90991b2d1a48fdb0ca9647833594bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe9be27d56324efabc68a6592926fe6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ee555e528ef4876b1b2e9957eacb968": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16a5123e234841fc9b1af753016a3157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98eec0369bb7438badc698387cf2bdc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "756dff02b4d14011a67de76e4e27fbec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c2f5329b7a04ac8af043a86fa72953a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2bcde8ba533441d95b3d4d6bfc036df",
              "IPY_MODEL_fff74475351d454e885af623a9107993",
              "IPY_MODEL_fcd7c8db8968483ca39f30bb7a37343c"
            ],
            "layout": "IPY_MODEL_bed6c529bf8047b4b9875ca8fa89bce3"
          }
        },
        "a2bcde8ba533441d95b3d4d6bfc036df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbf076bcc4124fac913621711addb0e6",
            "placeholder": "​",
            "style": "IPY_MODEL_d4793f4f974b4cedb365f91a3d504815",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "fff74475351d454e885af623a9107993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ddc5eb1d2e449c0a570be470f9d7fe5",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2638dcdc6a94e939780ffbc3b59e708",
            "value": 570
          }
        },
        "fcd7c8db8968483ca39f30bb7a37343c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_899d91409a1f4d91bda5da7e20ced404",
            "placeholder": "​",
            "style": "IPY_MODEL_cb97fdb2c5b54dd6afa6a9965ec7a977",
            "value": " 570/570 [00:00&lt;00:00, 17.2kB/s]"
          }
        },
        "bed6c529bf8047b4b9875ca8fa89bce3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbf076bcc4124fac913621711addb0e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4793f4f974b4cedb365f91a3d504815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ddc5eb1d2e449c0a570be470f9d7fe5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2638dcdc6a94e939780ffbc3b59e708": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "899d91409a1f4d91bda5da7e20ced404": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb97fdb2c5b54dd6afa6a9965ec7a977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "901a74da4949445da3b7960b02773824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21c4d96df4524184a5ea3f72fcb5717b",
              "IPY_MODEL_6944ac2666c3419b85db52280345c1b9",
              "IPY_MODEL_d0d7e684052540fbbe493aa13013d208"
            ],
            "layout": "IPY_MODEL_b60b38513a3e43f19a9f65dc2881b29b"
          }
        },
        "21c4d96df4524184a5ea3f72fcb5717b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bc25cfec28b4b92a591e8957515866c",
            "placeholder": "​",
            "style": "IPY_MODEL_4a621de3ed10426d96a902b434f82d8b",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "6944ac2666c3419b85db52280345c1b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75b7fdf395f64453b8682eead2fa7d31",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39a526c91f644e96b3671bebbcf0ed05",
            "value": 213450
          }
        },
        "d0d7e684052540fbbe493aa13013d208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f3eb465557f4378a01d296195bd7171",
            "placeholder": "​",
            "style": "IPY_MODEL_6b58e83ba65a40bf84bfca6b0a100729",
            "value": " 213k/213k [00:00&lt;00:00, 3.01MB/s]"
          }
        },
        "b60b38513a3e43f19a9f65dc2881b29b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bc25cfec28b4b92a591e8957515866c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a621de3ed10426d96a902b434f82d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75b7fdf395f64453b8682eead2fa7d31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39a526c91f644e96b3671bebbcf0ed05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f3eb465557f4378a01d296195bd7171": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b58e83ba65a40bf84bfca6b0a100729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63ec69e49a624ffcb4e733d172a21590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0dba75b62904b47930442def8a1f35a",
              "IPY_MODEL_09867eb6e50743fcaa528ab6e4e95c92",
              "IPY_MODEL_a5d3dcd42ca346ecaae7905f314313bd"
            ],
            "layout": "IPY_MODEL_e72154f7f0a442f8962b14efe93aa07f"
          }
        },
        "a0dba75b62904b47930442def8a1f35a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e13e67c80f5049d89c09229668bcf5f8",
            "placeholder": "​",
            "style": "IPY_MODEL_2e429bd842b64341abfb610662e036b4",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "09867eb6e50743fcaa528ab6e4e95c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15ae65572cc843178ff6307b2b12a58b",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a46063ad1bf84ecba6700da44bfc836c",
            "value": 435797
          }
        },
        "a5d3dcd42ca346ecaae7905f314313bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_591ddf1919b14d7f82a9c7f4a232c6d2",
            "placeholder": "​",
            "style": "IPY_MODEL_9797be97bebc4c718d25ef0990e90b5a",
            "value": " 436k/436k [00:00&lt;00:00, 3.12MB/s]"
          }
        },
        "e72154f7f0a442f8962b14efe93aa07f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e13e67c80f5049d89c09229668bcf5f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e429bd842b64341abfb610662e036b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15ae65572cc843178ff6307b2b12a58b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a46063ad1bf84ecba6700da44bfc836c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "591ddf1919b14d7f82a9c7f4a232c6d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9797be97bebc4c718d25ef0990e90b5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e872febea2e42a68edcd97be0eb7092": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19c9bab4b2084f46aae17b96f1745ad4",
              "IPY_MODEL_cfe57bc361ac4860858217e747353320",
              "IPY_MODEL_cf832384db734b43822319cf5d4987e2"
            ],
            "layout": "IPY_MODEL_8ed4b760a4b54925b20b5d7d6dbcd343"
          }
        },
        "19c9bab4b2084f46aae17b96f1745ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c1ece91fe5b44bf9e06fc565dcc65bc",
            "placeholder": "​",
            "style": "IPY_MODEL_f76aab1a234c4515b9ac0d84a4bd3873",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "cfe57bc361ac4860858217e747353320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e885f2e875e4b31b3514000a3d11ee7",
            "max": 526681800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11a6e4047b3a45ad9464e27a465e257b",
            "value": 526681800
          }
        },
        "cf832384db734b43822319cf5d4987e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31ef51ab826b4b069b67eea158bcb1ab",
            "placeholder": "​",
            "style": "IPY_MODEL_317f5cb48ccd4f40810cb3cfcfaf1631",
            "value": " 527M/527M [00:04&lt;00:00, 110MB/s]"
          }
        },
        "8ed4b760a4b54925b20b5d7d6dbcd343": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c1ece91fe5b44bf9e06fc565dcc65bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f76aab1a234c4515b9ac0d84a4bd3873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e885f2e875e4b31b3514000a3d11ee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11a6e4047b3a45ad9464e27a465e257b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31ef51ab826b4b069b67eea158bcb1ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "317f5cb48ccd4f40810cb3cfcfaf1631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6308854cf2aa4c8bbfe6135f15de39ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f688cb89165c489c8e5fb2ec4670f31b",
              "IPY_MODEL_537c4b5bd6f449e1802fe999ad913a3a",
              "IPY_MODEL_a4d4ba6063234549a183f5c7c82d6682"
            ],
            "layout": "IPY_MODEL_1f8bb93c150a4908bac723af047c512d"
          }
        },
        "f688cb89165c489c8e5fb2ec4670f31b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9e7b866791c426d8106c63f2c9804ee",
            "placeholder": "​",
            "style": "IPY_MODEL_20d6a17275464462b85e5d5156030036",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "537c4b5bd6f449e1802fe999ad913a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25bf8560ba834bc0af23e7a0b8190bc3",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca424cbd85284861903b2cb991b60423",
            "value": 29
          }
        },
        "a4d4ba6063234549a183f5c7c82d6682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5584a104c9a541ce885efddfeb933ecd",
            "placeholder": "​",
            "style": "IPY_MODEL_1098570da60d456a95504654951d79b9",
            "value": " 29.0/29.0 [00:00&lt;00:00, 1.06kB/s]"
          }
        },
        "1f8bb93c150a4908bac723af047c512d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9e7b866791c426d8106c63f2c9804ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20d6a17275464462b85e5d5156030036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25bf8560ba834bc0af23e7a0b8190bc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca424cbd85284861903b2cb991b60423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5584a104c9a541ce885efddfeb933ecd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1098570da60d456a95504654951d79b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fd50d63943a4c09bb01d93099b1e541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63da958fcb444e9a989ef476932656e5",
              "IPY_MODEL_e2c03e048bde430ca1eab7d989e2a062",
              "IPY_MODEL_16fc1bc897a843afa256628321eda644"
            ],
            "layout": "IPY_MODEL_ab5d3ddeee4e4be49c0e9288897af115"
          }
        },
        "63da958fcb444e9a989ef476932656e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdab9fcfda9b458490286b26edb51aa8",
            "placeholder": "​",
            "style": "IPY_MODEL_e0ae38deb7024708a2998231e3c73bbe",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "e2c03e048bde430ca1eab7d989e2a062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a18f88f130b4a1ebbd463dfeeedb4ac",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de9ea2b44ca14e93abee1ace7e82d8bd",
            "value": 570
          }
        },
        "16fc1bc897a843afa256628321eda644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fc6950e29cc401182f79d397e0a9849",
            "placeholder": "​",
            "style": "IPY_MODEL_2683d70e0b7243649c59544c12023c48",
            "value": " 570/570 [00:00&lt;00:00, 20.9kB/s]"
          }
        },
        "ab5d3ddeee4e4be49c0e9288897af115": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdab9fcfda9b458490286b26edb51aa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0ae38deb7024708a2998231e3c73bbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a18f88f130b4a1ebbd463dfeeedb4ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de9ea2b44ca14e93abee1ace7e82d8bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fc6950e29cc401182f79d397e0a9849": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2683d70e0b7243649c59544c12023c48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af625878ca814014ac8b853ff1ed69e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fc042bb266448a09d6e50a8d6085e07",
              "IPY_MODEL_de4b71c543644894bb0b9f08545d8fb5",
              "IPY_MODEL_bd03501ca168474681db04eaff7ee2b4"
            ],
            "layout": "IPY_MODEL_e70f9f8bd21a4517bbbd37618e8eae50"
          }
        },
        "6fc042bb266448a09d6e50a8d6085e07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ceff53c1582848ae85b4374e26034661",
            "placeholder": "​",
            "style": "IPY_MODEL_292184e323e147748933dc83f8cff702",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "de4b71c543644894bb0b9f08545d8fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d86d0cda83554311bbdb3149d4ef2675",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45bceea3d6da4730b759f1c3bbc1e167",
            "value": 213450
          }
        },
        "bd03501ca168474681db04eaff7ee2b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80160e685b99485193ae8c164295cf68",
            "placeholder": "​",
            "style": "IPY_MODEL_f73f563c4a214952b457b11b7e582503",
            "value": " 213k/213k [00:00&lt;00:00, 4.42MB/s]"
          }
        },
        "e70f9f8bd21a4517bbbd37618e8eae50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceff53c1582848ae85b4374e26034661": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "292184e323e147748933dc83f8cff702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d86d0cda83554311bbdb3149d4ef2675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45bceea3d6da4730b759f1c3bbc1e167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80160e685b99485193ae8c164295cf68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f73f563c4a214952b457b11b7e582503": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3885a3401fd34118a961eb60a0793fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_705fd9571662413c8aa5f4db31bd827e",
              "IPY_MODEL_7a20999f4be84f0198b48126880d4f55",
              "IPY_MODEL_280a88204258436c9f844215d018fcb3"
            ],
            "layout": "IPY_MODEL_bd2ac54e2bf14984b47720de98054c85"
          }
        },
        "705fd9571662413c8aa5f4db31bd827e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_811dfcb024034297b512327b89a8bf57",
            "placeholder": "​",
            "style": "IPY_MODEL_d8648b0c6522488086bb120fb1875932",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "7a20999f4be84f0198b48126880d4f55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_409f0cc38e834cdeba3cb091db1aa8ab",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c04b59358fd4346b44fd61a94c111c0",
            "value": 435797
          }
        },
        "280a88204258436c9f844215d018fcb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24319cc218b64ce4a1d3c0ea8aed6d16",
            "placeholder": "​",
            "style": "IPY_MODEL_0df4943da1ce4680bd7db10e98edd381",
            "value": " 436k/436k [00:00&lt;00:00, 7.22MB/s]"
          }
        },
        "bd2ac54e2bf14984b47720de98054c85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "811dfcb024034297b512327b89a8bf57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8648b0c6522488086bb120fb1875932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "409f0cc38e834cdeba3cb091db1aa8ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c04b59358fd4346b44fd61a94c111c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24319cc218b64ce4a1d3c0ea8aed6d16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0df4943da1ce4680bd7db10e98edd381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e96b351438fc4ff480f95df1426e08e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d84cd638b264e4f9cc64904368d2f23",
              "IPY_MODEL_c8ffda0aa8944f9ba0e167948748a360",
              "IPY_MODEL_342776199ac146d697b1f24b370c4362"
            ],
            "layout": "IPY_MODEL_4536c16ddd5c42c0b25d11a5e10524dc"
          }
        },
        "9d84cd638b264e4f9cc64904368d2f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7444a0b08f842dcb465e1d6059bacce",
            "placeholder": "​",
            "style": "IPY_MODEL_4379a16364bc48ecadf5548bf75ac221",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "c8ffda0aa8944f9ba0e167948748a360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_921332b0abc148f7aafacf97beb3044d",
            "max": 526681800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06e4f8b236634ea5a17d6823f2b43d07",
            "value": 526681800
          }
        },
        "342776199ac146d697b1f24b370c4362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2d818ae9b344a1a9946ba7c989f4e8f",
            "placeholder": "​",
            "style": "IPY_MODEL_1cba373e7ec540328f956455cdb2c123",
            "value": " 527M/527M [00:08&lt;00:00, 67.4MB/s]"
          }
        },
        "4536c16ddd5c42c0b25d11a5e10524dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7444a0b08f842dcb465e1d6059bacce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4379a16364bc48ecadf5548bf75ac221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "921332b0abc148f7aafacf97beb3044d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06e4f8b236634ea5a17d6823f2b43d07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2d818ae9b344a1a9946ba7c989f4e8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cba373e7ec540328f956455cdb2c123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f99a5ce99684adcb74b6d997dd4f6b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63e3ad6b2f714d83a9371224fc036969",
              "IPY_MODEL_841c04a5892848feaccb9c5f8db87714",
              "IPY_MODEL_15c166dfb76a4c778e078f4a798a1667"
            ],
            "layout": "IPY_MODEL_1ba6bc91c94a439f811d817a996a3f89"
          }
        },
        "63e3ad6b2f714d83a9371224fc036969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5be82c8821c48d3b1cb9017841f0d77",
            "placeholder": "​",
            "style": "IPY_MODEL_2d7c191b35fa4f10be56e5d6ea621584",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "841c04a5892848feaccb9c5f8db87714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9719939c3b0946748256bd92fd9534c6",
            "max": 558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28f0f0f927aa4d6d80a45e4bf15f1cfc",
            "value": 558
          }
        },
        "15c166dfb76a4c778e078f4a798a1667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cc709c0cbe2412d8d281ab9f84463b1",
            "placeholder": "​",
            "style": "IPY_MODEL_444d03ee8b4e4cb5a2ee62e769bc01a1",
            "value": " 558/558 [00:00&lt;00:00, 21.6kB/s]"
          }
        },
        "1ba6bc91c94a439f811d817a996a3f89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5be82c8821c48d3b1cb9017841f0d77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d7c191b35fa4f10be56e5d6ea621584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9719939c3b0946748256bd92fd9534c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28f0f0f927aa4d6d80a45e4bf15f1cfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8cc709c0cbe2412d8d281ab9f84463b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "444d03ee8b4e4cb5a2ee62e769bc01a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e7917045672490b88288cc47fb111e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f06b3a456911410e835a1ab4feca72e0",
              "IPY_MODEL_28309e7c29b242aeb49361bf8b5127d8",
              "IPY_MODEL_30719f59a4db452c939c3e8a54d30798"
            ],
            "layout": "IPY_MODEL_85294c2326b64a748275411f5201e159"
          }
        },
        "f06b3a456911410e835a1ab4feca72e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d92a01d03eb42098d864ef0bc145add",
            "placeholder": "​",
            "style": "IPY_MODEL_a8ba13da20be4372810a8a1359ca557c",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "28309e7c29b242aeb49361bf8b5127d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a1a84d5368e4a85bc2c5f3de605b20f",
            "max": 843438,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd26e87afb974ebdbfa5f67460712499",
            "value": 843438
          }
        },
        "30719f59a4db452c939c3e8a54d30798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37234288af2a444f9317d1a53376cde4",
            "placeholder": "​",
            "style": "IPY_MODEL_4393074977724b5d9c7514e6212b25e8",
            "value": " 843k/843k [00:00&lt;00:00, 12.0MB/s]"
          }
        },
        "85294c2326b64a748275411f5201e159": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d92a01d03eb42098d864ef0bc145add": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8ba13da20be4372810a8a1359ca557c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a1a84d5368e4a85bc2c5f3de605b20f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd26e87afb974ebdbfa5f67460712499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37234288af2a444f9317d1a53376cde4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4393074977724b5d9c7514e6212b25e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c72c905ae934db2b34b4ab00ac577d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a7b38b0978c41f3acd74bc82be39def",
              "IPY_MODEL_b6edc4817bf3431c991d8d923a89ff1e",
              "IPY_MODEL_f68553ac3b3b4ccfb4cdc67dc1a931cd"
            ],
            "layout": "IPY_MODEL_10cc1b639ff04b5d823e04b6ba32c668"
          }
        },
        "0a7b38b0978c41f3acd74bc82be39def": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3e7fe0be36140889edc96805cdd3f9a",
            "placeholder": "​",
            "style": "IPY_MODEL_b400ff9e85084e168d7a5d9e28b3f3b5",
            "value": "Downloading (…)solve/main/bpe.codes: 100%"
          }
        },
        "b6edc4817bf3431c991d8d923a89ff1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b19cdfc0d0c149b4a7b873f5da0b5ba5",
            "max": 1078931,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e84ed1195b234049818f31377d9afaf6",
            "value": 1078931
          }
        },
        "f68553ac3b3b4ccfb4cdc67dc1a931cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fa790ed2e894e888bbeb3e9013770b8",
            "placeholder": "​",
            "style": "IPY_MODEL_13993572354848a4b2c3b9317ebc4faa",
            "value": " 1.08M/1.08M [00:00&lt;00:00, 14.3MB/s]"
          }
        },
        "10cc1b639ff04b5d823e04b6ba32c668": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3e7fe0be36140889edc96805cdd3f9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b400ff9e85084e168d7a5d9e28b3f3b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b19cdfc0d0c149b4a7b873f5da0b5ba5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e84ed1195b234049818f31377d9afaf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fa790ed2e894e888bbeb3e9013770b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13993572354848a4b2c3b9317ebc4faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5876ad8f5e74428ca6002e0ae9097745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4936d6bed14436a88931c7775e18ff7",
              "IPY_MODEL_6a6a2a8153224a94a0476b164bde2b13",
              "IPY_MODEL_ea446597da424b29a15cddad8b6e0ae2"
            ],
            "layout": "IPY_MODEL_901ee533fc4147fd94a01cf6d0710e65"
          }
        },
        "c4936d6bed14436a88931c7775e18ff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_234fef11af4a4d5d9c1da7b50bcead21",
            "placeholder": "​",
            "style": "IPY_MODEL_2965235ba8cb4a8abaafb19e5195ce01",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "6a6a2a8153224a94a0476b164bde2b13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_304b52a248364e85adf8ad5f64505313",
            "max": 739523780,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5610672da1f4f7987ee84d17f0b3665",
            "value": 739523780
          }
        },
        "ea446597da424b29a15cddad8b6e0ae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a682d41932d54145a2802a4a47ba920e",
            "placeholder": "​",
            "style": "IPY_MODEL_3a1461733a2f4d9ab2d5123f73c4718a",
            "value": " 740M/740M [00:13&lt;00:00, 115MB/s]"
          }
        },
        "901ee533fc4147fd94a01cf6d0710e65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "234fef11af4a4d5d9c1da7b50bcead21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2965235ba8cb4a8abaafb19e5195ce01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "304b52a248364e85adf8ad5f64505313": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5610672da1f4f7987ee84d17f0b3665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a682d41932d54145a2802a4a47ba920e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a1461733a2f4d9ab2d5123f73c4718a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}