{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilamaiti/spring_2023_w266_final_project_heesuk_iris_srila/blob/main/iris/W266_essay_evaluation_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lhf_T8cMjGsp"
      },
      "source": [
        "# **Installing new libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fD4BChywisTm",
        "outputId": "dfece04d-d92e-4435-964c-0f74d605d308"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.27.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji==0.6.0\n",
            "  Downloading emoji-0.6.0.tar.gz (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.6.0-py3-none-any.whl size=49732 sha256=965adab48e7322285e511e1be2761a66608103da8faa19067ffe7991650e2d77\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/2a/7f/1a0012c86b1061c6ee2ed9568b1f830f857a51e8e416452af2\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting iterative-stratification\n",
            "  Downloading iterative_stratification-0.1.7-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from iterative-stratification) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from iterative-stratification) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from iterative-stratification) (1.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->iterative-stratification) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->iterative-stratification) (1.1.1)\n",
            "Installing collected packages: iterative-stratification\n",
            "Successfully installed iterative-stratification-0.1.7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (1.14.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (1.16.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (0.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (0.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (1.6.3)\n",
            "Collecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (67.6.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (3.3.0)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (1.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (3.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (2.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (1.53.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (23.3.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (0.32.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.11.0) (1.22.4)\n",
            "Collecting protobuf<3.20,>=3.9.2\n",
            "  Downloading protobuf-3.19.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow==2.11.0) (0.40.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.27.1)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.2.3)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.4.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.17.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (6.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard-data-server, protobuf, keras, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.0\n",
            "    Uninstalling tensorboard-data-server-0.7.0:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.1\n",
            "    Uninstalling tensorboard-2.12.1:\n",
            "      Successfully uninstalled tensorboard-2.12.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "Successfully installed google-auth-oauthlib-0.4.6 keras-2.11.0 protobuf-3.19.6 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: yellowbrick in /usr/local/lib/python3.9/dist-packages (1.5)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from yellowbrick) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from yellowbrick) (1.22.4)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from yellowbrick) (0.11.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from yellowbrick) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from yellowbrick) (1.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.4.4)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (5.12.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.0.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (23.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (4.39.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (8.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->yellowbrick) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->yellowbrick) (1.1.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib!=3.0.0,>=2.0.2->yellowbrick) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow_gpu==1.15.5 (from versions: 2.5.0, 2.5.1, 2.5.2, 2.5.3, 2.6.0, 2.6.1, 2.6.2, 2.6.3, 2.6.4, 2.6.5, 2.7.0rc0, 2.7.0rc1, 2.7.0, 2.7.1, 2.7.2, 2.7.3, 2.7.4, 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.12.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow_gpu==1.15.5\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install emoji==0.6.0\n",
        "!pip install scikit-multilearn\n",
        "!pip install iterative-stratification\n",
        "!pip install tensorflow==2.11.0\n",
        "!pip install yellowbrick\n",
        "!pip install tensorflow_gpu==1.15.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC3s_6EZjMBt"
      },
      "source": [
        "# **Importing libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaPH5XqxjU_z",
        "outputId": "6b95b826-d3f0-492d-9b06-2cd19505763a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers version: 4.27.4\n",
            "2.11.0\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "print(f'transformers version: {transformers.__version__}')\n",
        "from transformers import logging as hf_logging\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "hf_logging.set_verbosity_error()\n",
        "'''\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import spacy      \n",
        "from spacy import displacy\n",
        "from wordcloud import WordCloud\n",
        "from wordcloud import STOPWORDS\n",
        "from wordcloud import ImageColorGenerator\n",
        "nltk.download('punkt')\n",
        "'''\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from transformers import RobertaTokenizer, TFRobertaModel\n",
        "ROBERTA_MODEL_CHKPT = \"roberta-base\"\n",
        "BERTWEET_MODEL_CHKPT = \"vinai/bertweet-base\"\n",
        "BERT_MODEL_CHKPT = 'bert-base-cased'\n",
        "\n",
        "# Other required libraries\n",
        "import math\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import copy\n",
        "import sys\n",
        "import gc\n",
        "import pprint\n",
        "import statistics\n",
        "\n",
        "# data visualization\n",
        "from matplotlib import cm\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "\n",
        "# others\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "from scipy.cluster.hierarchy import set_link_color_palette\n",
        "from scipy.cluster.hierarchy import linkage\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "from yellowbrick.cluster import SilhouetteVisualizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# distances\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Data visualization libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Tensorflow libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils.layer_utils import count_params\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.losses import mae\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.regularizers import l1\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "\n",
        "import torch\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fjpBUG5jbmt"
      },
      "source": [
        "# **General functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahNGWcMIFD8u"
      },
      "source": [
        "## **Rounding Off to Custom Decimal Places**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5opWTwwnFLLP"
      },
      "outputs": [],
      "source": [
        "def roundPartial(value, resolution):\n",
        "    return round (value / resolution) * resolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYfihW3Mjgkf"
      },
      "source": [
        "## **Set parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pr1-rS8tjiqn"
      },
      "outputs": [],
      "source": [
        "def set_config_param(seed = 99):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    tf.keras.backend.clear_session()\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Colab Notebooks\"\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    \n",
        "    \n",
        "set_config_param(20230214)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yYB47Gdjo0L"
      },
      "source": [
        "## **Plot loss and accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BE9NqiNWjrPy"
      },
      "outputs": [],
      "source": [
        "def plot_loss_accuracy(history, col_list):\n",
        "    fig, ax = plt.subplots(2, 6, figsize=(16, 6), sharex='col', sharey='row')\n",
        "    fig.tight_layout(pad=5.0)\n",
        "    for idx, col in enumerate(col_list):\n",
        "\n",
        "        ax[0, idx].plot(history[col + '_loss'], lw=2, color='darkgoldenrod')\n",
        "        ax[0, idx].plot(history['val_' + col + '_loss'], lw=2, color='indianred')\n",
        "        #ax[0, idx].legend(loc='center left')\n",
        "        ax[0, idx].legend(['Train', 'Validation'], fontsize=5)\n",
        "        ax[0, idx].set_xlabel('Epochs', size=10)\n",
        "        ax[0, idx].set_title('Loss: ' + col)\n",
        "\n",
        "        ax[1, idx].plot(history[col + '_accuracy'], lw=2, color='darkgoldenrod')\n",
        "        ax[1, idx].plot(history['val_' + col + '_accuracy'], lw=2, color='indianred')\n",
        "        #ax[0, idx].legend(loc='center left')\n",
        "        ax[1, idx].legend(['Train', 'Validation'], fontsize=5)\n",
        "        ax[1, idx].set_xlabel('Epochs', size=10)\n",
        "        ax[1, idx].set_title('Accuracy: ' + col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dII35P-P_J_t"
      },
      "source": [
        "## **Plot Loss and other KPI specified**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yQgOGDu6_PVK"
      },
      "outputs": [],
      "source": [
        "def custom_plot(df, model_name, kpi_name, kpi_string):\n",
        "    x_arr = np.arange(len(df['loss'])) + 1\n",
        "    fig = plt.figure(figsize=(12, 4))\n",
        "    ax = fig.add_subplot(1, 2, 1)\n",
        "    ax.plot(x_arr, df['loss'], '-o', label = model_name + ' : Train loss')\n",
        "    ax.plot(x_arr, df['val_loss'], '--<', label = model_name + ' :  Validation loss')\n",
        "    ax.legend(fontsize = 15)\n",
        "    ax.set_xlabel('Epoch', size = 15)\n",
        "    ax.set_ylabel('Loss', size = 15)\n",
        "\n",
        "    ax = fig.add_subplot(1, 2, 2)\n",
        "    ax.plot(x_arr, df[kpi_name], '-o', label = model_name + ' : Train ' + kpi_string)\n",
        "    ax.plot(x_arr, df['val_' + kpi_name], '--<', label = model_name + ' : Validation ' + kpi_string)\n",
        "    ax.legend(fontsize = 15)\n",
        "    ax.set_xlabel('Epoch', size = 15)\n",
        "    ax.set_ylabel(kpi_name, size = 15)\n",
        "    #ax.set_ylim(0,1)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3y3byq0Fk9P"
      },
      "source": [
        "## **Text Encode**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cSxlBmVZFm2n"
      },
      "outputs": [],
      "source": [
        "def text_encode(texts, tokenizer, max_len):\n",
        "    input_ids = []\n",
        "    # token_type_ids = []\n",
        "    attention_mask = []\n",
        "    \n",
        "    for text in texts:\n",
        "        token = tokenizer(text, \n",
        "                          max_length = max_len, \n",
        "                          truncation = True, \n",
        "                          padding = 'max_length',\n",
        "                          add_special_tokens = True)\n",
        "        input_ids.append(token['input_ids'])\n",
        "        # token_type_ids.append(token['token_type_ids'])\n",
        "        attention_mask.append(token['attention_mask'])\n",
        "    \n",
        "    return np.array(input_ids), np.array(attention_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJw9YpJXjwSv"
      },
      "source": [
        "## **Custom metric**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_VCdZF9ZjzN6"
      },
      "outputs": [],
      "source": [
        "def MCRMSE(y_true, y_pred):\n",
        "    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis = 1)\n",
        "    return tf.reduce_mean(tf.sqrt(colwise_mse), axis = -1, keepdims = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdYaqDeEGJE-"
      },
      "source": [
        "## **Build Base Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "brWkfFsUk0wl"
      },
      "outputs": [],
      "source": [
        "def build_regression_model(loss = 'MCRMSE',\n",
        "                           model_name = 'Roberta', \n",
        "                           dense_dim = 6, \n",
        "                           MAX_LEN = 512,\n",
        "                           learning_rate = 1e-5,\n",
        "                           dropout = .1,\n",
        "                           number_of_hidden_layers = 1,\n",
        "                           hidden_layer_node_count = 64,\n",
        "                           retrain_layer_count = 0):\n",
        "    \n",
        "    # Define inputs\n",
        "    input_ids = tf.keras.Input(shape = (MAX_LEN ,), dtype = 'int64', name = 'input_ids')\n",
        "    attention_masks = tf.keras.Input(shape = (MAX_LEN ,), dtype = 'int64', name = 'attention_masks')\n",
        "    \n",
        "    if model_name == 'Roberta':\n",
        "        model_tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_MODEL_CHKPT)\n",
        "        model = TFRobertaModel.from_pretrained(ROBERTA_MODEL_CHKPT)\n",
        "    elif model_name == 'Bertweet':\n",
        "        model_tokenizer = AutoTokenizer.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "        model = TFRobertaModel.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "    elif model_name == 'Bert':\n",
        "        model_tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_CHKPT)\n",
        "        model = TFBertModel.from_pretrained(BERT_MODEL_CHKPT)  \n",
        "\n",
        "    # Adjust the trainable layer weights based on retrain_layer_count\n",
        "    # If retrain_layer_count is 0, then base model is frozen.\n",
        "    # If retrain_layer_count is 12, then the entire base model is trainable.\n",
        "    # And that implies that all the pretrained weights are lost and it relearns\n",
        "    # from the input data.\n",
        "    # If retrain_layer_count is between 1 and 11, then the last n layers of\n",
        "    # the pretrained model retrained.\n",
        "    if retrain_layer_count == 0:\n",
        "        # The pretained model is frozen\n",
        "        model.trainable = False           \n",
        "\n",
        "    elif retrain_layer_count == 12:  \n",
        "        # The pretrained model is retrained thru all layers.       \n",
        "        model.trainable = True     \n",
        "\n",
        "    else:    \n",
        "        # Restrict training to the num_train_layers outer transformer layers\n",
        "        retrain_layer_list = []\n",
        "        model.trainable = False  \n",
        "        for retrain_layer_number in range(retrain_layer_count):\n",
        "\n",
        "            layer_code = '_' + str(11 - retrain_layer_number)\n",
        "            retrain_layer_list.append(layer_code)\n",
        "        \n",
        "        print('Retrain layers: \\n', retrain_layer_list)\n",
        "        #model.compile()\n",
        "        print(f\"Number of trainable parameters : {count_params(model.trainable_weights)}\")\n",
        "        print(f\"Number of non-trainable parameters : {count_params(model.non_trainable_variables)}\")\n",
        "        for weight in model.weights:\n",
        "            weight._trainable = False\n",
        "            #print(\"***\", layer.name, layer._trainable)\n",
        "            if 'layer_' in weight.name and weight.name.split(\".\")[1].split(\"/\")[0] in retrain_layer_list:\n",
        "                weight._trainable = True\n",
        "                # print(\"$$$\", weight.name, weight._trainable)\n",
        "            elif 'layer_' not in weight.name :\n",
        "                weight._trainable = True\n",
        "                # print(\"###\", weight.name, weight._trainable)\n",
        "        model.compile()\n",
        "\n",
        "        for weight_details in model.weights:\n",
        "            print(weight_details.name, weight_details.trainable)\n",
        "    print(f\"Number of trainable parameters : {count_params(model.trainable_weights)}\")\n",
        "    print(f\"Number of non-trainable parameters : {count_params(model.non_trainable_variables)}\")\n",
        "                \n",
        "    # Insert pretrained model layer\n",
        "    pretrained_transformer = model([input_ids, attention_masks])\n",
        "\n",
        "    # Get the CLS output off the pretrained model\n",
        "    cls_token = pretrained_transformer[0][:, 0, :]\n",
        "\n",
        "    # Append the hidden layer and dropout layer\n",
        "    layer_list = []\n",
        "    for layer in range(number_of_hidden_layers):\n",
        "        if layer == 0:\n",
        "            hidden_layer = tf.keras.layers.Dense(units      = hidden_layer_node_count\n",
        "                                               , activation = 'relu'\n",
        "                                               , name       = 'hidden_layer_' + str(layer + 1)\n",
        "                                                )(cls_token)\n",
        "        else:\n",
        "            hidden_layer = tf.keras.layers.Dense(units      = hidden_layer_node_count\n",
        "                                               , activation = 'relu'\n",
        "                                               , name       = 'hidden_layer_' + str(layer + 1)\n",
        "                                            )(layer_list[-1])\n",
        "        layer_list.append(hidden_layer)\n",
        "        dropout_layer = tf.keras.layers.Dropout(dropout, \n",
        "                                                name = 'dropout_layer_' + str(layer + 1)\n",
        "                                               )(hidden_layer) \n",
        "        layer_list.append(dropout_layer)\n",
        "\n",
        "    # Add the output layer\n",
        "    output = tf.keras.layers.Dense(6,)(layer_list[-1])\n",
        "\n",
        "    # Build the final model\n",
        "    regression_model = tf.keras.Model(inputs = [input_ids, attention_masks], outputs = output)\n",
        "    \n",
        "    # Model compile\n",
        "    if loss == 'MCRMSE':\n",
        "        regression_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n",
        "                                 loss      = MCRMSE,\n",
        "                                 metrics   = MCRMSE\n",
        "                                )\n",
        "    \n",
        "    print(regression_model.summary())\n",
        "    keras.utils.plot_model(regression_model, \n",
        "                           show_shapes = False, \n",
        "                           show_dtype = False, \n",
        "                           show_layer_names = True, \n",
        "                           dpi = 90)\n",
        "    return regression_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SzxEshCMv3Te"
      },
      "outputs": [],
      "source": [
        "def model_fit(model, \n",
        "              df_train, \n",
        "              train_indices,\n",
        "              val_indices,\n",
        "              model_name = 'Roberta', \n",
        "              MAX_LEN = 512,\n",
        "              epochs = 5,\n",
        "              batch_size = 4,\n",
        "              validation_split = .2):\n",
        "  \n",
        "    # Building the tokenizer for the given model\n",
        "    if model_name == 'Roberta':\n",
        "        tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_MODEL_CHKPT)\n",
        "    elif model_name == 'Bertweet':\n",
        "        tokenizer = AutoTokenizer.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "    elif model_name == 'Bert':\n",
        "        tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_CHKPT)\n",
        "        \n",
        "    train_encoded_input_ids, train_encoded_attention_masks = text_encode(df_train.iloc[list(train_indices)]['full_text'], tokenizer, MAX_LEN)\n",
        "    val_encoded_input_ids, val_encoded_attention_masks = text_encode(df_train.iloc[list(val_indices)]['full_text'], tokenizer, MAX_LEN)\n",
        "\n",
        "    y_train = np.array(df_train.iloc[list(train_indices)][label_cols], dtype = \"float32\")\n",
        "    y_val = np.array(df_train.iloc[list(val_indices)][label_cols], dtype = \"float32\")\n",
        "    \n",
        "    hist = model.fit([train_encoded_input_ids, train_encoded_attention_masks],\n",
        "                     y_train,\n",
        "                     validation_data = ([val_encoded_input_ids, val_encoded_attention_masks], \n",
        "                                        y_val\n",
        "                                       ),\n",
        "                     batch_size = batch_size,        \n",
        "                     epochs = epochs\n",
        "                    )\n",
        "\n",
        "    df_history = pd.DataFrame(hist.history)\n",
        "    return df_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "202ecOu4GLFG"
      },
      "outputs": [],
      "source": [
        "def build_base_model(model_layer, learning_rate, dense_dim = 6):\n",
        "    \n",
        "    #define inputs\n",
        "    input_ids = tf.keras.Input(shape = (MAX_LEN ,), dtype = 'int64', name = 'input_ids')\n",
        "    attention_masks = tf.keras.Input(shape = (MAX_LEN ,), dtype = 'int64', name = 'attention_masks')\n",
        "    \n",
        "    #insert BERT layer\n",
        "    transformer_layer = model_layer([input_ids, attention_masks])\n",
        "    \n",
        "    #choose only last hidden-state\n",
        "    x = transformer_layer[1]\n",
        "    output = tf.keras.layers.Dense(dense_dim)(x)\n",
        "    #output = tf.keras.layers.Rescaling(scale=4.0, offset=1.0)(x)\n",
        "    model = tf.keras.models.Model(inputs = [input_ids, attention_masks], outputs = output)\n",
        "\n",
        "    model.compile(tf.keras.optimizers.Adam(learning_rate), loss = mse_loss, metrics = mse_metrics)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmCPltuehyyQ"
      },
      "source": [
        "## **Build a model with custom loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lnaCwE2Uhx-4"
      },
      "outputs": [],
      "source": [
        "def build_base_model_with_custom_loss(model_layer, learning_rate, dense_dim = 6):\n",
        "    \n",
        "    #define inputs\n",
        "    input_ids = tf.keras.Input(shape = (MAX_LEN ,), dtype = 'int64', name = 'input_ids')\n",
        "    attention_masks = tf.keras.Input(shape = (MAX_LEN ,), dtype = 'int64', name = 'attention_masks')\n",
        "    \n",
        "    #insert BERT layer\n",
        "    transformer_layer = model_layer([input_ids, attention_masks])\n",
        "    \n",
        "    #choose only last hidden-state\n",
        "    x = transformer_layer[1]\n",
        "    output = tf.keras.layers.Dense(dense_dim)(x)\n",
        "    #output = tf.keras.layers.Rescaling(scale=4.0, offset=1.0)(x)\n",
        "    model = tf.keras.models.Model(inputs = [input_ids, attention_masks], outputs = output)\n",
        "\n",
        "    model.compile(tf.keras.optimizers.Adam(learning_rate), loss = MCRMSE, metrics = MCRMSE)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96pZ-IUrCD30"
      },
      "source": [
        "##**Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mQ1hLAW2CGm4"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, y_test, test_encoded_input_ids, test_encoded_attention_masks):\n",
        "    score = model.evaluate([test_encoded_input_ids, test_encoded_attention_masks], \n",
        "                           y_test\n",
        "                          ) \n",
        "    print('\\nTest Loss : {:.2f}%'.format(score[0]))\n",
        "    print('\\nTest Accuracy :  {:.2f}%'.format(score[1]))\n",
        "    return score[0], score[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJV4COxjCc9j"
      },
      "source": [
        "## **Predict**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PJsH7HXpCiAT"
      },
      "outputs": [],
      "source": [
        "def predict_model(model, df_test, test_encoded_input_ids, test_encoded_attention_masks, label_cols):\n",
        "    predictions = model.predict([test_encoded_input_ids, test_encoded_attention_masks])\n",
        "    df_predictions = pd.DataFrame(predictions, columns=['pred_' + c for c in label_cols])\n",
        "    for col in label_cols:\n",
        "        df_predictions['transformed_pred_' + col] = df_predictions['pred_' + col].apply(lambda x : roundPartial(x, .5))\n",
        "    df_comparison = pd.merge(df_test, df_predictions, left_index = True, right_index = True)\n",
        "    return df_predictions, df_comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CGFbdlnFEMs"
      },
      "source": [
        "## **Plot Model Structure**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tmSoWa7kFHCc"
      },
      "outputs": [],
      "source": [
        "def plot_model_structure(model):\n",
        "    keras.utils.plot_model(model, show_shapes = False, show_dtype = False, show_layer_names = True, dpi = 90)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N73w6RpFsbPx"
      },
      "source": [
        "## **Samples of predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "sP5jgL0fsmpV"
      },
      "outputs": [],
      "source": [
        "def hall_of_fame(df, component, num):\n",
        "  samp = df.query(\"transformed_pred_\"+component+\"==\"+component).sample(num)\n",
        "  samp = samp.reset_index()\n",
        "  for index, row in samp.iterrows():\n",
        "      print(\"predicted: \",row[\"transformed_pred_\"+component])\n",
        "      print(\"original: \",row[component])\n",
        "      pprint.pprint(row[\"full_text\"])\n",
        "      print(\"**********\")\n",
        "\n",
        "def hall_of_shame(df, component, num):\n",
        "  samp = df.query(\"transformed_pred_\"+component+\"!=\"+component).sample(num)\n",
        "  samp = samp.reset_index()\n",
        "  for index, row in samp.iterrows():\n",
        "      print(\"predicted: \",row[\"transformed_pred_\"+component])\n",
        "      print(\"original: \",row[component])\n",
        "      pprint.pprint(row[\"full_text\"])\n",
        "      print(\"**********\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP0n_Dd8j26W"
      },
      "source": [
        "# **Read input files**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zLDHxYTxjxVl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14e706df-b01a-481f-c815-3a282e5431d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "# data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "%cd \"gdrive/MyDrive/Colab Notebooks/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Le5HU_86j4-9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "70854f99-9071-485f-81c5-c30d7aa82f74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        text_id                                          full_text  cohesion  \\\n",
              "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
              "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
              "2  00299B378633  Dear, Principal  If u change the school policy...       3.0   \n",
              "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
              "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
              "\n",
              "   syntax  vocabulary  phraseology  grammar  conventions  score_sum  \n",
              "0     3.5         3.0          3.0      4.0          3.0       20.0  \n",
              "1     2.5         3.0          2.0      2.0          2.5       14.5  \n",
              "2     3.5         3.0          3.0      3.0          2.5       18.0  \n",
              "3     4.5         4.5          4.5      4.0          5.0       27.0  \n",
              "4     3.0         3.0          3.0      2.5          2.5       16.5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e188f6a-cb62-488d-9a27-4a8d9ad1693b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>full_text</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "      <th>score_sum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0016926B079C</td>\n",
              "      <td>I think that students would benefit from learn...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0022683E9EA5</td>\n",
              "      <td>When a problem is a change you have to let it ...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>14.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00299B378633</td>\n",
              "      <td>Dear, Principal  If u change the school policy...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>003885A45F42</td>\n",
              "      <td>The best time in life is when you become yours...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0049B1DF5CCC</td>\n",
              "      <td>Small act of kindness can impact in other peop...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>16.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e188f6a-cb62-488d-9a27-4a8d9ad1693b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e188f6a-cb62-488d-9a27-4a8d9ad1693b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e188f6a-cb62-488d-9a27-4a8d9ad1693b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "input_train_df = pd.read_csv('train.csv')\n",
        "input_test_df = pd.read_csv('test.csv')\n",
        "# Cleaning up full_text : Removing tabl and carriage return characters\n",
        "input_train_df['full_text'] = input_train_df[\"full_text\"].replace(re.compile(r'[\\n\\r\\t]'), ' ', regex = True)\n",
        "input_test_df['full_text'] = input_test_df[\"full_text\"].replace(re.compile(r'[\\n\\r\\t]'), ' ', regex = True)\n",
        "\n",
        "label_cols = input_train_df.columns[2:]\n",
        "input_train_df['score_sum'] = np.sum(input_train_df[label_cols], axis = 1)\n",
        "pred_col_list = ['transformed_pred_' + col for col in label_cols]\n",
        "\n",
        "orig_train_df = copy.deepcopy(input_train_df)\n",
        "orig_train_df.to_csv(\"orig_train_df.csv\", index=False) \n",
        "orig_train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B51vr1w3upZy"
      },
      "source": [
        "# **Model building**\n",
        "\n",
        "As we do not have labels for our test data, we are repurposing our training data by splitting it into 80:20 ratio of training to split. We will only run this split once.\n",
        "\n",
        "The train part is then going thru k fold cross validation and get tested on validation set and final test is done on the test set. Final test accuracy will be the average MCRMSE score across k-folds.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Q9c7XpOGZi46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8258ea9-3a4d-45f2-fe36-e2de505e7248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train data : 3128\n",
            "Length of test data : 783\n"
          ]
        }
      ],
      "source": [
        "# shuffling them back again\n",
        "shuffle = np.random.permutation(np.arange(orig_train_df.shape[0]))\n",
        "orig_train_df = orig_train_df.iloc[shuffle]\n",
        "\n",
        "# Splitting the data in 80:20 split\n",
        "split = (0.8, 0.2)\n",
        "splits = np.multiply(len(orig_train_df), split).astype(int)\n",
        "df_train, df_test = orig_train_df[ : splits[0]], orig_train_df[splits[0] : ]\n",
        "df_train.to_csv(\"df_train_split.csv\", index=False)\n",
        "df_test.to_csv(\"df_test_split.csv\", index=False)\n",
        "\n",
        "print(f\"Length of train data : {len(df_train)}\")\n",
        "print(f\"Length of test data : {len(df_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3dExc7WuXWn"
      },
      "source": [
        "BERT-base-cased with all its layers frozen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed parameters\n",
        "dense_dim = 6\n",
        "number_of_splits = 2\n",
        "random_state = 2023\n",
        "mse_loss = MCRMSE\n",
        "mse_metrics = MCRMSE\n",
        "model_name_list = ['Bert', 'Bertweet'] # Roberta\n",
        "\n",
        "df_train = pd.read_csv('df_train_split.csv')\n",
        "df_test = pd.read_csv('df_test_split.csv')\n",
        "print(f\"Length of train data : {len(df_train)}\")\n",
        "print(f\"Length of test data : {len(df_test)}\")\n",
        "y_test = np.array(df_test[label_cols], dtype = \"float32\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ8SJdvbBZy_",
        "outputId": "107e30f3-4b97-49ec-f8b1-ce58f1583e25"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train data : 3128\n",
            "Length of test data : 783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable parameter dictionary\n",
        "param_list = [   # Completely frozen base layer\n",
        "                 {'epochs'                  : 10,\n",
        "                  'batch_size'              : 8,\n",
        "                  'learning_rate'           : 1e-5,\n",
        "                  'validation_split'        : .2,\n",
        "                  'dropout'                 : .1,\n",
        "                  'number_of_hidden_layers' : 2,\n",
        "                  'hidden_layer_node_count' : 64,\n",
        "                  'retrain_layer_count'     : 0\n",
        "                 }\n",
        "             ]"
      ],
      "metadata": {
        "id": "qx_nk6VzP-9O"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, param_entry in enumerate(param_list):\n",
        "    MAX_LEN = 512\n",
        "    epoch_val = param_entry['epochs']\n",
        "    batch_size_val = param_entry['batch_size']\n",
        "    learning_rate_val = param_entry['learning_rate']\n",
        "    validation_split_val = param_entry['validation_split']\n",
        "    dropout_val = param_entry['dropout']\n",
        "    number_of_hidden_layers_val = param_entry['number_of_hidden_layers']\n",
        "    hidden_layer_node_count_val = param_entry['hidden_layer_node_count']\n",
        "    retrain_layer_count_val = param_entry['retrain_layer_count']\n",
        "\n",
        "    print(\"************************\")\n",
        "    print(f\"Iteration : {idx + 1}\")\n",
        "    print(\"Parameters...\")\n",
        "    print(f\"Epochs : {epoch_val}\")\n",
        "    print(f\"Batch size : {batch_size_val}\")\n",
        "    print(f\"Learning rate : {learning_rate_val}\")\n",
        "    print(f\"Validation split : {validation_split_val}\")\n",
        "    print(f\"Dropout : {dropout_val}\")\n",
        "    print(f\"Number of hidden layers : {number_of_hidden_layers_val}\")\n",
        "    print(f\"Hidden layer node count : {hidden_layer_node_count_val}\")\n",
        "    print(f\"Retrain layer count : {retrain_layer_count_val}\")\n",
        "    print(\"************************\")\n",
        "    set_config_param(20230214)\n",
        "\n",
        "    model_tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_CHKPT)\n",
        "    model = TFRobertaModel.from_pretrained(BERT_MODEL_CHKPT)\n",
        "\n",
        "    train_input_ids, train_attention_masks = text_encode(df_train['full_text'], model_tokenizer, MAX_LEN)\n",
        "    test_input_ids, test_attention_masks = text_encode(df_test['full_text'], model_tokenizer, MAX_LEN)\n",
        "\n",
        "    y_train = np.array(df_train[label_cols], dtype = \"float32\")\n",
        "\n",
        "    bert = build_regression_model(loss= \"MCRMSE\", \n",
        "                                      model_name = \"Bert\",\n",
        "                                      dense_dim = 6, \n",
        "                                      MAX_LEN = 512,\n",
        "                                      learning_rate = learning_rate_val,\n",
        "                                      dropout=dropout_val,\n",
        "                                      number_of_hidden_layers = number_of_hidden_layers_val,\n",
        "                                      hidden_layer_node_count = hidden_layer_node_count_val,\n",
        "                                      retrain_layer_count = retrain_layer_count_val)\n",
        "    bert.summary()\n",
        "\n",
        "    history_v1 = bert.fit((train_input_ids, train_attention_masks),\n",
        "                  y_train,\n",
        "                  batch_size = batch_size_val,     \n",
        "                  epochs = epoch_val,\n",
        "                  validation_split = validation_split_val\n",
        "                  )\n",
        "\n",
        "    history_v1_df = pd.DataFrame(history_v1.history)\n",
        "\n",
        "    score_v1 = bert.evaluate([test_input_ids, test_attention_masks], \n",
        "                    y_test\n",
        "                  ) \n",
        "\n",
        "    predictions_v1 = bert.predict([test_input_ids, test_attention_masks])\n",
        "    df_pred_v1 = pd.DataFrame(predictions_v1, columns=['pred_' + c for c in label_cols])\n",
        "\n",
        "    for col in label_cols:\n",
        "      df_pred_v1['transformed_pred_' + col] = df_pred_v1['pred_' + col].apply(lambda x : roundPartial(x, .5))\n",
        "    \n",
        "    df_compare_v1= pd.merge(df_test, df_pred_v1, left_index = True, right_index = True)\n",
        "    df_compare_v1.to_csv(\"predict_bert_0.csv\", index=False)\n",
        "    all = []\n",
        "    for col in label_cols:\n",
        "      all.append(((df_compare_v1[col]-df_compare_v1[\"transformed_pred_\"+col]).pow(2).mean())**(0.5))\n",
        "    RMSE_scaled = statistics.fmean(all)\n",
        "    print(f\"RMSE_scaled: {RMSE_scaled}\")\n",
        "    \n",
        "    for label in label_cols:\n",
        "      print(label)\n",
        "      hall_of_fame(df_compare_v1,label,1)\n",
        "      print(\"************************\")\n",
        "      hall_of_shame(df_compare_v1,label,1)\n",
        "      print(\"************************\")\n",
        "    for component in label_cols:\n",
        "      print(component)\n",
        "      print(\"% Predicting too high: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\">\"+component))/len(df_compare_v1)))\n",
        "      print(\"% Predicted correctly: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"==\"+component))/len(df_compare_v1)))\n",
        "      print(\"% Predicting too low: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"<\"+component))/len(df_compare_v1)))\n",
        "      print(\"****\")\n",
        "    # Predicting too high or low for every score? \n",
        "    # for component in label_cols:\n",
        "    #   print(component)\n",
        "\n",
        "    #   for score in [1.0,1.5,2.0,2.5,3.0,3.5,4.0,4.5,5.0]:\n",
        "    #     if len(df_compare_v1[df_compare_v1[component]==score])==0:\n",
        "    #       print(component+\"==\"+str(score)+\" has 0 rows\")\n",
        "    #     else:\n",
        "    #       print(f'length: {len(df_compare_v1[df_compare_v1[component]==score])}')\n",
        "    #       print(\"% Predicting the above (\"+str(score)+\"): \" +\n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) &\n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]>score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #       print(\"% Predicting the same (\"+str(score)+\"): \" +\n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) & \n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]==score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #       print(\"% Predicting the below (\"+str(score)+\"): \" + \n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) & \n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]<score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #     print(\"****\")\n",
        "\n",
        "    for component in label_cols:\n",
        "      print(component)\n",
        "      print(\"% Predicting within .5: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"<=(\"+component+\"+.5) and transformed_pred_\"+component+\">=(\"+component+\"-.5)\"))/len(df_compare_v1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5721fcb7b61a4109a888cb6d1a006cb0",
            "0eb79ee7905849ccbcab24ea82257044",
            "b766cfddc90f44c8991948255ae03b62",
            "6ad057cf50a64c80a49ec5109b79ddd4",
            "ea2e84c3838d4bc1a9d3bb4e11465036",
            "933a4544352d413089c78273528dc9ae",
            "4ab014b6cce94e91b5bf4ca481192d14",
            "89b4094ee4574d5cbb6d0114b27b41fa",
            "0a990c1f7a6b4daea97a98e6af342096",
            "e68dff57d7814da794312cd738bebafc",
            "6bd85215efa14ca4a7ff82848b7649c7",
            "b234a9bee696475fb198af9ce9aad81a",
            "248268893bcb44198e12474e312fff3e",
            "22e3c1f959f94f11b7d9346de87427ee",
            "d2946235146446c0974bf7bbaeb65936",
            "8569e6e97e3d4785b59ae6683967b497",
            "5cc38adea8934817bb992cec745202c5",
            "f14a95df6b324cd387a06cf8f91a7301",
            "c04f3d60d6954e5da104e305556768f3",
            "35175699de0f4e13ac29ecd8c0f3ba14",
            "29656b6dba6e404aa87be3f1a89ab6d3",
            "f4baefb455974a918b76729bbe774a93",
            "2adeba9ef3844ad18d620b8c1df06c6b",
            "00b07c7e16154f0ab4a868b654d3581d",
            "63435d2f6d8843229948d2c73566fb15",
            "ee1de2f6f57e4dcc99fda855eb5180b8",
            "44a2c6f5305b4e46bb70dc9338ef7428",
            "8a3d3b03245a4e02b45ed37e660ef9c1",
            "2f8573abf79d49df96709dd7b6748f4c",
            "6f08dee0e50846ed958f92f1cea388dc",
            "d63585b9fee34ed8bbbf7e079e039798",
            "0c2fc778b3da45ea8ffab518eda31b6c",
            "d05b8334e8044260ae5c2cafe17dc700",
            "37f2721760de40e6804a3a72878cd09f",
            "68d3d09d573d47a091f52d030532de2b",
            "62f37697713f451eae531dc4bfd98219",
            "15a03ad7ed624c23be1a097fa3513f80",
            "63c3e3042ef5486691365ae0c5a4ccd2",
            "1429dea730b94acd9d20ab63c34c114b",
            "453814a9db27481593bf1d5cd553db57",
            "1681285568c0434e85b0576c69e592d6",
            "c530950116214723ace7c4a0911c0c1c",
            "aa9e78faa56e4ed59f9c262b4c179af1",
            "9167f58120e042948bb1bd5d790ae4ab",
            "f0ad88081d9342eba22477fb400b876f",
            "112565d9177a46038883241a5c3a8272",
            "cf61c809fe954c93b8254f9dea994b31",
            "c40be4c061424eff8a75c70e9d941647",
            "a94480b461c240e39bfe0d34e3c76b5c",
            "56a9d92be0744129b17dc7eb483de41e",
            "3e2babd4e0cf40578f2a525bfb448fad",
            "50319172a7154db68c96bb7cb48c41ca",
            "c0365664de8d4846916aa8f5602c400a",
            "442345d26c494f2893ea82dbdbfa5686",
            "22508a195d6f4fae821ef06e5cd90604"
          ]
        },
        "id": "_oBQigtnjgWT",
        "outputId": "37fb4d2e-258d-468b-b91e-4c3c7fc65777"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************************\n",
            "Iteration : 1\n",
            "Parameters...\n",
            "Epochs : 10\n",
            "Batch size : 8\n",
            "Learning rate : 1e-05\n",
            "Validation split : 0.2\n",
            "Dropout : 0.1\n",
            "Number of hidden layers : 2\n",
            "Hidden layer node count : 64\n",
            "Retrain layer count : 0\n",
            "************************\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5721fcb7b61a4109a888cb6d1a006cb0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b234a9bee696475fb198af9ce9aad81a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2adeba9ef3844ad18d620b8c1df06c6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37f2721760de40e6804a3a72878cd09f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/527M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0ad88081d9342eba22477fb400b876f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters : 0\n",
            "Number of non-trainable parameters : 108310272\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " hidden_layer_1 (Dense)         (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_layer_1 (Dropout)      (None, 64)           0           ['hidden_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            " hidden_layer_2 (Dense)         (None, 64)           4160        ['dropout_layer_1[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_layer_2 (Dropout)      (None, 64)           0           ['hidden_layer_2[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 6)            390         ['dropout_layer_2[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,364,038\n",
            "Trainable params: 53,766\n",
            "Non-trainable params: 108,310,272\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " hidden_layer_1 (Dense)         (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_layer_1 (Dropout)      (None, 64)           0           ['hidden_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            " hidden_layer_2 (Dense)         (None, 64)           4160        ['dropout_layer_1[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_layer_2 (Dropout)      (None, 64)           0           ['hidden_layer_2[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 6)            390         ['dropout_layer_2[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,364,038\n",
            "Trainable params: 53,766\n",
            "Non-trainable params: 108,310,272\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "313/313 [==============================] - 173s 503ms/step - loss: 3.2290 - MCRMSE: 3.2288 - val_loss: 2.8442 - val_MCRMSE: 2.8500\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 159s 507ms/step - loss: 2.5703 - MCRMSE: 2.5700 - val_loss: 2.0669 - val_MCRMSE: 2.0725\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 145s 464ms/step - loss: 1.7782 - MCRMSE: 1.7780 - val_loss: 1.1739 - val_MCRMSE: 1.1791\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 159s 507ms/step - loss: 1.1097 - MCRMSE: 1.1097 - val_loss: 0.6602 - val_MCRMSE: 0.6638\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 160s 510ms/step - loss: 0.9236 - MCRMSE: 0.9239 - val_loss: 0.5917 - val_MCRMSE: 0.5942\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 160s 510ms/step - loss: 0.8899 - MCRMSE: 0.8899 - val_loss: 0.5819 - val_MCRMSE: 0.5842\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 159s 510ms/step - loss: 0.8767 - MCRMSE: 0.8764 - val_loss: 0.5760 - val_MCRMSE: 0.5783\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 159s 509ms/step - loss: 0.8512 - MCRMSE: 0.8512 - val_loss: 0.5697 - val_MCRMSE: 0.5719\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 159s 509ms/step - loss: 0.8452 - MCRMSE: 0.8451 - val_loss: 0.5646 - val_MCRMSE: 0.5670\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 159s 510ms/step - loss: 0.8315 - MCRMSE: 0.8314 - val_loss: 0.5598 - val_MCRMSE: 0.5620\n",
            "25/25 [==============================] - 34s 1s/step - loss: 0.5626 - MCRMSE: 0.5633\n",
            "25/25 [==============================] - 37s 1s/step\n",
            "RMSE_scaled: 0.6349501059409383\n",
            "cohesion\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('Education change our life and teach you to think in a different way. Some '\n",
            " 'people rush trying to graduate from school or reach their gools ahead of '\n",
            " 'time which it is not good. Because they end up taking the wrong decision and '\n",
            " 'I do understand that as student you just think to finish school and graduate '\n",
            " 'to became profesional. The idea of finish high school in tree years instead '\n",
            " 'four,  it will force students to chose the wrong career because they will '\n",
            " 'not have enough time to get ready for college and they are still immature at '\n",
            " 'that age.  First of all, students who are trying to finish their high school '\n",
            " \"in tree years instead four they don't have enough time to prepare for \"\n",
            " 'college. They will not have build their knowledge to be succefull in '\n",
            " 'callege. High School is means to prepare and help students to get ready for '\n",
            " 'college, but spending less time in the school they would not have enough '\n",
            " 'time to learn or cover all the subject in clase. In addition, they will not '\n",
            " 'develop their skills and be succefull in college or their future. Some '\n",
            " 'people might think the is a good a idea to finish high school in tree years '\n",
            " 'because they can enter in college early and start to work but they might not '\n",
            " 'be ready for college.  Forthermore, students at that ege still immature that '\n",
            " \"they don't really know what they want to do with their life or if they want \"\n",
            " 'to go college. In addition, some kids might be even think drop off school '\n",
            " \"and don't comtinue in college because school require time, persevere, \"\n",
            " \"dedication and concentration which a lot of the students don't have when \"\n",
            " 'they are immature.  Many tennegers of theis kids do not apy much atention in '\n",
            " 'schoo because they are district in others things like hang out with their '\n",
            " 'frends and playing sport that they do not even think much in school. For '\n",
            " 'this reason, they need to spent four years in school instead tree so they '\n",
            " 'can learn to be responsible. Some parents and studenst migh think that it '\n",
            " 'not necesary spent four years at schoo when they can finish in tree but if '\n",
            " 'they are immature and inresponsible they are not going to be succefull in '\n",
            " 'their future.  Finally, students who want to finish their school in tree '\n",
            " \"years instead four, they don't know what career to chose or if they want to \"\n",
            " 'continue in college. Forthermore, they are still immanute to decide what to '\n",
            " 'do with their education that they end up chosing a wrong career. For theis '\n",
            " 'reasons are necesary to finish school with four years instead tree, so they '\n",
            " 'know what to do after school and they can be succefull in their future.')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  2.5\n",
            "('When are parents gave us advice we are able to learn do the right thing. For '\n",
            " 'example if you go work with your dad he gave you advice. Also they gave us '\n",
            " 'advice we learn how to do the right thing. Learning the right thing helps us '\n",
            " 'to make our life better. Learn something from more then one person because '\n",
            " 'they help you dont get in trouble and be a good student or son if you learn '\n",
            " 'from someone us.  Learning advice from school is good because everyone '\n",
            " 'learns and get good grades. Do something good for school is good because '\n",
            " 'when they gave you advice to do the right thing is class. For example the '\n",
            " 'gym teacher gave you advice to do the right not the bad advice because if '\n",
            " 'you do the bad thing you will get a bad grade and get in trouble. When we '\n",
            " 'get in trouble is bad and you always have to listen when they gave us advice '\n",
            " 'for you do well at your test. When we do well in our test is because the '\n",
            " 'teacher was having us advice and we were paying attecion.  Friends gave us '\n",
            " 'advice out side of school and inside school. When friends gave us advice '\n",
            " 'inside school is because they want a better life for us. When friends gave '\n",
            " 'us advice for our life is because they want us to be happy and be a better '\n",
            " 'person. Also when they gave us advice like when we play sports. When we play '\n",
            " 'sports the coach always have advice do win the game. When coaches gave us '\n",
            " 'advice to play good and win games that teams will be come so good if the '\n",
            " 'players get the advice of the coach.  When people ask for advice is because '\n",
            " 'they want to know what things are better like to buy. If we shop somewhere '\n",
            " 'then you need a advice from someone to know if is good or bad. When they '\n",
            " 'gave a advice of food you have to know if is good or bad for our health. If '\n",
            " 'we dont get a advice like for something maybe will be bad for us to eat or '\n",
            " 'do and may have problems. The person who do not gave a advice of what they '\n",
            " 'doing they will get in trouble if good for our body or not good.  When we '\n",
            " 'are in math class the students gave us advice same with the teacher. '\n",
            " 'Sometimes students gave us advice how to do the work of the problem more '\n",
            " 'than one student gave us advice. When teacher shows advice of our class work '\n",
            " 'how to do it and know when test are coming for be ready. Also the bus driver '\n",
            " 'gave us advice how to act inside the bus. If the bus driver does not gave '\n",
            " 'advice everyone in the bus will act crazy and maybe a accident. Thats why '\n",
            " 'everyone should said a advice for we could be safe and be good.')\n",
            "**********\n",
            "************************\n",
            "syntax\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('I have some reasons why I would disagree with the school board because I '\n",
            " \"don't like the idea of staying more time in school. Either way it is not a \"\n",
            " 'good idea because the school would face alot of work with the time extended '\n",
            " \"plus it's gonna be more work than ever with the school extending. And I have \"\n",
            " 'a lot of reasons why its a bad idea so I guess start the reading the '\n",
            " 'paragraphs right now.  First extending the school day would get a lot of '\n",
            " 'students mad at the school because they want to go home and do whatever they '\n",
            " 'want. The students would have to stay longer in the school and some would be '\n",
            " 'mad and some be happy about it. And students that are bulllies would have a '\n",
            " 'bigger chance on picking on people during the extended time of school. The '\n",
            " 'next day the school would most likely be getting emails from students and '\n",
            " 'parents complaining about the extended school day. While other students and '\n",
            " 'parents wont care and go to school like a normal day and al lot more.  Also '\n",
            " 'the jobs in the school could change like the teachers job and other jobs in '\n",
            " 'the school time would be extended. Some teachers would complain by the '\n",
            " 'extended school day if there gonna do a extended day everyday they are gonna '\n",
            " 'have to be payed more or else the school would die slowly because all '\n",
            " 'teachers,staff and other jobs in the school would quit and go work somewhere '\n",
            " 'else better and get paid more. If one teacher does quit their job because of '\n",
            " 'the extended time he/she would most likely tell other people that the school '\n",
            " 'is terrible then the school would barely get people to work there and in a '\n",
            " 'couple years later probably the school would be abandoned for other people '\n",
            " 'to explore to see the leftovers of the dead school.  Finally the school '\n",
            " 'would change by alot than before it ever has in its couple years of '\n",
            " 'existance. The school would have to face a lot of consequnces like a lot of '\n",
            " 'students posting on the internet about how the school is trash,boring and '\n",
            " 'now they want to go to a different school. And the teachers would complain '\n",
            " 'about if they are going to teach more than ever they want to get bad even '\n",
            " 'more money. And they would have to change the whole school time of the '\n",
            " 'day,the bus time and the students classes time which would took a very long '\n",
            " 'time to do. Either way other jobs in the school would be more difficult than '\n",
            " 'ever for example janitors,staff and teachers.  Even though the school really '\n",
            " \"does want to change original time to a extended time it's not the smartest \"\n",
            " 'idea in the world because theres gonna end up being consequnces to it and '\n",
            " 'they are not going to be fun for anyone. Either way next thing you know the '\n",
            " 'county that owns the school will just die because of the extended day. '\n",
            " 'Because then who knows probably no one then later on wants to go the either '\n",
            " 'school in the county anymore and would probably just moved out to go to a '\n",
            " 'better school. So this is why this idea is a bad idea. ')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  2.5\n",
            "('Would you like to seek multiple opinion from different people? I think is '\n",
            " 'good for you to seek opinion from people . Seeking multiple opinion can '\n",
            " 'benefit you make new friends,  have good relationship with your friends and '\n",
            " 'make someone trust in you to tell their secret to you. Well that is what i '\n",
            " 'think about Seeking multiple opinion.  Seeking multiple opinion can make '\n",
            " 'someone trust in you. When someone trust in you, he or she can tell you '\n",
            " 'their secret about everything they have in secret. If someone trust in you '\n",
            " 'he or she will know that you are a good friend. For example,  if you do '\n",
            " 'something wrong to your friend who trust in you, She or her is going to '\n",
            " 'forgive you when you say sorry because, he or she trust in you. Being nice '\n",
            " 'and respectful for example, not saying bad word to someone to be depressed, '\n",
            " 'saying please when you are asking someone for something can also make '\n",
            " 'someone trust in you.  Seeking multiple opinion can make you have good '\n",
            " 'relationship with someone.  Having a good relationship with someone is a '\n",
            " 'good thing to do in life.  Having a good relationship with someone can make '\n",
            " 'him or her get close to you . Helping your friend for example, helping him '\n",
            " 'or her with his homework or something he or she needs help with , advising '\n",
            " 'him or her to do the right if he or her did something wrong, being nice and '\n",
            " 'respectful to everyone can also make someone have a good relationship with '\n",
            " 'you.  Seeking multiple opinion allow you to make new friends. Sometime when '\n",
            " 'you are making new friends you dont just have to make friends, you have to '\n",
            " 'think about it .  Make a friend who respect everyone, correct you when you '\n",
            " 'do something wrong and someone who is there for you because, when something '\n",
            " 'happen to and you have a bad friend, he or she will not help you but, If you '\n",
            " 'have a good friend, he or she will help you when you are in a bad situation. '\n",
            " 'Good friends are all way there for you when you have a problem with '\n",
            " 'something or someone.  Well that is what I think about seeking multiple '\n",
            " 'opinion. I hope you know some benefit of seeking multiple opinion . Whould '\n",
            " 'you like to seek multiple opinion from different people ? I also hope you '\n",
            " 'learn smoething from what I think about seeking multiple '\n",
            " 'opinion.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ')\n",
            "**********\n",
            "************************\n",
            "vocabulary\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('when someone is already mastered something beyong , they will never grow, '\n",
            " 'base on what they experience alot of people they can not do another thing '\n",
            " 'becuase when they star they just mastered, alot of people try to do '\n",
            " 'something new or trying to make another future but is it imposible becuase '\n",
            " 'they alredy master up. And they will never grow becuase people star duing '\n",
            " 'the thing wrong they did not see the thing write  One reason thay people can '\n",
            " 'star a new life or do another thing it becuase when someone is alredy '\n",
            " 'mastered or they alredy pass for the momet and now they canit erased and '\n",
            " 'they never grow up, they will can go back and fix what they alrady did that '\n",
            " 'why is it importan thing before when someno it about ro do something and '\n",
            " 'also what someone alreadi did it hard to fix it again for example all what a '\n",
            " 'people did before in they pass they canot go fix it, people did thing and '\n",
            " 'they dont think about it that why they will never gow up when someno '\n",
            " 'thyaying to do something but they already mastered they will nwver can do '\n",
            " 'other thing and they will not ba a person that why can do something alse the '\n",
            " 'autor refere that, what you do beyong now yu anot do it again some people '\n",
            " 'may say people has mastered when they already pass but a person can change '\n",
            " 'that people can satar what they alredy mastered and the can fix it agin '\n",
            " 'people do bad thing and do something bad byt they stuill can starded and '\n",
            " 'they can kip growing and kip going becuase ther is ntohing can stop a person '\n",
            " 'whataver they already did they still can fix it there fore it no mater what '\n",
            " 'they did it just or what they pas when they satr the thing but alway can fix '\n",
            " 'it and kipp going kip growing on myon people experience they do think and '\n",
            " 'ther mastered up but alwas they fix and they satrded again and alwast ont '\n",
            " 'satar againg.  ')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  4.0\n",
            "('Energy should be conserve more because alot of people do not use alot of '\n",
            " 'these particular items half of the time. It is better to save energy rather '\n",
            " 'than waste. Like for eample, we use light everyday to see things around us '\n",
            " 'so that we do not trip or bump into things. If not we wouldnt be able to see '\n",
            " 'things near us. At times we take advantage way too much. Were wasting alot '\n",
            " 'of light source that we hardly ever use at times. Therefor, were wasting '\n",
            " 'alot of energy that we should not be wasting. Alot of people tend to go out '\n",
            " 'to places to run some errands and leave there lights on for no reason or '\n",
            " 'just keep the light on for no particular reason. The best way to save energy '\n",
            " 'would be to turn off the light before you go out and not just leave it on '\n",
            " 'because your just making your bills go up. When you do not even use it half '\n",
            " 'of the time. It would help alot and keep you from wasting alot of money.  '\n",
            " 'Second reason, would be us not recyling things that we drink or eat. We tend '\n",
            " 'to just throw it in the trash instead of the recyling bin. Even in schools '\n",
            " 'they have recyling bins but us people do not pay attention to it because it '\n",
            " 'is nowhere to be seen. It would be better if the recycling bin was to be '\n",
            " 'seen. I feel like people would use it and recycle more. Also will save '\n",
            " 'resources that can be cleaned and used again. Rather than just using more '\n",
            " 'products to make the particular object. Schools and other places should make '\n",
            " 'an improvement and stop using alotof energy and resources and make it easier '\n",
            " 'for the resources that are being used. Us people should recycle more and '\n",
            " 'save light source and actually help the world be a better place and keep it '\n",
            " 'clean and simple. If we were able to do that it would make everything else '\n",
            " 'easier.  Overall, schools should not be extending it for two more hours. '\n",
            " 'Reasons why is because teachers tend to use alot of paper to give students '\n",
            " 'to work on. Most of the times teachers would not use front and back of the '\n",
            " 'paper. They would always do work on seprate pices of papers and give them to '\n",
            " 'the students. To make things easier for them would be to use front and back '\n",
            " 'because there not using alot of paper. So that it can be graded on and be '\n",
            " 'thrown out by the students. Students never like to keep paper with them when '\n",
            " 'teachers grade them after. So alot of paper is going to waste for no reason. '\n",
            " 'Teachers should consider of teaching students with technology and doing work '\n",
            " 'on there rather then using alot of paper. Technology would help because '\n",
            " 'trees would not be going to waste and harm the things around there '\n",
            " 'surrounding just to make paper out of it. Alot of trees would be save and '\n",
            " 'have alot of resources still. People should just think about the goods thing '\n",
            " 'and the bad things about it. Like is it worth wasting all these resources '\n",
            " 'rather than using technology.  There is advantages and disadvantages of '\n",
            " 'extending school for two hours. The advantage would be students being able '\n",
            " 'to learn more and have more time spent with their peers and teachers. '\n",
            " 'Students would have more time to do work rather than doing it at home and '\n",
            " 'struggling. It is better for them not to waste time and get the help they '\n",
            " 'need. But, at the same time the teacher is giving them work which is bad in '\n",
            " 'the way but good also . The work that is being given to them is not bad but '\n",
            " 'the resources that makes is because of how it is made. Eventually, schools '\n",
            " 'should just use technology and do all the work there. Students would be able '\n",
            " 'to access it easier and teachers would not have to worry about the students '\n",
            " 'losing work or having problems. Students would also be more entertain '\n",
            " 'because all they like to do or be on is technology and it would help the '\n",
            " 'teachers alot.  Overall this point, teachers or not just them should '\n",
            " 'consider of managing the time they use on things that use alot of energy. It '\n",
            " 'would make the world a better place and more healthier. Trees would not have '\n",
            " 'to be cut down alot and affecting their surroundings. Basically would not '\n",
            " 'cause pollution in the air and hurt things around it like for example '\n",
            " 'animals . It is important to save energy an keep the world safe. Schools '\n",
            " 'should just do everthing on computers and make things easier. Rather than '\n",
            " 'wasting alot of materials for no good '\n",
            " 'reasons.                                   ')\n",
            "**********\n",
            "************************\n",
            "phraseology\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('I agree with Ralph waldo Emerson because he say that if you try to do '\n",
            " \"something you will never grow and that mean you can't do anything with \"\n",
            " 'Emerson. but that is not possible to do that if he say that the people will '\n",
            " 'be scared with that thing but if I agree with Emerson he can do something '\n",
            " 'about opinion and the people they can do the other opinion and to '\n",
            " 'understand, and how we can agree with other, we can agree something is very '\n",
            " 'important Emerson he can need to stop how to agree or to take out if we do '\n",
            " 'agree we can do each ether. and we can grow we can stay down, he can keep it '\n",
            " 'up not down if will be down how that will be not grow that need to grow is '\n",
            " 'not to stay down.  We can agree about the opinion and to come to understand '\n",
            " 'the agree with the original, the people agree but is not all of them some '\n",
            " 'they agree, because that give the opinion to understand ideas but spicy food '\n",
            " 'that does not agree with person or to the people with other does. The person '\n",
            " \"can agree and he can't do any opinion but he can understand the opinion that \"\n",
            " 'he agree. he suppose to agree because there are people they agree and they '\n",
            " 'grow the people have experiences.  Emerson he suppose to agree and people '\n",
            " 'will come to agree with him if is not that the people will not be able to '\n",
            " 'agree with him and that is good to grow, agree is opinion of the people and '\n",
            " 'correspondence the people they have experience to agree and he need to be '\n",
            " 'experiences to other people. Emerson he has a opinion for something he agree '\n",
            " 'and he can do whatever he know but that is not great if you have some ideas '\n",
            " \"you need to took and we can agree each other with other people if we don't \"\n",
            " 'know it we can tell with other people they know how they can agree the think '\n",
            " 'we have to agree and that will be good for other people they can say that '\n",
            " 'was very good to agree.  then if that will be great to the people we suppose '\n",
            " \"to it and that is good for the people or person If that he don't to agree \"\n",
            " 'the people they can do it many people they do something is important to them '\n",
            " 'if they don;t do anything how they can agree If Emerson does do anything '\n",
            " \"that mean he don't need the people to agree anything with him.  Ex.  I can \"\n",
            " 'agree and people they can be able to do whatever they want to do and if they '\n",
            " 'have anyithing we can help each other.')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.5\n",
            "original:  2.5\n",
            "('Author Ralph Waldo Emerson wrote \"Unless you try to do something beyond What '\n",
            " 'you already mastered, you will never grow.\"  I agree with author Ralph Waldo '\n",
            " 'Emerson because base on each experience of every people that they had '\n",
            " 'mastered, i think that what you already mastered in life it can make you be '\n",
            " 'more stronger base on the experience that you had.  I agree with the quote '\n",
            " 'because unless you try to something you need to have pasion and focused in '\n",
            " 'things that you can grow in life over things that you already mastered. You '\n",
            " 'can grow beyond and over things that you already master and learn new things '\n",
            " 'to keep growing not just staying in the same spot.  Experince new things in '\n",
            " 'life are going to make you feel more stronger and make you think that you '\n",
            " 'can do things that you maybe never thought about that you were going to do '\n",
            " 'beyond what you already mastered.  Unless that you need to reach and make '\n",
            " 'new goals to grow you need to make an efort no matter how hard it can be for '\n",
            " 'you, you need to focus in that goals that you want to grow more and have '\n",
            " 'more experience just for keep practecing.  Base on my experiences, i could '\n",
            " 'do something beyond what i already mastered because i want to learn new '\n",
            " \"things and try to make good things and that's going to make me grow more and \"\n",
            " 'experiences new things that i never thought that i can do. To grow exterior '\n",
            " 'and interion i need to be confident with my self and letting me know thing '\n",
            " 'that i can do better thing that i already mastered and be more suscescfull.  '\n",
            " \"I agree with author Emerson's statement because of what he wrote it make me \"\n",
            " 'feel confident with me and keep trying beyond what i already know and '\n",
            " 'already master you need to push your thought to make your goals come true.  '\n",
            " 'Thank you     ')\n",
            "**********\n",
            "************************\n",
            "grammar\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('Imagine that the school plans to add more time at school. I disagree of the '\n",
            " 'schools adding more time because it would be irritating,boring,stressed. and '\n",
            " 'kids do not want that to happen. The children wants to have a normal school '\n",
            " 'day. And they have to prove that they can do it,they believe in their self.  '\n",
            " 'First,It is boring because they want to have fun. And the reason why it is a '\n",
            " 'lot of fun because they want to have a good time. And thet can think about '\n",
            " 'what they want,What do they want to do when the schools are thjnking about '\n",
            " 'staying more longer at school. For example, Generic_Name went outside to '\n",
            " 'play after school.  Secondly,it is stressing because they would be crazy '\n",
            " 'about it. And the reason why it is stressing because the blood of the brian '\n",
            " 'would get bad. It would be horrible that they have blood pressure,haert '\n",
            " \"attacks,and they want to kill there self. They can't do that,but they can \"\n",
            " 'protect there self. For example,Generic_Name was taking a test but she got '\n",
            " 'nervous,Frustrated,lonly and upset.  Thirdly,it is irritating because kids '\n",
            " \"will get tired and dizzy at school. the reason why it's because their body \"\n",
            " 'do not have enough energy. For example,My best friend  Generic_Name studied '\n",
            " 'for a test,but she got tired. In my opinion it is not ok that a lot of '\n",
            " 'people get injured. And it is going to be difficult but it is worth a try,I '\n",
            " 'want a lot of people to be happy,not injured,not feeling down and feel '\n",
            " 'better about whats going on,or what is doing.  In closing,I disagree that '\n",
            " 'the school plans to add more time at school. And it is a bad idea,It would '\n",
            " 'get irritating,boring and stressed. In my opinion it is better for kids so '\n",
            " 'they can not worried about it. And it would be easier step by step and keep '\n",
            " 'going,Dont stop doing it.  I really think that it would be better if the '\n",
            " 'school would not have bullies,bad teachers back in the day because a lot of '\n",
            " 'teachers back in the they hit children because sometimes kids do not behave '\n",
            " 'and teachers think that the kids deserved it and i think that The kids do '\n",
            " 'not always get the right answer but In my opinion all teachers are different '\n",
            " 'because some teachers are nice,hardworking,sweet,mean,not inappropiate '\n",
            " 'aswell. And The teachers that i had or have from kindergarden to first '\n",
            " 'grade,second grade,third grade,fourth grade,fifith grade,sixth grade,Seventh '\n",
            " \"grade and 8th grade they're nice,helpful,caring too and thay dont hit us. \"\n",
            " 'They protect us,And i want for other kids have the same exciperence that i '\n",
            " 'have. And i want other kids or other people or everybody to be happy and '\n",
            " 'protected too. ')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  2.5\n",
            "('I think the people have to be guidance for the expert, Because the expert '\n",
            " 'know what is corrects, and what is not correct, and if we make aur decision '\n",
            " 'we will have many problem, and we gonna fail in the life, but therefore '\n",
            " 'alway we can triumph in the study, I just say our life can be better if we '\n",
            " 'have an expert who tall to the people, what is good and what is not good in '\n",
            " 'your life, If we working in group is more easy to understand something, and '\n",
            " 'when you work for yourself and you will understand less.  Example:Our life '\n",
            " 'will be better if the experts guidance the people, because they know what is '\n",
            " 'the best way you have to take, and they can help you if you are rong in '\n",
            " 'something.  Is very important work in group with experts, because they have '\n",
            " 'many experience in many thing, and they can help you to understand more than '\n",
            " 'you believe, and this is my idea why is important that the people have to be '\n",
            " 'guidance for the expert people and who have more experience, and i believe '\n",
            " 'that work in group is better than alone.')\n",
            "**********\n",
            "************************\n",
            "conventions\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('The one thing I hope I accomplish is to get a high paying job. I would want '\n",
            " \"a high paying job since it could pay off many things that I don't need to \"\n",
            " \"pay later. My reasons is to travel to many places I've never been to, buy \"\n",
            " \"many things as I want without spending my family money's, and I would try \"\n",
            " 'many different foods that could be expensive.  One reason why my '\n",
            " 'accomplishment is getting a high paying job is to travel around the world or '\n",
            " 'place that I never been to. Traveling around the world could be really '\n",
            " \"expansive since your going to buy many things you would need or don't need. \"\n",
            " 'Sometimes traveling depends on where you are going since some places are '\n",
            " 'cheap or expansive. Having a lot of a good amount while traveling is a good '\n",
            " 'because you could do anything you want with that money while your not at '\n",
            " 'home. I think having a high paying job is good for traveling is not always '\n",
            " \"cheap, you can buy anything you've ever wanted and not worrying much about \"\n",
            " 'using to much money.  The next reason is to buy many things as I want '\n",
            " 'without spending any or some of my parents or family members money. This is '\n",
            " \"important because it wouldn't matter much if you used you own money but if \"\n",
            " 'you use your family money you might have to pay them back later on. Another '\n",
            " 'reason is going out when you want to and you dont really want to spend your '\n",
            " 'family money because you need a lot since you could be going to many places. '\n",
            " 'When you want to take your family out to a really nice place or a place '\n",
            " 'where you think they would enjoy or relax, you can just surprise them by '\n",
            " 'already getting it done and paid off. Another reason it is a good idea to '\n",
            " 'get a high paying job, to not spend your family money.  The last reason is '\n",
            " 'trying many different foods that could be expansive. From my experiences I '\n",
            " 'know that most places has really expansive food that is really good. I also '\n",
            " 'know that going to a super fancy restaurant is expansive since all the foods '\n",
            " 'could be really good or just a rip off. Sometimes going to really fun places '\n",
            " 'or vacations foods are expansive because it could taste good and many people '\n",
            " \"would might want to try some, also if it was cheap many people would've gone \"\n",
            " 'crazy. Paying for good expansive food is worth it then paying too much for '\n",
            " 'something that taste bad.  In conclusion that a high paying job is good for '\n",
            " \"traveling to places you've never been to, spending lots of money without \"\n",
            " 'using your families money, and eating or buying really expansive foods. '\n",
            " 'Going to places you have never been to is great. Spending our own money lets '\n",
            " 'us buy anything we want. Also buying or trying new foods is really nice when '\n",
            " 'you can buy it. This is why I want my accomplishment to be a high paying '\n",
            " 'job.')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  2.0\n",
            "(\"Technalogy is the line that get the world people's in the cirlce, and create \"\n",
            " 'a group that make cummunication oaver cyber way by saving their time also '\n",
            " 'best way of connection between people it make it really easy to people who '\n",
            " 'are far away from each other by taking seconds to contact them. Using new '\n",
            " \"technalogy is fun like video game's that is the famous creation of new \"\n",
            " \"technalogy.  Technalogy doesn't create limition of connection between \"\n",
            " 'people, because it help people to create new connection over best '\n",
            " 'cumunicting sites, fastest way of connection between humans that are far '\n",
            " 'located from each other, also less cost of contact between people.  '\n",
            " 'Technalogy was the solution for the less connection between human that been '\n",
            " 'misconstrue by minorityof people those are who never used the way should be '\n",
            " 'used. secientestes people who find out after alots of research that '\n",
            " 'technalogy is the best way to persuad people connect with each other. '\n",
            " 'Technalogy created for one purpose to make easy life for humans, and create '\n",
            " 'a great cumuniction way through the world that connected with each other.  '\n",
            " \"Technalogy planned, designed to make the fastest way between human's by not \"\n",
            " \"taking longer time it make so easy people doesn't needed any more to go to \"\n",
            " 'our relatives place to cumnicate with them know it totally changed by '\n",
            " 'cellphone the new technalogy. One of the most amizing creation of technalogy '\n",
            " 'is news that people around the world get know about every knew stuff.  '\n",
            " 'Technalogy beside saving time it also cost less to connect with each other '\n",
            " \"it make it so easy to people who are willing to contact other's over fastest \"\n",
            " \"connection, and less cost .  Using new technalogy is fun like video game's \"\n",
            " 'that is the famous creation of new technalogy. It designed for different '\n",
            " 'ages by different version, and level. Also now days technalogy is the most '\n",
            " 'biggest part of humans life our life almost run with technalogy in every '\n",
            " \"part. but still some people think's that it's not helpful to have the \"\n",
            " 'advance system of technalogy.  Minority of people misconstrue about '\n",
            " 'technalogy because they never used the advance technalogy or they might be '\n",
            " 'used it but they never realize because at some points there are some how '\n",
            " 'people should be aware of how to should use it, and it all need knowledge '\n",
            " \"that some people doesn't have that so it's really hard for them to use it.  \"\n",
            " \"Technalogy might be useful to comunicate with people but sometimes it's hard \"\n",
            " \"for those group of people that doesn't have the knowledge how to use it, get \"\n",
            " 'benfite from it. So everything comes back to the circle that people '\n",
            " 'connected with it but this circle also need to have knowledge of writing, '\n",
            " 'reading, lessning that all include a great system of eduction. So eduction '\n",
            " 'help to learn about know technalogy, and technalogy helps to make life '\n",
            " 'easier also connected with other easily.        ')\n",
            "**********\n",
            "************************\n",
            "cohesion\n",
            "% Predicting too high: 0.27586206896551724\n",
            "% Predicted correctly: 0.29757343550446996\n",
            "% Predicting too low: 0.42656449553001274\n",
            "****\n",
            "syntax\n",
            "% Predicting too high: 0.2950191570881226\n",
            "% Predicted correctly: 0.34099616858237547\n",
            "% Predicting too low: 0.36398467432950193\n",
            "****\n",
            "vocabulary\n",
            "% Predicting too high: 0.2848020434227331\n",
            "% Predicted correctly: 0.37547892720306514\n",
            "% Predicting too low: 0.3397190293742018\n",
            "****\n",
            "phraseology\n",
            "% Predicting too high: 0.367816091954023\n",
            "% Predicted correctly: 0.3128991060025543\n",
            "% Predicting too low: 0.31928480204342274\n",
            "****\n",
            "grammar\n",
            "% Predicting too high: 0.30395913154533843\n",
            "% Predicted correctly: 0.2771392081736909\n",
            "% Predicting too low: 0.41890166028097064\n",
            "****\n",
            "conventions\n",
            "% Predicting too high: 0.3090676883780332\n",
            "% Predicted correctly: 0.3167305236270754\n",
            "% Predicting too low: 0.37420178799489145\n",
            "****\n",
            "cohesion\n",
            "% Predicting within .5: 0.7586206896551724\n",
            "syntax\n",
            "% Predicting within .5: 0.7675606641123882\n",
            "vocabulary\n",
            "% Predicting within .5: 0.8212005108556832\n",
            "phraseology\n",
            "% Predicting within .5: 0.7841634738186463\n",
            "grammar\n",
            "% Predicting within .5: 0.7420178799489144\n",
            "conventions\n",
            "% Predicting within .5: 0.7279693486590039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_compare_v1 = pd.read_csv(\"predict_bert_0.csv\")\n",
        "for component in label_cols:\n",
        "  print(pd.crosstab(df_compare_v1[component], df_compare_v1[\"transformed_pred_\"+component], margins=True))\n",
        "  print()"
      ],
      "metadata": {
        "id": "eFAPhe1LKsYl",
        "outputId": "37bb2edf-12d7-481b-f1cd-f367c1bce5fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformed_pred_cohesion  2.5  3.0  3.5  All\n",
            "cohesion                                     \n",
            "1.0                          2    0    0    2\n",
            "1.5                          5    1    0    6\n",
            "2.0                         13   51    0   64\n",
            "2.5                         24  138    0  162\n",
            "3.0                         13  200    6  219\n",
            "3.5                          7  182    9  198\n",
            "4.0                          5   79    9   93\n",
            "4.5                          0   28    7   35\n",
            "5.0                          0    4    0    4\n",
            "All                         69  683   31  783\n",
            "\n",
            "transformed_pred_syntax  2.5  3.0  3.5  All\n",
            "syntax                                     \n",
            "1.0                        4    0    0    4\n",
            "1.5                        3    2    0    5\n",
            "2.0                       27   69    0   96\n",
            "2.5                       23  126    0  149\n",
            "3.0                       13  244    0  257\n",
            "3.5                        5  165    0  170\n",
            "4.0                        1   77    3   81\n",
            "4.5                        0   19    0   19\n",
            "5.0                        0    2    0    2\n",
            "All                       76  704    3  783\n",
            "\n",
            "transformed_pred_vocabulary  3.0  3.5  All\n",
            "vocabulary                                \n",
            "1.5                            4    0    4\n",
            "2.0                           24    2   26\n",
            "2.5                           86   15  101\n",
            "3.0                          213   92  305\n",
            "3.5                          113   81  194\n",
            "4.0                           64   58  122\n",
            "4.5                           11   13   24\n",
            "5.0                            3    4    7\n",
            "All                          518  265  783\n",
            "\n",
            "transformed_pred_phraseology  2.5  3.0  3.5  All\n",
            "phraseology                                     \n",
            "1.0                             2    1    0    3\n",
            "1.5                             2    1    0    3\n",
            "2.0                             9   62    3   74\n",
            "2.5                             4  124   24  152\n",
            "3.0                             2  180   60  242\n",
            "3.5                             0  119   61  180\n",
            "4.0                             0   52   55  107\n",
            "4.5                             0    5   13   18\n",
            "5.0                             0    2    2    4\n",
            "All                            19  546  218  783\n",
            "\n",
            "transformed_pred_grammar  2.5  3.0  3.5  All\n",
            "grammar                                     \n",
            "1.0                         3    0    0    3\n",
            "1.5                         5    1    0    6\n",
            "2.0                        38   57    0   95\n",
            "2.5                        47  134    0  181\n",
            "3.0                        24  169    0  193\n",
            "3.5                         8  167    1  176\n",
            "4.0                         3   92    1   96\n",
            "4.5                         0   25    0   25\n",
            "5.0                         0    8    0    8\n",
            "All                       128  653    2  783\n",
            "\n",
            "transformed_pred_conventions  2.5  3.0  3.5  All\n",
            "conventions                                     \n",
            "1.0                             0    1    0    1\n",
            "1.5                             1    4    0    5\n",
            "2.0                             7   76    2   85\n",
            "2.5                             5  148    2  155\n",
            "3.0                             4  235    1  240\n",
            "3.5                             2  158    8  168\n",
            "4.0                             0   92    4   96\n",
            "4.5                             0   23    3   26\n",
            "5.0                             0    7    0    7\n",
            "All                            19  744   20  783\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT-base-cased with its first 6 layers unfrozen"
      ],
      "metadata": {
        "id": "xV2k32ZKDMq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed parameters\n",
        "dense_dim = 6\n",
        "number_of_splits = 2\n",
        "random_state = 2023\n",
        "mse_loss = MCRMSE\n",
        "mse_metrics = MCRMSE\n",
        "model_name_list = ['Bert', 'Bertweet'] # Roberta\n",
        "\n",
        "df_train = pd.read_csv('df_train_split.csv')\n",
        "df_test = pd.read_csv('df_test_split.csv')\n",
        "print(f\"Length of train data : {len(df_train)}\")\n",
        "print(f\"Length of test data : {len(df_test)}\")\n",
        "y_test = np.array(df_test[label_cols], dtype = \"float32\")"
      ],
      "metadata": {
        "id": "kLUL0--ADHKL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "811bdcb7-4144-407f-c560-28f8e0e967b2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train data : 3128\n",
            "Length of test data : 783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable parameter dictionary\n",
        "param_list = [   # Partially frozen base layer\n",
        "                 {'epochs'                  : 10,\n",
        "                  'batch_size'              : 8,\n",
        "                  'learning_rate'           : 1e-5,\n",
        "                  'validation_split'        : .2,\n",
        "                  'dropout'                 : .1,\n",
        "                  'number_of_hidden_layers' : 2,\n",
        "                  'hidden_layer_node_count' : 64,\n",
        "                  'retrain_layer_count'     : 6\n",
        "                 }\n",
        "             ]"
      ],
      "metadata": {
        "id": "VlW3K8Y6QJXa"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, param_entry in enumerate(param_list):\n",
        "    MAX_LEN = 512\n",
        "    epoch_val = param_entry['epochs']\n",
        "    batch_size_val = param_entry['batch_size']\n",
        "    learning_rate_val = param_entry['learning_rate']\n",
        "    validation_split_val = param_entry['validation_split']\n",
        "    dropout_val = param_entry['dropout']\n",
        "    number_of_hidden_layers_val = param_entry['number_of_hidden_layers']\n",
        "    hidden_layer_node_count_val = param_entry['hidden_layer_node_count']\n",
        "    retrain_layer_count_val = param_entry['retrain_layer_count']\n",
        "\n",
        "    print(\"************************\")\n",
        "    print(f\"Iteration : {idx + 1}\")\n",
        "    print(\"Parameters...\")\n",
        "    print(f\"Epochs : {epoch_val}\")\n",
        "    print(f\"Batch size : {batch_size_val}\")\n",
        "    print(f\"Learning rate : {learning_rate_val}\")\n",
        "    print(f\"Validation split : {validation_split_val}\")\n",
        "    print(f\"Dropout : {dropout_val}\")\n",
        "    print(f\"Number of hidden layers : {number_of_hidden_layers_val}\")\n",
        "    print(f\"Hidden layer node count : {hidden_layer_node_count_val}\")\n",
        "    print(f\"Retrain layer count : {retrain_layer_count_val}\")\n",
        "    print(\"************************\")\n",
        "    set_config_param(20230214)\n",
        "\n",
        "    model_tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_CHKPT)\n",
        "    model = TFRobertaModel.from_pretrained(BERT_MODEL_CHKPT)\n",
        "\n",
        "    train_input_ids, train_attention_masks = text_encode(df_train['full_text'], model_tokenizer, MAX_LEN)\n",
        "    test_input_ids, test_attention_masks = text_encode(df_test['full_text'], model_tokenizer, MAX_LEN)\n",
        "\n",
        "    y_train = np.array(df_train[label_cols], dtype = \"float32\")\n",
        "\n",
        "    bert = build_regression_model(loss= \"MCRMSE\", \n",
        "                                      model_name = \"Bert\",\n",
        "                                      dense_dim = 6, \n",
        "                                      MAX_LEN = 512,\n",
        "                                      learning_rate = learning_rate_val,\n",
        "                                      dropout=dropout_val,\n",
        "                                      number_of_hidden_layers = number_of_hidden_layers_val,\n",
        "                                      hidden_layer_node_count = hidden_layer_node_count_val,\n",
        "                                      retrain_layer_count = retrain_layer_count_val)\n",
        "    bert.summary()\n",
        "\n",
        "    history_v1 = bert.fit((train_input_ids, train_attention_masks),\n",
        "                  y_train,\n",
        "                  batch_size = batch_size_val,     \n",
        "                  epochs = epoch_val,\n",
        "                  validation_split = validation_split_val\n",
        "                  )\n",
        "\n",
        "    history_v1_df = pd.DataFrame(history_v1.history)\n",
        "\n",
        "    score_v1 = bert.evaluate([test_input_ids, test_attention_masks], \n",
        "                    y_test\n",
        "                  ) \n",
        "\n",
        "    predictions_v1 = bert.predict([test_input_ids, test_attention_masks])\n",
        "    df_pred_v1 = pd.DataFrame(predictions_v1, columns=['pred_' + c for c in label_cols])\n",
        "\n",
        "    for col in label_cols:\n",
        "      df_pred_v1['transformed_pred_' + col] = df_pred_v1['pred_' + col].apply(lambda x : roundPartial(x, .5))\n",
        "    \n",
        "    df_compare_v1= pd.merge(df_test, df_pred_v1, left_index = True, right_index = True)\n",
        "    df_compare_v1.to_csv(\"predict_bert_6.csv\", index=False)\n",
        "    all = []\n",
        "    for col in label_cols:\n",
        "      all.append(((df_compare_v1[col]-df_compare_v1[\"transformed_pred_\"+col]).pow(2).mean())**(0.5))\n",
        "    RMSE_scaled = statistics.fmean(all)\n",
        "    print(f\"RMSE_scaled: {RMSE_scaled}\")\n",
        "    \n",
        "    for label in label_cols:\n",
        "      print(label)\n",
        "      hall_of_fame(df_compare_v1,label,1)\n",
        "      print(\"************************\")\n",
        "      hall_of_shame(df_compare_v1,label,1)\n",
        "      print(\"************************\")\n",
        "    for component in label_cols:\n",
        "      print(component)\n",
        "      print(\"% Predicting too high: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\">\"+component))/len(df_compare_v1)))\n",
        "      print(\"% Predicted correctly: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"==\"+component))/len(df_compare_v1)))\n",
        "      print(\"% Predicting too low: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"<\"+component))/len(df_compare_v1)))\n",
        "      print(\"****\")\n",
        "    # Predicting too high or low for every score? \n",
        "    # for component in label_cols:\n",
        "    #   print(component)\n",
        "\n",
        "    #   for score in [1.0,1.5,2.0,2.5,3.0,3.5,4.0,4.5,5.0]:\n",
        "    #     if len(df_compare_v1[df_compare_v1[component]==score])==0:\n",
        "    #       print(component+\"==\"+str(score)+\" has 0 rows\")\n",
        "    #     else:\n",
        "    #       print(f'length: {len(df_compare_v1[df_compare_v1[component]==score])}')\n",
        "    #       print(\"% Predicting the above (\"+str(score)+\"): \" +\n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) &\n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]>score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #       print(\"% Predicting the same (\"+str(score)+\"): \" +\n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) & \n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]==score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #       print(\"% Predicting the below (\"+str(score)+\"): \" + \n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) & \n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]<score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #     print(\"****\")\n",
        "\n",
        "    for component in label_cols:\n",
        "      print(component)\n",
        "      print(\"% Predicting within .5: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"<=(\"+component+\"+.5) and transformed_pred_\"+component+\">=(\"+component+\"-.5)\"))/len(df_compare_v1)))"
      ],
      "metadata": {
        "id": "ri_zkHoCQJj8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66e0e09f-a459-45c9-a504-52cdb8df5e3d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************************\n",
            "Iteration : 1\n",
            "Parameters...\n",
            "Epochs : 10\n",
            "Batch size : 8\n",
            "Learning rate : 1e-05\n",
            "Validation split : 0.2\n",
            "Dropout : 0.1\n",
            "Number of hidden layers : 2\n",
            "Hidden layer node count : 64\n",
            "Retrain layer count : 6\n",
            "************************\n",
            "Retrain layers: \n",
            " ['_11', '_10', '_9', '_8', '_7', '_6']\n",
            "Number of trainable parameters : 0\n",
            "Number of non-trainable parameters : 108310272\n",
            "tf_bert_model/bert/embeddings/word_embeddings/weight:0 True\n",
            "tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0 True\n",
            "tf_bert_model/bert/embeddings/position_embeddings/embeddings:0 True\n",
            "tf_bert_model/bert/embeddings/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/embeddings/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0 False\n",
            "tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/attention/self/value/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/attention/self/value/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/attention/output/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/attention/output/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/intermediate/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/intermediate/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/output/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/output/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/gamma:0 False\n",
            "tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/beta:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/attention/self/query/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/attention/self/query/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/attention/self/key/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/attention/self/key/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/attention/self/value/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/attention/self/value/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/attention/output/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/attention/output/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/intermediate/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/intermediate/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/output/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/output/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/gamma:0 False\n",
            "tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/beta:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/attention/self/query/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/attention/self/query/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/attention/self/key/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/attention/self/key/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/attention/self/value/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/attention/self/value/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/attention/output/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/attention/output/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/intermediate/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/intermediate/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/output/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/output/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/gamma:0 False\n",
            "tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/beta:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/attention/self/query/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/attention/self/query/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/attention/self/key/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/attention/self/key/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/attention/self/value/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/attention/self/value/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/attention/output/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/attention/output/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/intermediate/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/intermediate/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/output/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/output/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/gamma:0 False\n",
            "tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/beta:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/attention/self/query/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/attention/self/query/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/attention/self/key/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/attention/self/key/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/attention/self/value/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/attention/self/value/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/attention/output/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/attention/output/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/intermediate/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/intermediate/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/output/dense/kernel:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/output/dense/bias:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/gamma:0 False\n",
            "tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/beta:0 False\n",
            "tf_bert_model/bert/encoder/layer_._6/attention/self/query/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/attention/self/query/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/attention/self/key/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/attention/self/key/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/attention/self/value/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/attention/self/value/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/attention/output/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/attention/output/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/intermediate/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/intermediate/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/output/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/output/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/attention/self/query/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/attention/self/query/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/attention/self/key/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/attention/self/key/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/attention/self/value/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/attention/self/value/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/attention/output/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/attention/output/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/intermediate/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/intermediate/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/output/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/output/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/attention/self/query/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/attention/self/query/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/attention/self/key/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/attention/self/key/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/attention/self/value/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/attention/self/value/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/attention/output/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/attention/output/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/intermediate/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/intermediate/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/output/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/output/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/attention/self/query/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/attention/self/query/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/attention/self/key/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/attention/self/key/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/attention/self/value/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/attention/self/value/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/attention/output/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/attention/output/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/intermediate/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/intermediate/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/output/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/output/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/attention/self/query/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/attention/self/query/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/attention/self/key/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/attention/self/key/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/attention/self/value/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/attention/self/value/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/attention/output/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/attention/output/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/intermediate/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/intermediate/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/output/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/output/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/attention/self/query/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/attention/self/query/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/attention/self/key/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/attention/self/key/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/attention/self/value/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/attention/self/value/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/attention/output/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/attention/output/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/intermediate/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/intermediate/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/output/dense/kernel:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/output/dense/bias:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/gamma:0 True\n",
            "tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/beta:0 True\n",
            "tf_bert_model/bert/pooler/dense/kernel:0 True\n",
            "tf_bert_model/bert/pooler/dense/bias:0 True\n",
            "Number of trainable parameters : 0\n",
            "Number of non-trainable parameters : 108310272\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " hidden_layer_1 (Dense)         (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_layer_1 (Dropout)      (None, 64)           0           ['hidden_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            " hidden_layer_2 (Dense)         (None, 64)           4160        ['dropout_layer_1[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_layer_2 (Dropout)      (None, 64)           0           ['hidden_layer_2[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 6)            390         ['dropout_layer_2[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,364,038\n",
            "Trainable params: 53,766\n",
            "Non-trainable params: 108,310,272\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " hidden_layer_1 (Dense)         (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_layer_1 (Dropout)      (None, 64)           0           ['hidden_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            " hidden_layer_2 (Dense)         (None, 64)           4160        ['dropout_layer_1[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_layer_2 (Dropout)      (None, 64)           0           ['hidden_layer_2[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 6)            390         ['dropout_layer_2[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,364,038\n",
            "Trainable params: 53,766\n",
            "Non-trainable params: 108,310,272\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "313/313 [==============================] - 177s 518ms/step - loss: 2.8908 - MCRMSE: 2.8905 - val_loss: 2.3138 - val_MCRMSE: 2.3185\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 159s 510ms/step - loss: 1.8035 - MCRMSE: 1.8032 - val_loss: 1.1169 - val_MCRMSE: 1.1218\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 159s 510ms/step - loss: 1.0596 - MCRMSE: 1.0597 - val_loss: 0.6423 - val_MCRMSE: 0.6456\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 159s 509ms/step - loss: 0.9095 - MCRMSE: 0.9097 - val_loss: 0.5968 - val_MCRMSE: 0.5993\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 159s 509ms/step - loss: 0.8735 - MCRMSE: 0.8736 - val_loss: 0.5873 - val_MCRMSE: 0.5895\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 159s 509ms/step - loss: 0.8624 - MCRMSE: 0.8623 - val_loss: 0.5780 - val_MCRMSE: 0.5801\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 159s 509ms/step - loss: 0.8593 - MCRMSE: 0.8590 - val_loss: 0.5720 - val_MCRMSE: 0.5740\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 159s 509ms/step - loss: 0.8242 - MCRMSE: 0.8241 - val_loss: 0.5663 - val_MCRMSE: 0.5684\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 160s 511ms/step - loss: 0.8147 - MCRMSE: 0.8146 - val_loss: 0.5578 - val_MCRMSE: 0.5598\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 160s 510ms/step - loss: 0.7938 - MCRMSE: 0.7938 - val_loss: 0.5524 - val_MCRMSE: 0.5543\n",
            "25/25 [==============================] - 34s 1s/step - loss: 0.5563 - MCRMSE: 0.5567\n",
            "25/25 [==============================] - 35s 1s/step\n",
            "RMSE_scaled: 0.6271226714613488\n",
            "cohesion\n",
            "predicted:  3.5\n",
            "original:  3.5\n",
            "('People think sometimes that influencing means you have to be an example for '\n",
            " 'the person, but in my opinion influencing someone could be through anything '\n",
            " 'like : internet, words, a friend and even family. I disagree with Albert '\n",
            " 'Schweitzer because he said,  Example is not the main thing in influencing '\n",
            " 'others ; it is the only thing.  First reason why I think an example is not '\n",
            " 'the only way to influence people. For example, I go to a party and there are '\n",
            " 'people under the age of twenty-one drinking alcohol, they do not have to be '\n",
            " 'someone I know for them to influence me to drink alcohol. Some people would '\n",
            " 'feel pressure to do it just because the other ones are doing it.  Second '\n",
            " 'reason why I think an example is not the only way to influence others. The '\n",
            " 'tv can influence people to buy thing from the commercials, it could be '\n",
            " 'anything. People sometimes do not think about how much money they spend on '\n",
            " 'stuff; at the and of day they use it once, and then forget about it.  On the '\n",
            " 'other hand, people think that the only way to influence someone is by an '\n",
            " 'example. In addiction, my mom is someone that consider as an example for me, '\n",
            " \"if she do soemthing wrong it doesn't mean that I am going to do it, too. I \"\n",
            " \"think being an example is something good as long as you don't do what they \"\n",
            " 'did wrong.  In conclusion, I think there are more ways to influence people. '\n",
            " 'It could be you influencing someone else or someone influcing you.')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  2.0\n",
            "('First of all Thomas Jefferson have wrote a great and wondeful idea how can '\n",
            " 'we get done any goal we planin to get done. We all know it is hard to done '\n",
            " 'someting we will use on our future, but when dono it the first time the '\n",
            " 'secound purpose will be much esily. however to accomplish a goal any one has '\n",
            " 'to work hard and fine out to get it done.  How to get done our purpose and '\n",
            " 'goal, all of use need to fine out how to get done some things ca happen many '\n",
            " 'obtacle beffor get to the pupose we planign to get done we all know wil take '\n",
            " 'a long time is not goin to happen jus with one person it will be hard to get '\n",
            " 'there.  On otherhan it is a gret idea to be to accomplish what we what or we '\n",
            " 'love to do on our rest of life becouse will make you a great person or a '\n",
            " 'exemple for others.')\n",
            "**********\n",
            "************************\n",
            "syntax\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('Even though other believe working alone is easier and better. I  strongly '\n",
            " 'believe student do benefit from working in a group. Working in a group has '\n",
            " \"it's advantages, and I feel it's a better choice. When work work in a group \"\n",
            " 'you can see different ideas,learn to work with other and also you can met '\n",
            " 'new people.  When you work with other people you can see the different ideas '\n",
            " 'also you can learn know things. You can see the same problem in different '\n",
            " 'ways but as a group you try to find the best way to solve them. For example '\n",
            " \"let's say you have to do a project for a class, and you have to do it in a \"\n",
            " 'group. As a group you can share you Knowledge of what you know about the '\n",
            " 'topic and share them with you group . Also you can share you ideas with your '\n",
            " 'group,and see if they like it or maybe they can add something more to your '\n",
            " 'idea to make it a better one . You can see who you have in common with them '\n",
            " 'also you can see the differences you have with you group members .  Working '\n",
            " 'as a group can really have a good advantages. If it is a really big project '\n",
            " 'you dint have to do it alone. Also you can split work and everyone can get a '\n",
            " 'small portion of the project. You can also see people creativity. In a group '\n",
            " 'every one is good in something, so lets say if there is some who is really '\n",
            " 'good at drawing and some one really good in writing then the project can '\n",
            " 'look really nice and the penmanship will look great. You can get it done '\n",
            " 'half as fast with every one in the group does what they have to do and work '\n",
            " 'as a team .  When you work in a group you can met new people. Maybe you '\n",
            " 'change schools. You do not know any one at your new school. When you work in '\n",
            " 'a group, you can meet new people and make friends. It also work if you are '\n",
            " 'shy because in a group you have to communicate with others to get the work '\n",
            " 'done, or you are just a born leader you can help other how to start the '\n",
            " 'project together or tell people how to do thing because they do not know '\n",
            " 'what to do first. Also it works so you can get out your confer zone and try '\n",
            " 'new things. For example you really like to draw but you do not know how to '\n",
            " 'draw really good maybe some one from your group knows how and they can teach '\n",
            " 'you .  As a conclusion I think student do benefit when they are in group. '\n",
            " 'Because not only they can share there different ideas. You learn how to work '\n",
            " 'as a team. You can met new people, and make new friends.        ')\n",
            "**********\n",
            "************************\n",
            "predicted:  2.5\n",
            "original:  1.5\n",
            "(\"yes, I am agree with that ..  Because it's true the can show the the act of \"\n",
            " 'our felling in this three words ..  1.. be anxious  2.. Felling 3.. not to '\n",
            " 'Belief the are self  ...  1.. Be anxious .  in the world 99% of population '\n",
            " 'the have a lot of staff going on in the are idea or concept , to how to do '\n",
            " 'the are work , how to do the are staff , and how to do the are poraplem self '\n",
            " '.  ,, and the have lot of pressures on the thought  . an effect feeling or '\n",
            " 'image retained after an experience . A mark produced on a surface by '\n",
            " 'pressurre and the can show the felling thaey have . the did not seeying the '\n",
            " \"are felling cuz the are sedition the are fell and the don't want to tell \"\n",
            " 'anyone and the are worry about it .  that why the can not change they are '\n",
            " 'are life .  2. Felling. .  All the copies of the a pubilcition printed at '\n",
            " 'one time from the same set of type.  some people did not showing the are '\n",
            " 'felling . the are state of being withe the are self and the can exp lean '\n",
            " 'what the have wane what the have need to do in the live the are confuse for '\n",
            " 'anything and the are scyer for that to tell anyone.  same time the are '\n",
            " 'thinks if the do sorting wrong it,s never gonna right and never gonna '\n",
            " 'right.  3 . Not to Belief the are self.  sometime the not blivet or respect '\n",
            " 'the are self and the are urgent to someone else to do the are work and the '\n",
            " 'can impressions the are felling. some time the sending a person to do '\n",
            " 'somting for it .  like they are sending the a person to giving for something '\n",
            " 'the are need it cuz the shameful to to something by the are self . and the '\n",
            " 'are can not doing the staff the .  In the life everything in impossible we '\n",
            " 'can do anything in live we can do the best we can go the way we want to go. '\n",
            " 'over time everything is going to change the live , the friends, the staff , '\n",
            " \"the feeling . the every secant . don't be shay for samthin you really when \"\n",
            " 'it or need it you can not Chang you can not be the beast you never be '\n",
            " 'porfect in the live . be porfect in live if you not make your miss tikesa '\n",
            " 'you can not be perfect in the feucher . if you take the right way you you be '\n",
            " 'the best in the all live thake the good posittion and do good live witout '\n",
            " 'the any impressions fell ......  ')\n",
            "**********\n",
            "************************\n",
            "vocabulary\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('Would you like four day of school stay of five? Can that be possible same, '\n",
            " 'companies are trying this new way of school, I think most of the student and '\n",
            " 'teacher would like, However most of the student does not know their benefits '\n",
            " 'or desadvage, the student just think about their time they can spend doing '\n",
            " 'other stuff like play videos games, play around, going out, but never time '\n",
            " 'how values is the time they are using right, and step to going 8 hours class '\n",
            " 'they going to have 10 hours the disadvantage will be the you have no have to '\n",
            " 'stay more at school which me you, which you going get tired you going to '\n",
            " 'have less time time to complete you homework they less classes is going to '\n",
            " 'be harder to stay focus, more classes which me more homework. you going '\n",
            " 'either awake more early and get of school more late, more project the '\n",
            " 'classes are going to be longer the they used to your going to more tired, '\n",
            " 'more angry,long topic to study, more test less life socials, life would be '\n",
            " 'more harder the already is your gonna have to pass more class to graduate, '\n",
            " 'you need to be focus and all your classes if u wanna graduate you gonna have '\n",
            " 'less energy to be in class and for does the already work its going to be '\n",
            " 'difficult to wake up in the morning your going to be exacting those people '\n",
            " 'are going to be sleeping in class ,the school most provide more food they '\n",
            " 'student are going to hungry, bad time about tree free day you can forget '\n",
            " 'import time or topic the you need in class so the teacher in going to need '\n",
            " 'to explain again and we student are losing time the can be sending in a new '\n",
            " 'topic.  Four day of school strep of five benefits if you stay focus during '\n",
            " 'the day with 10 hours you going to be learn at lot which good the most your '\n",
            " 'learn the best life is for you, have new3 classes the you want to have but '\n",
            " 'you couldnt have for the reason of time now you can have classes the you are '\n",
            " 'interesting, you can joy in new class that can you be good at it talent5 the '\n",
            " \"you didn't the you have .Education is the base of the world is the pendent \"\n",
            " 'what you studying and how good you are is how you status is life going to be '\n",
            " 'which me have more hours is going to be useful in life education yours4elf '\n",
            " 'in the best status the you can do in life; we gonna have more a hours you '\n",
            " 'have have more teacher so teacher so the can not be tired and give the '\n",
            " 'expectfict as its, the good time is a extra free day which me you can spend '\n",
            " 'with your family or with your friends people can go more relax to school '\n",
            " 'less pressure, more focus, have time to fisish your homework.  In conclusion '\n",
            " 'and my option i strongly believe the they should life 5 day of school so '\n",
            " 'people the work after school can have time to do anything they need, how can '\n",
            " 'be mo refocus during class, less tired less pressure no be worry about they '\n",
            " 'you going to have more classes the you don\"t need you have time to be in '\n",
            " 'after school active help you family during the afternoon be you homework it '\n",
            " 'way you life can be more eassy and the life teacher can be more essay for '\n",
            " 'them too.')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  4.0\n",
            "('No, students would not benefit from being able to attend classes from home. '\n",
            " 'There is a lot of action students have to take from being home school.  For '\n",
            " 'example the state has to make sure their doing their work instead of '\n",
            " 'sleeping and lacking around. You have to be responsible and be aware of your '\n",
            " \"work. I'm not saying all students can't attend online classes at home, but \"\n",
            " 'most cannot.  Going to school helps you learn and understand things better. '\n",
            " 'if you dont get something, you can ask for help and the teacher can explain '\n",
            " 'the problem to you. You also have a person teaching you instead of you '\n",
            " 'reading things by yourself and trying to understand. Being in class accurate '\n",
            " 'and up can keep you from falling asleep instead of sitting around at home '\n",
            " \"eating and sleeping all day. In addition of other students because i can't \"\n",
            " 'speak for everybody, some students can handle that and learn way better on '\n",
            " 'their own than having somebody teach them.  School groups is also another '\n",
            " 'reason how student learn faster and better. Working in groups help you learn '\n",
            " 'more from other students. Other students may know more than you or you might '\n",
            " 'know more than them, which is a good thing. Everybody has their own ideas '\n",
            " \"and opinions. You can't forget some students are antisocial and like to work \"\n",
            " 'alone. If you are one of them people, than working alone and at home is best '\n",
            " 'for you because you have nobody around to bother you.  Another reason being '\n",
            " \"home schooled isn't a good idea because you have to be responsible. Doing \"\n",
            " 'your work, making sure you up, and making sure you finishing it on time. You '\n",
            " 'have to make sure you get up on time, not staying asleep to long, or staying '\n",
            " 'on your phone. Being at school you have to get what you need done, at home '\n",
            " 'is like you know what you need done but you can do it later. Which makes you '\n",
            " 'lazy, staying at home eating,sleeping,and playing on your phone makes you '\n",
            " 'lazy. Its gonna make you forget that you have school to do. On the other '\n",
            " 'hand some students are responsible. They know what have to get done and they '\n",
            " 'get it done with or without any one telling them what to do or reminding '\n",
            " 'them.  School is learning place where you come and get your knowledge from. '\n",
            " 'Every parent should put their child in some learning program where they get '\n",
            " 'taught not taught on their own. School is the most popular place in the '\n",
            " 'world. Getting a education and great job is good reasons why you should come '\n",
            " 'to school. Great job equals great money. Good education equals a high '\n",
            " \"advance in getting in wonderful colleges. With out school you life won't be \"\n",
            " 'to bad but you know you can live a way better live with '\n",
            " 'school.              ')\n",
            "**********\n",
            "************************\n",
            "phraseology\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('Befits For An Extra Hour of School  85% of students who study more can pass '\n",
            " 'more test. I feel like some students could befits from an extra half an hour '\n",
            " 'of school because it could help students learn more. Also some students '\n",
            " 'struggle with some subjects so it could also befits some students who can '\n",
            " 'not stay back. School should add an extra half of a hour to school because '\n",
            " 'it could help students get more education, better job opportunity, and help '\n",
            " 'students to be better prepared for test.  First, students with more '\n",
            " 'education could help students lead to success. Education is helpful because '\n",
            " 'it is need in a lot of daily activities. Education is also super important '\n",
            " 'because it is through out life. Also some students who want to get in a good '\n",
            " 'collage but do not have the money for it if they have a good education they '\n",
            " 'can get in for free but they have to have good grades. Some students might '\n",
            " 'want to become a teacher but might not have the right education for that so '\n",
            " 'that why education is important.  Second, students could have better job '\n",
            " 'opportunity. Some students would not like the job they get. Also students '\n",
            " 'with good education could give students a job they want. Another thing a '\n",
            " 'better job could make the students get more money from higher paying job and '\n",
            " 'also some students could want to become a teacher. Students also do not have '\n",
            " 'to worry about how much they are getting paid and what type of job they '\n",
            " 'have. Some students could have a better job opportunity if they get an extra '\n",
            " '30 minutes because they get more education are more likely to pass their '\n",
            " 'test.  Third, students will be better prepared for test. Some students '\n",
            " 'struggle with a lot of test because they can not stay back. So I think an '\n",
            " 'extra 30 minutes could help students get a little more education and it '\n",
            " 'could help students learn more and be better prepared for test. An also '\n",
            " 'passing test is important because it is one of the highest grade and if u '\n",
            " 'fail them it could make your grade go down a lot. An some student may '\n",
            " 'struggle and that could help student do more activities and maybe they can '\n",
            " 'pass more.  In conclusion, I think an extra 30 minutes could hep students '\n",
            " 'get more education. It is also good for some student. It will also help '\n",
            " 'students be better prepared and it could let them lead to success. So I feel '\n",
            " 'like an extra 30 minutes is not that long so some student would also not '\n",
            " 'mine. So it could benefits some student to make them more successful.')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  4.0\n",
            "('Energy should be conserve more because alot of people do not use alot of '\n",
            " 'these particular items half of the time. It is better to save energy rather '\n",
            " 'than waste. Like for eample, we use light everyday to see things around us '\n",
            " 'so that we do not trip or bump into things. If not we wouldnt be able to see '\n",
            " 'things near us. At times we take advantage way too much. Were wasting alot '\n",
            " 'of light source that we hardly ever use at times. Therefor, were wasting '\n",
            " 'alot of energy that we should not be wasting. Alot of people tend to go out '\n",
            " 'to places to run some errands and leave there lights on for no reason or '\n",
            " 'just keep the light on for no particular reason. The best way to save energy '\n",
            " 'would be to turn off the light before you go out and not just leave it on '\n",
            " 'because your just making your bills go up. When you do not even use it half '\n",
            " 'of the time. It would help alot and keep you from wasting alot of money.  '\n",
            " 'Second reason, would be us not recyling things that we drink or eat. We tend '\n",
            " 'to just throw it in the trash instead of the recyling bin. Even in schools '\n",
            " 'they have recyling bins but us people do not pay attention to it because it '\n",
            " 'is nowhere to be seen. It would be better if the recycling bin was to be '\n",
            " 'seen. I feel like people would use it and recycle more. Also will save '\n",
            " 'resources that can be cleaned and used again. Rather than just using more '\n",
            " 'products to make the particular object. Schools and other places should make '\n",
            " 'an improvement and stop using alotof energy and resources and make it easier '\n",
            " 'for the resources that are being used. Us people should recycle more and '\n",
            " 'save light source and actually help the world be a better place and keep it '\n",
            " 'clean and simple. If we were able to do that it would make everything else '\n",
            " 'easier.  Overall, schools should not be extending it for two more hours. '\n",
            " 'Reasons why is because teachers tend to use alot of paper to give students '\n",
            " 'to work on. Most of the times teachers would not use front and back of the '\n",
            " 'paper. They would always do work on seprate pices of papers and give them to '\n",
            " 'the students. To make things easier for them would be to use front and back '\n",
            " 'because there not using alot of paper. So that it can be graded on and be '\n",
            " 'thrown out by the students. Students never like to keep paper with them when '\n",
            " 'teachers grade them after. So alot of paper is going to waste for no reason. '\n",
            " 'Teachers should consider of teaching students with technology and doing work '\n",
            " 'on there rather then using alot of paper. Technology would help because '\n",
            " 'trees would not be going to waste and harm the things around there '\n",
            " 'surrounding just to make paper out of it. Alot of trees would be save and '\n",
            " 'have alot of resources still. People should just think about the goods thing '\n",
            " 'and the bad things about it. Like is it worth wasting all these resources '\n",
            " 'rather than using technology.  There is advantages and disadvantages of '\n",
            " 'extending school for two hours. The advantage would be students being able '\n",
            " 'to learn more and have more time spent with their peers and teachers. '\n",
            " 'Students would have more time to do work rather than doing it at home and '\n",
            " 'struggling. It is better for them not to waste time and get the help they '\n",
            " 'need. But, at the same time the teacher is giving them work which is bad in '\n",
            " 'the way but good also . The work that is being given to them is not bad but '\n",
            " 'the resources that makes is because of how it is made. Eventually, schools '\n",
            " 'should just use technology and do all the work there. Students would be able '\n",
            " 'to access it easier and teachers would not have to worry about the students '\n",
            " 'losing work or having problems. Students would also be more entertain '\n",
            " 'because all they like to do or be on is technology and it would help the '\n",
            " 'teachers alot.  Overall this point, teachers or not just them should '\n",
            " 'consider of managing the time they use on things that use alot of energy. It '\n",
            " 'would make the world a better place and more healthier. Trees would not have '\n",
            " 'to be cut down alot and affecting their surroundings. Basically would not '\n",
            " 'cause pollution in the air and hurt things around it like for example '\n",
            " 'animals . It is important to save energy an keep the world safe. Schools '\n",
            " 'should just do everthing on computers and make things easier. Rather than '\n",
            " 'wasting alot of materials for no good '\n",
            " 'reasons.                                   ')\n",
            "**********\n",
            "************************\n",
            "grammar\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "(\"Students wouldn't benefit from attending to classes at home. Schools offer \"\n",
            " \"different options that distance learning does not. It's a good opportunity \"\n",
            " 'to attend regular classes. Everyone can learn in different ways but a better '\n",
            " \"option it's by attending normal classes. People have the option to choose \"\n",
            " 'whith what they feel comfortable. Attending to regular classes gives the '\n",
            " 'opportunity to pick their own classes. We can have many benefits by this. If '\n",
            " 'students attend to regular schools they have the opportunity to meet new '\n",
            " 'people, to participate at clubs and they have the chance to talk and get '\n",
            " 'help from teachers.  Students who attend normal schools have the opportunity '\n",
            " 'to meet new people. Not everyone likes to be anti-social and to be alone '\n",
            " 'without not knowing others. Sometimes is great to have a person that we can '\n",
            " 'tell everything. By going to school, we have the chance to talk to a '\n",
            " 'thousand of people and to make new friends. Once Generic_Name got the '\n",
            " 'options to pick home school or to attend to normal classes. She chose to do '\n",
            " 'classes at home. She was happy for the idea that she has not to wake up '\n",
            " 'early. For the first couple of weeks everything was fine. She was getting '\n",
            " 'use to it. One day she realized that she has no friends; she feels alone. '\n",
            " 'Generic_Name when to talk to her mom about the way she was feeling. Her mom '\n",
            " \"told her that if she weren't pick to stay at home and doing distance \"\n",
            " \"learning; she weren't to feel that way. Generic_Name thought about what her \"\n",
            " 'mom told her and she decide that the best option was attend to normal '\n",
            " 'classes at school. If we attend to regular classes, we are not going to feel '\n",
            " 'alone and we can make new friends.  Schools provides the chance to '\n",
            " \"participate at clubs. While distance learning don't have activities or clubs \"\n",
            " 'for students to do. Public schools have different kind of activities or '\n",
            " 'clubs that they can enjoy. Activities and clubs are a good way to help and '\n",
            " 'to prepare students for the future. They have the option to enjoy a team '\n",
            " 'from their preference. For example, a person who like football. They might '\n",
            " \"like to form part of the football team and that's what normal schools \"\n",
            " 'provides. If this person form part of a football team; he can get '\n",
            " 'scholarships to participate in big leagues. From clubs students can get an '\n",
            " 'idea of what career they want to get in the future, to discover new things, '\n",
            " 'and to get experience from this different activities.  Other might argue '\n",
            " 'that distance learning gives students time for their jobs, they can avoid '\n",
            " 'being getting in trouble and they can take care of their youngest siblings '\n",
            " 'while they are at home. However, people by attending to classes have the '\n",
            " \"chance to get help from teachers. It's a reality that not everyone is \"\n",
            " 'capable to understand easily. Sometimes we need a push or help from others '\n",
            " \"who knows about the things we don't. The awesome thing about normal schools \"\n",
            " 'is that teachers stay a little longer after school to help with hard work. '\n",
            " 'To pay attention during classes can be hard because of other classmates are '\n",
            " \"making noise or it's really hard to understand. Teachers talk about our \"\n",
            " 'grades and gives us advices to improve them. Talking to teachers helps to '\n",
            " 'understand because they give us a deeply explanation.  At school people have '\n",
            " 'the chance to make new friends, to have the oppoortunity to try new '\n",
            " 'activities and to improve academically with the help of teachers. Some '\n",
            " 'people can be in disagreement with public schools, but they have on mind '\n",
            " \"that sometimes it can be a better option. School it's a good way to get out \"\n",
            " 'of home for at least some hours. Not everyone likes to being at home for the '\n",
            " 'whole day. At school we can have fun with our friends, lunch time is unique '\n",
            " \"and that is something the distance learning don't offer. Activities after \"\n",
            " 'school are a good way to keep people out of trouble. To help them to choose '\n",
            " 'a good path. School have a variety of ways to have fun, not just by playing, '\n",
            " 'also by learning. ')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  2.5\n",
            "('The one place I would like to visit in the world would be Puerto Rico. I '\n",
            " 'would like to visit Puerto Rico because of the of the beautiful weather. I '\n",
            " \"would like to visit Puerto Rico because of the beautiful beach's and rivers. \"\n",
            " 'One other reason would be because of my family.  First, the weather most of '\n",
            " 'the time is hot even in the winter is hot. In the summer sometimes is ,so '\n",
            " 'hot that it can reach the temperature of 100 degrees. Most of the people '\n",
            " 'living in Puerto Rico are use to the hot temperature.  Next, you would see '\n",
            " \"people in the beach's or at the river some people have pool but some people \"\n",
            " \"can't buy pools because some don't have money and some people do have money \"\n",
            " \"so when the weather is hot you will see most of the people at the beach's or \"\n",
            " \"rivers. I personally like going to the river's because the water is colder \"\n",
            " \"and is really refreshing when it's really hot.  Next, another reason why I \"\n",
            " 'pick Puerto Rico was because of there delicious foods there a lot of '\n",
            " 'tropical dishes there is something call the three meat sandwich witch is '\n",
            " 'made of really tender pork meat,chicken,beef then they put potato sticks and '\n",
            " 'then they add the mayo and ketchup. In the holidays like Christmas '\n",
            " 'puertorican people cook a hole pig and then when the pig is done cooking '\n",
            " 'they cut the pig and shred it into pieces and then they eat it with rice mix '\n",
            " 'with beans.  Finally, most of my family is from Puerto Rico so most of my '\n",
            " \"family know's the best places to go and the type of food that we would like. \"\n",
            " 'Most of are family makes a party when we come from the U.S because we only '\n",
            " \"go and visit in the summer because of school we can't visit when ever we \"\n",
            " 'want to. When ever I visit Puerto Rico I have to see my two little brothers '\n",
            " 'and my friend that I have not seen sense last summer most of the time I go '\n",
            " 'to my consents house because we always play baseball or basketball ,but when '\n",
            " \"it's to hot we stay home watching T.V or playing PlayStation we play with my \"\n",
            " 'friend that lives in Virginia. When is time to go back to the U.S are family '\n",
            " \"get's sad and starst crying but we tell them that we will be back.\")\n",
            "**********\n",
            "************************\n",
            "conventions\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('Do people accomplish more if they are always doing something, or does '\n",
            " 'inactivity also serve a purpose? Olympic people did not just sit at home and '\n",
            " 'got an Olympic Golden medal for nothing, they worked hard to achieve their '\n",
            " 'goals. Yes, you always have to do something to become the succeed person '\n",
            " 'that you want to become, to reach and achieve your goals, and to stay active '\n",
            " 'and social with others.  In my native country of Generic_City people always '\n",
            " 'work hard, to get money, feed their families, and also teach their kids how '\n",
            " 'to succeed in school and other athletic stuff, with the bad community that '\n",
            " 'we have in their. As well as here a lot of people study and work hard to '\n",
            " 'succeed. For example, at Generic_school we have a cooking class, they always '\n",
            " 'push us forward and try to teach us new methods how to cook and seasoning '\n",
            " 'the food, that gives a huge opportunity for the students who want to do it '\n",
            " 'for living in the future.  Another reason, is that it will be twice as hard '\n",
            " 'if you say I want to achieve this goal at the end of this semester, but you '\n",
            " 'are not working to improve your self to achieve it. This is problem that '\n",
            " 'everyone have, like on our swimming team I had a really difficult goal to '\n",
            " 'achieve, I started to push my self to the limit and work as hard as everyone '\n",
            " 'else just to achieve it. And at the end of the season I did achieve it, '\n",
            " 'which was to get a time that under 35:00 seconds, I shock myself and made my '\n",
            " 'coach proud of me be achieving it.  Finally by working outside, or joining '\n",
            " \"an athletic team, or vising an old friends it's another really good way to \"\n",
            " 'staying active and social with others, and talking to other people is '\n",
            " 'another great way to solve a lot of problems, specially when you are sad or '\n",
            " \"having a bad time.  Other's may think that staying not active for a bit or \"\n",
            " 'at all is a good way, they think that because having a time alone with '\n",
            " 'yourself kind of make you think what is happening around you, However, if '\n",
            " 'you fill your time with friends and activities that you like to do, you will '\n",
            " 'not feel want to be alone because you will have a good friends all over you '\n",
            " 'all the time, and they will help you to reach the goals that you want to '\n",
            " 'achieve.')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  3.5\n",
            "(\"The school board shouldn't add one and half hours to school each day. To \"\n",
            " \"begin one reason i think they shouldn't is that a lot of kids who play \"\n",
            " \"sports or clubs after school might not be able to because they don't have \"\n",
            " \"time to learn about how life is and how difficult it is and people's life \"\n",
            " 'difficulties. One example is that some kids play videos and since they dont '\n",
            " 'have lots of time out side of school they might just play video game instead '\n",
            " 'of sports and if you give them more time out of school more opportunities '\n",
            " 'students will have. secondly Students will be more tired and less focus '\n",
            " 'because if students have more time in school the more earlier they will have '\n",
            " \"to sleep and most students don't fall asleep early also students have \"\n",
            " 'homework since they well most likely be tired from school they might take a '\n",
            " 'nap and there might either wake up to late to do homework or not have time '\n",
            " 'to finish all there homework. Thirdly more students will not want to be in '\n",
            " \"school and may drop out from either too much stress or they just don't want \"\n",
            " 'to be in school because the longer time there in school the more tired they '\n",
            " 'are and less time they have to do what makes them feel relaxed or not have '\n",
            " 'time to do what they love to do. students also might not have time to make '\n",
            " 'friends because there focusing on school and it might ruin there social '\n",
            " 'skill and conversation with strangers out side of school. Lastly less amount '\n",
            " 'of time they have to spend with there families because they would have to go '\n",
            " 'to school for extra time and as soon as they get home they have to do '\n",
            " 'homework and honestly by the time there done there going to be most likely '\n",
            " 'tired to do anything beside resting or sleeping. Also some students have '\n",
            " 'younger siblings to take care of after school so that would put more stress '\n",
            " 'on a student and either a family would have to pay for a baby sitter or some '\n",
            " \"families don't have money to pay for one so parents might take there student \"\n",
            " 'out of school just to take care of there sibling and so the extra time in '\n",
            " \"school wouldn't help him. To conclude those are the main reasons why I think \"\n",
            " \"we shouldn't have more school hours in school.  \")\n",
            "**********\n",
            "************************\n",
            "cohesion\n",
            "% Predicting too high: 0.29757343550446996\n",
            "% Predicted correctly: 0.3001277139208174\n",
            "% Predicting too low: 0.40229885057471265\n",
            "****\n",
            "syntax\n",
            "% Predicting too high: 0.33588761174968074\n",
            "% Predicted correctly: 0.33205619412515963\n",
            "% Predicting too low: 0.33205619412515963\n",
            "****\n",
            "vocabulary\n",
            "% Predicting too high: 0.24904214559386972\n",
            "% Predicted correctly: 0.3895274584929757\n",
            "% Predicting too low: 0.3614303959131545\n",
            "****\n",
            "phraseology\n",
            "% Predicting too high: 0.3550446998722861\n",
            "% Predicted correctly: 0.3269476372924649\n",
            "% Predicting too low: 0.31800766283524906\n",
            "****\n",
            "grammar\n",
            "% Predicting too high: 0.3001277139208174\n",
            "% Predicted correctly: 0.2784163473818646\n",
            "% Predicting too low: 0.421455938697318\n",
            "****\n",
            "conventions\n",
            "% Predicting too high: 0.3448275862068966\n",
            "% Predicted correctly: 0.2988505747126437\n",
            "% Predicting too low: 0.3563218390804598\n",
            "****\n",
            "cohesion\n",
            "% Predicting within .5: 0.7573435504469987\n",
            "syntax\n",
            "% Predicting within .5: 0.7739463601532567\n",
            "vocabulary\n",
            "% Predicting within .5: 0.8326947637292464\n",
            "phraseology\n",
            "% Predicting within .5: 0.7956577266922095\n",
            "grammar\n",
            "% Predicting within .5: 0.7203065134099617\n",
            "conventions\n",
            "% Predicting within .5: 0.7445721583652618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_compare_v1 = pd.read_csv(\"predict_bert_6.csv\")\n",
        "for component in label_cols:\n",
        "  print(pd.crosstab(df_compare_v1[component], df_compare_v1[\"transformed_pred_\"+component], margins=True))\n",
        "  print()"
      ],
      "metadata": {
        "id": "OVOPBW0OK1Z_",
        "outputId": "13911e59-c9c9-4065-dabf-23c65ddbcfd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformed_pred_cohesion  2.5  3.0  3.5  All\n",
            "cohesion                                     \n",
            "1.0                          2    0    0    2\n",
            "1.5                          5    1    0    6\n",
            "2.0                         18   43    3   64\n",
            "2.5                         24  119   19  162\n",
            "3.0                         16  180   23  219\n",
            "3.5                          9  158   31  198\n",
            "4.0                          4   65   24   93\n",
            "4.5                          0   20   15   35\n",
            "5.0                          0    2    2    4\n",
            "All                         78  588  117  783\n",
            "\n",
            "transformed_pred_syntax  2.5  3.0  3.5  All\n",
            "syntax                                     \n",
            "1.0                        4    0    0    4\n",
            "1.5                        3    2    0    5\n",
            "2.0                       24   70    2   96\n",
            "2.5                       27  119    3  149\n",
            "3.0                       21  200   36  257\n",
            "3.5                        9  128   33  170\n",
            "4.0                        1   62   18   81\n",
            "4.5                        0   13    6   19\n",
            "5.0                        0    2    0    2\n",
            "All                       89  596   98  783\n",
            "\n",
            "transformed_pred_vocabulary  2.5  3.0  3.5  All\n",
            "vocabulary                                     \n",
            "1.5                            2    2    0    4\n",
            "2.0                            8   17    1   26\n",
            "2.5                           15   77    9  101\n",
            "3.0                           11  215   79  305\n",
            "3.5                            1  118   75  194\n",
            "4.0                            0   68   54  122\n",
            "4.5                            0   10   14   24\n",
            "5.0                            0    2    5    7\n",
            "All                           37  509  237  783\n",
            "\n",
            "transformed_pred_phraseology  2.5  3.0  3.5  All\n",
            "phraseology                                     \n",
            "1.0                             3    0    0    3\n",
            "1.5                             1    2    0    3\n",
            "2.0                            24   48    2   74\n",
            "2.5                            11  115   26  152\n",
            "3.0                             5  180   57  242\n",
            "3.5                             1  114   65  180\n",
            "4.0                             0   55   52  107\n",
            "4.5                             0    3   15   18\n",
            "5.0                             0    2    2    4\n",
            "All                            45  519  219  783\n",
            "\n",
            "transformed_pred_grammar  2.5  3.0  3.5  All\n",
            "grammar                                     \n",
            "1.0                         3    0    0    3\n",
            "1.5                         5    1    0    6\n",
            "2.0                        30   65    0   95\n",
            "2.5                        51  129    1  181\n",
            "3.0                        28  164    1  193\n",
            "3.5                        17  156    3  176\n",
            "4.0                         8   86    2   96\n",
            "4.5                         0   25    0   25\n",
            "5.0                         1    7    0    8\n",
            "All                       143  633    7  783\n",
            "\n",
            "transformed_pred_conventions  2.5  3.0  3.5  All\n",
            "conventions                                     \n",
            "1.0                             0    1    0    1\n",
            "1.5                             3    2    0    5\n",
            "2.0                            11   71    3   85\n",
            "2.5                             4  144    7  155\n",
            "3.0                             3  209   28  240\n",
            "3.5                             4  143   21  168\n",
            "4.0                             0   76   20   96\n",
            "4.5                             0   20    6   26\n",
            "5.0                             0    4    3    7\n",
            "All                            25  670   88  783\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT-base-cased with all 12 layers unfrozen"
      ],
      "metadata": {
        "id": "nqdHzmdaDSGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed parameters\n",
        "dense_dim = 6\n",
        "number_of_splits = 2\n",
        "random_state = 2023\n",
        "mse_loss = MCRMSE\n",
        "mse_metrics = MCRMSE\n",
        "model_name_list = ['Bert', 'Bertweet'] # Roberta\n",
        "\n",
        "df_train = pd.read_csv('df_train_split.csv')\n",
        "df_test = pd.read_csv('df_test_split.csv')\n",
        "print(f\"Length of train data : {len(df_train)}\")\n",
        "print(f\"Length of test data : {len(df_test)}\")\n",
        "y_test = np.array(df_test[label_cols], dtype = \"float32\")"
      ],
      "metadata": {
        "id": "_tm-53JKDWJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d9332de-8997-4269-d438-0bf618d80afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train data : 3128\n",
            "Length of test data : 783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable parameter dictionary\n",
        "param_list = [   # Completely unfrozen base layer\n",
        "                 {'epochs'                  : 10,\n",
        "                  'batch_size'              : 8,\n",
        "                  'learning_rate'           : 1e-5,\n",
        "                  'validation_split'        : .2,\n",
        "                  'dropout'                 : .1,\n",
        "                  'number_of_hidden_layers' : 2,\n",
        "                  'hidden_layer_node_count' : 64,\n",
        "                  'retrain_layer_count'     : 12\n",
        "                 },\n",
        "             ]"
      ],
      "metadata": {
        "id": "hHIjC1XYQKAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, param_entry in enumerate(param_list):\n",
        "    MAX_LEN = 512\n",
        "    epoch_val = param_entry['epochs']\n",
        "    batch_size_val = param_entry['batch_size']\n",
        "    learning_rate_val = param_entry['learning_rate']\n",
        "    validation_split_val = param_entry['validation_split']\n",
        "    dropout_val = param_entry['dropout']\n",
        "    number_of_hidden_layers_val = param_entry['number_of_hidden_layers']\n",
        "    hidden_layer_node_count_val = param_entry['hidden_layer_node_count']\n",
        "    retrain_layer_count_val = param_entry['retrain_layer_count']\n",
        "\n",
        "    print(\"************************\")\n",
        "    print(f\"Iteration : {idx + 1}\")\n",
        "    print(\"Parameters...\")\n",
        "    print(f\"Epochs : {epoch_val}\")\n",
        "    print(f\"Batch size : {batch_size_val}\")\n",
        "    print(f\"Learning rate : {learning_rate_val}\")\n",
        "    print(f\"Validation split : {validation_split_val}\")\n",
        "    print(f\"Dropout : {dropout_val}\")\n",
        "    print(f\"Number of hidden layers : {number_of_hidden_layers_val}\")\n",
        "    print(f\"Hidden layer node count : {hidden_layer_node_count_val}\")\n",
        "    print(f\"Retrain layer count : {retrain_layer_count_val}\")\n",
        "    print(\"************************\")\n",
        "    set_config_param(20230214)\n",
        "\n",
        "    model_tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_CHKPT)\n",
        "    model = TFRobertaModel.from_pretrained(BERT_MODEL_CHKPT)\n",
        "\n",
        "    train_input_ids, train_attention_masks = text_encode(df_train['full_text'], model_tokenizer, MAX_LEN)\n",
        "    test_input_ids, test_attention_masks = text_encode(df_test['full_text'], model_tokenizer, MAX_LEN)\n",
        "\n",
        "    y_train = np.array(df_train[label_cols], dtype = \"float32\")\n",
        "\n",
        "    bert = build_regression_model(loss= \"MCRMSE\", \n",
        "                                      model_name = \"Bert\",\n",
        "                                      dense_dim = 6, \n",
        "                                      MAX_LEN = 512,\n",
        "                                      learning_rate = learning_rate_val,\n",
        "                                      dropout=dropout_val,\n",
        "                                      number_of_hidden_layers = number_of_hidden_layers_val,\n",
        "                                      hidden_layer_node_count = hidden_layer_node_count_val,\n",
        "                                      retrain_layer_count = retrain_layer_count_val)\n",
        "    bert.summary()\n",
        "\n",
        "    history_v1 = bert.fit((train_input_ids, train_attention_masks),\n",
        "                  y_train,\n",
        "                  batch_size = batch_size_val,     \n",
        "                  epochs = epoch_val,\n",
        "                  validation_split = validation_split_val\n",
        "                  )\n",
        "\n",
        "    history_v1_df = pd.DataFrame(history_v1.history)\n",
        "\n",
        "    score_v1 = bert.evaluate([test_input_ids, test_attention_masks], \n",
        "                    y_test\n",
        "                  ) \n",
        "\n",
        "    predictions_v1 = bert.predict([test_input_ids, test_attention_masks])\n",
        "    df_pred_v1 = pd.DataFrame(predictions_v1, columns=['pred_' + c for c in label_cols])\n",
        "\n",
        "    for col in label_cols:\n",
        "      df_pred_v1['transformed_pred_' + col] = df_pred_v1['pred_' + col].apply(lambda x : roundPartial(x, .5))\n",
        "    \n",
        "    df_compare_v1= pd.merge(df_test, df_pred_v1, left_index = True, right_index = True)\n",
        "    df_compare_v1.to_csv(\"predict_bert_12.csv\", index=False)\n",
        "    all = []\n",
        "    for col in label_cols:\n",
        "      all.append(((df_compare_v1[col]-df_compare_v1[\"transformed_pred_\"+col]).pow(2).mean())**(0.5))\n",
        "    RMSE_scaled = statistics.fmean(all)\n",
        "    print(f\"RMSE_scaled: {RMSE_scaled}\")\n",
        "    \n",
        "    for label in label_cols:\n",
        "      print(label)\n",
        "      hall_of_fame(df_compare_v1,label,1)\n",
        "      print(\"************************\")\n",
        "      hall_of_shame(df_compare_v1,label,1)\n",
        "      print(\"************************\")\n",
        "    for component in label_cols:\n",
        "      print(component)\n",
        "      print(\"% Predicting too high: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\">\"+component))/len(df_compare_v1)))\n",
        "      print(\"% Predicted correctly: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"==\"+component))/len(df_compare_v1)))\n",
        "      print(\"% Predicting too low: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"<\"+component))/len(df_compare_v1)))\n",
        "      print(\"****\")\n",
        "    # Predicting too high or low for every score? \n",
        "    # for component in label_cols:\n",
        "    #   print(component)\n",
        "\n",
        "    #   for score in [1.0,1.5,2.0,2.5,3.0,3.5,4.0,4.5,5.0]:\n",
        "    #     if len(df_compare_v1[df_compare_v1[component]==score])==0:\n",
        "    #       print(component+\"==\"+str(score)+\" has 0 rows\")\n",
        "    #     else:\n",
        "    #       print(f'length: {len(df_compare_v1[df_compare_v1[component]==score])}')\n",
        "    #       print(\"% Predicting the above (\"+str(score)+\"): \" +\n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) &\n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]>score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #       print(\"% Predicting the same (\"+str(score)+\"): \" +\n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) & \n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]==score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #       print(\"% Predicting the below (\"+str(score)+\"): \" + \n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) & \n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]<score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #     print(\"****\")\n",
        "\n",
        "    for component in label_cols:\n",
        "      print(component)\n",
        "      print(\"% Predicting within .5: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"<=(\"+component+\"+.5) and transformed_pred_\"+component+\">=(\"+component+\"-.5)\"))/len(df_compare_v1)))"
      ],
      "metadata": {
        "id": "fLLxEQE3QKHd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e5063f5-4de6-4426-8815-a8dd0430f4b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************************\n",
            "Iteration : 1\n",
            "Parameters...\n",
            "Epochs : 10\n",
            "Batch size : 8\n",
            "Learning rate : 1e-05\n",
            "Validation split : 0.2\n",
            "Dropout : 0.1\n",
            "Number of hidden layers : 2\n",
            "Hidden layer node count : 64\n",
            "Retrain layer count : 12\n",
            "************************\n",
            "Number of trainable parameters : 108310272\n",
            "Number of non-trainable parameters : 0\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " hidden_layer_1 (Dense)         (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_layer_1 (Dropout)      (None, 64)           0           ['hidden_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            " hidden_layer_2 (Dense)         (None, 64)           4160        ['dropout_layer_1[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_layer_2 (Dropout)      (None, 64)           0           ['hidden_layer_2[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 6)            390         ['dropout_layer_2[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,364,038\n",
            "Trainable params: 108,364,038\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " hidden_layer_1 (Dense)         (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_layer_1 (Dropout)      (None, 64)           0           ['hidden_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            " hidden_layer_2 (Dense)         (None, 64)           4160        ['dropout_layer_1[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_layer_2 (Dropout)      (None, 64)           0           ['hidden_layer_2[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 6)            390         ['dropout_layer_2[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,364,038\n",
            "Trainable params: 108,364,038\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 384s 1s/step - loss: 1.0622 - MCRMSE: 1.0622 - val_loss: 0.5243 - val_MCRMSE: 0.5280\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 361s 1s/step - loss: 0.8955 - MCRMSE: 0.8956 - val_loss: 0.4795 - val_MCRMSE: 0.4816\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 365s 1s/step - loss: 0.8518 - MCRMSE: 0.8517 - val_loss: 0.4736 - val_MCRMSE: 0.4755\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 365s 1s/step - loss: 0.8302 - MCRMSE: 0.8300 - val_loss: 0.4629 - val_MCRMSE: 0.4644\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 364s 1s/step - loss: 0.7934 - MCRMSE: 0.7934 - val_loss: 0.4836 - val_MCRMSE: 0.4844\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 351s 1s/step - loss: 0.7694 - MCRMSE: 0.7695 - val_loss: 0.4994 - val_MCRMSE: 0.5011\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 351s 1s/step - loss: 0.7456 - MCRMSE: 0.7458 - val_loss: 0.4764 - val_MCRMSE: 0.4786\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 352s 1s/step - loss: 0.7370 - MCRMSE: 0.7368 - val_loss: 0.4669 - val_MCRMSE: 0.4680\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 353s 1s/step - loss: 0.7034 - MCRMSE: 0.7032 - val_loss: 0.4865 - val_MCRMSE: 0.4870\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 339s 1s/step - loss: 0.6931 - MCRMSE: 0.6931 - val_loss: 0.4757 - val_MCRMSE: 0.4773\n",
            "25/25 [==============================] - 33s 1s/step - loss: 0.4708 - MCRMSE: 0.4701\n",
            "25/25 [==============================] - 36s 1s/step\n",
            "RMSE_scaled: 0.5267901151738109\n",
            "cohesion\n",
            "predicted:  3.5\n",
            "original:  3.5\n",
            "('Being true to yourself in a world so cruel is the best to accomplishment. '\n",
            " 'The most important lessons life can give is stand your ground, be more '\n",
            " 'forward with certain individuals, cut what seems to be negative. '\n",
            " 'Individuality can always be a good, sometimes you never need that helping '\n",
            " 'hand because not everyone is helpful. Some try to be the bad person by '\n",
            " 'stepping over you.  Most experiences, I myself have gone through were never '\n",
            " 'the best. Everyone might seem like the good person, but we never know what '\n",
            " 'is really behind them. First off, you should simply just stand your ground. '\n",
            " 'Show them that not everything is meant to be worked within two people.  '\n",
            " 'Another reason, achieving things on your own shows you a lot of things you '\n",
            " 'never knew before. One of those might be you have made through school by '\n",
            " 'yourself and got your diploma. Accomplishment comes with many struggles and '\n",
            " 'steps. Not just anyone makes it through; some give up because maybe others '\n",
            " 'told them that not everything is for them.  Lastly, cut out certain people '\n",
            " 'that you know never got you anywhere. Everyday is a lesson if we recognize '\n",
            " 'it or not. Some days are harder than others, but there is never a day you '\n",
            " 'should give. Every job can be easy with a positive mindset.  In conclusion, '\n",
            " 'my reasons to accomplishment to stand your ground, move forward, and to '\n",
            " 'leave negativity behind can lead to bigger success and open '\n",
            " 'opportunity.      ')\n",
            "**********\n",
            "************************\n",
            "predicted:  2.5\n",
            "original:  3.0\n",
            "('taking online clases is one of the best option, for many student who has '\n",
            " 'problem to attendace in the school.  taking online clases can help to '\n",
            " 'student, who need to work full time because they are having many '\n",
            " 'responsability in there home some of the students are living by themself, '\n",
            " 'people who have to pay bills and work extra hours and they are not having '\n",
            " 'time for going to school decide to giving up and not finish there education '\n",
            " \".  many student don't have money for getting lunch or can not apply for get \"\n",
            " 'free lunch.  and they don t want to spend more money in the school or '\n",
            " 'students who has childrens are paying babysitting the time when there are in '\n",
            " 'the school, and want to continue studing.  Student can have better grades.  '\n",
            " 'they can access online any time during the day, they can focus in clases '\n",
            " 'they having more time to work in assigment, they can add extra time to check '\n",
            " 'test, homeworks, vocabularies, etc they can memorise more easily, because '\n",
            " 'they can repeat the information many times they want. access online clases, '\n",
            " 'student do not have another student to interrup the clases least problem '\n",
            " 'between of students, getting online education , people will not skip clases '\n",
            " 'becauses. they think be in a classroom is to bore and they decide to leaving '\n",
            " 'the classroom. a big problem is a lot student s are missing the buss, '\n",
            " 'because there a late for minutes them the a lossing a day of school .  '\n",
            " 'people are getting sick easily the food from the school is not healthy, '\n",
            " 'people pefer to not eat than eat the food from the cafeteria that is '\n",
            " 'affecting attends .  this idea to have clases online it going to make '\n",
            " 'students feels they are getting enoght help from the school, having online '\n",
            " 'education is a great idea for student it will increseasing the attendance ')\n",
            "**********\n",
            "************************\n",
            "syntax\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('I think its a good idea to ask people for other people opinion because '\n",
            " 'people might have better thought on something, they can have different '\n",
            " 'options for you, and it also can help you later in life.  I think we should '\n",
            " 'ask people for there opinion because they might have a better thought. For '\n",
            " 'example if you wanted to go shopping for cloths and you dont know which one '\n",
            " 'to pick. People will give options of what they think and they can tell you '\n",
            " 'which one they prefer more. There are variety options you can pick from. You '\n",
            " 'can choose your own and ask people if they like it or not. If you dont know '\n",
            " 'which one to pick between two options. You can ask friends, family, or '\n",
            " 'anyone you feel comfuterble with you can get an idea which one you want '\n",
            " 'more. Its always a good thing to ask for people opinion.  Asking for people '\n",
            " 'opinion is good they can have different options for you. You can ask on '\n",
            " 'different flavor of ice cream you can get as many options as you want . '\n",
            " 'People can give you differnt opionions on what they think which ice cream '\n",
            " 'taste better than other ones. different options is always a good thing to '\n",
            " 'use. Its bad sometimes haveing only one option the more options the better. '\n",
            " 'The more options you get you wont have problems with picking things of what '\n",
            " 'you want. It is easier to to pick and and you can have what you want.  All '\n",
            " 'these opinions can help us out later in life. In the future you might need '\n",
            " 'help on which flavor ice cream is good. You can ask someone and they can '\n",
            " 'give you an opinion which one is good. Its good to have opinion some of them '\n",
            " 'you might not like. Everyone dont have the same opinion which is okay '\n",
            " 'everyone can have different opinion on different types of things. over time '\n",
            " 'you might need an opinion on something and you can thing what people have '\n",
            " 'said before or you can ask someone to help you out.  Different opinions and '\n",
            " 'thoughts can help you more in life and you wont have problems with picking '\n",
            " 'things. its good to have different opinions on different things that people '\n",
            " 'give you. All these opinions people give you can help you later in the '\n",
            " 'future and different kinda of opinions. I think it is better choice to ask '\n",
            " 'someone on thier opinions and get an idea of what other people think about '\n",
            " 'different things.                                                ')\n",
            "**********\n",
            "************************\n",
            "predicted:  2.5\n",
            "original:  3.5\n",
            "('Well I want to start saying that the first impressions about people can '\n",
            " \"change but if the impressions change is because something happen. I'm saying \"\n",
            " 'it because of some of my experiences with other people that I met and change '\n",
            " \"my impressions about them. Sometimes people don't change,instead of saying \"\n",
            " 'that people change your impressions about them maybe you need to know your '\n",
            " 'self first and see what is happening also you need to known why that person '\n",
            " 'change your impressions because maybe something sad or bad is happening on '\n",
            " \"their life and you don't know it.  So let me tell you an experience that \"\n",
            " 'happen to me a few moths ago so I met this girl and she was very nice with '\n",
            " 'me and I start thinking that she was that nice with everyone and no I was '\n",
            " 'wrong she only was that nice with me so I decide to date her so I tell her '\n",
            " 'if she want go to see a movie next weekend and she tell me, yes! and I say '\n",
            " 'great so like 3 days before going to see the movie she start acting weird '\n",
            " 'and I ask her if she was OK? and she tell me yes,so the next day I start '\n",
            " 'talking with her and she tell me what was happening and she tell me that her '\n",
            " 'mother was sick and she was sad,so she tell me everything that was happening '\n",
            " 'and I understand why she was acting weird.  In conclusion my impressions '\n",
            " 'about her it was starting to change but I decide to talk with her to see '\n",
            " 'what was happening, before that I start saying that she change and my '\n",
            " 'impressions about her change. is bad to change the impressions about a '\n",
            " \"person without knowing what is happening in their life,because you don't \"\n",
            " 'know if that person is waiting for you to ask them what is happening. So I '\n",
            " 'think you should ask that person what is happening and then you decide what '\n",
            " 'are you going to do. These are some of the many reason why I disagree with '\n",
            " 'the statement.')\n",
            "**********\n",
            "************************\n",
            "vocabulary\n",
            "predicted:  4.0\n",
            "original:  4.0\n",
            "(\"I really need to find a career path. With your help, I think we'll be able \"\n",
            " 'to come up with a solution. You should come my school not just to help me, '\n",
            " 'but to help others too. Students need to gain experience to at least '\n",
            " 'understand what to do, and how to act in the work place. They can really '\n",
            " 'benefit by finding a new career. Their interest can take them a long way. '\n",
            " 'Your help can take them a long way, and they can potentially help you too. '\n",
            " 'Coming to my school would help me gain experience, find an interest, and '\n",
            " 'gain something beneficial.  Experience is key in finding a job that '\n",
            " 'interests you. If I join an internship I can potentially gain a lot of '\n",
            " 'experience. An internship helps you to prepare for whats to come later on in '\n",
            " 'your career. Work ethic and how to do your job are things you might learn. I '\n",
            " 'really need to learn whats the wrong thing to do, and whats the right thing '\n",
            " 'to do in the work place. For example, you need to learn how to address your '\n",
            " 'boss in a polite way. If you mess that up, it could possibly cost you your '\n",
            " 'career. I really need to learn this stuff to improve my career later down '\n",
            " 'the line. I know you would be capable to help me with that.  Benefits are '\n",
            " 'things you gain out of a situation. If you help me I will benefit from this, '\n",
            " 'and you could benefit from this too. I can gain a lot if you help me. I '\n",
            " 'could pursue an amazing career that would help me out a lot. My career would '\n",
            " 'help me pay for bills, rent, and my car. If your internship helps me find a '\n",
            " \"good career, that career can help me financially. It's like a domino affect. \"\n",
            " 'It can also benefit me emotionally. If I really like my job, that makes me '\n",
            " \"happy. Don't forget that this could benefit you too. You could potentially \"\n",
            " 'gain knowledge about what your doing wrong and what your doing right. You '\n",
            " 'can improve as a manager of your business; possibly changing your work style '\n",
            " 'or business style. I can help you with certain things too if I join your '\n",
            " 'internship.  You have to be interested in something to start a good career. '\n",
            " \"What is your career going to be based around? You can help me find a job I'm \"\n",
            " \"interested in or lead me down a path where I can start the job I'm \"\n",
            " 'interested in. In my opinion, you have to like your job to succeed in your '\n",
            " \"career. If you don't, It could lead to quitting. If I know what I want to \"\n",
            " \"do, you can point me in the right direction and I'll work hard in order to \"\n",
            " \"reach my goal. If I don't know what I want to do, you can help me find \"\n",
            " \"something. You can see what I'm good at and what I'm not good at, what my \"\n",
            " 'likes and dislikes are, and from there you can help me find a career I want '\n",
            " \"to pursue. I know you will help me find a career I'm interested in.  In \"\n",
            " 'conclusion, experience is something I want to gain in order to know how to '\n",
            " 'do other things. I want to gain a lot of benefits, because they will lead to '\n",
            " \"good and better things. I really want to find a good career that I'm \"\n",
            " 'interested in so I can manage myself. I know if you were to come to my '\n",
            " 'school and talk to me, and let me join your internship, I would be able to '\n",
            " 'gain all these things. ')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.5\n",
            "original:  3.0\n",
            "('Being yourself is being true to yourself and to others for example. When '\n",
            " \"you're hanging out with a group of people. Don't act like someone else but \"\n",
            " \"yourself because you will get caught for trying to be someone that you're \"\n",
            " \"not and get made fun of for being something that you're not. It's better to \"\n",
            " 'be yourself because you want people to like who you really are. Not someone '\n",
            " \"you ain't your just lying to yourself and others.  Ralph Waldo Emerson was a \"\n",
            " \"Author who believe ''to be yourself in a world that is constantly trying to \"\n",
            " \"make you something else is the greatest accomplishment''. I agree with that \"\n",
            " 'statement but not so many could say the same. There is many human on this '\n",
            " 'planet who cant accomplishment being their self than being someone else than '\n",
            " 'their self .  Many people struggle to be their self because of society. '\n",
            " 'Society brain washes people to be someone else than being their self.  '\n",
            " 'Nowadays being yourself is lame and being someone else is Amazing to some '\n",
            " 'people. Their is con on being someone else like lying to people until they '\n",
            " 'fine out who you really are. Than they might not like who you really are '\n",
            " 'then your feelings are hurt . Therefore your friendless and hurt ,But you '\n",
            " 'could always pick yourself up by being yourself. Than by over time people '\n",
            " 'will start to notice how you change and they will want to have relationship '\n",
            " \"with you.  It's healthy to have relationships with you being yourself than \"\n",
            " 'being someone else. The reason why i am saying that is because you dont want '\n",
            " 'to be lying to the other person the whole time during the relationship . It '\n",
            " 'will bring problems to the relationships .However its always a good idea to '\n",
            " 'talk it out and come clean.  Being yourself make a huge impacts in people '\n",
            " 'daily life. It could go for the good or the worse its all up to the person. '\n",
            " 'Therefore its important to be yourself always no matter what or whats the '\n",
            " 'cost of it . Also make sure to take pride of being yourself.        ')\n",
            "**********\n",
            "************************\n",
            "phraseology\n",
            "predicted:  3.5\n",
            "original:  3.5\n",
            "('Your principal has decided all students must participate in at least one '\n",
            " 'extracurricular activity. I agree because now days all kids do is stay home '\n",
            " 'and be on there phones and do nothing. I know that because I used to do the '\n",
            " \"same thing before and i didn't like to do anything at all but then I started \"\n",
            " 'playing a sport and it help a lot but i think that. Participating in a '\n",
            " 'extracurricular activity may help you by staying healthy, get you out of '\n",
            " 'trouble,and get you in a good college.  one example is staying healthy by '\n",
            " 'playing a sport you can help prevent a lot of things like maintain a good '\n",
            " 'weight, and keep you from getting sick. Keeping a good weight is good for '\n",
            " 'your health because it keeps you from getting other diseases,more than 1/4 '\n",
            " 'of the people in the U.S. are obese. Why not start at a young age and '\n",
            " 'prevent from being sick and other things. Another thing that can help is '\n",
            " 'eating healthy, we can prevent sickness to in order to do that you might '\n",
            " 'want to think about trying out a new sport.  Another example is getting you '\n",
            " 'out of trouble you can avoid a lot of drama. I learned that social media can '\n",
            " 'get you into a lot of trouble, half of the time a lot of the drama comes '\n",
            " 'from social media. Maybe if you join a club or a sports team you can think '\n",
            " 'before doing something that can get you in trouble. One time my friend made '\n",
            " 'the soccer team but she got in trouble so they kicked her off the team and '\n",
            " 'she learned from her mistake and never got in trouble again. When in your in '\n",
            " \"a cub or playing a sports half of the time you don't have time to be in \"\n",
            " 'drama get in trouble.  Last example is joining a club, working on the year '\n",
            " 'book,serve in the student council and, playing a sport can get you into a '\n",
            " 'good college now a days colleges are looking to see if you have participated '\n",
            " 'in any sports or clubs. When i graduate high school i want to go to college '\n",
            " 'and a study to be a general surgeon and participating in a sport or joining '\n",
            " 'a club can help me get into a college. You meed new people when you join new '\n",
            " 'clubs and make new friend ships. When you want to go into a club or in '\n",
            " 'sports do something that you like not something your friends like or '\n",
            " 'something that can help you in life with.  In conclusion staying '\n",
            " 'healthy,getting out of trouble,and going into a new college can help you '\n",
            " 'when you participate in a extracurricular activity. staying healthy by '\n",
            " 'playing a sports and eating healthy can prevent you from getting sick. '\n",
            " 'Staying out of trouble can avoid a lot of drama from school and social media '\n",
            " 'think before you do something your going to regret . Joining a club or '\n",
            " 'participating in a sport can help you get into the college you want and you '\n",
            " 'can meet new people and make new friend ships.')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.5\n",
            "original:  4.0\n",
            "('Technology has had positive effects on people because you can use cellphones '\n",
            " 'to interact people, you can also be shopping at home without having to leave '\n",
            " 'your house, and also if you are a gamer you can also play with people from '\n",
            " \"around the world. That's why technology has had a positive effects on \"\n",
            " 'people.  Technology is a big impact on people because phones can do '\n",
            " 'anything. You can be in video call with friends and family without having to '\n",
            " 'leave your house. You can also call your family with just your phone. One '\n",
            " 'last thing you can do with phones is that you can make group chats with your '\n",
            " 'friends and family. You can be playing games with your friends or you can '\n",
            " 'just chat with them.  With the important of technology you can also do '\n",
            " 'shopping. You can shop without having to leave your home at all. If you are '\n",
            " 'from another country you can shop from around the world and you can buy '\n",
            " 'things that represent your country and feel like home. One last thing you '\n",
            " 'can do with shopping online is that can order food from any restaurant and '\n",
            " 'it will get sent right to your home. you can also send stuff to your friends '\n",
            " 'and family by just sending it to them  With technology if your a gamer like '\n",
            " 'myself you can play with anyone from around the world. With gaming you can '\n",
            " 'play with your friends and you can be talking and playing at the same time. '\n",
            " 'Also with your gaming system you can also watch hulu, and with hulu can '\n",
            " 'watch movies without having to go to the movie theater. Also with gaming '\n",
            " 'with friends is that you can just have a blast while gaming. The '\n",
            " 'counterclaim will be what if your not a gamer? If your not a gamer then you '\n",
            " 'can take school at home without having to leave your house.  In conclusion i '\n",
            " 'agree that technology has had positive effects on people because it has '\n",
            " 'brought us cellphones to connect people from around the world. You can also '\n",
            " 'shop online without having to leave your home. You can also be gaming with '\n",
            " \"people from around the world. That's why technology has had a positive \"\n",
            " 'impact on peoples lives.             ')\n",
            "**********\n",
            "************************\n",
            "grammar\n",
            "predicted:  3.5\n",
            "original:  3.5\n",
            "('Students chould not be required to take a music, a drama or an art class. '\n",
            " 'Student should only be required to take classes that they actually need. '\n",
            " 'Having to take those classes just adds classes you need to graduate. It is '\n",
            " 'also all a waist of time if the students are not actually in to it.  '\n",
            " 'Firstly, these classes are just extra classes that we dont really need. In '\n",
            " 'my opnion, I believe that student should be able to graduate highschool with '\n",
            " 'the classes they need. English, Math, History and Science are all classes '\n",
            " \"that can support them when they go to college. If student don't take these \"\n",
            " 'classes they may also graduate ealier then they are supposed to. For '\n",
            " 'example, I go to a highschool where I get the credits I need and I am able '\n",
            " 'to graduate a year earlier. Which I think everyone should have the chance '\n",
            " 'too.  Lastly, if a student is not interested in one of these classes they '\n",
            " \"won't try. Even if they do try and fail then its just holding them back. \"\n",
            " \"They will start stressing over it when they won't actually end up needing \"\n",
            " 'it. Student will also consume most of their time bringing up their grade in '\n",
            " 'these classes that they will not work on other classes. Then they will end '\n",
            " 'up failing.  On the other hand, some might say these classes should be '\n",
            " 'required because student might find interest in one of those and would like '\n",
            " 'to persue it after graduating. I think that if a student is interested then '\n",
            " 'they should be allowed to take the class of your choice. However, if your '\n",
            " 'not then you should not be pushed to take them when you dont want to.  In '\n",
            " 'conclusion, student should not be forced to take elcective classes. If they '\n",
            " 'want to they should but if not then they shouldnt need it to graduate. '\n",
            " 'Electives are just extra classes needed to graduate and they also have no '\n",
            " 'pont if the student are not actually interested. po p')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  4.0\n",
            "('By extending the school day two hours, students and teachers will have more '\n",
            " 'advantages to learn and to teach.  I agree to follow this model by extending '\n",
            " 'the school day two hours. There are many reasons of why it will be better '\n",
            " 'and will benefit us as students. One of the reasons is that we will have '\n",
            " 'more time in the weekend to review our notes, homework, and things that we '\n",
            " 'need help with. Another reason is that we will be doing the same forty hours '\n",
            " 'of school even if we will have a four-day school week. It also will benefit '\n",
            " 'teachers by increasing their time to review test or projects made by the '\n",
            " 'students.  Most of the time there are things at school that we do not really '\n",
            " 'understand, and a four-day school week will give us more time to study and '\n",
            " 'review these things at home. We the students have the opportunity to go to '\n",
            " 'school and graduate, but also some of us have obligations and '\n",
            " 'responsibilities. For example in my personal life, I have to work after '\n",
            " 'school everyday. And most of the time when I get home, I feel tired and I '\n",
            " 'just go to sleep, I forget if I have homework or not. Therefore this model '\n",
            " 'will give us more time to work and being less worry about going to school '\n",
            " 'five-day week. We can concentrate at school four days and the other day we '\n",
            " 'can work and do homework or projects when we have to.  Also a four-day '\n",
            " 'school week will benefit us because we will be doing the same forty hours. '\n",
            " 'Therefore our grades and education would not change. And I do not think that '\n",
            " 'is necessary to study all five days, it is not about how many days do you go '\n",
            " 'to school, is about how you take advantages from it. For example if you go '\n",
            " 'to school everyday just to talk with your teammates, is like you were '\n",
            " 'absent. For that reason I agree to extend the two hours of school, that way '\n",
            " 'we can concentrate four days and having in mind that we will have three days '\n",
            " 'to study or to keep learning at home.  Another reason of why I agree to '\n",
            " 'extend the school day, is because it will benefit the teachers also. It will '\n",
            " 'benefit the teachers by giving them more time to review and grade homework, '\n",
            " 'projects or test that students took in the class. It also will give us the '\n",
            " 'opportunity to spend more time with our families and people around us. For '\n",
            " 'example, I work with my father in construction, and I almost do not see him '\n",
            " 'all day until the night. This four-day school week, will give me the '\n",
            " 'opportunity to spend a entire day working with him without being worry about '\n",
            " 'the school for a day. And just like me, there is a lot of people who will be '\n",
            " 'benefit from it.  Finally, school should be extended two hours day, that way '\n",
            " 'we can have more time in the weekend to prepare for tests, teachers will '\n",
            " 'have more time to grade them. And we will have three days to spend with our '\n",
            " 'families.                     ')\n",
            "**********\n",
            "************************\n",
            "conventions\n",
            "predicted:  2.5\n",
            "original:  2.5\n",
            "('Can we accomplish more if we are always doing something ?  Sometimes we are '\n",
            " \"lazy and we don't want to do nothing, but if we are doing always something \"\n",
            " 'we can be more stronger and helpful to the citizen.  Sometimes we are lazy, '\n",
            " 'but that is bad in our life because we has to learn about this life and '\n",
            " 'prepare for the future and other things. One day we would grow up and we '\n",
            " \"would does not know anything and we're gonna fall in our life, therefor i \"\n",
            " 'told them this advice.  Thomas Jefferson wrote, \"Determine never to be '\n",
            " 'idle...it is wonderful how much may be done if we are always doing.\"  we can '\n",
            " 'be stronger if we are always doing something because we can learn about '\n",
            " 'everything that we did and we can get strength to be better, also we can be '\n",
            " 'a adviser to other peoples for example: Kids, Teenager, also Adults.  We can '\n",
            " 'be helpful if we are always doing something because one day that we fall '\n",
            " 'down, also we can stand up more stronger and healthy. We can help person '\n",
            " 'with our experiences, also we can help kids give them a advise because we '\n",
            " 'want a good, strong citizen in this world and they can make it better, and '\n",
            " 'help each other.  In conclusion we can be stronger, healthy for people that '\n",
            " \"don't know anything in this life. We can do better things for our future, \"\n",
            " 'furthermore kids will be our future, therefore we are gonna fight for them, '\n",
            " \"and their future because if we are lazy and we don't do anything we are \"\n",
            " 'gonna fail. We need more activities in our life and do something all the '\n",
            " 'time because for that we can learn ah be adviser, also we need a break but '\n",
            " 'we has to continue learning and to be success in our life, and complete our '\n",
            " 'dreams.')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  3.5\n",
            "(\"The school board shouldn't add one and half hours to school each day. To \"\n",
            " \"begin one reason i think they shouldn't is that a lot of kids who play \"\n",
            " \"sports or clubs after school might not be able to because they don't have \"\n",
            " \"time to learn about how life is and how difficult it is and people's life \"\n",
            " 'difficulties. One example is that some kids play videos and since they dont '\n",
            " 'have lots of time out side of school they might just play video game instead '\n",
            " 'of sports and if you give them more time out of school more opportunities '\n",
            " 'students will have. secondly Students will be more tired and less focus '\n",
            " 'because if students have more time in school the more earlier they will have '\n",
            " \"to sleep and most students don't fall asleep early also students have \"\n",
            " 'homework since they well most likely be tired from school they might take a '\n",
            " 'nap and there might either wake up to late to do homework or not have time '\n",
            " 'to finish all there homework. Thirdly more students will not want to be in '\n",
            " \"school and may drop out from either too much stress or they just don't want \"\n",
            " 'to be in school because the longer time there in school the more tired they '\n",
            " 'are and less time they have to do what makes them feel relaxed or not have '\n",
            " 'time to do what they love to do. students also might not have time to make '\n",
            " 'friends because there focusing on school and it might ruin there social '\n",
            " 'skill and conversation with strangers out side of school. Lastly less amount '\n",
            " 'of time they have to spend with there families because they would have to go '\n",
            " 'to school for extra time and as soon as they get home they have to do '\n",
            " 'homework and honestly by the time there done there going to be most likely '\n",
            " 'tired to do anything beside resting or sleeping. Also some students have '\n",
            " 'younger siblings to take care of after school so that would put more stress '\n",
            " 'on a student and either a family would have to pay for a baby sitter or some '\n",
            " \"families don't have money to pay for one so parents might take there student \"\n",
            " 'out of school just to take care of there sibling and so the extra time in '\n",
            " \"school wouldn't help him. To conclude those are the main reasons why I think \"\n",
            " \"we shouldn't have more school hours in school.  \")\n",
            "**********\n",
            "************************\n",
            "cohesion\n",
            "% Predicting too high: 0.2222222222222222\n",
            "% Predicted correctly: 0.31800766283524906\n",
            "% Predicting too low: 0.45977011494252873\n",
            "****\n",
            "syntax\n",
            "% Predicting too high: 0.194125159642401\n",
            "% Predicted correctly: 0.384418901660281\n",
            "% Predicting too low: 0.421455938697318\n",
            "****\n",
            "vocabulary\n",
            "% Predicting too high: 0.24393358876117496\n",
            "% Predicted correctly: 0.44316730523627074\n",
            "% Predicting too low: 0.3128991060025543\n",
            "****\n",
            "phraseology\n",
            "% Predicting too high: 0.2669220945083014\n",
            "% Predicted correctly: 0.40485312899106\n",
            "% Predicting too low: 0.3282247765006386\n",
            "****\n",
            "grammar\n",
            "% Predicting too high: 0.25925925925925924\n",
            "% Predicted correctly: 0.37292464878671777\n",
            "% Predicting too low: 0.367816091954023\n",
            "****\n",
            "conventions\n",
            "% Predicting too high: 0.14942528735632185\n",
            "% Predicted correctly: 0.3665389527458493\n",
            "% Predicting too low: 0.4840357598978289\n",
            "****\n",
            "cohesion\n",
            "length: 2\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 6\n",
            "% Predicting the above (1.5): 0.8333333333333334\n",
            "% Predicting the same (1.5): 0.16666666666666666\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 64\n",
            "% Predicting the above (2.0): 0.734375\n",
            "% Predicting the same (2.0): 0.234375\n",
            "% Predicting the below (2.0): 0.03125\n",
            "****\n",
            "length: 162\n",
            "% Predicting the above (2.5): 0.4691358024691358\n",
            "% Predicting the same (2.5): 0.41975308641975306\n",
            "% Predicting the below (2.5): 0.1111111111111111\n",
            "****\n",
            "length: 219\n",
            "% Predicting the above (3.0): 0.182648401826484\n",
            "% Predicting the same (3.0): 0.45662100456621\n",
            "% Predicting the below (3.0): 0.3607305936073059\n",
            "****\n",
            "length: 198\n",
            "% Predicting the above (3.5): 0.020202020202020204\n",
            "% Predicting the same (3.5): 0.30303030303030304\n",
            "% Predicting the below (3.5): 0.6767676767676768\n",
            "****\n",
            "length: 93\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.053763440860215055\n",
            "% Predicting the below (4.0): 0.946236559139785\n",
            "****\n",
            "length: 35\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 4\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "syntax\n",
            "length: 4\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 5\n",
            "% Predicting the above (1.5): 0.6\n",
            "% Predicting the same (1.5): 0.4\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 96\n",
            "% Predicting the above (2.0): 0.7083333333333334\n",
            "% Predicting the same (2.0): 0.2708333333333333\n",
            "% Predicting the below (2.0): 0.020833333333333332\n",
            "****\n",
            "length: 149\n",
            "% Predicting the above (2.5): 0.28187919463087246\n",
            "% Predicting the same (2.5): 0.610738255033557\n",
            "% Predicting the below (2.5): 0.10738255033557047\n",
            "****\n",
            "length: 257\n",
            "% Predicting the above (3.0): 0.1245136186770428\n",
            "% Predicting the same (3.0): 0.5252918287937743\n",
            "% Predicting the below (3.0): 0.35019455252918286\n",
            "****\n",
            "length: 170\n",
            "% Predicting the above (3.5): 0.01764705882352941\n",
            "% Predicting the same (3.5): 0.24705882352941178\n",
            "% Predicting the below (3.5): 0.7352941176470589\n",
            "****\n",
            "length: 81\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.06172839506172839\n",
            "% Predicting the below (4.0): 0.9382716049382716\n",
            "****\n",
            "length: 19\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 2\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "vocabulary\n",
            "vocabulary==1.0 has 0 rows\n",
            "****\n",
            "length: 4\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 26\n",
            "% Predicting the above (2.0): 0.8076923076923077\n",
            "% Predicting the same (2.0): 0.19230769230769232\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 101\n",
            "% Predicting the above (2.5): 0.6336633663366337\n",
            "% Predicting the same (2.5): 0.3465346534653465\n",
            "% Predicting the below (2.5): 0.019801980198019802\n",
            "****\n",
            "length: 305\n",
            "% Predicting the above (3.0): 0.29180327868852457\n",
            "% Predicting the same (3.0): 0.580327868852459\n",
            "% Predicting the below (3.0): 0.12786885245901639\n",
            "****\n",
            "length: 194\n",
            "% Predicting the above (3.5): 0.061855670103092786\n",
            "% Predicting the same (3.5): 0.5309278350515464\n",
            "% Predicting the below (3.5): 0.4072164948453608\n",
            "****\n",
            "length: 122\n",
            "% Predicting the above (4.0): 0.00819672131147541\n",
            "% Predicting the same (4.0): 0.20491803278688525\n",
            "% Predicting the below (4.0): 0.7868852459016393\n",
            "****\n",
            "length: 24\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.08333333333333333\n",
            "% Predicting the below (4.5): 0.9166666666666666\n",
            "****\n",
            "length: 7\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "phraseology\n",
            "length: 3\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 3\n",
            "% Predicting the above (1.5): 0.6666666666666666\n",
            "% Predicting the same (1.5): 0.3333333333333333\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 74\n",
            "% Predicting the above (2.0): 0.7027027027027027\n",
            "% Predicting the same (2.0): 0.2702702702702703\n",
            "% Predicting the below (2.0): 0.02702702702702703\n",
            "****\n",
            "length: 152\n",
            "% Predicting the above (2.5): 0.5263157894736842\n",
            "% Predicting the same (2.5): 0.4407894736842105\n",
            "% Predicting the below (2.5): 0.03289473684210526\n",
            "****\n",
            "length: 242\n",
            "% Predicting the above (3.0): 0.256198347107438\n",
            "% Predicting the same (3.0): 0.5495867768595041\n",
            "% Predicting the below (3.0): 0.19421487603305784\n",
            "****\n",
            "length: 180\n",
            "% Predicting the above (3.5): 0.05\n",
            "% Predicting the same (3.5): 0.42777777777777776\n",
            "% Predicting the below (3.5): 0.5222222222222223\n",
            "****\n",
            "length: 107\n",
            "% Predicting the above (4.0): 0.009345794392523364\n",
            "% Predicting the same (4.0): 0.17757009345794392\n",
            "% Predicting the below (4.0): 0.8130841121495327\n",
            "****\n",
            "length: 18\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 4\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "grammar\n",
            "length: 3\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 6\n",
            "% Predicting the above (1.5): 0.6666666666666666\n",
            "% Predicting the same (1.5): 0.3333333333333333\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 95\n",
            "% Predicting the above (2.0): 0.6947368421052632\n",
            "% Predicting the same (2.0): 0.28421052631578947\n",
            "% Predicting the below (2.0): 0.021052631578947368\n",
            "****\n",
            "length: 181\n",
            "% Predicting the above (2.5): 0.43646408839779005\n",
            "% Predicting the same (2.5): 0.4585635359116022\n",
            "% Predicting the below (2.5): 0.10497237569060773\n",
            "****\n",
            "length: 193\n",
            "% Predicting the above (3.0): 0.22279792746113988\n",
            "% Predicting the same (3.0): 0.49740932642487046\n",
            "% Predicting the below (3.0): 0.27979274611398963\n",
            "****\n",
            "length: 176\n",
            "% Predicting the above (3.5): 0.045454545454545456\n",
            "% Predicting the same (3.5): 0.42045454545454547\n",
            "% Predicting the below (3.5): 0.5340909090909091\n",
            "****\n",
            "length: 96\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.10416666666666667\n",
            "% Predicting the below (4.0): 0.8958333333333334\n",
            "****\n",
            "length: 25\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 8\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "conventions\n",
            "length: 1\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 5\n",
            "% Predicting the above (1.5): 0.8\n",
            "% Predicting the same (1.5): 0.2\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 85\n",
            "% Predicting the above (2.0): 0.5058823529411764\n",
            "% Predicting the same (2.0): 0.4\n",
            "% Predicting the below (2.0): 0.09411764705882353\n",
            "****\n",
            "length: 155\n",
            "% Predicting the above (2.5): 0.34838709677419355\n",
            "% Predicting the same (2.5): 0.5612903225806452\n",
            "% Predicting the below (2.5): 0.09032258064516129\n",
            "****\n",
            "length: 240\n",
            "% Predicting the above (3.0): 0.0625\n",
            "% Predicting the same (3.0): 0.5416666666666666\n",
            "% Predicting the below (3.0): 0.3958333333333333\n",
            "****\n",
            "length: 168\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.19642857142857142\n",
            "% Predicting the below (3.5): 0.8035714285714286\n",
            "****\n",
            "length: 96\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.020833333333333332\n",
            "% Predicting the below (4.0): 0.9791666666666666\n",
            "****\n",
            "length: 26\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 7\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "cohesion\n",
            "% Predicting within .5: 0.8288633461047255\n",
            "syntax\n",
            "% Predicting within .5: 0.8646232439335888\n",
            "vocabulary\n",
            "% Predicting within .5: 0.9195402298850575\n",
            "phraseology\n",
            "% Predicting within .5: 0.8710089399744572\n",
            "grammar\n",
            "% Predicting within .5: 0.8212005108556832\n",
            "conventions\n",
            "% Predicting within .5: 0.8250319284802043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_compare_v1 = pd.read_csv(\"predict_bert_12.csv\")\n",
        "for component in label_cols:\n",
        "  print(pd.crosstab(df_compare_v1[component], df_compare_v1[\"transformed_pred_\"+component], margins=True))\n",
        "  print()"
      ],
      "metadata": {
        "id": "soKr77IRK5Lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zN5pnfXQua0e"
      },
      "source": [
        "BERTweet with all layers frozen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed parameters\n",
        "dense_dim = 6\n",
        "number_of_splits = 2\n",
        "random_state = 2023\n",
        "mse_loss = MCRMSE\n",
        "mse_metrics = MCRMSE\n",
        "model_name_list = ['Bert', 'Bertweet'] # Roberta\n",
        "\n",
        "df_train = pd.read_csv('df_train_split.csv')\n",
        "df_test = pd.read_csv('df_test_split.csv')\n",
        "print(f\"Length of train data : {len(df_train)}\")\n",
        "print(f\"Length of test data : {len(df_test)}\")\n",
        "y_test = np.array(df_test[label_cols], dtype = \"float32\")"
      ],
      "metadata": {
        "id": "osNV7GVVDk2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4339e907-b116-41d5-aa00-183de8ecd3fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train data : 3128\n",
            "Length of test data : 783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable parameter dictionary\n",
        "param_list = [   # Completely frozen base layer\n",
        "                 {'epochs'                  : 10,\n",
        "                  'batch_size'              : 8,\n",
        "                  'learning_rate'           : 1e-5,\n",
        "                  'validation_split'        : .2,\n",
        "                  'dropout'                 : .1,\n",
        "                  'number_of_hidden_layers' : 2,\n",
        "                  'hidden_layer_node_count' : 64,\n",
        "                  'retrain_layer_count'     : 0\n",
        "                 }\n",
        "             ]"
      ],
      "metadata": {
        "id": "_QPrhWegQZfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, param_entry in enumerate(param_list):\n",
        "    MAX_LEN = 512\n",
        "    epoch_val = param_entry['epochs']\n",
        "    batch_size_val = param_entry['batch_size']\n",
        "    learning_rate_val = param_entry['learning_rate']\n",
        "    validation_split_val = param_entry['validation_split']\n",
        "    dropout_val = param_entry['dropout']\n",
        "    number_of_hidden_layers_val = param_entry['number_of_hidden_layers']\n",
        "    hidden_layer_node_count_val = param_entry['hidden_layer_node_count']\n",
        "    retrain_layer_count_val = param_entry['retrain_layer_count']\n",
        "\n",
        "    print(\"************************\")\n",
        "    print(f\"Iteration : {idx + 1}\")\n",
        "    print(\"Parameters...\")\n",
        "    print(f\"Epochs : {epoch_val}\")\n",
        "    print(f\"Batch size : {batch_size_val}\")\n",
        "    print(f\"Learning rate : {learning_rate_val}\")\n",
        "    print(f\"Validation split : {validation_split_val}\")\n",
        "    print(f\"Dropout : {dropout_val}\")\n",
        "    print(f\"Number of hidden layers : {number_of_hidden_layers_val}\")\n",
        "    print(f\"Hidden layer node count : {hidden_layer_node_count_val}\")\n",
        "    print(f\"Retrain layer count : {retrain_layer_count_val}\")\n",
        "    print(\"************************\")\n",
        "    set_config_param(20230214)\n",
        "\n",
        "    model_tokenizer = AutoTokenizer.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "    model = TFRobertaModel.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "\n",
        "    train_input_ids, train_attention_masks = text_encode(df_train['full_text'], model_tokenizer, MAX_LEN)\n",
        "    test_input_ids, test_attention_masks = text_encode(df_test['full_text'], model_tokenizer, MAX_LEN)\n",
        "\n",
        "    y_train = np.array(df_train[label_cols], dtype = \"float32\")\n",
        "\n",
        "    bertweet = build_regression_model(loss= \"MCRMSE\", \n",
        "                                      model_name = \"Bertweet\",\n",
        "                                      dense_dim = 6, \n",
        "                                      MAX_LEN = 512,\n",
        "                                      learning_rate = learning_rate_val,\n",
        "                                      dropout=dropout_val,\n",
        "                                      number_of_hidden_layers = number_of_hidden_layers_val,\n",
        "                                      hidden_layer_node_count = hidden_layer_node_count_val,\n",
        "                                      retrain_layer_count = retrain_layer_count_val)\n",
        "    bertweet.summary()\n",
        "\n",
        "    history_v1 = bertweet.fit((train_input_ids, train_attention_masks),\n",
        "                  y_train,\n",
        "                  batch_size = batch_size_val,     \n",
        "                  epochs = epoch_val,\n",
        "                  validation_split = validation_split_val\n",
        "                  )\n",
        "\n",
        "    history_v1_df = pd.DataFrame(history_v1.history)\n",
        "\n",
        "    score_v1 = bertweet.evaluate([test_input_ids, test_attention_masks], \n",
        "                    y_test\n",
        "                  ) \n",
        "\n",
        "    predictions_v1 = bertweet.predict([test_input_ids, test_attention_masks])\n",
        "    df_pred_v1 = pd.DataFrame(predictions_v1, columns=['pred_' + c for c in label_cols])\n",
        "\n",
        "    for col in label_cols:\n",
        "      df_pred_v1['transformed_pred_' + col] = df_pred_v1['pred_' + col].apply(lambda x : roundPartial(x, .5))\n",
        "    \n",
        "    df_compare_v1= pd.merge(df_test, df_pred_v1, left_index = True, right_index = True)\n",
        "    df_compare_v1.to_csv(\"predict_bertweet_0.csv\", index=False)\n",
        "\n",
        "    all = []\n",
        "    for col in label_cols:\n",
        "      all.append(((df_compare_v1[col]-df_compare_v1[\"transformed_pred_\"+col]).pow(2).mean())**(0.5))\n",
        "    RMSE_scaled = statistics.fmean(all)\n",
        "    print(f\"RMSE_scaled: {RMSE_scaled}\")\n",
        "\n",
        "    for label in label_cols:\n",
        "      print(label)\n",
        "      hall_of_fame(df_compare_v1,label,1)\n",
        "      print(\"************************\")\n",
        "      hall_of_shame(df_compare_v1,label,1)\n",
        "      print(\"************************\")\n",
        "    for component in label_cols:\n",
        "      print(component)\n",
        "      print(\"% Predicting too high: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\">\"+component))/len(df_compare_v1)))\n",
        "      print(\"% Predicted correctly: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"==\"+component))/len(df_compare_v1)))\n",
        "      print(\"% Predicting too low: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"<\"+component))/len(df_compare_v1)))\n",
        "      print(\"****\")\n",
        "    # Predicting too high or low for every score? \n",
        "\n",
        "    # for component in label_cols:\n",
        "    #   print(component)\n",
        "\n",
        "    #   for score in [1.0,1.5,2.0,2.5,3.0,3.5,4.0,4.5,5.0]:\n",
        "    #     if len(df_compare_v1[df_compare_v1[component]==score])==0:\n",
        "    #       print(component+\"==\"+str(score)+\" has 0 rows\")\n",
        "    #     else:\n",
        "    #       print(f'length: {len(df_compare_v1[df_compare_v1[component]==score])}')\n",
        "    #       print(\"% Predicting the above (\"+str(score)+\"): \" +\n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) &\n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]>score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #       print(\"% Predicting the same (\"+str(score)+\"): \" +\n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) & \n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]==score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #       print(\"% Predicting the below (\"+str(score)+\"): \" + \n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) & \n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]<score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #     print(\"****\")\n",
        "    for component in label_cols:\n",
        "      print(component)\n",
        "      print(\"% Predicting within .5: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"<=(\"+component+\"+.5) and transformed_pred_\"+component+\">=(\"+component+\"-.5)\"))/len(df_compare_v1)))"
      ],
      "metadata": {
        "id": "9ldRv4D6QZ1o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0f99a5ce99684adcb74b6d997dd4f6b6",
            "63e3ad6b2f714d83a9371224fc036969",
            "841c04a5892848feaccb9c5f8db87714",
            "15c166dfb76a4c778e078f4a798a1667",
            "1ba6bc91c94a439f811d817a996a3f89",
            "f5be82c8821c48d3b1cb9017841f0d77",
            "2d7c191b35fa4f10be56e5d6ea621584",
            "9719939c3b0946748256bd92fd9534c6",
            "28f0f0f927aa4d6d80a45e4bf15f1cfc",
            "8cc709c0cbe2412d8d281ab9f84463b1",
            "444d03ee8b4e4cb5a2ee62e769bc01a1",
            "0e7917045672490b88288cc47fb111e8",
            "f06b3a456911410e835a1ab4feca72e0",
            "28309e7c29b242aeb49361bf8b5127d8",
            "30719f59a4db452c939c3e8a54d30798",
            "85294c2326b64a748275411f5201e159",
            "9d92a01d03eb42098d864ef0bc145add",
            "a8ba13da20be4372810a8a1359ca557c",
            "5a1a84d5368e4a85bc2c5f3de605b20f",
            "fd26e87afb974ebdbfa5f67460712499",
            "37234288af2a444f9317d1a53376cde4",
            "4393074977724b5d9c7514e6212b25e8",
            "0c72c905ae934db2b34b4ab00ac577d8",
            "0a7b38b0978c41f3acd74bc82be39def",
            "b6edc4817bf3431c991d8d923a89ff1e",
            "f68553ac3b3b4ccfb4cdc67dc1a931cd",
            "10cc1b639ff04b5d823e04b6ba32c668",
            "e3e7fe0be36140889edc96805cdd3f9a",
            "b400ff9e85084e168d7a5d9e28b3f3b5",
            "b19cdfc0d0c149b4a7b873f5da0b5ba5",
            "e84ed1195b234049818f31377d9afaf6",
            "3fa790ed2e894e888bbeb3e9013770b8",
            "13993572354848a4b2c3b9317ebc4faa",
            "5876ad8f5e74428ca6002e0ae9097745",
            "c4936d6bed14436a88931c7775e18ff7",
            "6a6a2a8153224a94a0476b164bde2b13",
            "ea446597da424b29a15cddad8b6e0ae2",
            "901ee533fc4147fd94a01cf6d0710e65",
            "234fef11af4a4d5d9c1da7b50bcead21",
            "2965235ba8cb4a8abaafb19e5195ce01",
            "304b52a248364e85adf8ad5f64505313",
            "c5610672da1f4f7987ee84d17f0b3665",
            "a682d41932d54145a2802a4a47ba920e",
            "3a1461733a2f4d9ab2d5123f73c4718a"
          ]
        },
        "outputId": "96312c46-0930-4cb3-f37c-9a199d9d125f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************************\n",
            "Iteration : 1\n",
            "Parameters...\n",
            "Epochs : 10\n",
            "Batch size : 8\n",
            "Learning rate : 1e-05\n",
            "Validation split : 0.2\n",
            "Dropout : 0.1\n",
            "Number of hidden layers : 2\n",
            "Hidden layer node count : 64\n",
            "Retrain layer count : 0\n",
            "************************\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/558 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f99a5ce99684adcb74b6d997dd4f6b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/843k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e7917045672490b88288cc47fb111e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/bpe.codes:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c72c905ae934db2b34b4ab00ac577d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/740M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5876ad8f5e74428ca6002e0ae9097745"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters : 0\n",
            "Number of non-trainable parameters : 134899968\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_roberta_model_1 (TFRobertaM  TFBaseModelOutputWi  134899968  ['input_ids[0][0]',              \n",
            " odel)                          thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_roberta_model_1[0][0]']     \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " hidden_layer_1 (Dense)         (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_layer_1 (Dropout)      (None, 64)           0           ['hidden_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            " hidden_layer_2 (Dense)         (None, 64)           4160        ['dropout_layer_1[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_layer_2 (Dropout)      (None, 64)           0           ['hidden_layer_2[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 6)            390         ['dropout_layer_2[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 134,953,734\n",
            "Trainable params: 53,766\n",
            "Non-trainable params: 134,899,968\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_roberta_model_1 (TFRobertaM  TFBaseModelOutputWi  134899968  ['input_ids[0][0]',              \n",
            " odel)                          thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_roberta_model_1[0][0]']     \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " hidden_layer_1 (Dense)         (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_layer_1 (Dropout)      (None, 64)           0           ['hidden_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            " hidden_layer_2 (Dense)         (None, 64)           4160        ['dropout_layer_1[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_layer_2 (Dropout)      (None, 64)           0           ['hidden_layer_2[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 6)            390         ['dropout_layer_2[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 134,953,734\n",
            "Trainable params: 53,766\n",
            "Non-trainable params: 134,899,968\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "313/313 [==============================] - 177s 515ms/step - loss: 3.0059 - MCRMSE: 3.0057 - val_loss: 2.7446 - val_MCRMSE: 2.7494\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 159s 508ms/step - loss: 2.4625 - MCRMSE: 2.4624 - val_loss: 2.1009 - val_MCRMSE: 2.1056\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 161s 513ms/step - loss: 1.7884 - MCRMSE: 1.7881 - val_loss: 1.3632 - val_MCRMSE: 1.3672\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 162s 518ms/step - loss: 1.2083 - MCRMSE: 1.2080 - val_loss: 0.8587 - val_MCRMSE: 0.8614\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 163s 522ms/step - loss: 0.9832 - MCRMSE: 0.9832 - val_loss: 0.6731 - val_MCRMSE: 0.6747\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 149s 476ms/step - loss: 0.9135 - MCRMSE: 0.9135 - val_loss: 0.6302 - val_MCRMSE: 0.6317\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 148s 474ms/step - loss: 0.8971 - MCRMSE: 0.8970 - val_loss: 0.6178 - val_MCRMSE: 0.6192\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 163s 520ms/step - loss: 0.8905 - MCRMSE: 0.8905 - val_loss: 0.6102 - val_MCRMSE: 0.6118\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 163s 522ms/step - loss: 0.8614 - MCRMSE: 0.8614 - val_loss: 0.6044 - val_MCRMSE: 0.6062\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 163s 522ms/step - loss: 0.8428 - MCRMSE: 0.8427 - val_loss: 0.5995 - val_MCRMSE: 0.6012\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.6029 - MCRMSE: 0.6030\n",
            "25/25 [==============================] - 34s 1s/step\n",
            "RMSE_scaled: 0.6875804283199073\n",
            "cohesion\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('although former British minister Winston Churchill says \"success consists of '\n",
            " 'going from failure to failure without loss of enthusiasm.\" actually to get '\n",
            " 'to success sometimes does take failure to get it. actually this is very true '\n",
            " 'for people who never give and work hard even after they fail time and time '\n",
            " 'and again. for example when you fail at something to keep trying after till '\n",
            " \"you succeed. some people think if you fail you won't be successful that is \"\n",
            " 'not true. if you never give up you will be successful. another example when '\n",
            " 'you fall you always get back up and keep going and pushing forward. only you '\n",
            " \"can decide if you want to always fail or try harder. to get success it ain't \"\n",
            " 'easy. there is a saying nothing that is easy to get is wroth having. this '\n",
            " 'relates to what Churchill said. Winston Churchill is a wise man and i would '\n",
            " 'agree with him. everything he said about failing and being successful after '\n",
            " 'is true. they are so many successful people who have failed plenty of times '\n",
            " 'in their life. it happens to all people no can be perfect at what they want '\n",
            " 'or do in their life. inconclousion Winston Churchill is a wise man for his '\n",
            " 'saying. his saying can motivate many people who feel like giving up after '\n",
            " 'failing. ')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  2.5\n",
            "('A local workplace that you would like to pursue convince employer include '\n",
            " 'why you like this job .  My First, reason is allowing students to explore '\n",
            " 'the local bakery exploreing the local bakery can help students see what a '\n",
            " 'person dose in the a local bakery. The students can learn new things in a '\n",
            " 'local bakery for example my friend learn new things in the local bakery. '\n",
            " 'This can help students learn better things in the local bakery here is my '\n",
            " 'second reason.  My Next, reason is working at a local pursue bakery working '\n",
            " 'at a local bakery is helpful for me because I can make new friends and talk '\n",
            " 'with others. I can learn new stuff and do better in the local bakery.  for '\n",
            " 'an example I made new friends and talk with others at the local bakery. Here '\n",
            " 'are my other reason of allowing the exmployer a visit .  My Last,  reason is '\n",
            " 'allowing the employer for a visit at the local bakery allowing the employer '\n",
            " 'to come and visit. This would be very helpfull for me because the employer '\n",
            " 'can come see the bakery. And see how the students can also learn what a '\n",
            " 'bakery can do inside. I chose this job becuase it was a creativ job for me . '\n",
            " 'For an example this job help me in learning things and stuff . In closing '\n",
            " 'this is what a local workplace I chose . ')\n",
            "**********\n",
            "************************\n",
            "syntax\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('I am not agree with those educators that say, the summer break is too long '\n",
            " \"and the students can't retain imformation as easily when they return in the \"\n",
            " \"fall. The summer break is made to a students's benefit, it help the students \"\n",
            " 'as a relajation during the summer. The students have to spend time with '\n",
            " 'their family a lot as possible they can. Some of them need to make money, '\n",
            " 'and they take the summer break to make it. That is why I am not agree the '\n",
            " \"educators that does't wants the summer break long.  One reason,the students \"\n",
            " 'are in the school almost a whole year, and all that time they are stressed '\n",
            " 'by all the work they have to do in the school. Caming the summer break the '\n",
            " \"students wait it with antusiasm, and work hard to finish the school's work \"\n",
            " \"and enjoy summer break, it help them as a relajation after a school's \"\n",
            " 'stress, they have to forget the school by a mommet, and relax their brains. '\n",
            " \"Second reason, during the school's time the students does't have a lot of \"\n",
            " 'time to spend with their family, and the summer break is a good time of the '\n",
            " 'year to spend it with their dear, persons, friends, classmate, girlfriend, '\n",
            " \"and family. After it, the students are more prepared to star the school's \"\n",
            " 'year concentred at what they have to focus in the school with a clean brain '\n",
            " \",and do all the school's work. Third reason, some students have some \"\n",
            " 'obligations in their homes, for example some of those are: pay cellphone, '\n",
            " 'pay room, buy food, and pay car, so some student take advantages of the '\n",
            " 'summer break to make some money to helps them to pay all their obligations '\n",
            " \"in their homes, and don't take the school's time to spend it in other \"\n",
            " 'obligations, and take their time just to teh schools. Finally, the student '\n",
            " \"does't need the summer break shorter, they have a lot of things to do during \"\n",
            " \"the summer break, and it would't be justly to them, I am againt to the \"\n",
            " 'educators that feel the summer break is too long.')\n",
            "**********\n",
            "************************\n",
            "predicted:  2.0\n",
            "original:  3.5\n",
            "('\"Determine never to be idle...it is wonderful how much may be done if we are '\n",
            " 'always doing,\" a quote from Thomas Jefferson, meaning the more active we '\n",
            " 'are, the more we are able to accomplish. Although many would believe being '\n",
            " 'active would be the obvious answer, there are reasons as to why being '\n",
            " 'inactive may allow us to achieve more. By being inactive, we have plenty of '\n",
            " 'time on our hands to accomplish things, we have the energy to accomplish '\n",
            " 'more, rather than constantly being worked up and doing something, and we '\n",
            " 'also have time to brainstorm ideas.  Constantly doing something does not '\n",
            " 'give us the time we need to accomplish goals. By always have a fixed '\n",
            " 'schedule or always having to do something, we feel as though we connot risk '\n",
            " 'wasting any time by trying to achieve something. Having those few extra '\n",
            " 'minutes out of the day can allow us to create or focus on our hobbies, which '\n",
            " 'then can get us to accomplish things. For example, over the summer, my dad '\n",
            " 'decided to take time out of his job to focus on his love for plants. He then '\n",
            " 'decided to make it his goal to bulid a garden, by taking time out of his '\n",
            " 'very fixed work schedule to do it. By the end on the summer, he had '\n",
            " 'accomplished his goal; just from taking some time off.  Always doing '\n",
            " 'something causes us to lack the energy we need to accomplish things. When '\n",
            " 'constantly doing things and working, we are too tired to achieve anything, '\n",
            " 'because we put all our energy into everthing else we do. We become fatigue '\n",
            " 'and restless when constantly doing something. For example, my mother is '\n",
            " 'always doing something; she goes to class, goes to work, then comes home to '\n",
            " 'clean and cook. She is never able to accomplish anything because she does '\n",
            " 'not have enough energy. When we constantly work, all we want to do after is '\n",
            " 'sleep, rather than causing us to want to accomplish things.  By not always '\n",
            " 'having to do things, we are able to new brainstorm ideas. We can brainstorm '\n",
            " 'goals that we would like to accomplish. When always doing something our '\n",
            " 'minds are focused on other things, rather than focusing on acheiving goals. '\n",
            " 'We dont have time to sit and brainstorm when we are constantly working. Our '\n",
            " 'minds cannot focus on multiple things at once, meaning it does not have '\n",
            " 'space for other thoughts of accomplishments.  Even though many people think '\n",
            " 'that constantly being active helps accomplish more, it is not always true. '\n",
            " 'We can accomplish just as much, or even more when being inactive than always '\n",
            " 'doing something. By being inactive we have the time to accomplish things, we '\n",
            " 'have the energy to achieve more goals, rathan than being tired and restless, '\n",
            " 'and we are able to brainstorm ideas without other thoughts in our minds to '\n",
            " 'distract us.')\n",
            "**********\n",
            "************************\n",
            "vocabulary\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('Though most people think the inactivity serve a purpose however, the people '\n",
            " 'always need to doing things in their lives. All the people need to have '\n",
            " 'something to do in their life. Most people in the world think an inactivity '\n",
            " 'person can have in effect to other people, so the people need to always do '\n",
            " 'something in their life. The people need to have more activity in their '\n",
            " 'life. A activity person can have many success things can change their life '\n",
            " 'and the future a new generation in their families. A person with more '\n",
            " 'activity can be more successful .The inactivity is a person lazy can do not '\n",
            " 'care about doing something their life so, they may be do not care about '\n",
            " 'other people too.  Many people in the world does not have a job , but they '\n",
            " 'do not look for it. The people feels lazy to move around looking for work '\n",
            " 'and they only waste their time doing nothing. The people pass their time '\n",
            " 'without a work so, they are not doing nothing for their future for that many '\n",
            " 'people in the world are very poor. They can have a good future if they do '\n",
            " 'not waste their times doing nothing. In many countries there are people who '\n",
            " 'are very lazy for work, so they going to streets to ask other people give '\n",
            " 'money to them. The people have many opportunities in their life but , they '\n",
            " 'do not think about it. An inactivity person do not care about if they can '\n",
            " 'have a job or not. That kind of people just think have a free times. To be a '\n",
            " 'lazy person do not have any purpose in the life. Many children in the world '\n",
            " 'suffer with their parents because, they do not have a job .The children with '\n",
            " 'young age have to work because, their parents are very inactivity in the '\n",
            " 'their jobs. The inactivity can have a effect in the children because they '\n",
            " 'have to go to streets with parents ask for money to other person.  Most '\n",
            " 'people in world are very lazy. Some students have inactivity in the schools '\n",
            " '.The students when they have to do a work in group, they want to the easy '\n",
            " 'part of the work for that some students have problem when they become '\n",
            " 'adults. Most the students are very lazy so, they want all the things easy. '\n",
            " 'When the students become in adults they think all are going to be easy for '\n",
            " 'them like student years. Sometimes the work is next to them, but they are so '\n",
            " 'lazy for doing any work, so they only avoid the work. The people want to '\n",
            " 'waste their time in easy ways like spend time in home. Sometimes the people '\n",
            " 'want to find a job with easy ways to do it for that many people do not have '\n",
            " 'a job. The students need to be more activity person. To be a inactivity '\n",
            " 'person in young age can have a big a effect in the future. The students need '\n",
            " 'to have a purpose do not have to be inactivity person.  In the world many '\n",
            " 'people are unemployment, so they think that can be better for them. The '\n",
            " 'people can spend more time with their families,but they not need to be lazy. '\n",
            " 'They need to doing something for their country or their families. Many '\n",
            " 'people says if the world have less unemployment the economic can change for '\n",
            " 'a good way. The economic is very important for a future of the countries. If '\n",
            " 'the world can have less inactivity person the economic can change, so the '\n",
            " 'countries can have less poor people.  In conclusion, to be an inactivity '\n",
            " 'person does not have a purpose in life. The people need to always do '\n",
            " 'somethings for their life. If the people always do somethings, that people '\n",
            " 'can change the ways how can be their future life. An activity person always '\n",
            " 'are doing things with a purpose, so the person can be successful in '\n",
            " 'anythings they done. If the people are an inactivity person that mean they '\n",
            " 'can not have any purpose, so the people never has to be an inactivity '\n",
            " 'person. The people never need to act lazy around. Any people need to act '\n",
            " 'like more a activity person so, they can be more succesful in '\n",
            " 'life.                  ')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  4.0\n",
            "('Should the city council adoption the curfew of a 10 p. m weekday and a '\n",
            " 'midnight weekend curfew for teenagers?  You often hear people say that '\n",
            " 'teenagers are costing more problem to other people and for the around them '\n",
            " 'environment. The city council should adoption the 10 p. m midnight curfew '\n",
            " 'for teenagers because teens would stay out of problems, and they would have '\n",
            " 'more time to do school work.  To start, the curfew would avoid teenagers '\n",
            " 'being in problem with the law. For example,teens with the curfew would not '\n",
            " 'be in gangs or cost problem to others. Lets say that teens had the curfew it '\n",
            " 'would expand beyond the level of doing good to others and staying out of '\n",
            " 'gangs or doing bad stuff. They would be able to achieve their goals fast and '\n",
            " 'force on what is next in life. Even though, this curfew sounds bad its not '\n",
            " 'bad because teens would learn that the curfew is just to help them and help '\n",
            " 'the environment around them.  Secondly, the curfew would allow teens with '\n",
            " 'more time on their schools work and have time to force on their work. For '\n",
            " 'example, teens would have more time to focus on their schools work than '\n",
            " 'being on the streets with gangs. With that being said teens would have a '\n",
            " 'chance of achieving their dreams and being successful in live without a bad '\n",
            " 'influences. In this scenario, it show that a curfew is not bad because it '\n",
            " 'has some good way in live and it allow people to do good stuff for others. '\n",
            " 'Ultimately, with this curfew it allows young people to see the better side '\n",
            " 'in life and it would help them to stay focus in schools by achieving their '\n",
            " 'work and doing the right things.  Some people may say that having a curfew '\n",
            " 'is unfairly interfere in young people lives. For example, young people have '\n",
            " 'the right to choose the way they want to be. Therefor, being later in night '\n",
            " 'dose not meant that young people are doing bad stuff or their are in gangs '\n",
            " 'also they are just having fun in their way. Thus, being in a curfew it show '\n",
            " 'young people that their are controlling by other people just because they '\n",
            " 'have a different way of having fun. In this scenario, it show that having a '\n",
            " 'curfew is just unfairly for teenagers just because other teens got in '\n",
            " 'trouble it dose not means that all of the young people needs to have a '\n",
            " 'curfew.  In conclusion, the city council would just being helpful to the '\n",
            " 'young people by add a time limit. And it would help the environment around '\n",
            " 'them and it would give more time and focus to the young people. All in all, '\n",
            " 'it is a good thing to put a curfew because teens would have more time to '\n",
            " 'spent with their family and doing good stuff for the environment.    ')\n",
            "**********\n",
            "************************\n",
            "phraseology\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('I think, with that changing 4 days of work in a week have disadvantages and '\n",
            " 'some benefits. because people will not have time to live their normal life '\n",
            " 'or do work at home, they will use the same amount of energy and resources '\n",
            " 'and people will not support to work many hours in a day.  In addition, '\n",
            " 'people have already their own routine to work, even thought if some busines '\n",
            " 'try to change work days.  To began,  people will not have time to share with '\n",
            " 'their family, also working 4 day a week for 10 hours will cause problem in '\n",
            " 'your family, children in those time do not have enough responsibility to be '\n",
            " 'home by their self, even thought, people will not have time to do work at '\n",
            " 'home. For example; to clean their house, to go work after school and to '\n",
            " 'coexists their problems or thoughts with the family. And to do other works '\n",
            " 'at the end of the day.  Second, working 10 hours a day they will use the '\n",
            " 'same quantity of energy and resources because is the same sum of hours that '\n",
            " 'all people work, if they work 8 hours a day for 5 day, even that people may '\n",
            " 'use more energy, because the rest of the week people will need energy, as '\n",
            " 'well to work 10 hours a day will use the same amount of resources, to make '\n",
            " 'up all the works that you need to do.  Lastly, people will not support '\n",
            " 'working 10 hours a day, because many people have their routine to work, or '\n",
            " 'some of them have problems working to many hours, another reason why people '\n",
            " 'can not work 10 hours a day is that they have their own routine work, as '\n",
            " 'well student in school will not support to be in class. For example many '\n",
            " 'student gets bored in class juts been 8 hours in school and if we compare '\n",
            " 'there will be a lot if issue with their attendance. another point is many '\n",
            " 'student work to support their self, so in that occation they will not '\n",
            " 'available to work and make money.  To conclude, to work 10 hours a day is to '\n",
            " 'hard for many people and they will try to work less hours in a day, because '\n",
            " 'they can not have time to share with the family, also they can get sick for '\n",
            " 'being working to many hours. even thought on this times some people worked '\n",
            " '10 hours a day, but at the end of all that working to much can cause serious '\n",
            " 'problems with your health.        ')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  3.5\n",
            "('Can a positive attitude take you to the life that you always have '\n",
            " 'dreamed?.There are so many reasons to support that a positive attitude is '\n",
            " 'the key to open the doors of succesful!!!. Being positive, anyone acquire '\n",
            " 'the capacity of be smart to make good decisions. For example a negative '\n",
            " 'person never going to take risk to make a hard decision because always going '\n",
            " 'to think in that everything goes to be bad. Positive attitude must be in the '\n",
            " 'mind of everybody because is the only way to be succesful in this world. '\n",
            " 'Positive person eventhough sometimes make mistakes never going to give up '\n",
            " 'and always going to keep trying to achive anything, no matter the negative '\n",
            " 'commentaries of the people. A positive attitude bring the happiness that '\n",
            " \"everyone is looking, it's like be a super man with super powers. A lot of \"\n",
            " 'famous people like actors, singers,entrepreneurs, and others recomend be '\n",
            " 'positive even upon a pouring rain all of them are a good example to say '\n",
            " 'that. All these things prove that be positive always going to be the step '\n",
            " 'that everyone should take to be someone in this life.  All these things that '\n",
            " 'positive always going to be the step that everyone should take to be someone '\n",
            " 'in this life there are a lot of famous like actors, singers, entrepreneurs, '\n",
            " 'and others recomend be positive even upon a pouring rain because a positive '\n",
            " \"attitude bring the happiness that everyone is looking, it's like be a super \"\n",
            " 'man with super powers, always a Positive person eventhough sometimes make '\n",
            " 'mistakes never going to give up and always going to keep trying to achive '\n",
            " 'anything, no matter the negative commentaries of the people that is why a '\n",
            " 'positive attitude must be in the mind of everybody because is the only way '\n",
            " 'to be succesful in this world, for example a negative person never going to '\n",
            " 'take risk to make a hard decision because always going to think in that '\n",
            " 'everything goes to be bad the only way to make it is being positive, anyone '\n",
            " 'acquire the capacity of be smart to make good decisions think about this '\n",
            " 'cuestion, Can a positive attitude take you to the life that you always have '\n",
            " 'dreamed?.There are so many reasons to support that a positive attitude is '\n",
            " 'the key to open the doors of succesful.')\n",
            "**********\n",
            "************************\n",
            "grammar\n",
            "predicted:  3.0\n",
            "original:  3.0\n",
            "('So i think it we should do the four day school week here at Generic_School.  '\n",
            " 'Because here are one advantage and one disadvantage. The one advantage is '\n",
            " 'that the student will get a three day week end. And then here is a another '\n",
            " 'advantage is that the student would have enough time to finish their '\n",
            " 'homework and project. And then for the one disadvantage is that the student '\n",
            " 'would have a longer school day because they are adding the eight hour that '\n",
            " 'we are going to miss for Friday school day. they would be dividing that '\n",
            " 'eight hour of school for the four day of school that we are going to have. '\n",
            " 'and then here is a another disadvantage like would the student who play '\n",
            " 'sport have short practice because of this like if we do in real life would '\n",
            " 'that actually happen.  So here is my first reason why it is a good reason '\n",
            " 'for this to happen because it would save the school a bunch of money on '\n",
            " 'electric bill. And then here is another good reason that we should do this '\n",
            " 'is that it would help the teacher teach to student understand the material a '\n",
            " 'little bit better. And then here is second reason why it is a bad reason to '\n",
            " 'do this and school like this will give student who play sport a short time '\n",
            " 'to do homework at home because they have school then after school they have '\n",
            " 'practice  So in conclusion we should try this for a month and then after '\n",
            " 'that month we can see if we should keep this thing going on for the rest of '\n",
            " 'the school year. like we can ask the student if they want it to stay. Or we '\n",
            " 'can back the regular secudule like we go the regular time that we get school '\n",
            " 'and then we go back to the five day school week. like in my opinion we '\n",
            " 'should try this out and see how this turn out like would most of the student '\n",
            " 'like this or would most of them hate like i think this is going to be like a '\n",
            " '50 50  chance of this working and not working. like i feel like most of the '\n",
            " 'student would like and the rest of student hating this because the extending '\n",
            " 'hour of the school day but the student who are going to love this is because '\n",
            " 'of the three day weekend and then for the teacher they all would love this '\n",
            " 'idea for the school year')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  2.0\n",
            "('Working with group is more beneficial because, if a person work in group '\n",
            " 'then he/she can share thought and ideas before start working. Also, it helps '\n",
            " 'student to learn how to communicate with other team member because team work '\n",
            " 'is very important and necessary to learn before students start working '\n",
            " 'professionally.  I believe that working in group will gives student more '\n",
            " 'ideas and everyone in group can share their thoughts with each other. It '\n",
            " 'also helps students to finish their work on time and the most important is '\n",
            " 'that not only one person have burden to do all work. Communication is the '\n",
            " 'key of working in group because, group working is also helps students to '\n",
            " 'learn how to communicate and how people should behave when they work as a '\n",
            " 'team.  Team work and communication is very important to learn before a '\n",
            " 'person go to college or before start working professionally because, if a '\n",
            " 'person does not have ability to work in team then it would be very hard to '\n",
            " 'adjust in college or professional work environment. There are many '\n",
            " 'advantages of working in group for instance, student can plan and share '\n",
            " 'ideas with their group, they can discuss the work with each other before the '\n",
            " 'start work on any project and they can also help each other if any of the '\n",
            " 'group member is confused in anything. The most important part of the any '\n",
            " 'project or any other work is finish on time and if not then no matter how '\n",
            " 'much hard work the person put is just useless. Group working is also save '\n",
            " 'time because everyone work together rather then only one person has burden '\n",
            " 'to complete all work.  To conclude, I just want to mention that I understand '\n",
            " 'that working alone is more beneficial for some people but, working in group '\n",
            " 'is much better more easier than working alone. For instance, working in '\n",
            " \"group gives more ideas from different people's sense of humor and people get \"\n",
            " 'chance to work with different people whose thoughts and working style is '\n",
            " 'different.   ')\n",
            "**********\n",
            "************************\n",
            "conventions\n",
            "predicted:  2.5\n",
            "original:  2.5\n",
            "('Today, in the actuality, a lot of people have a big dreams that we can to '\n",
            " 'complete have a better life for our future family or also to own self but a '\n",
            " 'many people be surrender becuase most of the time have the fuilures, when '\n",
            " 'they are doing something; I think that our life without the fuilures will be '\n",
            " \"bored and easy becuase we don't have the energies to work hard or fight for \"\n",
            " \"our goals or dreams. I agree with Churchill's statement about the important \"\n",
            " 'role that failure plays in the pursuit of success because you can help other '\n",
            " 'to complete their dreams or their goals, also you can have more spirit and a '\n",
            " 'positives attitudes than you have in the begging, also you can be a '\n",
            " 'successful and strong person.  You can help others to complete with their '\n",
            " 'dreams or their goals, because sometimes a lot of people who want to comply '\n",
            " \"their dreams or goals they don't have the motivation of their families or \"\n",
            " 'the economy necessary to buy all the studies or all the things that they '\n",
            " 'need, so when you finish all the goals that you make you, you can assist to '\n",
            " 'others. I know an experience of child from Mexico, his name was '\n",
            " 'Generic_Name. Generic_Name was a child with the low economy resources, I '\n",
            " 'remember that he toll us all the things that he was comply to get a better '\n",
            " 'life for his family and him self. So one day, Generic_Name received a big '\n",
            " 'notice from a presidency of Generic_City, the place were we live, that he '\n",
            " 'can have a opportunity to study whatever he want. He and his family were '\n",
            " 'happy for the big opportunity that Generic_Name have. At pass of the years, '\n",
            " 'when Generic_Name finished study the collage, I know that Generic_Name is a '\n",
            " 'big entrepreneur from a big company that he created after finished the '\n",
            " 'college. Today, also Generic_Name likes help other people who want to be a '\n",
            " 'successful in their life like the presidency help him. In my observation to '\n",
            " 'be a good person likes Generic_Name makes that you have a lot of open '\n",
            " 'opportunities to get the success or the things that Generic_Name every day '\n",
            " 'was dreamed.  Also you can be a successful and strong person because all '\n",
            " 'people knows that the life is not easy and less if you want to do something '\n",
            " 'hard or something that you need put a lot of time in it to pursuit of '\n",
            " 'success and if you think that your goals or dreams are difficult to '\n",
            " 'complete. Sometimes we need strive more that the people or your mind think. '\n",
            " 'Another of my experiences is when was in Mexico, I was little girl, I '\n",
            " 'remember that most of my days I talked with my family, my mother, my father '\n",
            " 'and also sometimes with my grandfathers; about that I want study the High '\n",
            " 'School in Untied States because I saw a TV Shows and movies shows all the '\n",
            " 'schools and also my father lived a lot of years in this country so, he talk '\n",
            " 'me about the schools, the teachers, the classmates, the classes and '\n",
            " 'classrooms that were to different form my country, the lunch time and I '\n",
            " 'think that the thing that was more exercise was with the lockers because in '\n",
            " \"my country don't have lockers or something to put our things likes books, \"\n",
            " 'pencils, notebooks and sometimes, the food. At the time that was grow up, I '\n",
            " 'was continue with the same mentality to come to this country to comply my '\n",
            " 'studies. I remember that have a lot of failures in the time to the arrival '\n",
            " 'to United States but,even if never let that my thoughts or the commentaries '\n",
            " 'of the negative people will be fell bad about my big dream. I think that was '\n",
            " 'a strong person because is hard to come to other place with different '\n",
            " 'culture and customers in everything and also is hard and sad separate to the '\n",
            " 'persons who love.  Other might say that the importance role that failure '\n",
            " 'plays in the pursuit of success does not matter or they are disagree because '\n",
            " 'you can lose your forces to continue and accomplish your goals and sometimes '\n",
            " 'this failure can make us fell sad. However, you can have more spirit and '\n",
            " 'positives attitudes than you have in the begging because when you have a '\n",
            " 'failure in something that you study a lot or put your all time in it, you '\n",
            " 'can have the mentality that you can to do well it, just you need strive a '\n",
            " 'little be more that you make before. This is one of my experiences in my '\n",
            " 'life; the last week, in my History class with Generic_Name, we have a quiz '\n",
            " 'form the first unit so, we did the quiz, but the majority of my classmates '\n",
            " \"and me, we don't pass the quiz, my teacher talked with us to give us a \"\n",
            " 'another opportunity to pass it. A lot of my classmates tell her that they do '\n",
            " 'not were think that they can pass it even though they study a lot before the '\n",
            " 'retake but, I have the spirit and the positives attitudes that I can passed '\n",
            " 'the quiz with a good grade and study well at home. I think that my '\n",
            " 'experience, it is good example because a lot of people who want to complete '\n",
            " 'their dreams does not matter the times that they need to try to get a good '\n",
            " 'result and a good recompense for the effort that they make.  In my opinion, '\n",
            " 'I think that Churchill\\'s statement \"success consists of going from failure '\n",
            " 'to failure without loss of enthusiasm\" it is important and I agree with it '\n",
            " 'because you can motive other people to be a good person with good feelings '\n",
            " 'and goals, another reason is because you can to be a successful and '\n",
            " 'respectful person and you can have a good attitudes through haved a bad '\n",
            " 'results, every time you need stay be happy. Most of the people we have the '\n",
            " 'big goals to comply something that always we dreaming.')\n",
            "**********\n",
            "************************\n",
            "predicted:  3.0\n",
            "original:  2.0\n",
            "('FIRST, I CHOOSE TOHAVE THE LONGER SPRING BREAKS.SECOND ,THE STUDENT CAN '\n",
            " 'TRAVEL TO VISIT THEIR FAMILY.THIRD, ENJOYA THE BEACH FOR TIME THAT STUDENTS '\n",
            " \"WANTS.DOESN'T HAVE WORRY ABOUT GOING BACK TO SCHOOL.  FIRST I CHOSE THAT \"\n",
            " 'STUDENTS SHOULD HAVE LONGER BREAK BECAUSE THE STUDENT NEED TO FUN FOR THE '\n",
            " 'BREAK . II CHOSE THAT STUDENT HAVE THE LONGER SUMMER BREAK BECAUSE THE IS MY '\n",
            " 'FAVORITE BREAK IN MY ALL FAMILY STAY HOME OR SOMETIME WE ARE TRAVEL SOME '\n",
            " 'ANOTHER COUNTRY .  THE MOST OF THE STUDENT TRAVEL FOR ANOTHER PLACE .THE '\n",
            " 'SOME STUDENTS CAN TRAVEL TO VISIT THEIR FAMILY BECAUSE THERE FAMILY WAS A '\n",
            " 'DIFFERNT COUNTRY OR DIFFERENT PLACE .WE ARE VISIT HOME BECAUSE WE ARE ENJOYA '\n",
            " 'THEIR FAMILY.WE ARE TRAVEL THE THE FUN PLACE BECAUSE MY FAMILY WAS A LOVE '\n",
            " 'THERE .  WE ARE TRAVEL THE BEACH WE ARE ENJOY THE BEACH FOR MY FAMILY OR MY '\n",
            " 'FRIENDS BECAUSE MY FRIEND AND WE ARE PLAY THE SAND WE HAVE THE FUN .MY ALL '\n",
            " 'FAMILY WAS GOING THERE WE HAVE FUN. I CHOSE TONOT HAVE LONGER SPRING BREAK '\n",
            " \"BECAUSE WON'T CATCH COLD .MORE DIFFICULT FOR STUDENTS OF THE CANSANTRATE .I \"\n",
            " 'CHOSE THE BOTH SIDE BECAUSE THERE WAS A NOT HAVE LONGER SUMMER BECAUSE WE '\n",
            " 'CAN CATCH COLD MOVE DIFICULT FOR THE CONSANTRATE FOR THE STUDENTS .WE ARE '\n",
            " 'TAKING THE LONG BREAKBECAUSE WE ARE FORGET THE EVERYTHINGS . I THINKS ALL '\n",
            " 'STUDENT ENJOYA THE SUMMER BREAK BECAUSE THE SUMMER BREAK WAS THE FUN FOR THE '\n",
            " 'STUDENTS.  MOST OF THE STUDENTS TAKE THE LONG BREAK BECAUSE TNE STUDENTS '\n",
            " 'MOVE THE DIFFERENT PLACE .SUMMER BREAK TAKE THE 1WEAK FOR STUDENTS .THERE '\n",
            " 'WAS THE DIFFERENTS KINDS OF THE SEASON BECAUES MOST PEOPLE LOVE SUMMER OR '\n",
            " 'WINTER AND SPRINGS.SOME PEOPLE LOVE THE SUMMER OR SOME PEOPLE LOVE THE '\n",
            " 'WINTER OR PEOPLE THE SPRINGS. THE SUMMER BREAKS OR WINTER SOMST OF THE '\n",
            " 'PEOPLE ENJOY WINTER .THIS SPRING BREAK I WAS A TRAVEL TO MY COUNTRY BECAUSE '\n",
            " \"I'M VISIT TO MY FRIENDS .I LOVE TO VISIT MY FRENSD .I THINK I AM MOVING \"\n",
            " 'DIFFERENT PLACE FOR THREE DAY THIS PLACE WAS A BEAUTIFUL.THER WAS DIFFERENT '\n",
            " 'KINDS OF FLOWER OR DIFFERENT KINDS OF THE COLORS OR DIFFERENT FROOT OR '\n",
            " 'DIFFERENT DRESS  DIFFERENT KINDS OF FESTIBLE.MOST STUDENTS LOVE TAKE 4,4 '\n",
            " 'WEAK BREAKS THE SCHOOLS '\n",
            " '.                                                                                                      ')\n",
            "**********\n",
            "************************\n",
            "cohesion\n",
            "% Predicting too high: 0.2988505747126437\n",
            "% Predicted correctly: 0.2950191570881226\n",
            "% Predicting too low: 0.4061302681992337\n",
            "****\n",
            "syntax\n",
            "% Predicting too high: 0.2541507024265645\n",
            "% Predicted correctly: 0.2962962962962963\n",
            "% Predicting too low: 0.4495530012771392\n",
            "****\n",
            "vocabulary\n",
            "% Predicting too high: 0.26053639846743293\n",
            "% Predicted correctly: 0.3780332056194125\n",
            "% Predicting too low: 0.3614303959131545\n",
            "****\n",
            "phraseology\n",
            "% Predicting too high: 0.2669220945083014\n",
            "% Predicted correctly: 0.30268199233716475\n",
            "% Predicting too low: 0.43039591315453385\n",
            "****\n",
            "grammar\n",
            "% Predicting too high: 0.31928480204342274\n",
            "% Predicted correctly: 0.26436781609195403\n",
            "% Predicting too low: 0.4163473818646232\n",
            "****\n",
            "conventions\n",
            "% Predicting too high: 0.3167305236270754\n",
            "% Predicted correctly: 0.2937420178799489\n",
            "% Predicting too low: 0.3895274584929757\n",
            "****\n",
            "cohesion\n",
            "length: 2\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 6\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 64\n",
            "% Predicting the above (2.0): 1.0\n",
            "% Predicting the same (2.0): 0.0\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 162\n",
            "% Predicting the above (2.5): 0.8024691358024691\n",
            "% Predicting the same (2.5): 0.19135802469135801\n",
            "% Predicting the below (2.5): 0.006172839506172839\n",
            "****\n",
            "length: 219\n",
            "% Predicting the above (3.0): 0.1461187214611872\n",
            "% Predicting the same (3.0): 0.6940639269406392\n",
            "% Predicting the below (3.0): 0.1598173515981735\n",
            "****\n",
            "length: 198\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.24242424242424243\n",
            "% Predicting the below (3.5): 0.7575757575757576\n",
            "****\n",
            "length: 93\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.0\n",
            "% Predicting the below (4.0): 1.0\n",
            "****\n",
            "length: 35\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 4\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "syntax\n",
            "length: 4\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 5\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 96\n",
            "% Predicting the above (2.0): 0.9791666666666666\n",
            "% Predicting the same (2.0): 0.020833333333333332\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 149\n",
            "% Predicting the above (2.5): 0.610738255033557\n",
            "% Predicting the same (2.5): 0.3691275167785235\n",
            "% Predicting the below (2.5): 0.020134228187919462\n",
            "****\n",
            "length: 257\n",
            "% Predicting the above (3.0): 0.019455252918287938\n",
            "% Predicting the same (3.0): 0.6614785992217899\n",
            "% Predicting the below (3.0): 0.31906614785992216\n",
            "****\n",
            "length: 170\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.029411764705882353\n",
            "% Predicting the below (3.5): 0.9705882352941176\n",
            "****\n",
            "length: 81\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.0\n",
            "% Predicting the below (4.0): 1.0\n",
            "****\n",
            "length: 19\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 2\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "vocabulary\n",
            "vocabulary==1.0 has 0 rows\n",
            "****\n",
            "length: 4\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 26\n",
            "% Predicting the above (2.0): 1.0\n",
            "% Predicting the same (2.0): 0.0\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 101\n",
            "% Predicting the above (2.5): 0.9207920792079208\n",
            "% Predicting the same (2.5): 0.0594059405940594\n",
            "% Predicting the below (2.5): 0.019801980198019802\n",
            "****\n",
            "length: 305\n",
            "% Predicting the above (3.0): 0.26557377049180325\n",
            "% Predicting the same (3.0): 0.6983606557377049\n",
            "% Predicting the below (3.0): 0.036065573770491806\n",
            "****\n",
            "length: 194\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.39690721649484534\n",
            "% Predicting the below (3.5): 0.6030927835051546\n",
            "****\n",
            "length: 122\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.0\n",
            "% Predicting the below (4.0): 1.0\n",
            "****\n",
            "length: 24\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 7\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "phraseology\n",
            "length: 3\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 3\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 74\n",
            "% Predicting the above (2.0): 0.9864864864864865\n",
            "% Predicting the same (2.0): 0.013513513513513514\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 152\n",
            "% Predicting the above (2.5): 0.8355263157894737\n",
            "% Predicting the same (2.5): 0.16447368421052633\n",
            "% Predicting the below (2.5): 0.0\n",
            "****\n",
            "length: 242\n",
            "% Predicting the above (3.0): 0.012396694214876033\n",
            "% Predicting the same (3.0): 0.8553719008264463\n",
            "% Predicting the below (3.0): 0.1322314049586777\n",
            "****\n",
            "length: 180\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.022222222222222223\n",
            "% Predicting the below (3.5): 0.9777777777777777\n",
            "****\n",
            "length: 107\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.0\n",
            "% Predicting the below (4.0): 1.0\n",
            "****\n",
            "length: 18\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 4\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "grammar\n",
            "length: 3\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 6\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 95\n",
            "% Predicting the above (2.0): 1.0\n",
            "% Predicting the same (2.0): 0.0\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 181\n",
            "% Predicting the above (2.5): 0.7237569060773481\n",
            "% Predicting the same (2.5): 0.27071823204419887\n",
            "% Predicting the below (2.5): 0.0055248618784530384\n",
            "****\n",
            "length: 193\n",
            "% Predicting the above (3.0): 0.07772020725388601\n",
            "% Predicting the same (3.0): 0.7512953367875648\n",
            "% Predicting the below (3.0): 0.17098445595854922\n",
            "****\n",
            "length: 176\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.07386363636363637\n",
            "% Predicting the below (3.5): 0.9261363636363636\n",
            "****\n",
            "length: 96\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.0\n",
            "% Predicting the below (4.0): 1.0\n",
            "****\n",
            "length: 25\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 8\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "conventions\n",
            "length: 1\n",
            "% Predicting the above (1.0): 1.0\n",
            "% Predicting the same (1.0): 0.0\n",
            "% Predicting the below (1.0): 0.0\n",
            "****\n",
            "length: 5\n",
            "% Predicting the above (1.5): 1.0\n",
            "% Predicting the same (1.5): 0.0\n",
            "% Predicting the below (1.5): 0.0\n",
            "****\n",
            "length: 85\n",
            "% Predicting the above (2.0): 0.9882352941176471\n",
            "% Predicting the same (2.0): 0.011764705882352941\n",
            "% Predicting the below (2.0): 0.0\n",
            "****\n",
            "length: 155\n",
            "% Predicting the above (2.5): 0.8580645161290322\n",
            "% Predicting the same (2.5): 0.12903225806451613\n",
            "% Predicting the below (2.5): 0.012903225806451613\n",
            "****\n",
            "length: 240\n",
            "% Predicting the above (3.0): 0.10416666666666667\n",
            "% Predicting the same (3.0): 0.7916666666666666\n",
            "% Predicting the below (3.0): 0.10416666666666667\n",
            "****\n",
            "length: 168\n",
            "% Predicting the above (3.5): 0.0\n",
            "% Predicting the same (3.5): 0.1130952380952381\n",
            "% Predicting the below (3.5): 0.8869047619047619\n",
            "****\n",
            "length: 96\n",
            "% Predicting the above (4.0): 0.0\n",
            "% Predicting the same (4.0): 0.0\n",
            "% Predicting the below (4.0): 1.0\n",
            "****\n",
            "length: 26\n",
            "% Predicting the above (4.5): 0.0\n",
            "% Predicting the same (4.5): 0.0\n",
            "% Predicting the below (4.5): 1.0\n",
            "****\n",
            "length: 7\n",
            "% Predicting the above (5.0): 0.0\n",
            "% Predicting the same (5.0): 0.0\n",
            "% Predicting the below (5.0): 1.0\n",
            "****\n",
            "cohesion\n",
            "% Predicting within .5: 0.7241379310344828\n",
            "syntax\n",
            "% Predicting within .5: 0.7292464878671775\n",
            "vocabulary\n",
            "% Predicting within .5: 0.8071519795657727\n",
            "phraseology\n",
            "% Predicting within .5: 0.7343550446998723\n",
            "grammar\n",
            "% Predicting within .5: 0.6704980842911877\n",
            "conventions\n",
            "% Predicting within .5: 0.7049808429118773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_compare_v1 = pd.read_csv(\"predict_bertweet_0.csv\")\n",
        "for component in label_cols:\n",
        "  print(pd.crosstab(df_compare_v1[component], df_compare_v1[\"transformed_pred_\"+component], margins=True))\n",
        "  print()"
      ],
      "metadata": {
        "id": "oxUUt3tcK7vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERTweet with its first 6 layers unfrozen"
      ],
      "metadata": {
        "id": "dLWyqxG4Dnul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed parameters\n",
        "dense_dim = 6\n",
        "number_of_splits = 2\n",
        "random_state = 2023\n",
        "mse_loss = MCRMSE\n",
        "mse_metrics = MCRMSE\n",
        "model_name_list = ['Bert', 'Bertweet'] # Roberta\n",
        "\n",
        "df_train = pd.read_csv('df_train_split.csv')\n",
        "df_test = pd.read_csv('df_test_split.csv')\n",
        "print(f\"Length of train data : {len(df_train)}\")\n",
        "print(f\"Length of test data : {len(df_test)}\")\n",
        "y_test = np.array(df_test[label_cols], dtype = \"float32\")"
      ],
      "metadata": {
        "id": "JR7KuCt9Dqid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acc5d257-0fe9-4745-d6d3-ac3cf8346a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train data : 3128\n",
            "Length of test data : 783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable parameter dictionary\n",
        "param_list = [   # Partially frozen base layer\n",
        "                 {'epochs'                  : 10,\n",
        "                  'batch_size'              : 8,\n",
        "                  'learning_rate'           : 1e-5,\n",
        "                  'validation_split'        : .2,\n",
        "                  'dropout'                 : .1,\n",
        "                  'number_of_hidden_layers' : 2,\n",
        "                  'hidden_layer_node_count' : 64,\n",
        "                  'retrain_layer_count'     : 6\n",
        "                 }\n",
        "             ]"
      ],
      "metadata": {
        "id": "H3srUqj_QZ_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, param_entry in enumerate(param_list):\n",
        "    MAX_LEN = 512\n",
        "    epoch_val = param_entry['epochs']\n",
        "    batch_size_val = param_entry['batch_size']\n",
        "    learning_rate_val = param_entry['learning_rate']\n",
        "    validation_split_val = param_entry['validation_split']\n",
        "    dropout_val = param_entry['dropout']\n",
        "    number_of_hidden_layers_val = param_entry['number_of_hidden_layers']\n",
        "    hidden_layer_node_count_val = param_entry['hidden_layer_node_count']\n",
        "    retrain_layer_count_val = param_entry['retrain_layer_count']\n",
        "\n",
        "    print(\"************************\")\n",
        "    print(f\"Iteration : {idx + 1}\")\n",
        "    print(\"Parameters...\")\n",
        "    print(f\"Epochs : {epoch_val}\")\n",
        "    print(f\"Batch size : {batch_size_val}\")\n",
        "    print(f\"Learning rate : {learning_rate_val}\")\n",
        "    print(f\"Validation split : {validation_split_val}\")\n",
        "    print(f\"Dropout : {dropout_val}\")\n",
        "    print(f\"Number of hidden layers : {number_of_hidden_layers_val}\")\n",
        "    print(f\"Hidden layer node count : {hidden_layer_node_count_val}\")\n",
        "    print(f\"Retrain layer count : {retrain_layer_count_val}\")\n",
        "    print(\"************************\")\n",
        "    set_config_param(20230214)\n",
        "\n",
        "    model_tokenizer = AutoTokenizer.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "    model = TFRobertaModel.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "\n",
        "    train_input_ids, train_attention_masks = text_encode(df_train['full_text'], model_tokenizer, MAX_LEN)\n",
        "    test_input_ids, test_attention_masks = text_encode(df_test['full_text'], model_tokenizer, MAX_LEN)\n",
        "\n",
        "    y_train = np.array(df_train[label_cols], dtype = \"float32\")\n",
        "\n",
        "    bertweet = build_regression_model(loss= \"MCRMSE\", \n",
        "                                      model_name = \"Bertweet\",\n",
        "                                      dense_dim = 6, \n",
        "                                      MAX_LEN = 512,\n",
        "                                      learning_rate = learning_rate_val,\n",
        "                                      dropout=dropout_val,\n",
        "                                      number_of_hidden_layers = number_of_hidden_layers_val,\n",
        "                                      hidden_layer_node_count = hidden_layer_node_count_val,\n",
        "                                      retrain_layer_count = retrain_layer_count_val)\n",
        "    bertweet.summary()\n",
        "\n",
        "    history_v1 = bertweet.fit((train_input_ids, train_attention_masks),\n",
        "                  y_train,\n",
        "                  batch_size = batch_size_val,     \n",
        "                  epochs = epoch_val,\n",
        "                  validation_split = validation_split_val\n",
        "                  )\n",
        "\n",
        "    history_v1_df = pd.DataFrame(history_v1.history)\n",
        "\n",
        "    score_v1 = bertweet.evaluate([test_input_ids, test_attention_masks], \n",
        "                    y_test\n",
        "                  ) \n",
        "\n",
        "    predictions_v1 = bertweet.predict([test_input_ids, test_attention_masks])\n",
        "    df_pred_v1 = pd.DataFrame(predictions_v1, columns=['pred_' + c for c in label_cols])\n",
        "\n",
        "    for col in label_cols:\n",
        "      df_pred_v1['transformed_pred_' + col] = df_pred_v1['pred_' + col].apply(lambda x : roundPartial(x, .5))\n",
        "    \n",
        "    df_compare_v1= pd.merge(df_test, df_pred_v1, left_index = True, right_index = True)\n",
        "    df_compare_v1.to_csv(\"predict_bertweet_6.csv\", index=False)\n",
        "\n",
        "    all = []\n",
        "    for col in label_cols:\n",
        "      all.append(((df_compare_v1[col]-df_compare_v1[\"transformed_pred_\"+col]).pow(2).mean())**(0.5))\n",
        "    RMSE_scaled = statistics.fmean(all)\n",
        "    print(f\"RMSE_scaled: {RMSE_scaled}\")\n",
        "\n",
        "    for label in label_cols:\n",
        "      print(label)\n",
        "      hall_of_fame(df_compare_v1,label,1)\n",
        "      print(\"************************\")\n",
        "      hall_of_shame(df_compare_v1,label,1)\n",
        "      print(\"************************\")\n",
        "    for component in label_cols:\n",
        "      print(component)\n",
        "      print(\"% Predicting too high: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\">\"+component))/len(df_compare_v1)))\n",
        "      print(\"% Predicted correctly: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"==\"+component))/len(df_compare_v1)))\n",
        "      print(\"% Predicting too low: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"<\"+component))/len(df_compare_v1)))\n",
        "      print(\"****\")\n",
        "    # Predicting too high or low for every score? \n",
        "\n",
        "    # for component in label_cols:\n",
        "    #   print(component)\n",
        "\n",
        "    #   for score in [1.0,1.5,2.0,2.5,3.0,3.5,4.0,4.5,5.0]:\n",
        "    #     if len(df_compare_v1[df_compare_v1[component]==score])==0:\n",
        "    #       print(component+\"==\"+str(score)+\" has 0 rows\")\n",
        "    #     else:\n",
        "    #       print(f'length: {len(df_compare_v1[df_compare_v1[component]==score])}')\n",
        "    #       print(\"% Predicting the above (\"+str(score)+\"): \" +\n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) &\n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]>score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #       print(\"% Predicting the same (\"+str(score)+\"): \" +\n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) & \n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]==score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #       print(\"% Predicting the below (\"+str(score)+\"): \" + \n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) & \n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]<score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #     print(\"****\")\n",
        "    for component in label_cols:\n",
        "      print(component)\n",
        "      print(\"% Predicting within .5: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"<=(\"+component+\"+.5) and transformed_pred_\"+component+\">=(\"+component+\"-.5)\"))/len(df_compare_v1)))"
      ],
      "metadata": {
        "id": "sg5wOlghQaJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffaa4136-cf64-472f-ceec-fa7421e47056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************************\n",
            "Iteration : 1\n",
            "Parameters...\n",
            "Epochs : 10\n",
            "Batch size : 8\n",
            "Learning rate : 1e-05\n",
            "Validation split : 0.2\n",
            "Dropout : 0.1\n",
            "Number of hidden layers : 2\n",
            "Hidden layer node count : 64\n",
            "Retrain layer count : 6\n",
            "************************\n",
            "Retrain layers: \n",
            " ['_11', '_10', '_9', '_8', '_7', '_6']\n",
            "Number of trainable parameters : 0\n",
            "Number of non-trainable parameters : 134899968\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/attention/self/query/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/attention/self/query/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/attention/self/key/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/attention/self/key/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/attention/self/value/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/attention/self/value/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/attention/output/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/attention/output/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/attention/output/LayerNorm/gamma:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/attention/output/LayerNorm/beta:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/intermediate/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/intermediate/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/output/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/output/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/output/LayerNorm/gamma:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._0/output/LayerNorm/beta:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/attention/self/query/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/attention/self/query/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/attention/self/key/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/attention/self/key/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/attention/self/value/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/attention/self/value/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/attention/output/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/attention/output/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/attention/output/LayerNorm/gamma:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/attention/output/LayerNorm/beta:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/intermediate/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/intermediate/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/output/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/output/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/output/LayerNorm/gamma:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._1/output/LayerNorm/beta:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/attention/self/query/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/attention/self/query/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/attention/self/key/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/attention/self/key/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/attention/self/value/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/attention/self/value/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/attention/output/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/attention/output/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/attention/output/LayerNorm/gamma:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/attention/output/LayerNorm/beta:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/intermediate/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/intermediate/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/output/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/output/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/output/LayerNorm/gamma:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._2/output/LayerNorm/beta:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/attention/self/query/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/attention/self/query/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/attention/self/key/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/attention/self/key/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/attention/self/value/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/attention/self/value/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/attention/output/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/attention/output/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/attention/output/LayerNorm/gamma:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/attention/output/LayerNorm/beta:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/intermediate/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/intermediate/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/output/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/output/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/output/LayerNorm/gamma:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._3/output/LayerNorm/beta:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/attention/self/query/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/attention/self/query/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/attention/self/key/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/attention/self/key/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/attention/self/value/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/attention/self/value/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/attention/output/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/attention/output/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/attention/output/LayerNorm/gamma:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/attention/output/LayerNorm/beta:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/intermediate/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/intermediate/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/output/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/output/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/output/LayerNorm/gamma:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._4/output/LayerNorm/beta:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/attention/self/query/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/attention/self/query/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/attention/self/key/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/attention/self/key/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/attention/self/value/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/attention/self/value/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/attention/output/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/attention/output/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/attention/output/LayerNorm/gamma:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/attention/output/LayerNorm/beta:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/intermediate/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/intermediate/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/output/dense/kernel:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/output/dense/bias:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/output/LayerNorm/gamma:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._5/output/LayerNorm/beta:0 False\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/attention/self/query/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/attention/self/query/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/attention/self/key/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/attention/self/key/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/attention/self/value/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/attention/self/value/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/attention/output/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/attention/output/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/attention/output/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/attention/output/LayerNorm/beta:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/intermediate/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/intermediate/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/output/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/output/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/output/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._6/output/LayerNorm/beta:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/attention/self/query/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/attention/self/query/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/attention/self/key/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/attention/self/key/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/attention/self/value/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/attention/self/value/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/attention/output/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/attention/output/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/attention/output/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/attention/output/LayerNorm/beta:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/intermediate/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/intermediate/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/output/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/output/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/output/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._7/output/LayerNorm/beta:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/attention/self/query/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/attention/self/query/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/attention/self/key/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/attention/self/key/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/attention/self/value/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/attention/self/value/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/attention/output/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/attention/output/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/attention/output/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/attention/output/LayerNorm/beta:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/intermediate/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/intermediate/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/output/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/output/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/output/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._8/output/LayerNorm/beta:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/attention/self/query/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/attention/self/query/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/attention/self/key/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/attention/self/key/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/attention/self/value/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/attention/self/value/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/attention/output/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/attention/output/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/attention/output/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/attention/output/LayerNorm/beta:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/intermediate/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/intermediate/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/output/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/output/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/output/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._9/output/LayerNorm/beta:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/attention/self/query/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/attention/self/query/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/attention/self/key/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/attention/self/key/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/attention/self/value/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/attention/self/value/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/attention/output/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/attention/output/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/attention/output/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/attention/output/LayerNorm/beta:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/intermediate/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/intermediate/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/output/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/output/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/output/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._10/output/LayerNorm/beta:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/attention/self/query/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/attention/self/query/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/attention/self/key/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/attention/self/key/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/attention/self/value/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/attention/self/value/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/attention/output/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/attention/output/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/attention/output/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/attention/output/LayerNorm/beta:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/intermediate/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/intermediate/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/output/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/output/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/output/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/encoder/layer_._11/output/LayerNorm/beta:0 True\n",
            "tf_roberta_model_1/roberta/pooler/dense/kernel:0 True\n",
            "tf_roberta_model_1/roberta/pooler/dense/bias:0 True\n",
            "tf_roberta_model_1/roberta/embeddings/word_embeddings/weight:0 True\n",
            "tf_roberta_model_1/roberta/embeddings/token_type_embeddings/embeddings:0 True\n",
            "tf_roberta_model_1/roberta/embeddings/position_embeddings/embeddings:0 True\n",
            "tf_roberta_model_1/roberta/embeddings/LayerNorm/gamma:0 True\n",
            "tf_roberta_model_1/roberta/embeddings/LayerNorm/beta:0 True\n",
            "Number of trainable parameters : 0\n",
            "Number of non-trainable parameters : 134899968\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_roberta_model_1 (TFRobertaM  TFBaseModelOutputWi  134899968  ['input_ids[0][0]',              \n",
            " odel)                          thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_roberta_model_1[0][0]']     \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " hidden_layer_1 (Dense)         (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_layer_1 (Dropout)      (None, 64)           0           ['hidden_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            " hidden_layer_2 (Dense)         (None, 64)           4160        ['dropout_layer_1[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_layer_2 (Dropout)      (None, 64)           0           ['hidden_layer_2[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 6)            390         ['dropout_layer_2[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 134,953,734\n",
            "Trainable params: 53,766\n",
            "Non-trainable params: 134,899,968\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_roberta_model_1 (TFRobertaM  TFBaseModelOutputWi  134899968  ['input_ids[0][0]',              \n",
            " odel)                          thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_roberta_model_1[0][0]']     \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " hidden_layer_1 (Dense)         (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_layer_1 (Dropout)      (None, 64)           0           ['hidden_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            " hidden_layer_2 (Dense)         (None, 64)           4160        ['dropout_layer_1[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_layer_2 (Dropout)      (None, 64)           0           ['hidden_layer_2[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 6)            390         ['dropout_layer_2[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 134,953,734\n",
            "Trainable params: 53,766\n",
            "Non-trainable params: 134,899,968\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "313/313 [==============================] - 160s 459ms/step - loss: 2.9545 - MCRMSE: 2.9542 - val_loss: 2.6879 - val_MCRMSE: 2.6926\n",
            "Epoch 2/10\n",
            "208/313 [==================>...........] - ETA: 39s - loss: 2.4793 - MCRMSE: 2.4793"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_compare_v1 = pd.read_csv(\"predict_bertweet_6.csv\")\n",
        "for component in label_cols:\n",
        "  print(pd.crosstab(df_compare_v1[component], df_compare_v1[\"transformed_pred_\"+component], margins=True))\n",
        "  print()"
      ],
      "metadata": {
        "id": "tapAn1G63Ncp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERTweet with all its layers unfrozen"
      ],
      "metadata": {
        "id": "cwZV561yDtp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed parameters\n",
        "dense_dim = 6\n",
        "number_of_splits = 2\n",
        "random_state = 2023\n",
        "mse_loss = MCRMSE\n",
        "mse_metrics = MCRMSE\n",
        "model_name_list = ['Bert', 'Bertweet'] # Roberta\n",
        "\n",
        "df_train = pd.read_csv('df_train_split.csv')\n",
        "df_test = pd.read_csv('df_test_split.csv')\n",
        "print(f\"Length of train data : {len(df_train)}\")\n",
        "print(f\"Length of test data : {len(df_test)}\")\n",
        "y_test = np.array(df_test[label_cols], dtype = \"float32\")"
      ],
      "metadata": {
        "id": "EK7jPfHeDsh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable parameter dictionary\n",
        "param_list = [   # Completely unfrozen base layer\n",
        "                 {'epochs'                  : 10,\n",
        "                  'batch_size'              : 8,\n",
        "                  'learning_rate'           : 1e-5,\n",
        "                  'validation_split'        : .2,\n",
        "                  'dropout'                 : .1,\n",
        "                  'number_of_hidden_layers' : 2,\n",
        "                  'hidden_layer_node_count' : 64,\n",
        "                  'retrain_layer_count'     : 12\n",
        "                 },\n",
        "             ]"
      ],
      "metadata": {
        "id": "Ug6ZH807QaVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, param_entry in enumerate(param_list):\n",
        "    MAX_LEN = 512\n",
        "    epoch_val = param_entry['epochs']\n",
        "    batch_size_val = param_entry['batch_size']\n",
        "    learning_rate_val = param_entry['learning_rate']\n",
        "    validation_split_val = param_entry['validation_split']\n",
        "    dropout_val = param_entry['dropout']\n",
        "    number_of_hidden_layers_val = param_entry['number_of_hidden_layers']\n",
        "    hidden_layer_node_count_val = param_entry['hidden_layer_node_count']\n",
        "    retrain_layer_count_val = param_entry['retrain_layer_count']\n",
        "\n",
        "    print(\"************************\")\n",
        "    print(f\"Iteration : {idx + 1}\")\n",
        "    print(\"Parameters...\")\n",
        "    print(f\"Epochs : {epoch_val}\")\n",
        "    print(f\"Batch size : {batch_size_val}\")\n",
        "    print(f\"Learning rate : {learning_rate_val}\")\n",
        "    print(f\"Validation split : {validation_split_val}\")\n",
        "    print(f\"Dropout : {dropout_val}\")\n",
        "    print(f\"Number of hidden layers : {number_of_hidden_layers_val}\")\n",
        "    print(f\"Hidden layer node count : {hidden_layer_node_count_val}\")\n",
        "    print(f\"Retrain layer count : {retrain_layer_count_val}\")\n",
        "    print(\"************************\")\n",
        "    set_config_param(20230214)\n",
        "\n",
        "    model_tokenizer = AutoTokenizer.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "    model = TFRobertaModel.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "\n",
        "    train_input_ids, train_attention_masks = text_encode(df_train['full_text'], model_tokenizer, MAX_LEN)\n",
        "    test_input_ids, test_attention_masks = text_encode(df_test['full_text'], model_tokenizer, MAX_LEN)\n",
        "\n",
        "    y_train = np.array(df_train[label_cols], dtype = \"float32\")\n",
        "\n",
        "    bertweet = build_regression_model(loss= \"MCRMSE\", \n",
        "                                      model_name = \"Bertweet\",\n",
        "                                      dense_dim = 6, \n",
        "                                      MAX_LEN = 512,\n",
        "                                      learning_rate = learning_rate_val,\n",
        "                                      dropout=dropout_val,\n",
        "                                      number_of_hidden_layers = number_of_hidden_layers_val,\n",
        "                                      hidden_layer_node_count = hidden_layer_node_count_val,\n",
        "                                      retrain_layer_count = retrain_layer_count_val)\n",
        "    bertweet.summary()\n",
        "\n",
        "    history_v1 = bertweet.fit((train_input_ids, train_attention_masks),\n",
        "                  y_train,\n",
        "                  batch_size = batch_size_val,     \n",
        "                  epochs = epoch_val,\n",
        "                  validation_split = validation_split_val\n",
        "                  )\n",
        "\n",
        "    history_v1_df = pd.DataFrame(history_v1.history)\n",
        "\n",
        "    score_v1 = bertweet.evaluate([test_input_ids, test_attention_masks], \n",
        "                    y_test\n",
        "                  ) \n",
        "\n",
        "    predictions_v1 = bertweet.predict([test_input_ids, test_attention_masks])\n",
        "    df_pred_v1 = pd.DataFrame(predictions_v1, columns=['pred_' + c for c in label_cols])\n",
        "\n",
        "    for col in label_cols:\n",
        "      df_pred_v1['transformed_pred_' + col] = df_pred_v1['pred_' + col].apply(lambda x : roundPartial(x, .5))\n",
        "    \n",
        "    df_compare_v1= pd.merge(df_test, df_pred_v1, left_index = True, right_index = True)\n",
        "    df_compare_v1.to_csv(\"predict_bertweet_12.csv\", index=False)\n",
        "\n",
        "    all = []\n",
        "    for col in label_cols:\n",
        "      all.append(((df_compare_v1[col]-df_compare_v1[\"transformed_pred_\"+col]).pow(2).mean())**(0.5))\n",
        "    RMSE_scaled = statistics.fmean(all)\n",
        "    print(f\"RMSE_scaled: {RMSE_scaled}\")\n",
        "\n",
        "    for label in label_cols:\n",
        "      print(label)\n",
        "      hall_of_fame(df_compare_v1,label,1)\n",
        "      print(\"************************\")\n",
        "      hall_of_shame(df_compare_v1,label,1)\n",
        "      print(\"************************\")\n",
        "    for component in label_cols:\n",
        "      print(component)\n",
        "      print(\"% Predicting too high: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\">\"+component))/len(df_compare_v1)))\n",
        "      print(\"% Predicted correctly: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"==\"+component))/len(df_compare_v1)))\n",
        "      print(\"% Predicting too low: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"<\"+component))/len(df_compare_v1)))\n",
        "      print(\"****\")\n",
        "    # Predicting too high or low for every score? \n",
        "\n",
        "    # for component in label_cols:\n",
        "    #   print(component)\n",
        "\n",
        "    #   for score in [1.0,1.5,2.0,2.5,3.0,3.5,4.0,4.5,5.0]:\n",
        "    #     if len(df_compare_v1[df_compare_v1[component]==score])==0:\n",
        "    #       print(component+\"==\"+str(score)+\" has 0 rows\")\n",
        "    #     else:\n",
        "    #       print(f'length: {len(df_compare_v1[df_compare_v1[component]==score])}')\n",
        "    #       print(\"% Predicting the above (\"+str(score)+\"): \" +\n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) &\n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]>score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #       print(\"% Predicting the same (\"+str(score)+\"): \" +\n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) & \n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]==score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #       print(\"% Predicting the below (\"+str(score)+\"): \" + \n",
        "    #             str(len(df_compare_v1[(df_compare_v1[component]==score) & \n",
        "    #                                   (df_compare_v1[\"transformed_pred_\"+component]<score)])/len(df_compare_v1[df_compare_v1[component]==score])))\n",
        "    #     print(\"****\")\n",
        "    for component in label_cols:\n",
        "      print(component)\n",
        "      print(\"% Predicting within .5: \" + str(len(df_compare_v1.query(\"transformed_pred_\"+component+\"<=(\"+component+\"+.5) and transformed_pred_\"+component+\">=(\"+component+\"-.5)\"))/len(df_compare_v1)))"
      ],
      "metadata": {
        "id": "v2WHf9FO5mV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_compare_v1 = pd.read_csv(\"predict_bertweet_12.csv\")\n",
        "for component in label_cols:\n",
        "  print(pd.crosstab(df_compare_v1[component], df_compare_v1[\"transformed_pred_\"+component], margins=True))\n",
        "  print()"
      ],
      "metadata": {
        "id": "zQsAxB06LE7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_compare_v1)"
      ],
      "metadata": {
        "id": "y573G-r-HG33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_compare_v1[\"character_count\"] = df_compare_v1.full_text.str.len()"
      ],
      "metadata": {
        "id": "Vg4xRReLGqLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_compare_v1[df_compare_v1[\"character_count\"]<280])"
      ],
      "metadata": {
        "id": "XsevoYXxR96P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2ET_cAludgH"
      },
      "source": [
        "Concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LED6NugFs3Ec"
      },
      "outputs": [],
      "source": [
        "set_config_param(20230214)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tuz4PZrbh1vk"
      },
      "source": [
        "# **Clustering**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[\"score_sum\"].hist()\n",
        "plt.title(\"Train Dataset's Total Scores\")\n",
        "plt.xlabel(\"Total Score\")\n",
        "plt.ylabel(\"Number of Essays\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hWXYOWjpPEUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTMJpfp8YzNz"
      },
      "outputs": [],
      "source": [
        "df_rating = copy.deepcopy(df_train[label_cols])\n",
        "rating_values_array = np.array(df_rating[label_cols])\n",
        "\n",
        "# standardize\n",
        "sc = StandardScaler()\n",
        "rating_values_array_std = sc.fit(rating_values_array).transform(rating_values_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHFkIEq5Cgul"
      },
      "outputs": [],
      "source": [
        "km = KMeans(random_state=42)\n",
        "visualizer = KElbowVisualizer(km, k=(2,10))\n",
        " \n",
        "visualizer.fit(rating_values_array_std)        # Fit the data to the visualizer\n",
        "visualizer.show()        # Finalize and render the figure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLpAtecfC72h"
      },
      "source": [
        "Here is how the Elbow / SSE Plot would look like. As per the plot given below, for n_clusters = 3 that represents the elbow you start seeing diminishing returns by increasing k. The line starts looking linear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2cZ4AyoDOoU"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 3, figsize=(20,5))\n",
        "for idx, i in enumerate([2, 3, 4]):\n",
        "    '''\n",
        "    Create KMeans instance for different number of clusters\n",
        "    '''\n",
        "    km = KMeans(n_clusters=i, init='k-means++', n_init=10, max_iter=100, random_state=42)\n",
        "    #q, mod = divmod(i, 2)\n",
        "    '''\n",
        "    Create SilhouetteVisualizer instance with KMeans instance\n",
        "    Fit the visualizer\n",
        "    '''\n",
        "    visualizer = SilhouetteVisualizer(km, colors='yellowbrick', ax=ax[idx])\n",
        "    visualizer.fit(rating_values_array_std) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-e9bqdIGWnZ"
      },
      "source": [
        "Given above, the Silhouette plot for n_clusters = 3 looks to be most appropriate than others as it stands well against all the three measuring criteria (scores below average Silhouette score, Wide fluctuations in the size of the plot, and non-uniform thickness)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Spyt5ysCGSEp"
      },
      "outputs": [],
      "source": [
        "km_base = KMeans(n_clusters=3,\n",
        "           #init='random',\n",
        "           init='k-means++',\n",
        "           n_init=10,\n",
        "           max_iter=300,\n",
        "           tol=1e-04,\n",
        "           random_state=1234)\n",
        "\n",
        "# predict k-means classes\n",
        "y_km_base = km_base.fit_predict(rating_values_array_std)\n",
        "\n",
        "# Assigning cluster value to the datafarme\n",
        "df_train['cluster_id'] = y_km_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8Jlal-4bqri"
      },
      "outputs": [],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgY72Q0Qj5rF"
      },
      "source": [
        "We can see that an increase in *k* is associated with a decrease in the within-cluster SSE. \n",
        "\n",
        "This is because the examples are closer to the centroid they assigned to.\n",
        "\n",
        "**The elbow solution**: the optimal *k* is where the within-cluster SSE begings to increase most rapidly.\n",
        "\n",
        "For this particular example the elbow is at *k=2* so we started with a good number of clusters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2RZdPo215xy"
      },
      "outputs": [],
      "source": [
        "df_train_cluster0 = df_train[df_train.cluster_id == 0]\n",
        "df_train_cluster1 = df_train[df_train.cluster_id == 1]\n",
        "df_train_cluster2 = df_train[df_train.cluster_id == 2]\n",
        "\n",
        "print(f\"Length of cluster 0 : {len(df_train_cluster0)}\")\n",
        "print(f\"Length of cluster 1 : {len(df_train_cluster1)}\")\n",
        "print(f\"Length of cluster 2 : {len(df_train_cluster2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1Hd6zkQeqvc"
      },
      "outputs": [],
      "source": [
        "print(f\"Min and max score in cluster 0 are : {np.min(df_train_cluster0['score_sum'])} and {np.max(df_train_cluster0['score_sum'])}\")\n",
        "print(f\"Min and Max score in cluster 1 are : {np.min(df_train_cluster1['score_sum'])} and {np.max(df_train_cluster1['score_sum'])}\")\n",
        "print(f\"Min and Max score in cluster 2 are : {np.min(df_train_cluster2['score_sum'])} and {np.max(df_train_cluster2['score_sum'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61PU78V5HbuI"
      },
      "source": [
        "The cluster is divided based on the distribution of the data. Low-scores are in one bucket, medium scores are placed in another and top scrores are placed in the higher bucket."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kbjNbnOZGJi"
      },
      "source": [
        "# **Model parameter setup**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed parameters\n",
        "dense_dim = 6\n",
        "number_of_splits = 2\n",
        "random_state = 2023\n",
        "mse_loss = MCRMSE\n",
        "mse_metrics = MCRMSE"
      ],
      "metadata": {
        "id": "jdKR-L-1UjLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining the two clusters' data\n",
        "df_train = pd.concat([df_train_cluster0, df_train_cluster1, df_train_cluster2])\n",
        "\n",
        "# shuffling them back again\n",
        "shuffle = np.random.permutation(np.arange(df_train.shape[0]))\n",
        "df_train = df_train.iloc[shuffle]\n",
        "\n",
        "MCRMSE_list = []\n",
        "\n",
        "'''\n",
        "rating_cluster has two values 0 and 1.\n",
        "We are doing k fold with stratification using rating_cluster.\n",
        "We introduced this new column to split on as as our data ouput is multi class\n",
        "and multi label with continuous values and traditional k fold split does not\n",
        "support that.\n",
        "This new column will help us to see if our model is performing better for which \n",
        "group : above or below average.\n",
        "'''"
      ],
      "metadata": {
        "id": "H3QubIulTTw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_list = ['Bert'] # , 'Bertweet' Roberta\n",
        "# Variable parameter dictionary\n",
        "param_list = [   # Completely frozen base layer\n",
        "                 {'epochs'                  : 10,\n",
        "                  'batch_size'              : 8,\n",
        "                  'learning_rate'           : 1e-5,\n",
        "                  'validation_split'        : .2,\n",
        "                  'dropout'                 : .1,\n",
        "                  'number_of_hidden_layers' : 2,\n",
        "                  'hidden_layer_node_count' : 64,\n",
        "                  'retrain_layer_count'     : 0\n",
        "                 }\n",
        "             ]"
      ],
      "metadata": {
        "id": "ilTJLL1rTUE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHeyCiPxENqg"
      },
      "outputs": [],
      "source": [
        "for param_val_model_name in model_name_list:\n",
        "\n",
        "    for idx, param_entry in enumerate(param_list):\n",
        "    \n",
        "        param_val_epoch = param_entry['epochs']\n",
        "        param_val_batch_size = param_entry['batch_size']\n",
        "        param_val_learning_rate = param_entry['learning_rate']\n",
        "        param_val_validation_split = param_entry['validation_split']\n",
        "        param_val_dropout = param_entry['dropout']\n",
        "        param_val_number_of_hidden_layers = param_entry['number_of_hidden_layers']\n",
        "        param_val_hidden_layer_node_count = param_entry['hidden_layer_node_count']\n",
        "        param_val_retrain_layer_count = param_entry['retrain_layer_count']\n",
        "\n",
        "        for kfold, (train_indices, val_indices) in enumerate(StratifiedKFold(n_splits     = number_of_splits, \n",
        "                                                                             shuffle      = True, \n",
        "                                                                             random_state = random_state\n",
        "                                                                             ).split(df_train['cluster_id'].values.tolist(), \n",
        "                                                                                     df_train['cluster_id'].values.tolist()\n",
        "                                                                                    )\n",
        "                                                            ):\n",
        "            print(\"************************\")\n",
        "            print(f\"Model : {param_val_model_name}\")\n",
        "            print(f\"Iteration : {idx + 1}\")\n",
        "            print(\"Parameters...\")\n",
        "            print(f\"Epochs : {param_val_epoch}\")\n",
        "            print(f\"Batch size : {param_val_batch_size}\")\n",
        "            print(f\"Learning rate : {param_val_learning_rate}\")\n",
        "            print(f\"Validation split : {param_val_validation_split}\")\n",
        "            print(f\"Dropout : {param_val_dropout}\")\n",
        "            print(f\"Number of hidden layers : {param_val_number_of_hidden_layers}\")\n",
        "            print(f\"Hidden layer node count : {param_val_hidden_layer_node_count}\")\n",
        "            print(f\"Retrain layer count : {param_val_retrain_layer_count}\")\n",
        "            print(f\"k-fold : {kfold + 1}\")\n",
        "            print(f\"length of train data : {len(train_indices)}\")\n",
        "            print(f\"length of validation data : {len(val_indices)}\")\n",
        "            print(\"************************\")\n",
        "            set_config_param(20230214)\n",
        "\n",
        "            # Building the tokenizer for the given model\n",
        "            if param_val_model_name == 'Roberta':\n",
        "                tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_MODEL_CHKPT)\n",
        "            elif param_val_model_name == 'Bertweet':\n",
        "                tokenizer = AutoTokenizer.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "            elif param_val_model_name == 'Bert':\n",
        "                tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_CHKPT)\n",
        "            \n",
        "            # Model building\n",
        "            print(\"Building model...\")\n",
        "            regression_model = build_regression_model(loss                    = 'MCRMSE',\n",
        "                                                      model_name              = param_val_model_name, \n",
        "                                                      dense_dim               = dense_dim, \n",
        "                                                      MAX_LEN                 = MAX_LEN,\n",
        "                                                      learning_rate           = param_val_learning_rate,\n",
        "                                                      dropout                 = param_val_dropout,\n",
        "                                                      number_of_hidden_layers = param_val_number_of_hidden_layers,\n",
        "                                                      hidden_layer_node_count = param_val_hidden_layer_node_count,\n",
        "                                                      retrain_layer_count     = param_val_retrain_layer_count\n",
        "                                                     )\n",
        "        \n",
        "            # Model fitting\n",
        "            print(\"Fitting model...\")\n",
        "            df_history = model_fit(model            = regression_model, \n",
        "                                   df_train         = df_train, \n",
        "                                   train_indices    = train_indices,\n",
        "                                   val_indices      = val_indices,\n",
        "                                   model_name       = param_val_model_name, \n",
        "                                   MAX_LEN          = MAX_LEN,\n",
        "                                   epochs           = param_val_epoch,\n",
        "                                   batch_size       = param_val_batch_size,\n",
        "                                   validation_split = param_val_validation_split\n",
        "                                  )\n",
        "            print(df_history.T)\n",
        "\n",
        "            print(\"Plotting loss and MCRMSE...\")\n",
        "            custom_plot(df         = df_history, \n",
        "                        model_name = param_val_model_name, \n",
        "                        kpi_name   = 'MCRMSE', \n",
        "                        kpi_string = 'MCRMSE'\n",
        "                       )\n",
        "\n",
        "            # Prep for model evaluation with test data\n",
        "            print(\"Evaluating mode...\")\n",
        "            test_encoded_input_ids, test_encoded_attention_masks = text_encode(texts      = df_test['full_text'], \n",
        "                                                                               tokenizer = tokenizer, \n",
        "                                                                               max_len    = MAX_LEN\n",
        "                                                                              )\n",
        "            # Model evaluation\n",
        "            test_loss, test_accuracy = evaluate_model(regression_model, \n",
        "                                                      y_test, \n",
        "                                                      test_encoded_input_ids, \n",
        "                                                      test_encoded_attention_masks\n",
        "                                                     )\n",
        "\n",
        "            # Model prediction\n",
        "            print(\"Model prediction...\")\n",
        "            df_prediction, df_comparison = predict_model(regression_model, \n",
        "                                                         df_test, \n",
        "                                                         test_encoded_input_ids, \n",
        "                                                         test_encoded_attention_masks, \n",
        "                                                         label_cols\n",
        "                                                        )\n",
        "\n",
        "            print(\"Plotting model structure...\")\n",
        "            keras.utils.plot_model(regression_model, \n",
        "                                   show_shapes      = False, \n",
        "                                   show_dtype       = False, \n",
        "                                   show_layer_names = True, \n",
        "                                   dpi              = 90\n",
        "                                  )\n",
        "\n",
        "            print(\"Appending to kpi list...\")\n",
        "            temp_dict = {'model_name'                  : param_val_model_name,\n",
        "                         'iteration'                   : idx + 1,\n",
        "                         'epoch'                       : param_val_epoch,\n",
        "                         'batch_size'                  : param_val_batch_size,\n",
        "                         'learning_rate'               : param_val_learning_rate,\n",
        "                         'validation_split'            : param_val_validation_split,\n",
        "                         'dropout'                     : param_val_dropout,\n",
        "                         'number_of_hidden_layers'     : param_val_number_of_hidden_layers,\n",
        "                         'hidden_layer_node_count'     : param_val_hidden_layer_node_count,\n",
        "                         'retrain_layer_count'         : param_val_retrain_layer_count,\n",
        "                         'fold'                        : kfold + 1, \n",
        "                         'train_loss'                  : df_history.iloc[-1][0],\n",
        "                         'train_accuracy'              : df_history.iloc[-1][1],\n",
        "                         'val_loss'                    : df_history.iloc[-1][2],\n",
        "                         'val_accuracy'                : df_history.iloc[-1][3],\n",
        "                         'test_loss'                   : test_loss,\n",
        "                         'test_accuracy'               : test_accuracy\n",
        "                        }\n",
        "            MCRMSE_list.append(temp_dict)\n",
        "            \n",
        "            # # Saving the model\n",
        "            # print(\"Saving the model...\")\n",
        "            # model_file_name = 'regression_model_' + param_val_model_name.lower() + '_iter_' + str(idx + 1) + '_kfold_' + str(kfold + 1) + \".h5\"\n",
        "            # regression_model.save(model_file_name)\n",
        "\n",
        "            for label in label_cols:\n",
        "              print(label)\n",
        "              hall_of_fame(df_comparison,label,1)\n",
        "              print(\"************************\")\n",
        "              hall_of_shame(df_comparison,label,1)\n",
        "              print(\"************************\")\n",
        "            for component in label_cols:\n",
        "              print(component)\n",
        "              print(\"% Predicted too high: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\">\"+component))/len(df_comparison)))\n",
        "              print(\"% Predicted correctly: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\"==\"+component))/len(df_comparison)))\n",
        "              print(\"% Predicted too low: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\"<\"+component))/len(df_comparison)))\n",
        "              print(\"****\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_list = ['Bert'] # , 'Bertweet' Roberta\n",
        "# Variable parameter dictionary\n",
        "param_list = [   # Partially frozen base layer\n",
        "                 {'epochs'                  : 10,\n",
        "                  'batch_size'              : 8,\n",
        "                  'learning_rate'           : 1e-5,\n",
        "                  'validation_split'        : .2,\n",
        "                  'dropout'                 : .1,\n",
        "                  'number_of_hidden_layers' : 2,\n",
        "                  'hidden_layer_node_count' : 64,\n",
        "                  'retrain_layer_count'     : 6\n",
        "                 }\n",
        "             ]"
      ],
      "metadata": {
        "id": "7CbvW1-OWJcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param_val_model_name in model_name_list:\n",
        "\n",
        "    for idx, param_entry in enumerate(param_list):\n",
        "    \n",
        "        param_val_epoch = param_entry['epochs']\n",
        "        param_val_batch_size = param_entry['batch_size']\n",
        "        param_val_learning_rate = param_entry['learning_rate']\n",
        "        param_val_validation_split = param_entry['validation_split']\n",
        "        param_val_dropout = param_entry['dropout']\n",
        "        param_val_number_of_hidden_layers = param_entry['number_of_hidden_layers']\n",
        "        param_val_hidden_layer_node_count = param_entry['hidden_layer_node_count']\n",
        "        param_val_retrain_layer_count = param_entry['retrain_layer_count']\n",
        "\n",
        "        for kfold, (train_indices, val_indices) in enumerate(StratifiedKFold(n_splits     = number_of_splits, \n",
        "                                                                             shuffle      = True, \n",
        "                                                                             random_state = random_state\n",
        "                                                                             ).split(df_train['cluster_id'].values.tolist(), \n",
        "                                                                                     df_train['cluster_id'].values.tolist()\n",
        "                                                                                    )\n",
        "                                                            ):\n",
        "            print(\"************************\")\n",
        "            print(f\"Model : {param_val_model_name}\")\n",
        "            print(f\"Iteration : {idx + 1}\")\n",
        "            print(\"Parameters...\")\n",
        "            print(f\"Epochs : {param_val_epoch}\")\n",
        "            print(f\"Batch size : {param_val_batch_size}\")\n",
        "            print(f\"Learning rate : {param_val_learning_rate}\")\n",
        "            print(f\"Validation split : {param_val_validation_split}\")\n",
        "            print(f\"Dropout : {param_val_dropout}\")\n",
        "            print(f\"Number of hidden layers : {param_val_number_of_hidden_layers}\")\n",
        "            print(f\"Hidden layer node count : {param_val_hidden_layer_node_count}\")\n",
        "            print(f\"Retrain layer count : {param_val_retrain_layer_count}\")\n",
        "            print(f\"k-fold : {kfold + 1}\")\n",
        "            print(f\"length of train data : {len(train_indices)}\")\n",
        "            print(f\"length of validation data : {len(val_indices)}\")\n",
        "            print(\"************************\")\n",
        "            set_config_param(20230214)\n",
        "\n",
        "            # Building the tokenizer for the given model\n",
        "            if param_val_model_name == 'Roberta':\n",
        "                tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_MODEL_CHKPT)\n",
        "            elif param_val_model_name == 'Bertweet':\n",
        "                tokenizer = AutoTokenizer.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "            elif param_val_model_name == 'Bert':\n",
        "                tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_CHKPT)\n",
        "            \n",
        "            # Model building\n",
        "            print(\"Building model...\")\n",
        "            regression_model = build_regression_model(loss                    = 'MCRMSE',\n",
        "                                                      model_name              = param_val_model_name, \n",
        "                                                      dense_dim               = dense_dim, \n",
        "                                                      MAX_LEN                 = MAX_LEN,\n",
        "                                                      learning_rate           = param_val_learning_rate,\n",
        "                                                      dropout                 = param_val_dropout,\n",
        "                                                      number_of_hidden_layers = param_val_number_of_hidden_layers,\n",
        "                                                      hidden_layer_node_count = param_val_hidden_layer_node_count,\n",
        "                                                      retrain_layer_count     = param_val_retrain_layer_count\n",
        "                                                     )\n",
        "        \n",
        "            # Model fitting\n",
        "            print(\"Fitting model...\")\n",
        "            df_history = model_fit(model            = regression_model, \n",
        "                                   df_train         = df_train, \n",
        "                                   train_indices    = train_indices,\n",
        "                                   val_indices      = val_indices,\n",
        "                                   model_name       = param_val_model_name, \n",
        "                                   MAX_LEN          = MAX_LEN,\n",
        "                                   epochs           = param_val_epoch,\n",
        "                                   batch_size       = param_val_batch_size,\n",
        "                                   validation_split = param_val_validation_split\n",
        "                                  )\n",
        "            print(df_history.T)\n",
        "\n",
        "            print(\"Plotting loss and MCRMSE...\")\n",
        "            custom_plot(df         = df_history, \n",
        "                        model_name = param_val_model_name, \n",
        "                        kpi_name   = 'MCRMSE', \n",
        "                        kpi_string = 'MCRMSE'\n",
        "                       )\n",
        "\n",
        "            # Prep for model evaluation with test data\n",
        "            print(\"Evaluating mode...\")\n",
        "            test_encoded_input_ids, test_encoded_attention_masks = text_encode(texts      = df_test['full_text'], \n",
        "                                                                               tokenizer = tokenizer, \n",
        "                                                                               max_len    = MAX_LEN\n",
        "                                                                              )\n",
        "            # Model evaluation\n",
        "            test_loss, test_accuracy = evaluate_model(regression_model, \n",
        "                                                      y_test, \n",
        "                                                      test_encoded_input_ids, \n",
        "                                                      test_encoded_attention_masks\n",
        "                                                     )\n",
        "\n",
        "            # Model prediction\n",
        "            print(\"Model prediction...\")\n",
        "            df_prediction, df_comparison = predict_model(regression_model, \n",
        "                                                         df_test, \n",
        "                                                         test_encoded_input_ids, \n",
        "                                                         test_encoded_attention_masks, \n",
        "                                                         label_cols\n",
        "                                                        )\n",
        "\n",
        "            print(\"Plotting model structure...\")\n",
        "            keras.utils.plot_model(regression_model, \n",
        "                                   show_shapes      = False, \n",
        "                                   show_dtype       = False, \n",
        "                                   show_layer_names = True, \n",
        "                                   dpi              = 90\n",
        "                                  )\n",
        "\n",
        "            print(\"Appending to kpi list...\")\n",
        "            temp_dict = {'model_name'                  : param_val_model_name,\n",
        "                         'iteration'                   : idx + 1,\n",
        "                         'epoch'                       : param_val_epoch,\n",
        "                         'batch_size'                  : param_val_batch_size,\n",
        "                         'learning_rate'               : param_val_learning_rate,\n",
        "                         'validation_split'            : param_val_validation_split,\n",
        "                         'dropout'                     : param_val_dropout,\n",
        "                         'number_of_hidden_layers'     : param_val_number_of_hidden_layers,\n",
        "                         'hidden_layer_node_count'     : param_val_hidden_layer_node_count,\n",
        "                         'retrain_layer_count'         : param_val_retrain_layer_count,\n",
        "                         'fold'                        : kfold + 1, \n",
        "                         'train_loss'                  : df_history.iloc[-1][0],\n",
        "                         'train_accuracy'              : df_history.iloc[-1][1],\n",
        "                         'val_loss'                    : df_history.iloc[-1][2],\n",
        "                         'val_accuracy'                : df_history.iloc[-1][3],\n",
        "                         'test_loss'                   : test_loss,\n",
        "                         'test_accuracy'               : test_accuracy\n",
        "                        }\n",
        "            MCRMSE_list.append(temp_dict)\n",
        "            \n",
        "            # # Saving the model\n",
        "            # print(\"Saving the model...\")\n",
        "            # model_file_name = 'regression_model_' + param_val_model_name.lower() + '_iter_' + str(idx + 1) + '_kfold_' + str(kfold + 1) + \".h5\"\n",
        "            # regression_model.save(model_file_name)\n",
        "\n",
        "            for label in label_cols:\n",
        "              print(label)\n",
        "              hall_of_fame(df_comparison,label,1)\n",
        "              print(\"************************\")\n",
        "              hall_of_shame(df_comparison,label,1)\n",
        "              print(\"************************\")\n",
        "            for component in label_cols:\n",
        "              print(component)\n",
        "              print(\"% Predicted too high: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\">\"+component))/len(df_comparison)))\n",
        "              print(\"% Predicted correctly: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\"==\"+component))/len(df_comparison)))\n",
        "              print(\"% Predicted too low: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\"<\"+component))/len(df_comparison)))\n",
        "              print(\"****\")"
      ],
      "metadata": {
        "id": "dxSmMFd3XICM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_list = ['Bert'] # , 'Bertweet' Roberta\n",
        "# Variable parameter dictionary\n",
        "param_list = [   # Completely unfrozen base layer\n",
        "                 {'epochs'                  : 10,\n",
        "                  'batch_size'              : 8,\n",
        "                  'learning_rate'           : 1e-5,\n",
        "                  'validation_split'        : .2,\n",
        "                  'dropout'                 : .1,\n",
        "                  'number_of_hidden_layers' : 2,\n",
        "                  'hidden_layer_node_count' : 64,\n",
        "                  'retrain_layer_count'     : 12\n",
        "                 },\n",
        "             ]"
      ],
      "metadata": {
        "id": "tQR2U-dBWVM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param_val_model_name in model_name_list:\n",
        "\n",
        "    for idx, param_entry in enumerate(param_list):\n",
        "    \n",
        "        param_val_epoch = param_entry['epochs']\n",
        "        param_val_batch_size = param_entry['batch_size']\n",
        "        param_val_learning_rate = param_entry['learning_rate']\n",
        "        param_val_validation_split = param_entry['validation_split']\n",
        "        param_val_dropout = param_entry['dropout']\n",
        "        param_val_number_of_hidden_layers = param_entry['number_of_hidden_layers']\n",
        "        param_val_hidden_layer_node_count = param_entry['hidden_layer_node_count']\n",
        "        param_val_retrain_layer_count = param_entry['retrain_layer_count']\n",
        "\n",
        "        for kfold, (train_indices, val_indices) in enumerate(StratifiedKFold(n_splits     = number_of_splits, \n",
        "                                                                             shuffle      = True, \n",
        "                                                                             random_state = random_state\n",
        "                                                                             ).split(df_train['cluster_id'].values.tolist(), \n",
        "                                                                                     df_train['cluster_id'].values.tolist()\n",
        "                                                                                    )\n",
        "                                                            ):\n",
        "            print(\"************************\")\n",
        "            print(f\"Model : {param_val_model_name}\")\n",
        "            print(f\"Iteration : {idx + 1}\")\n",
        "            print(\"Parameters...\")\n",
        "            print(f\"Epochs : {param_val_epoch}\")\n",
        "            print(f\"Batch size : {param_val_batch_size}\")\n",
        "            print(f\"Learning rate : {param_val_learning_rate}\")\n",
        "            print(f\"Validation split : {param_val_validation_split}\")\n",
        "            print(f\"Dropout : {param_val_dropout}\")\n",
        "            print(f\"Number of hidden layers : {param_val_number_of_hidden_layers}\")\n",
        "            print(f\"Hidden layer node count : {param_val_hidden_layer_node_count}\")\n",
        "            print(f\"Retrain layer count : {param_val_retrain_layer_count}\")\n",
        "            print(f\"k-fold : {kfold + 1}\")\n",
        "            print(f\"length of train data : {len(train_indices)}\")\n",
        "            print(f\"length of validation data : {len(val_indices)}\")\n",
        "            print(\"************************\")\n",
        "            set_config_param(20230214)\n",
        "\n",
        "            # Building the tokenizer for the given model\n",
        "            if param_val_model_name == 'Roberta':\n",
        "                tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_MODEL_CHKPT)\n",
        "            elif param_val_model_name == 'Bertweet':\n",
        "                tokenizer = AutoTokenizer.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "            elif param_val_model_name == 'Bert':\n",
        "                tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_CHKPT)\n",
        "            \n",
        "            # Model building\n",
        "            print(\"Building model...\")\n",
        "            regression_model = build_regression_model(loss                    = 'MCRMSE',\n",
        "                                                      model_name              = param_val_model_name, \n",
        "                                                      dense_dim               = dense_dim, \n",
        "                                                      MAX_LEN                 = MAX_LEN,\n",
        "                                                      learning_rate           = param_val_learning_rate,\n",
        "                                                      dropout                 = param_val_dropout,\n",
        "                                                      number_of_hidden_layers = param_val_number_of_hidden_layers,\n",
        "                                                      hidden_layer_node_count = param_val_hidden_layer_node_count,\n",
        "                                                      retrain_layer_count     = param_val_retrain_layer_count\n",
        "                                                     )\n",
        "        \n",
        "            # Model fitting\n",
        "            print(\"Fitting model...\")\n",
        "            df_history = model_fit(model            = regression_model, \n",
        "                                   df_train         = df_train, \n",
        "                                   train_indices    = train_indices,\n",
        "                                   val_indices      = val_indices,\n",
        "                                   model_name       = param_val_model_name, \n",
        "                                   MAX_LEN          = MAX_LEN,\n",
        "                                   epochs           = param_val_epoch,\n",
        "                                   batch_size       = param_val_batch_size,\n",
        "                                   validation_split = param_val_validation_split\n",
        "                                  )\n",
        "            print(df_history.T)\n",
        "\n",
        "            print(\"Plotting loss and MCRMSE...\")\n",
        "            custom_plot(df         = df_history, \n",
        "                        model_name = param_val_model_name, \n",
        "                        kpi_name   = 'MCRMSE', \n",
        "                        kpi_string = 'MCRMSE'\n",
        "                       )\n",
        "\n",
        "            # Prep for model evaluation with test data\n",
        "            print(\"Evaluating mode...\")\n",
        "            test_encoded_input_ids, test_encoded_attention_masks = text_encode(texts      = df_test['full_text'], \n",
        "                                                                               tokenizer = tokenizer, \n",
        "                                                                               max_len    = MAX_LEN\n",
        "                                                                              )\n",
        "            # Model evaluation\n",
        "            test_loss, test_accuracy = evaluate_model(regression_model, \n",
        "                                                      y_test, \n",
        "                                                      test_encoded_input_ids, \n",
        "                                                      test_encoded_attention_masks\n",
        "                                                     )\n",
        "\n",
        "            # Model prediction\n",
        "            print(\"Model prediction...\")\n",
        "            df_prediction, df_comparison = predict_model(regression_model, \n",
        "                                                         df_test, \n",
        "                                                         test_encoded_input_ids, \n",
        "                                                         test_encoded_attention_masks, \n",
        "                                                         label_cols\n",
        "                                                        )\n",
        "\n",
        "            print(\"Plotting model structure...\")\n",
        "            keras.utils.plot_model(regression_model, \n",
        "                                   show_shapes      = False, \n",
        "                                   show_dtype       = False, \n",
        "                                   show_layer_names = True, \n",
        "                                   dpi              = 90\n",
        "                                  )\n",
        "\n",
        "            print(\"Appending to kpi list...\")\n",
        "            temp_dict = {'model_name'                  : param_val_model_name,\n",
        "                         'iteration'                   : idx + 1,\n",
        "                         'epoch'                       : param_val_epoch,\n",
        "                         'batch_size'                  : param_val_batch_size,\n",
        "                         'learning_rate'               : param_val_learning_rate,\n",
        "                         'validation_split'            : param_val_validation_split,\n",
        "                         'dropout'                     : param_val_dropout,\n",
        "                         'number_of_hidden_layers'     : param_val_number_of_hidden_layers,\n",
        "                         'hidden_layer_node_count'     : param_val_hidden_layer_node_count,\n",
        "                         'retrain_layer_count'         : param_val_retrain_layer_count,\n",
        "                         'fold'                        : kfold + 1, \n",
        "                         'train_loss'                  : df_history.iloc[-1][0],\n",
        "                         'train_accuracy'              : df_history.iloc[-1][1],\n",
        "                         'val_loss'                    : df_history.iloc[-1][2],\n",
        "                         'val_accuracy'                : df_history.iloc[-1][3],\n",
        "                         'test_loss'                   : test_loss,\n",
        "                         'test_accuracy'               : test_accuracy\n",
        "                        }\n",
        "            MCRMSE_list.append(temp_dict)\n",
        "            \n",
        "            # # Saving the model\n",
        "            # print(\"Saving the model...\")\n",
        "            # model_file_name = 'regression_model_' + param_val_model_name.lower() + '_iter_' + str(idx + 1) + '_kfold_' + str(kfold + 1) + \".h5\"\n",
        "            # regression_model.save(model_file_name)\n",
        "\n",
        "            for label in label_cols:\n",
        "              print(label)\n",
        "              hall_of_fame(df_comparison,label,1)\n",
        "              print(\"************************\")\n",
        "              hall_of_shame(df_comparison,label,1)\n",
        "              print(\"************************\")\n",
        "            for component in label_cols:\n",
        "              print(component)\n",
        "              print(\"% Predicted too high: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\">\"+component))/len(df_comparison)))\n",
        "              print(\"% Predicted correctly: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\"==\"+component))/len(df_comparison)))\n",
        "              print(\"% Predicted too low: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\"<\"+component))/len(df_comparison)))\n",
        "              print(\"****\")"
      ],
      "metadata": {
        "id": "JJbaEmqeWeSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_list = ['Bertweet'] # ,  Roberta\n",
        "# Variable parameter dictionary\n",
        "param_list = [   # Completely frozen base layer\n",
        "                 {'epochs'                  : 10,\n",
        "                  'batch_size'              : 8,\n",
        "                  'learning_rate'           : 1e-5,\n",
        "                  'validation_split'        : .2,\n",
        "                  'dropout'                 : .1,\n",
        "                  'number_of_hidden_layers' : 2,\n",
        "                  'hidden_layer_node_count' : 64,\n",
        "                  'retrain_layer_count'     : 0\n",
        "                 }\n",
        "             ]"
      ],
      "metadata": {
        "id": "XrxR2zQHWegL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param_val_model_name in model_name_list:\n",
        "\n",
        "    for idx, param_entry in enumerate(param_list):\n",
        "    \n",
        "        param_val_epoch = param_entry['epochs']\n",
        "        param_val_batch_size = param_entry['batch_size']\n",
        "        param_val_learning_rate = param_entry['learning_rate']\n",
        "        param_val_validation_split = param_entry['validation_split']\n",
        "        param_val_dropout = param_entry['dropout']\n",
        "        param_val_number_of_hidden_layers = param_entry['number_of_hidden_layers']\n",
        "        param_val_hidden_layer_node_count = param_entry['hidden_layer_node_count']\n",
        "        param_val_retrain_layer_count = param_entry['retrain_layer_count']\n",
        "\n",
        "        for kfold, (train_indices, val_indices) in enumerate(StratifiedKFold(n_splits     = number_of_splits, \n",
        "                                                                             shuffle      = True, \n",
        "                                                                             random_state = random_state\n",
        "                                                                             ).split(df_train['cluster_id'].values.tolist(), \n",
        "                                                                                     df_train['cluster_id'].values.tolist()\n",
        "                                                                                    )\n",
        "                                                            ):\n",
        "            print(\"************************\")\n",
        "            print(f\"Model : {param_val_model_name}\")\n",
        "            print(f\"Iteration : {idx + 1}\")\n",
        "            print(\"Parameters...\")\n",
        "            print(f\"Epochs : {param_val_epoch}\")\n",
        "            print(f\"Batch size : {param_val_batch_size}\")\n",
        "            print(f\"Learning rate : {param_val_learning_rate}\")\n",
        "            print(f\"Validation split : {param_val_validation_split}\")\n",
        "            print(f\"Dropout : {param_val_dropout}\")\n",
        "            print(f\"Number of hidden layers : {param_val_number_of_hidden_layers}\")\n",
        "            print(f\"Hidden layer node count : {param_val_hidden_layer_node_count}\")\n",
        "            print(f\"Retrain layer count : {param_val_retrain_layer_count}\")\n",
        "            print(f\"k-fold : {kfold + 1}\")\n",
        "            print(f\"length of train data : {len(train_indices)}\")\n",
        "            print(f\"length of validation data : {len(val_indices)}\")\n",
        "            print(\"************************\")\n",
        "            set_config_param(20230214)\n",
        "\n",
        "            # Building the tokenizer for the given model\n",
        "            if param_val_model_name == 'Roberta':\n",
        "                tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_MODEL_CHKPT)\n",
        "            elif param_val_model_name == 'Bertweet':\n",
        "                tokenizer = AutoTokenizer.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "            elif param_val_model_name == 'Bert':\n",
        "                tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_CHKPT)\n",
        "            \n",
        "            # Model building\n",
        "            print(\"Building model...\")\n",
        "            regression_model = build_regression_model(loss                    = 'MCRMSE',\n",
        "                                                      model_name              = param_val_model_name, \n",
        "                                                      dense_dim               = dense_dim, \n",
        "                                                      MAX_LEN                 = MAX_LEN,\n",
        "                                                      learning_rate           = param_val_learning_rate,\n",
        "                                                      dropout                 = param_val_dropout,\n",
        "                                                      number_of_hidden_layers = param_val_number_of_hidden_layers,\n",
        "                                                      hidden_layer_node_count = param_val_hidden_layer_node_count,\n",
        "                                                      retrain_layer_count     = param_val_retrain_layer_count\n",
        "                                                     )\n",
        "        \n",
        "            # Model fitting\n",
        "            print(\"Fitting model...\")\n",
        "            df_history = model_fit(model            = regression_model, \n",
        "                                   df_train         = df_train, \n",
        "                                   train_indices    = train_indices,\n",
        "                                   val_indices      = val_indices,\n",
        "                                   model_name       = param_val_model_name, \n",
        "                                   MAX_LEN          = MAX_LEN,\n",
        "                                   epochs           = param_val_epoch,\n",
        "                                   batch_size       = param_val_batch_size,\n",
        "                                   validation_split = param_val_validation_split\n",
        "                                  )\n",
        "            print(df_history.T)\n",
        "\n",
        "            print(\"Plotting loss and MCRMSE...\")\n",
        "            custom_plot(df         = df_history, \n",
        "                        model_name = param_val_model_name, \n",
        "                        kpi_name   = 'MCRMSE', \n",
        "                        kpi_string = 'MCRMSE'\n",
        "                       )\n",
        "\n",
        "            # Prep for model evaluation with test data\n",
        "            print(\"Evaluating mode...\")\n",
        "            test_encoded_input_ids, test_encoded_attention_masks = text_encode(texts      = df_test['full_text'], \n",
        "                                                                               tokenizer = tokenizer, \n",
        "                                                                               max_len    = MAX_LEN\n",
        "                                                                              )\n",
        "            # Model evaluation\n",
        "            test_loss, test_accuracy = evaluate_model(regression_model, \n",
        "                                                      y_test, \n",
        "                                                      test_encoded_input_ids, \n",
        "                                                      test_encoded_attention_masks\n",
        "                                                     )\n",
        "\n",
        "            # Model prediction\n",
        "            print(\"Model prediction...\")\n",
        "            df_prediction, df_comparison = predict_model(regression_model, \n",
        "                                                         df_test, \n",
        "                                                         test_encoded_input_ids, \n",
        "                                                         test_encoded_attention_masks, \n",
        "                                                         label_cols\n",
        "                                                        )\n",
        "\n",
        "            print(\"Plotting model structure...\")\n",
        "            keras.utils.plot_model(regression_model, \n",
        "                                   show_shapes      = False, \n",
        "                                   show_dtype       = False, \n",
        "                                   show_layer_names = True, \n",
        "                                   dpi              = 90\n",
        "                                  )\n",
        "\n",
        "            print(\"Appending to kpi list...\")\n",
        "            temp_dict = {'model_name'                  : param_val_model_name,\n",
        "                         'iteration'                   : idx + 1,\n",
        "                         'epoch'                       : param_val_epoch,\n",
        "                         'batch_size'                  : param_val_batch_size,\n",
        "                         'learning_rate'               : param_val_learning_rate,\n",
        "                         'validation_split'            : param_val_validation_split,\n",
        "                         'dropout'                     : param_val_dropout,\n",
        "                         'number_of_hidden_layers'     : param_val_number_of_hidden_layers,\n",
        "                         'hidden_layer_node_count'     : param_val_hidden_layer_node_count,\n",
        "                         'retrain_layer_count'         : param_val_retrain_layer_count,\n",
        "                         'fold'                        : kfold + 1, \n",
        "                         'train_loss'                  : df_history.iloc[-1][0],\n",
        "                         'train_accuracy'              : df_history.iloc[-1][1],\n",
        "                         'val_loss'                    : df_history.iloc[-1][2],\n",
        "                         'val_accuracy'                : df_history.iloc[-1][3],\n",
        "                         'test_loss'                   : test_loss,\n",
        "                         'test_accuracy'               : test_accuracy\n",
        "                        }\n",
        "            MCRMSE_list.append(temp_dict)\n",
        "            \n",
        "            # # Saving the model\n",
        "            # print(\"Saving the model...\")\n",
        "            # model_file_name = 'regression_model_' + param_val_model_name.lower() + '_iter_' + str(idx + 1) + '_kfold_' + str(kfold + 1) + \".h5\"\n",
        "            # regression_model.save(model_file_name)\n",
        "\n",
        "            for label in label_cols:\n",
        "              print(label)\n",
        "              hall_of_fame(df_comparison,label,1)\n",
        "              print(\"************************\")\n",
        "              hall_of_shame(df_comparison,label,1)\n",
        "              print(\"************************\")\n",
        "            for component in label_cols:\n",
        "              print(component)\n",
        "              print(\"% Predicted too high: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\">\"+component))/len(df_comparison)))\n",
        "              print(\"% Predicted correctly: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\"==\"+component))/len(df_comparison)))\n",
        "              print(\"% Predicted too low: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\"<\"+component))/len(df_comparison)))\n",
        "              print(\"****\")"
      ],
      "metadata": {
        "id": "c58WkBFSXB4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_list = ['Bertweet'] # ,  Roberta\n",
        "# Variable parameter dictionary\n",
        "param_list = [   # Partially frozen base layer\n",
        "                 {'epochs'                  : 10,\n",
        "                  'batch_size'              : 8,\n",
        "                  'learning_rate'           : 1e-5,\n",
        "                  'validation_split'        : .2,\n",
        "                  'dropout'                 : .1,\n",
        "                  'number_of_hidden_layers' : 2,\n",
        "                  'hidden_layer_node_count' : 64,\n",
        "                  'retrain_layer_count'     : 6\n",
        "                 }\n",
        "             ]"
      ],
      "metadata": {
        "id": "MtEZR1JSWmKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param_val_model_name in model_name_list:\n",
        "\n",
        "    for idx, param_entry in enumerate(param_list):\n",
        "    \n",
        "        param_val_epoch = param_entry['epochs']\n",
        "        param_val_batch_size = param_entry['batch_size']\n",
        "        param_val_learning_rate = param_entry['learning_rate']\n",
        "        param_val_validation_split = param_entry['validation_split']\n",
        "        param_val_dropout = param_entry['dropout']\n",
        "        param_val_number_of_hidden_layers = param_entry['number_of_hidden_layers']\n",
        "        param_val_hidden_layer_node_count = param_entry['hidden_layer_node_count']\n",
        "        param_val_retrain_layer_count = param_entry['retrain_layer_count']\n",
        "\n",
        "        for kfold, (train_indices, val_indices) in enumerate(StratifiedKFold(n_splits     = number_of_splits, \n",
        "                                                                             shuffle      = True, \n",
        "                                                                             random_state = random_state\n",
        "                                                                             ).split(df_train['cluster_id'].values.tolist(), \n",
        "                                                                                     df_train['cluster_id'].values.tolist()\n",
        "                                                                                    )\n",
        "                                                            ):\n",
        "            print(\"************************\")\n",
        "            print(f\"Model : {param_val_model_name}\")\n",
        "            print(f\"Iteration : {idx + 1}\")\n",
        "            print(\"Parameters...\")\n",
        "            print(f\"Epochs : {param_val_epoch}\")\n",
        "            print(f\"Batch size : {param_val_batch_size}\")\n",
        "            print(f\"Learning rate : {param_val_learning_rate}\")\n",
        "            print(f\"Validation split : {param_val_validation_split}\")\n",
        "            print(f\"Dropout : {param_val_dropout}\")\n",
        "            print(f\"Number of hidden layers : {param_val_number_of_hidden_layers}\")\n",
        "            print(f\"Hidden layer node count : {param_val_hidden_layer_node_count}\")\n",
        "            print(f\"Retrain layer count : {param_val_retrain_layer_count}\")\n",
        "            print(f\"k-fold : {kfold + 1}\")\n",
        "            print(f\"length of train data : {len(train_indices)}\")\n",
        "            print(f\"length of validation data : {len(val_indices)}\")\n",
        "            print(\"************************\")\n",
        "            set_config_param(20230214)\n",
        "\n",
        "            # Building the tokenizer for the given model\n",
        "            if param_val_model_name == 'Roberta':\n",
        "                tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_MODEL_CHKPT)\n",
        "            elif param_val_model_name == 'Bertweet':\n",
        "                tokenizer = AutoTokenizer.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "            elif param_val_model_name == 'Bert':\n",
        "                tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_CHKPT)\n",
        "            \n",
        "            # Model building\n",
        "            print(\"Building model...\")\n",
        "            regression_model = build_regression_model(loss                    = 'MCRMSE',\n",
        "                                                      model_name              = param_val_model_name, \n",
        "                                                      dense_dim               = dense_dim, \n",
        "                                                      MAX_LEN                 = MAX_LEN,\n",
        "                                                      learning_rate           = param_val_learning_rate,\n",
        "                                                      dropout                 = param_val_dropout,\n",
        "                                                      number_of_hidden_layers = param_val_number_of_hidden_layers,\n",
        "                                                      hidden_layer_node_count = param_val_hidden_layer_node_count,\n",
        "                                                      retrain_layer_count     = param_val_retrain_layer_count\n",
        "                                                     )\n",
        "        \n",
        "            # Model fitting\n",
        "            print(\"Fitting model...\")\n",
        "            df_history = model_fit(model            = regression_model, \n",
        "                                   df_train         = df_train, \n",
        "                                   train_indices    = train_indices,\n",
        "                                   val_indices      = val_indices,\n",
        "                                   model_name       = param_val_model_name, \n",
        "                                   MAX_LEN          = MAX_LEN,\n",
        "                                   epochs           = param_val_epoch,\n",
        "                                   batch_size       = param_val_batch_size,\n",
        "                                   validation_split = param_val_validation_split\n",
        "                                  )\n",
        "            print(df_history.T)\n",
        "\n",
        "            print(\"Plotting loss and MCRMSE...\")\n",
        "            custom_plot(df         = df_history, \n",
        "                        model_name = param_val_model_name, \n",
        "                        kpi_name   = 'MCRMSE', \n",
        "                        kpi_string = 'MCRMSE'\n",
        "                       )\n",
        "\n",
        "            # Prep for model evaluation with test data\n",
        "            print(\"Evaluating mode...\")\n",
        "            test_encoded_input_ids, test_encoded_attention_masks = text_encode(texts      = df_test['full_text'], \n",
        "                                                                               tokenizer = tokenizer, \n",
        "                                                                               max_len    = MAX_LEN\n",
        "                                                                              )\n",
        "            # Model evaluation\n",
        "            test_loss, test_accuracy = evaluate_model(regression_model, \n",
        "                                                      y_test, \n",
        "                                                      test_encoded_input_ids, \n",
        "                                                      test_encoded_attention_masks\n",
        "                                                     )\n",
        "\n",
        "            # Model prediction\n",
        "            print(\"Model prediction...\")\n",
        "            df_prediction, df_comparison = predict_model(regression_model, \n",
        "                                                         df_test, \n",
        "                                                         test_encoded_input_ids, \n",
        "                                                         test_encoded_attention_masks, \n",
        "                                                         label_cols\n",
        "                                                        )\n",
        "\n",
        "            print(\"Plotting model structure...\")\n",
        "            keras.utils.plot_model(regression_model, \n",
        "                                   show_shapes      = False, \n",
        "                                   show_dtype       = False, \n",
        "                                   show_layer_names = True, \n",
        "                                   dpi              = 90\n",
        "                                  )\n",
        "\n",
        "            print(\"Appending to kpi list...\")\n",
        "            temp_dict = {'model_name'                  : param_val_model_name,\n",
        "                         'iteration'                   : idx + 1,\n",
        "                         'epoch'                       : param_val_epoch,\n",
        "                         'batch_size'                  : param_val_batch_size,\n",
        "                         'learning_rate'               : param_val_learning_rate,\n",
        "                         'validation_split'            : param_val_validation_split,\n",
        "                         'dropout'                     : param_val_dropout,\n",
        "                         'number_of_hidden_layers'     : param_val_number_of_hidden_layers,\n",
        "                         'hidden_layer_node_count'     : param_val_hidden_layer_node_count,\n",
        "                         'retrain_layer_count'         : param_val_retrain_layer_count,\n",
        "                         'fold'                        : kfold + 1, \n",
        "                         'train_loss'                  : df_history.iloc[-1][0],\n",
        "                         'train_accuracy'              : df_history.iloc[-1][1],\n",
        "                         'val_loss'                    : df_history.iloc[-1][2],\n",
        "                         'val_accuracy'                : df_history.iloc[-1][3],\n",
        "                         'test_loss'                   : test_loss,\n",
        "                         'test_accuracy'               : test_accuracy\n",
        "                        }\n",
        "            MCRMSE_list.append(temp_dict)\n",
        "            \n",
        "            # # Saving the model\n",
        "            # print(\"Saving the model...\")\n",
        "            # model_file_name = 'regression_model_' + param_val_model_name.lower() + '_iter_' + str(idx + 1) + '_kfold_' + str(kfold + 1) + \".h5\"\n",
        "            # regression_model.save(model_file_name)\n",
        "\n",
        "            for label in label_cols:\n",
        "              print(label)\n",
        "              hall_of_fame(df_comparison,label,1)\n",
        "              print(\"************************\")\n",
        "              hall_of_shame(df_comparison,label,1)\n",
        "              print(\"************************\")\n",
        "            for component in label_cols:\n",
        "              print(component)\n",
        "              print(\"% Predicted too high: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\">\"+component))/len(df_comparison)))\n",
        "              print(\"% Predicted correctly: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\"==\"+component))/len(df_comparison)))\n",
        "              print(\"% Predicted too low: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\"<\"+component))/len(df_comparison)))\n",
        "              print(\"****\")"
      ],
      "metadata": {
        "id": "AsjCJKI-XBKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_list = ['Bertweet'] # ,  Roberta\n",
        "# Variable parameter dictionary\n",
        "param_list = [   # Completely unfrozen base layer\n",
        "                 {'epochs'                  : 10,\n",
        "                  'batch_size'              : 8,\n",
        "                  'learning_rate'           : 1e-5,\n",
        "                  'validation_split'        : .2,\n",
        "                  'dropout'                 : .1,\n",
        "                  'number_of_hidden_layers' : 2,\n",
        "                  'hidden_layer_node_count' : 64,\n",
        "                  'retrain_layer_count'     : 12\n",
        "                 },\n",
        "             ]"
      ],
      "metadata": {
        "id": "i40hO2kuWmVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param_val_model_name in model_name_list:\n",
        "\n",
        "    for idx, param_entry in enumerate(param_list):\n",
        "    \n",
        "        param_val_epoch = param_entry['epochs']\n",
        "        param_val_batch_size = param_entry['batch_size']\n",
        "        param_val_learning_rate = param_entry['learning_rate']\n",
        "        param_val_validation_split = param_entry['validation_split']\n",
        "        param_val_dropout = param_entry['dropout']\n",
        "        param_val_number_of_hidden_layers = param_entry['number_of_hidden_layers']\n",
        "        param_val_hidden_layer_node_count = param_entry['hidden_layer_node_count']\n",
        "        param_val_retrain_layer_count = param_entry['retrain_layer_count']\n",
        "\n",
        "        for kfold, (train_indices, val_indices) in enumerate(StratifiedKFold(n_splits     = number_of_splits, \n",
        "                                                                             shuffle      = True, \n",
        "                                                                             random_state = random_state\n",
        "                                                                             ).split(df_train['cluster_id'].values.tolist(), \n",
        "                                                                                     df_train['cluster_id'].values.tolist()\n",
        "                                                                                    )\n",
        "                                                            ):\n",
        "            print(\"************************\")\n",
        "            print(f\"Model : {param_val_model_name}\")\n",
        "            print(f\"Iteration : {idx + 1}\")\n",
        "            print(\"Parameters...\")\n",
        "            print(f\"Epochs : {param_val_epoch}\")\n",
        "            print(f\"Batch size : {param_val_batch_size}\")\n",
        "            print(f\"Learning rate : {param_val_learning_rate}\")\n",
        "            print(f\"Validation split : {param_val_validation_split}\")\n",
        "            print(f\"Dropout : {param_val_dropout}\")\n",
        "            print(f\"Number of hidden layers : {param_val_number_of_hidden_layers}\")\n",
        "            print(f\"Hidden layer node count : {param_val_hidden_layer_node_count}\")\n",
        "            print(f\"Retrain layer count : {param_val_retrain_layer_count}\")\n",
        "            print(f\"k-fold : {kfold + 1}\")\n",
        "            print(f\"length of train data : {len(train_indices)}\")\n",
        "            print(f\"length of validation data : {len(val_indices)}\")\n",
        "            print(\"************************\")\n",
        "            set_config_param(20230214)\n",
        "\n",
        "            # Building the tokenizer for the given model\n",
        "            if param_val_model_name == 'Roberta':\n",
        "                tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_MODEL_CHKPT)\n",
        "            elif param_val_model_name == 'Bertweet':\n",
        "                tokenizer = AutoTokenizer.from_pretrained(BERTWEET_MODEL_CHKPT)\n",
        "            elif param_val_model_name == 'Bert':\n",
        "                tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_CHKPT)\n",
        "            \n",
        "            # Model building\n",
        "            print(\"Building model...\")\n",
        "            regression_model = build_regression_model(loss                    = 'MCRMSE',\n",
        "                                                      model_name              = param_val_model_name, \n",
        "                                                      dense_dim               = dense_dim, \n",
        "                                                      MAX_LEN                 = MAX_LEN,\n",
        "                                                      learning_rate           = param_val_learning_rate,\n",
        "                                                      dropout                 = param_val_dropout,\n",
        "                                                      number_of_hidden_layers = param_val_number_of_hidden_layers,\n",
        "                                                      hidden_layer_node_count = param_val_hidden_layer_node_count,\n",
        "                                                      retrain_layer_count     = param_val_retrain_layer_count\n",
        "                                                     )\n",
        "        \n",
        "            # Model fitting\n",
        "            print(\"Fitting model...\")\n",
        "            df_history = model_fit(model            = regression_model, \n",
        "                                   df_train         = df_train, \n",
        "                                   train_indices    = train_indices,\n",
        "                                   val_indices      = val_indices,\n",
        "                                   model_name       = param_val_model_name, \n",
        "                                   MAX_LEN          = MAX_LEN,\n",
        "                                   epochs           = param_val_epoch,\n",
        "                                   batch_size       = param_val_batch_size,\n",
        "                                   validation_split = param_val_validation_split\n",
        "                                  )\n",
        "            print(df_history.T)\n",
        "\n",
        "            print(\"Plotting loss and MCRMSE...\")\n",
        "            custom_plot(df         = df_history, \n",
        "                        model_name = param_val_model_name, \n",
        "                        kpi_name   = 'MCRMSE', \n",
        "                        kpi_string = 'MCRMSE'\n",
        "                       )\n",
        "\n",
        "            # Prep for model evaluation with test data\n",
        "            print(\"Evaluating mode...\")\n",
        "            test_encoded_input_ids, test_encoded_attention_masks = text_encode(texts      = df_test['full_text'], \n",
        "                                                                               tokenizer = tokenizer, \n",
        "                                                                               max_len    = MAX_LEN\n",
        "                                                                              )\n",
        "            # Model evaluation\n",
        "            test_loss, test_accuracy = evaluate_model(regression_model, \n",
        "                                                      y_test, \n",
        "                                                      test_encoded_input_ids, \n",
        "                                                      test_encoded_attention_masks\n",
        "                                                     )\n",
        "\n",
        "            # Model prediction\n",
        "            print(\"Model prediction...\")\n",
        "            df_prediction, df_comparison = predict_model(regression_model, \n",
        "                                                         df_test, \n",
        "                                                         test_encoded_input_ids, \n",
        "                                                         test_encoded_attention_masks, \n",
        "                                                         label_cols\n",
        "                                                        )\n",
        "\n",
        "            print(\"Plotting model structure...\")\n",
        "            keras.utils.plot_model(regression_model, \n",
        "                                   show_shapes      = False, \n",
        "                                   show_dtype       = False, \n",
        "                                   show_layer_names = True, \n",
        "                                   dpi              = 90\n",
        "                                  )\n",
        "\n",
        "            print(\"Appending to kpi list...\")\n",
        "            temp_dict = {'model_name'                  : param_val_model_name,\n",
        "                         'iteration'                   : idx + 1,\n",
        "                         'epoch'                       : param_val_epoch,\n",
        "                         'batch_size'                  : param_val_batch_size,\n",
        "                         'learning_rate'               : param_val_learning_rate,\n",
        "                         'validation_split'            : param_val_validation_split,\n",
        "                         'dropout'                     : param_val_dropout,\n",
        "                         'number_of_hidden_layers'     : param_val_number_of_hidden_layers,\n",
        "                         'hidden_layer_node_count'     : param_val_hidden_layer_node_count,\n",
        "                         'retrain_layer_count'         : param_val_retrain_layer_count,\n",
        "                         'fold'                        : kfold + 1, \n",
        "                         'train_loss'                  : df_history.iloc[-1][0],\n",
        "                         'train_accuracy'              : df_history.iloc[-1][1],\n",
        "                         'val_loss'                    : df_history.iloc[-1][2],\n",
        "                         'val_accuracy'                : df_history.iloc[-1][3],\n",
        "                         'test_loss'                   : test_loss,\n",
        "                         'test_accuracy'               : test_accuracy\n",
        "                        }\n",
        "            MCRMSE_list.append(temp_dict)\n",
        "            \n",
        "            # # Saving the model\n",
        "            # print(\"Saving the model...\")\n",
        "            # model_file_name = 'regression_model_' + param_val_model_name.lower() + '_iter_' + str(idx + 1) + '_kfold_' + str(kfold + 1) + \".h5\"\n",
        "            # regression_model.save(model_file_name)\n",
        "\n",
        "            for label in label_cols:\n",
        "              print(label)\n",
        "              hall_of_fame(df_comparison,label,1)\n",
        "              print(\"************************\")\n",
        "              hall_of_shame(df_comparison,label,1)\n",
        "              print(\"************************\")\n",
        "            for component in label_cols:\n",
        "              print(component)\n",
        "              print(\"% Predicted too high: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\">\"+component))/len(df_comparison)))\n",
        "              print(\"% Predicted correctly: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\"==\"+component))/len(df_comparison)))\n",
        "              print(\"% Predicted too low: \" + str(len(df_comparison.query(\"transformed_pred_\"+component+\"<\"+component))/len(df_comparison)))\n",
        "              print(\"****\")"
      ],
      "metadata": {
        "id": "MuGt3OWDXAgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pk6ZkXlSjt5B"
      },
      "outputs": [],
      "source": [
        "# kpi_col_list = ['model_name',\n",
        "#                 'iteration',\n",
        "#                 'epoch_val',\n",
        "#                 'batch_size_val',\n",
        "#                 'learning_rate_val',\n",
        "#                 'validation_split_val',\n",
        "#                 'dropout_val',\n",
        "#                 'number_of_hidden_layers_val',\n",
        "#                 'hidden_layer_node_count_val',\n",
        "#                 'retrain_layer_count_val',\n",
        "#                 'fold', \n",
        "#                 'train_loss', \n",
        "#                 'train_accuracy', \n",
        "#                 'val_loss', \n",
        "#                 'val_accuracy', \n",
        "#                 'test_loss', \n",
        "#                 'test_accuracy'\n",
        "#                ]\n",
        "# df_MCRMSE = pd.DataFrame(MCRMSE_list, columns = kpi_col_list)    \n",
        "# df_MCRMSE.to_csv(\"kpi_stats_bertweet.csv\", index = False)\n",
        "# df_MCRMSE    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDwRZh-7ENeh"
      },
      "outputs": [],
      "source": [
        "# print(\"Average test accuracy and loss...\")\n",
        "# df_MCRMSE.groupby(['model_name', 'iteration']).agg({'test_loss'      : [np.mean, np.min, np.max],  \n",
        "#                                                     'test_accuracy'  : [np.mean, np.min, np.max] \n",
        "#                                                    }\n",
        "#                                                   )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Appendix\n",
        "Other experiments with the hyper parameters"
      ],
      "metadata": {
        "id": "phqVvESQdeRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def regression_model_with_bert(num_classes=9,                  # [1, 1.5, 2, 2.5....4.5, 5]: 9 classes\n",
        "                               num_train_layers=0,\n",
        "                               num_hidden_layer=1,\n",
        "                               num_hidden_units=256,\n",
        "                               dropout=0.3,\n",
        "                               learning_rate=0.00005,\n",
        "                               activation = 'relu',\n",
        "                               optimizer='adam'):\n",
        "    \"\"\"\n",
        "    Build a simple regression model with BERT. Use the CLS Output for regression purposes.\n",
        "    \"\"\"\n",
        "    # =========== BEGIN generate \"input features\" using pre-trained model tokenizer ==================================\n",
        "    if num_train_layers == 0:\n",
        "        bert_model.trainable = False                 # Freeze all layers of pre-trained BERT model\n",
        "\n",
        "    elif num_train_layers == 12:         \n",
        "        bert_model.trainable = True                  # Train all layers of the BERT model\n",
        "\n",
        "    else:                                            # Restrict training to the num_train_layers outer transformer layers\n",
        "        retrain_layers = []\n",
        "        for retrain_layer_number in range(num_train_layers):\n",
        "            layer_code = '_' + str(11 - retrain_layer_number)\n",
        "            retrain_layers.append(layer_code) \n",
        "        # print('retrain layers: ', retrain_layers)\n",
        "\n",
        "        for w in bert_model.weights:\n",
        "            if not any([x in w.name for x in retrain_layers]):\n",
        "                #print('freezing: ', w)\n",
        "                w._trainable = False\n",
        "    \n",
        "    # Input Layer\n",
        "    input_ids = tf.keras.layers.Input(shape=(MAX_LENGTH), dtype=tf.int64, name='input_ids_layer')\n",
        "    attention_mask = tf.keras.layers.Input(shape=(MAX_LENGTH), dtype=tf.int64, name='attention_mask_layer')\n",
        "\n",
        "    bert_inputs = {'input_ids': input_ids,\n",
        "                  'attention_mask': attention_mask\n",
        "                  }\n",
        "                      \n",
        "    # Bert output: being used as an input feature in the classification model below\n",
        "    bert_out = bert_model(bert_inputs)        # full features as an input to the following classification model\n",
        "    # pooler_output = bert_out[1]             # one vector for each\n",
        "    cls_token = bert_out[0][:, 0, :]          # give us a raw CLS tokens\n",
        "\n",
        "\n",
        "    layer_list = []\n",
        "    for hidden_layer_number in range(num_hidden_layer):\n",
        "        if hidden_layer_number == 0:\n",
        "            hidden_layer = tf.keras.layers.Dense(units = num_hidden_units\n",
        "                                        , activation = activation\n",
        "                                        , name = 'hidden_layer_' + str(hidden_layer_number + 1)\n",
        "                                        )(cls_token)\n",
        "        else:\n",
        "            hidden_layer = tf.keras.layers.Dense(units = num_hidden_units\n",
        "                                        , activation = activation\n",
        "                                        , name = 'hidden_layer_' + str(hidden_layer_number + 1)\n",
        "                                        )(layer_list[-1])\n",
        "        layer_list.append(hidden_layer)\n",
        "        dropout_layer = tf.keras.layers.Dropout(dropout, name = 'dropout_layer_' + str(hidden_layer_number + 1))(hidden_layer) \n",
        "        layer_list.append(dropout_layer)\n",
        "\n",
        "    output = tf.keras.layers.Dense(6,)(layer_list[-1])\n",
        "    regression_model = tf.keras.Model(inputs = [input_ids, attention_mask], outputs = output)\n",
        "\n",
        "    def selected_optimizer(optimizer):\n",
        "      if optimizer.lower() == 'sgd':\n",
        "        return SGD(learning_rate=learning_rate)           \n",
        "      elif optimizer.lower() == 'adam':\n",
        "        return Adam(learning_rate=learning_rate)          \n",
        "\n",
        "    regression_model.compile(optimizer = selected_optimizer(optimizer),\n",
        "                             loss=MCRMSE,\n",
        "                             metrics=MCRMSE) \n",
        "\n",
        "    return regression_model, count_params(regression_model.trainable_weights), count_params(regression_model.non_trainable_weights)\n",
        "def train_regression(model, batch_size, epochs):  \n",
        "  checkpoint_filepath = '/content/gdrive/MyDrive/Kaggle/Model_Checkpoint'         #  Create a new directory, Model_Checkpoint, in my Google Drive first and navigate the path here\n",
        "  model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
        "                                                                  save_weights_only=True,\n",
        "                                                                  monitor='val_loss',\n",
        "                                                                  mode='min',\n",
        "                                                                  save_best_only=True)  \n",
        "  # The following parameters say: \"If there hasn't been at least an improvement of 0.001 in the validation loss over the previous 3 epochs, then stop the training and keep the best model you found.\"\n",
        "  early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', \n",
        "                                              min_delta=0.001, # minimium amount of change to count as an improvement\n",
        "                                              patience=3,      # how many epochs to wait before stopping\n",
        "                                              restore_best_weights=True)\n",
        "\n",
        "  print('Training Regression with BERT.....\\n====================================='  )\n",
        "  regression_model_history = model.fit([train_encodings.input_ids, \n",
        "                                        train_encodings.attention_mask\n",
        "                                        ], \n",
        "                                        y_train,   \n",
        "                                        validation_split = .1,\n",
        "                                        # validation_data =([val_encodings.input_ids, \n",
        "                                        #                     val_encodings.attention_mask], \n",
        "                                        #                   y_val\n",
        "                                        #                   ),    \n",
        "                                        batch_size = batch_size, \n",
        "                                        # callbacks=[callback, model_checkpoint_callback, tensorboard_callback],\n",
        "                                        callbacks=[early_stopping_callback, model_checkpoint_callback],\n",
        "                                        epochs = epochs \n",
        "                                        # verbose=0    # make output invisible\n",
        "                                        )    \n",
        "  df_regression_model_history = pd.DataFrame(regression_model_history.history)\n",
        "  display(df_regression_model_history.T)     \n",
        "  return df_regression_model_history\n",
        "def plot_loss_mcrmse(df, eval_metric):\n",
        "    x_arr = np.arange(len(df['loss'])) + 1\n",
        "    fig = plt.figure(figsize=(12, 4))\n",
        "    ax = fig.add_subplot(1, 2, 1)\n",
        "    ax.plot(x_arr, df['loss'], '-o', label = 'Train Loss')\n",
        "    ax.plot(x_arr, df['val_loss'], '--<', label = 'Validation Loss')\n",
        "    ax.legend(fontsize = 12)\n",
        "    ax.set_xlabel('Epoch', size = 12)\n",
        "    ax.set_ylabel('Loss', size = 12)\n",
        "\n",
        "    ax = fig.add_subplot(1, 2, 2)\n",
        "    ax.plot(x_arr, df[eval_metric], '-o', label = 'Train ' + eval_metric)\n",
        "    ax.plot(x_arr, df['val_' + eval_metric], '--<', label = 'Validation ' + eval_metric)\n",
        "    ax.legend(fontsize = 12)\n",
        "    ax.set_xlabel('Epoch', size = 12)\n",
        "    ax.set_ylabel('MCRMSE', size = 12)\n",
        "    #ax.set_ylim(0,1)\n",
        "    plt.show()\n",
        "def evaluate_test_labels(model):\n",
        "  score_regression = model.evaluate([test_encodings.input_ids, \n",
        "                                          test_encodings.attention_mask\n",
        "                                          ], \n",
        "                                          y_test\n",
        "                                          ) \n",
        "  print('\\nEvaluate Test Metrics:\\n=================================')\n",
        "  print('\\nTest loss: {:.4f}'.format(score_regression[0]))\n",
        "  print('\\nTest MCRMSE score: {:.4f}'.format(score_regression[1]),'\\n')\n",
        "  return score_regression\n",
        "def predict_test_labels(model):\n",
        "  predictions = model.predict([test_encodings.input_ids, test_encodings.attention_mask])    # -1 in reshape function is used when you don't know or want to explicitly tell the dimension of that axis.\n",
        "  df_pred = pd.DataFrame(predictions, columns=['pred_'+ col for col in label_cols])\n",
        "  return df_pred\n",
        "def scaled_pred(df):\n",
        "  pred_scaled = []\n",
        "  for col in df:\n",
        "    df[col + '_scaled'] = df[col].apply(lambda val: round(val/0.5) * 0.5)\n",
        "    pred_scaled.append(df[col + '_scaled'])\n",
        "  return pd.DataFrame(pred_scaled).T\n",
        "def run_regression_experiment(num_train_layers=0,\n",
        "                              num_hidden_layer=1,\n",
        "                              num_hidden_units=256,\n",
        "                              dropout=0.3,\n",
        "                              learning_rate=0.00005,\n",
        "                              batch_size=8,\n",
        "                              csv_filename='perf_summary_regression_w_BERT.csv',\n",
        "                              activation = 'relu',                                    # 'relu', 'leaky_relu', 'gelu'\n",
        "                              optimizer='adam',                                       # 'adam', 'sgd'\n",
        "                              epochs=1): ### UPDATE AT THE END\n",
        "  set_config_param(20230214)\n",
        "  df_perf_summary = pd.DataFrame()\n",
        "  \n",
        "  for layer in num_train_layers:  \n",
        "    print('\\n******************************************************')\n",
        "    print(f'Regression with BERT: Number of Unfrozen Layers = {layer}')\n",
        "    print('******************************************************\\n')\n",
        "\n",
        "    # build a regression model\n",
        "    regression_with_bert, num_trainable_params, num_non_trainable_params = regression_model_with_bert(num_classes = 9,                          # [1, 1.5, 2, 2.5....4.5, 5]: 9 classes\n",
        "                                                                                                      num_train_layers = layer,\n",
        "                                                                                                      num_hidden_layer = num_hidden_layer,\n",
        "                                                                                                      num_hidden_units = num_hidden_units,\n",
        "                                                                                                      dropout = dropout,\n",
        "                                                                                                      learning_rate = learning_rate,\n",
        "                                                                                                      activation = activation,\n",
        "                                                                                                      optimizer=optimizer)\n",
        "    # print(f'Parameter Values:\\n======================\\nnum_hidden_layer = {num_hidden_layer}\\nnum_hidden_units = {num_hidden_units}\\ndropout = {dropout}\\nlearning_rate = {learning_rate}\\nbatch_size = {batch_size}\\n')\n",
        "    \n",
        "    # model summary and plot model structure\n",
        "    display(regression_with_bert.summary())\n",
        "    display(keras.utils.plot_model(regression_with_bert, show_shapes=False, show_dtype=False, show_layer_names=True, dpi=90))\n",
        "\n",
        "    # train model\n",
        "    df_regression_model_history = train_regression(regression_with_bert, batch_size, epochs)\n",
        "    print(\"\\nPlotting loss and MCRMSE...\")\n",
        "    plot_loss_mcrmse(df_regression_model_history, 'MCRMSE')  \n",
        "    # print(\"\\nTensorBoard: Evolution of Loss and MCRMSE:\\n=============================================\")\n",
        "    # %tensorboard --logdir logs/fit\n",
        "\n",
        "    # Evaluate test set\n",
        "    score_regression = evaluate_test_labels(regression_with_bert)\n",
        "\n",
        "    # Predict test set\n",
        "    df_pred = predict_test_labels(regression_with_bert)\n",
        "    df_pred_scaled = scaled_pred(df_pred)\n",
        "    \n",
        "    # Create a final table with y_true, y_pred_raw, and y_pred_scaled\n",
        "    # display(generate_final_table(df_pred))\n",
        "\n",
        "    # ========== Performace metrics summary ===================================\n",
        "    perf_metrics = pd.DataFrame({'NLP Model':\"bert-base-cased\",\n",
        "                                'Num_Trainable_layers': layer,\n",
        "                                # 'Trainable_Params':  f'{num_trainable_params:,}',\n",
        "                                # 'Non-Trainable_Params':  f'{num_non_trainable_params:,}',\n",
        "                                'Epochs':epochs,                                                              \n",
        "                                'Test_MCRMSE':round(score_regression[1], 4), \n",
        "                                'Test_Loss':round(score_regression[0], 4), \n",
        "                                'Train_MCRMSE':round(df_regression_model_history.iloc[-1][1], 4), \n",
        "                                'Train_Loss':round(df_regression_model_history.iloc[-1][0], 4), \n",
        "                                'Val_MCRMSE':round(df_regression_model_history.iloc[-1][3], 4), \n",
        "                                'Val_Loss':round(df_regression_model_history.iloc[-1][2], 4),  \n",
        "                                'Optimizer': optimizer, \n",
        "                                'Activation': activation,  \n",
        "                                'Learning_Rate':learning_rate,                               \n",
        "                                'Num_Hidden_Layers':num_hidden_layer, \n",
        "                                'Num_hidden_Units':num_hidden_units,                                 \n",
        "                                'Dropout': dropout, \n",
        "                                'Batch_Size': batch_size}, index=[0])\n",
        "    df_perf_summary = df_perf_summary.append(perf_metrics)\n",
        "  df_perf_summary.to_csv(csv_filename, index=False)\n",
        "  display(df_perf_summary.reset_index(drop=True))\n",
        "def generate_final_table(df_pred):\n",
        "  print('\\nFinal Table: y_true vs. y_pred_raw vs. y_pred_scaled\\n======================================================')\n",
        "  df_final = pd.concat([df_test[['full_text']].reset_index(drop=True), df_test[label_cols].reset_index(drop=True), df_pred], axis=1)\n",
        "  display(df_final)\n",
        "  return df_final\n",
        "def run_regression_experiment_1(num_train_layers=0,\n",
        "                              num_hidden_layer=1,\n",
        "                              num_hidden_units=256,\n",
        "                              dropout=0.3,\n",
        "                              learning_rate=0.00005,\n",
        "                              batch_size=8,\n",
        "                              csv_filename='perf_summary_regression_w_BERT.csv',\n",
        "                              activation = 'relu',                                    # 'relu', 'leaky_relu', 'gelu'\n",
        "                              optimizer='adam',                                       # 'adam', 'sgd'\n",
        "                              epochs=10):\n",
        "\n",
        "  # df_perf_summary = pd.DataFrame()\n",
        "  # for layer in num_train_layers:  \n",
        "  print('\\n******************************************************')\n",
        "  print(f'Regression with BERT: Number of Unfrozen Layers = {num_train_layers}')\n",
        "  print('******************************************************\\n')\n",
        "\n",
        "\n",
        "  # build a regression model\n",
        "  regression_with_bert, num_trainable_params, num_non_trainable_params = regression_model_with_bert(num_classes = 9,                          # [1, 1.5, 2, 2.5....4.5, 5]: 9 classes\n",
        "                                                                                                    num_train_layers = num_train_layers,\n",
        "                                                                                                    num_hidden_layer = num_hidden_layer,\n",
        "                                                                                                    num_hidden_units = num_hidden_units,\n",
        "                                                                                                    dropout = dropout,\n",
        "                                                                                                    learning_rate = learning_rate,\n",
        "                                                                                                    activation = activation,\n",
        "                                                                                                    optimizer=optimizer)\n",
        "  # print(f'Parameter Values:\\n======================\\nnum_hidden_layer = {num_hidden_layer}\\nnum_hidden_units = {num_hidden_units}\\ndropout = {dropout}\\nlearning_rate = {learning_rate}\\nbatch_size = {batch_size}\\n')\n",
        "  \n",
        "  # model summary and plot model structure\n",
        "  display(regression_with_bert.summary())\n",
        "  display(keras.utils.plot_model(regression_with_bert, show_shapes=False, show_dtype=False, show_layer_names=True, dpi=90))\n",
        "\n",
        "  # train model\n",
        "  df_regression_model_history = train_regression(regression_with_bert, batch_size, epochs)\n",
        "  print(\"\\nPlotting loss and MCRMSE...\")\n",
        "  plot_loss_mcrmse(df_regression_model_history, 'MCRMSE')  \n",
        "  # print(\"\\nTensorBoard: Evolution of Loss and MCRMSE:\\n=============================================\")\n",
        "  # %tensorboard --logdir logs/fit\n",
        "\n",
        "  # Evaluate test set\n",
        "  score_regression = evaluate_test_labels(regression_with_bert)\n",
        "\n",
        "  # Predict test set\n",
        "  df_pred = predict_test_labels(regression_with_bert)\n",
        "  df_pred_scaled = scaled_pred(df_pred)\n",
        "  df_pred.to_csv('df_pred.csv', index=False)\n",
        "  \n",
        "  # Create a final table with y_true, y_pred_raw, and y_pred_scaled\n",
        "  df_final = generate_final_table(df_pred)\n",
        "  display(generate_final_table(df_pred))\n",
        "  df_final.to_csv('df_final.csv', index=False)\n",
        "\n",
        "  # ========== Performace metrics summary ===================================\n",
        "  perf_metrics = pd.DataFrame({'NLP Model':\"bert-base-cased\",\n",
        "                              'Num_Trainable_layers': num_train_layers,\n",
        "                              # 'Trainable_Params':  f'{num_trainable_params:,}',\n",
        "                              # 'Non-Trainable_Params':  f'{num_non_trainable_params:,}',\n",
        "                              'Epochs':epochs,                                                              \n",
        "                              'Test_MCRMSE':round(score_regression[1], 4), \n",
        "                              'Test_Loss':round(score_regression[0], 4), \n",
        "                              'Train_MCRMSE':round(df_regression_model_history.iloc[-1][1], 4), \n",
        "                              'Train_Loss':round(df_regression_model_history.iloc[-1][0], 4), \n",
        "                              'Val_MCRMSE':round(df_regression_model_history.iloc[-1][3], 4), \n",
        "                              'Val_Loss':round(df_regression_model_history.iloc[-1][2], 4),  \n",
        "                              'Optimizer': optimizer, \n",
        "                              'Activation': activation,  \n",
        "                              'Learning_Rate':learning_rate,                               \n",
        "                              'Num_Hidden_Layers':num_hidden_layer, \n",
        "                              'Num_hidden_Units':num_hidden_units,                                 \n",
        "                              'Dropout': dropout, \n",
        "                              'Batch_Size': batch_size}, index=[0])\n",
        "    # df_perf_summary = df_perf_summary.append(perf_metrics)\n",
        "  perf_metrics.to_csv(csv_filename, index=False)\n",
        "  display(perf_metrics.reset_index(drop=True))"
      ],
      "metadata": {
        "id": "X6fxpQJFlDH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_regression_experiment(num_train_layers=np.arange(0,13,6),\n",
        "                          activation='relu',\n",
        "                          optimizer='adam',                          \n",
        "                          csv_filename='perf_summary_regression_w_BERT_1.csv')"
      ],
      "metadata": {
        "id": "6PZfOmUGddGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_regression_experiment(num_train_layers=np.arange(0,13,2),\n",
        "                          num_hidden_layer=2,\n",
        "                          num_hidden_units=64,\n",
        "                          dropout=0.1,\n",
        "                          learning_rate=0.00001,\n",
        "                          batch_size=16,\n",
        "                          csv_filename='perf_summary_regression_w_BERT_2.csv',\n",
        "                          activation='relu',\n",
        "                          optimizer='adam',\n",
        "                          epochs=10)"
      ],
      "metadata": {
        "id": "akVSmP58v_We"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_regression_experiment(num_train_layers=np.arange(0,13,2),\n",
        "                          csv_filename='perf_summary_regression_w_BERT_5.csv')"
      ],
      "metadata": {
        "id": "5PeAFzQhv_eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_regression_experiment(num_train_layers=np.arange(0,13,6),\n",
        "                          # num_hidden_layer=1,\n",
        "                          # num_hidden_units=256,\n",
        "                          # dropout=0.3,\n",
        "                          # learning_rate=0.00005,\n",
        "                          batch_size=16,\n",
        "                          activation='relu',\n",
        "                          optimizer='adam',\n",
        "                          csv_filename='perf_summary_regression_w_BERT_4.csv')"
      ],
      "metadata": {
        "id": "ADKyWC2Dv_lK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_regression_experiment(num_train_layers=np.arange(0,13,6),\n",
        "                          # num_hidden_layer=1,\n",
        "                          # num_hidden_units=256,\n",
        "                          # dropout=0.3,\n",
        "                          # learning_rate=0.00005,\n",
        "                          batch_size=16,\n",
        "                          activation='gelu',\n",
        "                          optimizer='adam',\n",
        "                          csv_filename='perf_summary_regression_w_BERT_batch16_gelu.csv')"
      ],
      "metadata": {
        "id": "IQkEBRrEv5mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_regression_experiment(num_train_layers=np.arange(0,7,2),\n",
        "                          # num_hidden_layer=1,\n",
        "                          # num_hidden_units=256,\n",
        "                          # dropout=0.3,\n",
        "                          # learning_rate=0.00005,\n",
        "                          batch_size=16,\n",
        "                          activation='leaky_relu',\n",
        "                          optimizer='adam',\n",
        "                          csv_filename='perf_summary_regression_w_BERT_batch16_leakyRelu.csv')"
      ],
      "metadata": {
        "id": "9KsoMwRRv5pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_regression_experiment(num_train_layers=np.arange(2,5,2),\n",
        "# run_regression_experiment(num_train_layers=np.arange(0,9,2),\n",
        "                          # num_hidden_layer=1,\n",
        "                          # num_hidden_units=256,\n",
        "                          dropout=0.1,\n",
        "                          # learning_rate=0.00005,\n",
        "                          batch_size=16,\n",
        "                          activation='relu',\n",
        "                          optimizer='adam',\n",
        "                          csv_filename='perf_summary_regression_w_BERT_batch16_leakyRelu.csv')"
      ],
      "metadata": {
        "id": "h2-i0Bccv5wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_regression_experiment(num_train_layers=np.arange(0,7,2),\n",
        "                          # num_hidden_layer=1,\n",
        "                          # num_hidden_units=256,\n",
        "                          dropout=0.2,\n",
        "                          # learning_rate=0.00005,\n",
        "                          batch_size=16,\n",
        "                          activation='leaky_relu',\n",
        "                          optimizer='adam',\n",
        "                          csv_filename='perf_summary_regression_w_BERT_batch16_leakyRelu_sgd.csv')"
      ],
      "metadata": {
        "id": "dp1zCoQTvxAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " run_regression_experiment(num_train_layers=np.arange(0,7,2),\n",
        "                          # num_hidden_layer=1,\n",
        "                          # num_hidden_units=256,\n",
        "                          dropout=0.2,\n",
        "                          learning_rate=0.0001,\n",
        "                          batch_size=16,\n",
        "                          activation='leaky_relu',\n",
        "                          optimizer='adam',\n",
        "                          csv_filename='perf_summary_regression_w_BERT_batch16_leakyRelu_lowerLR.csv')"
      ],
      "metadata": {
        "id": "FieQsIpzvxC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_regression_experiment(num_train_layers=np.arange(0,13,4),\n",
        "                          # num_hidden_layer=1,\n",
        "                          num_hidden_units=128,\n",
        "                          dropout=0.2,\n",
        "                          learning_rate=0.0005,\n",
        "                          batch_size=16,\n",
        "                          activation='leaky_relu',\n",
        "                          optimizer='adam',\n",
        "                          csv_filename='perf_summary_regression_w_BERT_batch16_leakyRelu_lowerLR2.csv')"
      ],
      "metadata": {
        "id": "N5_xlwdavxFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " run_regression_experiment(num_train_layers=np.arange(0,13,4),\n",
        "                          # num_hidden_layer=1,\n",
        "                          num_hidden_units=64,\n",
        "                          dropout=0.2,\n",
        "                          learning_rate=0.0005,\n",
        "                          batch_size=16,\n",
        "                          activation='leaky_relu',\n",
        "                          optimizer='adam',\n",
        "                          csv_filename='perf_summary_regression_w_BERT_batch16_leakyRelu_lowerLR128.csv')"
      ],
      "metadata": {
        "id": "drc4AOITvxIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_regression_experiment_1(num_train_layers=12,\n",
        "                          num_hidden_layer=2,\n",
        "                          num_hidden_units=64,\n",
        "                          dropout=0.1,\n",
        "                          learning_rate=0.00001,\n",
        "                          batch_size=16,\n",
        "                          csv_filename='perf_summary_regression_w_BERT_final1.csv',\n",
        "                          activation='relu',\n",
        "                          optimizer='adam',\n",
        "                          epochs=10)"
      ],
      "metadata": {
        "id": "BDn1FN-ZvxLD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FYfihW3Mjgkf",
        "6yYB47Gdjo0L",
        "dII35P-P_J_t"
      ],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f99a5ce99684adcb74b6d997dd4f6b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63e3ad6b2f714d83a9371224fc036969",
              "IPY_MODEL_841c04a5892848feaccb9c5f8db87714",
              "IPY_MODEL_15c166dfb76a4c778e078f4a798a1667"
            ],
            "layout": "IPY_MODEL_1ba6bc91c94a439f811d817a996a3f89"
          }
        },
        "63e3ad6b2f714d83a9371224fc036969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5be82c8821c48d3b1cb9017841f0d77",
            "placeholder": "​",
            "style": "IPY_MODEL_2d7c191b35fa4f10be56e5d6ea621584",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "841c04a5892848feaccb9c5f8db87714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9719939c3b0946748256bd92fd9534c6",
            "max": 558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28f0f0f927aa4d6d80a45e4bf15f1cfc",
            "value": 558
          }
        },
        "15c166dfb76a4c778e078f4a798a1667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cc709c0cbe2412d8d281ab9f84463b1",
            "placeholder": "​",
            "style": "IPY_MODEL_444d03ee8b4e4cb5a2ee62e769bc01a1",
            "value": " 558/558 [00:00&lt;00:00, 21.6kB/s]"
          }
        },
        "1ba6bc91c94a439f811d817a996a3f89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5be82c8821c48d3b1cb9017841f0d77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d7c191b35fa4f10be56e5d6ea621584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9719939c3b0946748256bd92fd9534c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28f0f0f927aa4d6d80a45e4bf15f1cfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8cc709c0cbe2412d8d281ab9f84463b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "444d03ee8b4e4cb5a2ee62e769bc01a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e7917045672490b88288cc47fb111e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f06b3a456911410e835a1ab4feca72e0",
              "IPY_MODEL_28309e7c29b242aeb49361bf8b5127d8",
              "IPY_MODEL_30719f59a4db452c939c3e8a54d30798"
            ],
            "layout": "IPY_MODEL_85294c2326b64a748275411f5201e159"
          }
        },
        "f06b3a456911410e835a1ab4feca72e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d92a01d03eb42098d864ef0bc145add",
            "placeholder": "​",
            "style": "IPY_MODEL_a8ba13da20be4372810a8a1359ca557c",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "28309e7c29b242aeb49361bf8b5127d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a1a84d5368e4a85bc2c5f3de605b20f",
            "max": 843438,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd26e87afb974ebdbfa5f67460712499",
            "value": 843438
          }
        },
        "30719f59a4db452c939c3e8a54d30798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37234288af2a444f9317d1a53376cde4",
            "placeholder": "​",
            "style": "IPY_MODEL_4393074977724b5d9c7514e6212b25e8",
            "value": " 843k/843k [00:00&lt;00:00, 12.0MB/s]"
          }
        },
        "85294c2326b64a748275411f5201e159": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d92a01d03eb42098d864ef0bc145add": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8ba13da20be4372810a8a1359ca557c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a1a84d5368e4a85bc2c5f3de605b20f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd26e87afb974ebdbfa5f67460712499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37234288af2a444f9317d1a53376cde4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4393074977724b5d9c7514e6212b25e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c72c905ae934db2b34b4ab00ac577d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a7b38b0978c41f3acd74bc82be39def",
              "IPY_MODEL_b6edc4817bf3431c991d8d923a89ff1e",
              "IPY_MODEL_f68553ac3b3b4ccfb4cdc67dc1a931cd"
            ],
            "layout": "IPY_MODEL_10cc1b639ff04b5d823e04b6ba32c668"
          }
        },
        "0a7b38b0978c41f3acd74bc82be39def": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3e7fe0be36140889edc96805cdd3f9a",
            "placeholder": "​",
            "style": "IPY_MODEL_b400ff9e85084e168d7a5d9e28b3f3b5",
            "value": "Downloading (…)solve/main/bpe.codes: 100%"
          }
        },
        "b6edc4817bf3431c991d8d923a89ff1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b19cdfc0d0c149b4a7b873f5da0b5ba5",
            "max": 1078931,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e84ed1195b234049818f31377d9afaf6",
            "value": 1078931
          }
        },
        "f68553ac3b3b4ccfb4cdc67dc1a931cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fa790ed2e894e888bbeb3e9013770b8",
            "placeholder": "​",
            "style": "IPY_MODEL_13993572354848a4b2c3b9317ebc4faa",
            "value": " 1.08M/1.08M [00:00&lt;00:00, 14.3MB/s]"
          }
        },
        "10cc1b639ff04b5d823e04b6ba32c668": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3e7fe0be36140889edc96805cdd3f9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b400ff9e85084e168d7a5d9e28b3f3b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b19cdfc0d0c149b4a7b873f5da0b5ba5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e84ed1195b234049818f31377d9afaf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fa790ed2e894e888bbeb3e9013770b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13993572354848a4b2c3b9317ebc4faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5876ad8f5e74428ca6002e0ae9097745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4936d6bed14436a88931c7775e18ff7",
              "IPY_MODEL_6a6a2a8153224a94a0476b164bde2b13",
              "IPY_MODEL_ea446597da424b29a15cddad8b6e0ae2"
            ],
            "layout": "IPY_MODEL_901ee533fc4147fd94a01cf6d0710e65"
          }
        },
        "c4936d6bed14436a88931c7775e18ff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_234fef11af4a4d5d9c1da7b50bcead21",
            "placeholder": "​",
            "style": "IPY_MODEL_2965235ba8cb4a8abaafb19e5195ce01",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "6a6a2a8153224a94a0476b164bde2b13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_304b52a248364e85adf8ad5f64505313",
            "max": 739523780,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5610672da1f4f7987ee84d17f0b3665",
            "value": 739523780
          }
        },
        "ea446597da424b29a15cddad8b6e0ae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a682d41932d54145a2802a4a47ba920e",
            "placeholder": "​",
            "style": "IPY_MODEL_3a1461733a2f4d9ab2d5123f73c4718a",
            "value": " 740M/740M [00:13&lt;00:00, 115MB/s]"
          }
        },
        "901ee533fc4147fd94a01cf6d0710e65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "234fef11af4a4d5d9c1da7b50bcead21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2965235ba8cb4a8abaafb19e5195ce01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "304b52a248364e85adf8ad5f64505313": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5610672da1f4f7987ee84d17f0b3665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a682d41932d54145a2802a4a47ba920e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a1461733a2f4d9ab2d5123f73c4718a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5721fcb7b61a4109a888cb6d1a006cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0eb79ee7905849ccbcab24ea82257044",
              "IPY_MODEL_b766cfddc90f44c8991948255ae03b62",
              "IPY_MODEL_6ad057cf50a64c80a49ec5109b79ddd4"
            ],
            "layout": "IPY_MODEL_ea2e84c3838d4bc1a9d3bb4e11465036"
          }
        },
        "0eb79ee7905849ccbcab24ea82257044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_933a4544352d413089c78273528dc9ae",
            "placeholder": "​",
            "style": "IPY_MODEL_4ab014b6cce94e91b5bf4ca481192d14",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "b766cfddc90f44c8991948255ae03b62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89b4094ee4574d5cbb6d0114b27b41fa",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a990c1f7a6b4daea97a98e6af342096",
            "value": 29
          }
        },
        "6ad057cf50a64c80a49ec5109b79ddd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e68dff57d7814da794312cd738bebafc",
            "placeholder": "​",
            "style": "IPY_MODEL_6bd85215efa14ca4a7ff82848b7649c7",
            "value": " 29.0/29.0 [00:00&lt;00:00, 731B/s]"
          }
        },
        "ea2e84c3838d4bc1a9d3bb4e11465036": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "933a4544352d413089c78273528dc9ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ab014b6cce94e91b5bf4ca481192d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89b4094ee4574d5cbb6d0114b27b41fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a990c1f7a6b4daea97a98e6af342096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e68dff57d7814da794312cd738bebafc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bd85215efa14ca4a7ff82848b7649c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b234a9bee696475fb198af9ce9aad81a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_248268893bcb44198e12474e312fff3e",
              "IPY_MODEL_22e3c1f959f94f11b7d9346de87427ee",
              "IPY_MODEL_d2946235146446c0974bf7bbaeb65936"
            ],
            "layout": "IPY_MODEL_8569e6e97e3d4785b59ae6683967b497"
          }
        },
        "248268893bcb44198e12474e312fff3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cc38adea8934817bb992cec745202c5",
            "placeholder": "​",
            "style": "IPY_MODEL_f14a95df6b324cd387a06cf8f91a7301",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "22e3c1f959f94f11b7d9346de87427ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c04f3d60d6954e5da104e305556768f3",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35175699de0f4e13ac29ecd8c0f3ba14",
            "value": 570
          }
        },
        "d2946235146446c0974bf7bbaeb65936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29656b6dba6e404aa87be3f1a89ab6d3",
            "placeholder": "​",
            "style": "IPY_MODEL_f4baefb455974a918b76729bbe774a93",
            "value": " 570/570 [00:00&lt;00:00, 20.4kB/s]"
          }
        },
        "8569e6e97e3d4785b59ae6683967b497": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cc38adea8934817bb992cec745202c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f14a95df6b324cd387a06cf8f91a7301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c04f3d60d6954e5da104e305556768f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35175699de0f4e13ac29ecd8c0f3ba14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29656b6dba6e404aa87be3f1a89ab6d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4baefb455974a918b76729bbe774a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2adeba9ef3844ad18d620b8c1df06c6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00b07c7e16154f0ab4a868b654d3581d",
              "IPY_MODEL_63435d2f6d8843229948d2c73566fb15",
              "IPY_MODEL_ee1de2f6f57e4dcc99fda855eb5180b8"
            ],
            "layout": "IPY_MODEL_44a2c6f5305b4e46bb70dc9338ef7428"
          }
        },
        "00b07c7e16154f0ab4a868b654d3581d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a3d3b03245a4e02b45ed37e660ef9c1",
            "placeholder": "​",
            "style": "IPY_MODEL_2f8573abf79d49df96709dd7b6748f4c",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "63435d2f6d8843229948d2c73566fb15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f08dee0e50846ed958f92f1cea388dc",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d63585b9fee34ed8bbbf7e079e039798",
            "value": 213450
          }
        },
        "ee1de2f6f57e4dcc99fda855eb5180b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c2fc778b3da45ea8ffab518eda31b6c",
            "placeholder": "​",
            "style": "IPY_MODEL_d05b8334e8044260ae5c2cafe17dc700",
            "value": " 213k/213k [00:00&lt;00:00, 10.5MB/s]"
          }
        },
        "44a2c6f5305b4e46bb70dc9338ef7428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a3d3b03245a4e02b45ed37e660ef9c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f8573abf79d49df96709dd7b6748f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f08dee0e50846ed958f92f1cea388dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d63585b9fee34ed8bbbf7e079e039798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c2fc778b3da45ea8ffab518eda31b6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d05b8334e8044260ae5c2cafe17dc700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37f2721760de40e6804a3a72878cd09f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68d3d09d573d47a091f52d030532de2b",
              "IPY_MODEL_62f37697713f451eae531dc4bfd98219",
              "IPY_MODEL_15a03ad7ed624c23be1a097fa3513f80"
            ],
            "layout": "IPY_MODEL_63c3e3042ef5486691365ae0c5a4ccd2"
          }
        },
        "68d3d09d573d47a091f52d030532de2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1429dea730b94acd9d20ab63c34c114b",
            "placeholder": "​",
            "style": "IPY_MODEL_453814a9db27481593bf1d5cd553db57",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "62f37697713f451eae531dc4bfd98219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1681285568c0434e85b0576c69e592d6",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c530950116214723ace7c4a0911c0c1c",
            "value": 435797
          }
        },
        "15a03ad7ed624c23be1a097fa3513f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa9e78faa56e4ed59f9c262b4c179af1",
            "placeholder": "​",
            "style": "IPY_MODEL_9167f58120e042948bb1bd5d790ae4ab",
            "value": " 436k/436k [00:00&lt;00:00, 17.5MB/s]"
          }
        },
        "63c3e3042ef5486691365ae0c5a4ccd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1429dea730b94acd9d20ab63c34c114b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "453814a9db27481593bf1d5cd553db57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1681285568c0434e85b0576c69e592d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c530950116214723ace7c4a0911c0c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa9e78faa56e4ed59f9c262b4c179af1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9167f58120e042948bb1bd5d790ae4ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0ad88081d9342eba22477fb400b876f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_112565d9177a46038883241a5c3a8272",
              "IPY_MODEL_cf61c809fe954c93b8254f9dea994b31",
              "IPY_MODEL_c40be4c061424eff8a75c70e9d941647"
            ],
            "layout": "IPY_MODEL_a94480b461c240e39bfe0d34e3c76b5c"
          }
        },
        "112565d9177a46038883241a5c3a8272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56a9d92be0744129b17dc7eb483de41e",
            "placeholder": "​",
            "style": "IPY_MODEL_3e2babd4e0cf40578f2a525bfb448fad",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "cf61c809fe954c93b8254f9dea994b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50319172a7154db68c96bb7cb48c41ca",
            "max": 526681800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0365664de8d4846916aa8f5602c400a",
            "value": 526681800
          }
        },
        "c40be4c061424eff8a75c70e9d941647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_442345d26c494f2893ea82dbdbfa5686",
            "placeholder": "​",
            "style": "IPY_MODEL_22508a195d6f4fae821ef06e5cd90604",
            "value": " 527M/527M [00:06&lt;00:00, 86.3MB/s]"
          }
        },
        "a94480b461c240e39bfe0d34e3c76b5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56a9d92be0744129b17dc7eb483de41e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e2babd4e0cf40578f2a525bfb448fad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50319172a7154db68c96bb7cb48c41ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0365664de8d4846916aa8f5602c400a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "442345d26c494f2893ea82dbdbfa5686": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22508a195d6f4fae821ef06e5cd90604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}