{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkE5IR1x2aZMDuMcAT3/ER",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "268136072bd843b992a00cd02cbf5658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4de40eda6004b36b0711603a502a563",
              "IPY_MODEL_0dce78eef238477286c5a338c0785729",
              "IPY_MODEL_7f128b925bd54f41a3671c8a3254edf0"
            ],
            "layout": "IPY_MODEL_765f5ab348554559bc714fad68cc0757"
          }
        },
        "b4de40eda6004b36b0711603a502a563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b71cb9c5816643f398cc73ca4d044070",
            "placeholder": "​",
            "style": "IPY_MODEL_e9617f844fd043a38c36b1eaaeae569e",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "0dce78eef238477286c5a338c0785729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81a5804a1a3b4811b4d280802bb9e643",
            "max": 739523780,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b287232db5284e82bc3130310d1465e2",
            "value": 739523780
          }
        },
        "7f128b925bd54f41a3671c8a3254edf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97c4f98c49c5458590c2ee1b76d1b0df",
            "placeholder": "​",
            "style": "IPY_MODEL_96176dcf26f748c09ce55aa15614ca01",
            "value": " 740M/740M [00:33&lt;00:00, 23.7MB/s]"
          }
        },
        "765f5ab348554559bc714fad68cc0757": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b71cb9c5816643f398cc73ca4d044070": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9617f844fd043a38c36b1eaaeae569e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81a5804a1a3b4811b4d280802bb9e643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b287232db5284e82bc3130310d1465e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97c4f98c49c5458590c2ee1b76d1b0df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96176dcf26f748c09ce55aa15614ca01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilamaiti/spring_2023_w266_final_project_heesuk_iris_srila/blob/main/srila/bertweet_ell.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Installing new libraries**"
      ],
      "metadata": {
        "id": "Lhf_T8cMjGsp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD4BChywisTm",
        "outputId": "c4c3e533-e302-4109-ef0d-64460fbe68ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.8.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.9/dist-packages (1.8.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from wordcloud) (8.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from wordcloud) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.9/dist-packages (from wordcloud) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (23.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (4.39.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (5.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (3.0.9)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->wordcloud) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emoji==0.6.0 in /usr/local/lib/python3.9/dist-packages (0.6.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.9/dist-packages (0.13.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "!pip install wordcloud\n",
        "!pip install transformers\n",
        "!pip install emoji==0.6.0\n",
        "!pip3 install tokenizers\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing libraries**"
      ],
      "metadata": {
        "id": "bC3s_6EZjMBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(f'transformers version: {transformers.__version__}')\n",
        "from transformers import logging as hf_logging\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "hf_logging.set_verbosity_error()\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import spacy      \n",
        "from spacy import displacy\n",
        "from wordcloud import WordCloud\n",
        "from wordcloud import STOPWORDS\n",
        "from wordcloud import ImageColorGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Other required libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import copy\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Data visualization libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Tensorflow libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils.layer_utils import count_params\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.losses import mae\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.regularizers import l1\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.models import load_model\n",
        "\n",
        "import torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaPH5XqxjU_z",
        "outputId": "9f9cf414-79e0-4d96-e206-8a13d5b6542b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers version: 4.27.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General functions**"
      ],
      "metadata": {
        "id": "5fjpBUG5jbmt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Set parameters**"
      ],
      "metadata": {
        "id": "FYfihW3Mjgkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_config_param(seed = 99):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    tf.keras.backend.clear_session()\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Kaggle\"\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    \n",
        "    \n",
        "set_config_param(20230214)"
      ],
      "metadata": {
        "id": "pr1-rS8tjiqn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Plot loss and accuracy**"
      ],
      "metadata": {
        "id": "6yYB47Gdjo0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_accuracy(history, col_list):\n",
        "    fig, ax = plt.subplots(2, 6, figsize=(16, 6), sharex='col', sharey='row')\n",
        "    fig.tight_layout(pad=5.0)\n",
        "    for idx, col in enumerate(col_list):\n",
        "\n",
        "        ax[0, idx].plot(history[col + '_loss'], lw=2, color='darkgoldenrod')\n",
        "        ax[0, idx].plot(history['val_' + col + '_loss'], lw=2, color='indianred')\n",
        "        #ax[0, idx].legend(loc='center left')\n",
        "        ax[0, idx].legend(['Train', 'Validation'], fontsize=5)\n",
        "        ax[0, idx].set_xlabel('Epochs', size=10)\n",
        "        ax[0, idx].set_title('Loss: ' + col)\n",
        "\n",
        "        ax[1, idx].plot(history[col + '_accuracy'], lw=2, color='darkgoldenrod')\n",
        "        ax[1, idx].plot(history['val_' + col + '_accuracy'], lw=2, color='indianred')\n",
        "        #ax[0, idx].legend(loc='center left')\n",
        "        ax[1, idx].legend(['Train', 'Validation'], fontsize=5)\n",
        "        ax[1, idx].set_xlabel('Epochs', size=10)\n",
        "        ax[1, idx].set_title('Accuracy: ' + col)"
      ],
      "metadata": {
        "id": "BE9NqiNWjrPy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Custom metric**"
      ],
      "metadata": {
        "id": "uJw9YpJXjwSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MCRMSE(y_true, y_pred):\n",
        "    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n",
        "    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=-1, keepdims=True)"
      ],
      "metadata": {
        "id": "_VCdZF9ZjzN6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Read input files**"
      ],
      "metadata": {
        "id": "zP0n_Dd8j26W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_train_df = pd.read_csv('train.csv')\n",
        "input_test_df = pd.read_csv('test.csv')\n",
        "label_cols = df_train.columns[2:]\n",
        "orig_train_df = copy.deepcopy(input_train_df)\n",
        "orig_train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Le5HU_86j4-9",
        "outputId": "54e810d1-31ce-4f90-9476-a3a5f82c99b4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        text_id                                          full_text  cohesion  \\\n",
              "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
              "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
              "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
              "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
              "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
              "\n",
              "   syntax  vocabulary  phraseology  grammar  conventions  \n",
              "0     3.5         3.0          3.0      4.0          3.0  \n",
              "1     2.5         3.0          2.0      2.0          2.5  \n",
              "2     3.5         3.0          3.0      3.0          2.5  \n",
              "3     4.5         4.5          4.5      4.0          5.0  \n",
              "4     3.0         3.0          3.0      2.5          2.5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-726fd043-db72-47d9-986a-a700fbf305c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>full_text</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0016926B079C</td>\n",
              "      <td>I think that students would benefit from learn...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0022683E9EA5</td>\n",
              "      <td>When a problem is a change you have to let it ...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00299B378633</td>\n",
              "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>003885A45F42</td>\n",
              "      <td>The best time in life is when you become yours...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0049B1DF5CCC</td>\n",
              "      <td>Small act of kindness can impact in other peop...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-726fd043-db72-47d9-986a-a700fbf305c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-726fd043-db72-47d9-986a-a700fbf305c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-726fd043-db72-47d9-986a-a700fbf305c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Spliting the data**\n",
        "Original test data is very limited, there are only 3 records and it does not have labels to test. So we decided to repurpose the given train data to split into train, test and validation sets."
      ],
      "metadata": {
        "id": "A4DOnrFpkBz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shuffle = np.random.permutation(np.arange(orig_train_df.shape[0]))\n",
        "orig_train_df = orig_train_df.iloc[shuffle]\n",
        "split=(0.8,0.1,0.1)\n",
        "splits = np.multiply(len(orig_train_df), split).astype(int)\n",
        "df_train, df_val, df_test = np.split(orig_train_df, [splits[0], splits[0] + splits[1]])\n",
        "\n",
        "X_train, X_val, X_test = df_train['full_text'], df_val['full_text'], df_test['full_text']\n",
        "y_train, y_val, y_test = np.array(df_train[label_cols]), np.array(df_val[label_cols]), np.array(df_test[label_cols])"
      ],
      "metadata": {
        "id": "ZtWKcw09kKZt"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model building**"
      ],
      "metadata": {
        "id": "6LVCmgcikTTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_config_param()\n",
        "MAX_LENGTH = 512\n",
        "epochs = 5\n",
        "batch_size = 8\n",
        "dropout = .1\n",
        "learning_rate = .00005\n",
        "number_of_hidden_layer = 1\n",
        "hidden_layer_node_count = 256\n",
        "trainable_flag = False\n",
        "retrain_layer_count = 0"
      ],
      "metadata": {
        "id": "Uqi7K_9ylr37"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bertweet_model_checkpoint = 'vinai/bertweet-base'   \n",
        "bertweet_model = TFAutoModel.from_pretrained(bertweet_model_checkpoint)\n",
        "bertweet_tokenizer = AutoTokenizer.from_pretrained(bertweet_model_checkpoint, use_fast=False, normalization = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "268136072bd843b992a00cd02cbf5658",
            "b4de40eda6004b36b0711603a502a563",
            "0dce78eef238477286c5a338c0785729",
            "7f128b925bd54f41a3671c8a3254edf0",
            "765f5ab348554559bc714fad68cc0757",
            "b71cb9c5816643f398cc73ca4d044070",
            "e9617f844fd043a38c36b1eaaeae569e",
            "81a5804a1a3b4811b4d280802bb9e643",
            "b287232db5284e82bc3130310d1465e2",
            "97c4f98c49c5458590c2ee1b76d1b0df",
            "96176dcf26f748c09ce55aa15614ca01"
          ]
        },
        "id": "gMKPylKdmMXZ",
        "outputId": "17ff3313-8dbf-4e53-db78-6678d3595485"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/740M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "268136072bd843b992a00cd02cbf5658"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_text(text, tokenizer):\n",
        "    \n",
        "    encoded = tokenizer.batch_encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=MAX_LENGTH,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors=\"tf\",\n",
        "    )\n",
        "\n",
        "    input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n",
        "    attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_masks\": attention_masks\n",
        "    }"
      ],
      "metadata": {
        "id": "zdV8CU_tPhHd"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tf.keras.layers.Input(shape=(MAX_LENGTH,), dtype=tf.int32, name='input_ids_layer')\n",
        "attention_mask = tf.keras.layers.Input(shape=(MAX_LENGTH,), dtype=tf.int32, name='attention_mask_layer')"
      ],
      "metadata": {
        "id": "fBhhdt6tQIpS"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = encode_text(df_train['full_text'].tolist(), bertweet_tokenizer)\n",
        "val_encodings = encode_text(df_val['full_text'].tolist(), bertweet_tokenizer)\n",
        "test_encodings = encode_text(df_test['full_text'].tolist(), bertweet_tokenizer)"
      ],
      "metadata": {
        "id": "XvirTQAhQeLK"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPVx-RaAUk2r",
        "outputId": "5ae6fc7c-d95e-4b2c-fa1a-b189f5a5a6e5"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': array([[    0, 16017, 19819, ...,     1,     1,     1],\n",
              "        [    0,     8,   101, ...,     1,     1,     1],\n",
              "        [    0,     8,  5766, ...,     1,     1,     1],\n",
              "        ...,\n",
              "        [    0,   726,  2522, ...,     9,  6553,     2],\n",
              "        [    0,  1038,    14, ...,     1,     1,     1],\n",
              "        [    0,  2420,    83, ...,   153,    15,     2]], dtype=int32),\n",
              " 'attention_masks': array([[1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1, ..., 1, 1, 1],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 1, 1, 1]], dtype=int32)}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgpr29jOUzvv",
        "outputId": "e768ff5d-4a8d-43d6-f0fd-f535ca718c3a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_masks'])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bertweet_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R9-o9OiSINX",
        "outputId": "63ef4042-38ac-4569-8506-86fbd2a4c948"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaModel(\n",
              "  (embeddings): RobertaEmbeddings(\n",
              "    (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
              "    (position_embeddings): Embedding(130, 768, padding_idx=1)\n",
              "    (token_type_embeddings): Embedding(1, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): RobertaEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): RobertaPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bertweet_model_v1 = bertweet_model(input_ids, attention_mask=attention_mask)\n",
        "cls_token, pooler_output = bertweet_model_v1[0], bertweet_model_v1[1]"
      ],
      "metadata": {
        "id": "3ksetNxoPhXc"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cls_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXr5LmdHTlG5",
        "outputId": "8aa30629-11fb-4b18-f6e5-e4b183e5197a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 512, 768) dtype=float32 (created by layer 'tf_roberta_model')>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pooler_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adbDBSj4Tr-w",
        "outputId": "5273fc3e-ca04-4425-80e5-8ca79a785edf"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_roberta_model')>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_list = []\n",
        "\n",
        "for hidden_layer_number in range(number_of_hidden_layer):\n",
        "    if hidden_layer_number == 0:\n",
        "        hidden_layer = tf.keras.layers.Dense(units = hidden_layer_node_count\n",
        "                                    , activation = 'relu'\n",
        "                                    , name = 'hidden_layer_' + str(hidden_layer_number + 1)\n",
        "                                     )(cls_token)\n",
        "    else:\n",
        "        hidden_layer = tf.keras.layers.Dense(units = hidden_layer_node_count\n",
        "                                    , activation = 'relu'\n",
        "                                    , name = 'hidden_layer_' + str(hidden_layer_number + 1)\n",
        "                                     )(layer_list[-1])\n",
        "    layer_list.append(hidden_layer)\n",
        "    dropout_layer = tf.keras.layers.Dropout(dropout, name = 'dropout_layer_' + str(hidden_layer_number + 1))(hidden_layer) \n",
        "    layer_list.append(dropout_layer)\n"
      ],
      "metadata": {
        "id": "cqJaBHwTPhaa"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = tf.keras.layers.Dense(6,)(layer_list[-1])\n",
        "bertweet_v1_regression_model = tf.keras.Model(inputs = [input_ids, \n",
        "                                                        attention_mask\n",
        "                                                       ], \n",
        "                                                       outputs = output\n",
        "                                             )\n",
        "\n",
        "bertweet_v1_regression_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n",
        "                                     loss = MCRMSE, \n",
        "                                     metrics=MCRMSE\n",
        "                                    ) \n",
        "print(bertweet_v1_regression_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRD1yhqxTSGm",
        "outputId": "1bb35567-d18d-48d3-fc8e-c245576df94b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids_layer (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask_layer (InputLay  [(None, 512)]       0           []                               \n",
            " er)                                                                                              \n",
            "                                                                                                  \n",
            " tf_roberta_model (TFRobertaMod  TFBaseModelOutputWi  134899968  ['input_ids_layer[0][0]',        \n",
            " el)                            thPoolingAndCrossAt               'attention_mask_layer[0][0]']   \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " hidden_layer_1 (Dense)         (None, 512, 256)     196864      ['tf_roberta_model[1][0]']       \n",
            "                                                                                                  \n",
            " dropout_layer_1 (Dropout)      (None, 512, 256)     0           ['hidden_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512, 6)       1542        ['dropout_layer_1[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 135,098,374\n",
            "Trainable params: 135,098,374\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(bertweet_v1_regression_model, show_shapes=False, show_dtype=False, show_layer_names=True, dpi=90)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "MJDDW9AbTSKQ",
        "outputId": "ed00849e-e1f9-431d-f3f4-a761f2f99e4a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bertweet_v1_regression_model_history = bertweet_v1_regression_model.fit([train_encodings['input_ids'], \n",
        "                                                                         train_encodings['attention_masks']\n",
        "                                                                        ], \n",
        "                                                                        y_train,   \n",
        "                                                                        validation_data =([val_encodings['input_ids'], \n",
        "                                                                                           val_encodings['attention_masks']\n",
        "                                                                                          ], \n",
        "                                                                                          y_val\n",
        "                                                                                         ),    \n",
        "                                                                        batch_size = batch_size, \n",
        "                                                                        epochs = epochs\n",
        "                                                                       )                                                  \n",
        "bertweet_v1_regression_model_history_df = pd.DataFrame(bertweet_v1_regression_model_history.history)\n",
        "bertweet_v1_regression_model_history_df.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "MuKGjALlTSN5",
        "outputId": "ed71a4f6-9001-42fa-c814-284da9b32d4a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-a060fbaf794c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m bertweet_v1_regression_model_history = bertweet_v1_regression_model.fit([train_encodings['input_ids'], \n\u001b[0m\u001b[1;32m      2\u001b[0m                                                                          \u001b[0mtrain_encodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_masks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                                         ], \n\u001b[1;32m      4\u001b[0m                                                                         \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                                         validation_data =([val_encodings['input_ids'], \n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file5ug54bps.py\u001b[0m in \u001b[0;36mtf__MCRMSE\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0mcolwise_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"<ipython-input-5-366c7ade3828>\", line 2, in MCRMSE  *\n        colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n\n    ValueError: Dimensions must be equal, but are 8 and 512 for '{{node MCRMSE/sub}} = Sub[T=DT_FLOAT](IteratorGetNext:2, model/dense/BiasAdd)' with input shapes: [8,6], [8,512,6].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XY2XkyEWUNfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XvkSN8mbUNij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jxP7OEQmPhdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HL557L53PhgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from emoji import demojize\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "\n",
        "tokenizer = TweetTokenizer()\n",
        "\n",
        "\n",
        "def normalizeToken(token):\n",
        "    lowercased_token = token.lower()\n",
        "    if token.startswith(\"@\"):\n",
        "        return \"@USER\"\n",
        "    elif lowercased_token.startswith(\"http\") or lowercased_token.startswith(\"www\"):\n",
        "        return \"HTTPURL\"\n",
        "    elif len(token) == 1:\n",
        "        return demojize(token)\n",
        "    else:\n",
        "        if token == \"’\":\n",
        "            return \"'\"\n",
        "        elif token == \"…\":\n",
        "            return \"...\"\n",
        "        else:\n",
        "            return token\n",
        "\n",
        "'''\n",
        "https://preply.com/en/blog/the-most-used-internet-abbreviations-for-texting-and-tweeting/\n",
        "'''\n",
        "def normalizeTweet(tweet):\n",
        "    tokens = tokenizer.tokenize(tweet.replace(\"’\", \"'\").replace(\"…\", \"...\"))\n",
        "    normTweet = \" \".join([normalizeToken(token) for token in tokens])\n",
        "\n",
        "    normTweet = (\n",
        "        normTweet.replace(\"cannot \", \"can not \")\n",
        "        .replace(\"n't \", \" n't \")\n",
        "        .replace(\"n 't \", \" n't \")\n",
        "        .replace(\"ca n't\", \"can't\")\n",
        "        .replace(\"ai n't\", \"ain't\")\n",
        "        .replace(\"bc\", \"because\")\n",
        "        .replace(\"btw\", \"by the way\")\n",
        "        .replace(\"cya\", \"see ya\")\n",
        "        .replace(\" u \", \" you \")\n",
        "        .replace(\"dm\", \"direct message\")\n",
        "        .replace(\"gm\", \"good morning\")\n",
        "        .replace(\"ftw\", \"for the win\")\n",
        "        .replace(\"tbh\", \"to be honest\")\n",
        "        .replace(\"fwiw\", \"for what it’s worth\")\n",
        "        .replace(\"idk\", \"I don't know\")\n",
        "        .replace(\"ily\", \"I love you\")\n",
        "        .replace(\"brb\", \"be right back\")\n",
        "        .replace(\"imo\", \"in my opinion\")\n",
        "        .replace(\"irl\", \"in real life\")\n",
        "        .replace(\"jk\", \"just kidding\")\n",
        "        .replace(\"lmk\", \"let me know\")\n",
        "        .replace(\"lmc\", \"let me check\")\n",
        "        .replace(\"lol\", \"laughing out loud\")\n",
        "        .replace(\"nbd\", \"no big deal\")\n",
        "        .replace(\"np\", \"no problem\")\n",
        "        .replace(\"wc\", \"welcome\")\n",
        "        .replace(\"nsfw\", \"not safe for work\")\n",
        "        .replace(\"nvm\", \"never mind\")\n",
        "        .replace(\"omg\", \"oh my god\")\n",
        "        .replace(\"otoh\", \"on the other hand\")\n",
        "        .replace(\"omw\", \"on my way\")\n",
        "        .replace(\"rofl\", \"rolling on floor laughing\")\n",
        "        .replace(\"SO\", \"significant other\")\n",
        "        .replace(\"thx\", \"thanks\")\n",
        "        .replace(\"tmi\", \"too much information\")\n",
        "        .replace(\"ttyl\", \"talk to you later\")\n",
        "        .replace(\"fwiw\", \"for what it’s worth\")\n",
        "        .replace(\"yolo\", \"you only live once\")\n",
        "        .replace(\"tldr\", \"too long, didn't read\")\n",
        "        .replace(\"asap\", \"as soon as possible\")\n",
        "        .replace(\"bau\", \"business as usual\")\n",
        "        .replace(\"fyi\", \"for your information\")\n",
        "        .replace(\"fyip\", \"for your information please\")\n",
        "        .replace(\"fya\", \"for your action\")\n",
        "        .replace(\"fyap\", \"for your action please\")\n",
        "        .replace(\"msg\", \"message\")\n",
        "        .replace(\"fb\", \"facebook\")\n",
        "        .replace(\"txt\", \"text\")\n",
        "        .replace(\"gtg\", \"got to go\")\n",
        "    )\n",
        "    normTweet = (\n",
        "        normTweet.replace(\"'m \", \" 'm \")\n",
        "        .replace(\"'re \", \" 're \")\n",
        "        .replace(\"'s \", \" 's \")\n",
        "        .replace(\"'ll \", \" 'll \")\n",
        "        .replace(\"'d \", \" 'd \")\n",
        "        .replace(\"'ve \", \" 've \")\n",
        "    )\n",
        "    normTweet = (\n",
        "        normTweet.replace(\" p . m .\", \"  p.m.\")\n",
        "        .replace(\" p . m \", \" p.m \")\n",
        "        .replace(\" a . m .\", \" a.m.\")\n",
        "        .replace(\" a . m \", \" a.m \")\n",
        "    )\n",
        "\n",
        "    return \" \".join(normTweet.split())"
      ],
      "metadata": {
        "id": "Bs2mxbaP6YPr"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "#from TweetNormalizer import normalizeTweet\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-large\")\n",
        "\n",
        "line = normalizeTweet(\"DHEC confirms https://postandcourier.com/health/covid19/sc-has-first-two-presumptive-cases-of-coronavirus-dhec-confirms/article_bddfe4ae-5fd3-11ea-9ce4-5f495366cee6.html?utm_medium=social&utm_source=twitter&utm_campaign=user-share… via @postandcourier 😢\")\n",
        "\n",
        "input_ids = torch.tensor([tokenizer.encode(line)])\n",
        "input_ids\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvlvYpUR5Yxx",
        "outputId": "f69ca622-126b-4599-f5df-07e71b61a33c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    0, 38462, 11270,  4236, 21402, 17075, 21871,  4236, 21402, 13082,\n",
              "          4832, 42326,   618,     8,   740,  1021,   257,   910,   906,   479,\n",
              "          3137,  1589,   474,  1589,   740, 19414, 13561,   753,  1589,  2850,\n",
              "           111,    34,   111,    78,   111,    80,   111,  9383,  7252, 46238,\n",
              "          2088,   111,  1200,   111,     9,   111,  9240,    15,  6402, 10209,\n",
              "           687,   111,   385,    37,   740,   111,  7856, 10209,  4339,  1589,\n",
              "          1566, 18134,   741, 47821, 10668,   204,    10,   242,   111,   195,\n",
              "           856,   417,   155,   111,   365,   364,   102,   111,   361,  8635,\n",
              "           204,   111,   195,   856,   204,  4015, 40721,  8635,   364,   231,\n",
              "           479, 48445, 17487, 16080,   119, 18134,  4761,  5457,   592,   359,\n",
              "         16080,   119, 18134,  1300,  5457,  7409,   359, 16080,   119, 18134,\n",
              "           637,  5457,  3018,   111,   458,  1666,  4236, 21402, 11409,  4236,\n",
              "         21402,  1039,   618,     8,   740,  1021,   257,   910,   906,  4236,\n",
              "         21402, 39398,  1277, 10172,   649,  3070,  5505,  7258,     2]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/github/devhemza/BERTweet_sentiment_analysis/blob/main/BERTweet.ipynb#scrollTo=KrZkll3WI1jF"
      ],
      "metadata": {
        "id": "zLhk-SgxvNJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ell_dataset(Dataset):\n",
        "\n",
        "  def __init__(self, tweets, targets, tokenizer, max_len):\n",
        "    self.tweets = tweets\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.tweets)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    tweet = str(self.tweets[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      tweet,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      truncation= True,\n",
        "      return_token_type_ids=False,\n",
        "      padding = 'max_length',\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'tweet_text': tweet,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "metadata": {
        "id": "2GQ1ACriuhj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V6lZKVR0uhgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y8ZxFpcbuhdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Iw0Yg4huhaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IRTfK41muhVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XkRJU9t5uhPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uqEmblJpuhE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tf.keras.layers.Input(shape=(MAX_LENGTH,), dtype=tf.int64, name='input_ids_layer')\n",
        "token_type_ids = tf.keras.layers.Input(shape=(MAX_LENGTH,), dtype=tf.int64, name='token_type_ids_layer')\n",
        "attention_mask = tf.keras.layers.Input(shape=(MAX_LENGTH,), dtype=tf.int64, name='attention_mask_layer')\n",
        "\n",
        "bert_inputs = {'input_ids': input_ids,\n",
        "               'token_type_ids': token_type_ids,\n",
        "               'attention_mask': attention_mask\n",
        "              }\n",
        "                   \n",
        "# Bert output: being used as an input feature in the classification model below\n",
        "bertweet_model_v1_out = bertweet_model_v1(bert_inputs)        \n",
        "# pooler_output = bert_out[1]             # one vector for each\n",
        "cls_token = bertweet_model_v1_out[0][:, 0, :]          # give us a raw CLS tokens\n",
        "\n",
        "layer_list = []\n",
        "\n",
        "for hidden_layer_number in range(number_of_hidden_layer):\n",
        "    if hidden_layer_number == 0:\n",
        "        hidden_layer = tf.keras.layers.Dense(units = hidden_layer_node_count\n",
        "                                    , activation = 'relu'\n",
        "                                    , name = 'hidden_layer_' + str(hidden_layer_number + 1)\n",
        "                                     )(cls_token)\n",
        "    else:\n",
        "        hidden_layer = tf.keras.layers.Dense(units = hidden_layer_node_count\n",
        "                                    , activation = 'relu'\n",
        "                                    , name = 'hidden_layer_' + str(hidden_layer_number + 1)\n",
        "                                     )(layer_list[-1])\n",
        "    layer_list.append(hidden_layer)\n",
        "    dropout_layer = tf.keras.layers.Dropout(dropout, name = 'dropout_layer_' + str(hidden_layer_number + 1))(hidden_layer) \n",
        "    layer_list.append(dropout_layer)\n",
        "\n",
        "output = tf.keras.layers.Dense(6,)(layer_list[-1])\n",
        "bertweet_v1_regression_model = tf.keras.Model(inputs = [input_ids, \n",
        "                                                        token_type_ids,\n",
        "                                                        attention_mask\n",
        "                                                       ], \n",
        "                                                       outputs = output\n",
        "                                             )\n",
        "\n",
        "bertweet_v1_regression_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n",
        "                                     loss = MCRMSE, \n",
        "                                     metrics=MCRMSE\n",
        "                                    ) \n",
        "print(bertweet_v1_regression_model.summary())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "1SA5yDH-kbyc",
        "outputId": "536d8811-13c4-4fb1-cdae-7daf64f82a6f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-5e2d39a4a34c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Bert output: being used as an input feature in the classification model below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mbertweet_model_v1_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbertweet_model_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_inputs\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# full features as an input to the following classification model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m# pooler_output = bert_out[1]             # one vector for each\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mcls_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbertweet_model_v1_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m          \u001b[0;31m# give us a raw CLS tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'size'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v9AFXSV_ufRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fPnbrIYaufWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(bertweet_v1_regression_model, show_shapes=False, show_dtype=False, show_layer_names=True, dpi=90)"
      ],
      "metadata": {
        "id": "XgD_0K9_kfDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bertweet_v1_regression_model_history = bertweet_v1_regression_model.fit([train_encodings.input_ids, \n",
        "                                                                         train_encodings.token_type_ids, \n",
        "                                                                         train_encodings.attention_mask\n",
        "                                                                        ], \n",
        "                                                                        y_train,   \n",
        "                                                                        validation_data =([val_encodings.input_ids, \n",
        "                                                                                           val_encodings.token_type_ids, \n",
        "                                                                                           val_encodings.attention_mask\n",
        "                                                                                          ], \n",
        "                                                                                          y_val\n",
        "                                                                                         ),    \n",
        "                                                                        batch_size = batch_size, \n",
        "                                                                        epochs = epochs\n",
        "                                                                       )                                                  \n",
        "bertweet_v1_regression_model_history_df = pd.DataFrame(bertweet_v1_regression_model_history.history)\n",
        "bertweet_v1_regression_model_history_df.T\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "-qfeOo3PpbEg",
        "outputId": "0f66c3ff-80a5-4420-e617-185466edb657"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-714a43a1ea66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m regression_model_history = bertweet_v1_regression_model.fit([train_encodings.input_ids, \n\u001b[0m\u001b[1;32m      2\u001b[0m                                                              \u001b[0mtrain_encodings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                              \u001b[0mtrain_encodings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                             ], \n\u001b[1;32m      5\u001b[0m                                                             \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'bertweet_v1_regression_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score_bertweet_v1_regression_model = bertweet_v1_regression_model.evaluate([test_encodings.input_ids, \n",
        "                                                                            test_encodings.token_type_ids, \n",
        "                                                                            test_encodings.attention_mask\n",
        "                                                                           ], \n",
        "                                                                           y_test\n",
        "                                                                          ) \n",
        "\n",
        "print(score_bertweet_v1_regression_model)"
      ],
      "metadata": {
        "id": "ONMfWYmukho3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_bertweet_v1_regression_model = bertweet_v1_regression_model.predict([test_encodings.input_ids, \n",
        "                                                                                 test_encodings.token_type_ids, \n",
        "                                                                                 test_encodings.attention_mask\n",
        "                                                                                ]\n",
        "                                                                               )\n",
        "print(predictions_bertweet_v1_regression_model)"
      ],
      "metadata": {
        "id": "1zgN-t9CkjhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test[label_cols]"
      ],
      "metadata": {
        "id": "wOp86kJ4kmyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_bertweet_v1_regression_model"
      ],
      "metadata": {
        "id": "-1dTKW5NkohZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_arr = np.arange(len(bertweet_v1_regression_model['loss'])) + 1\n",
        "\n",
        "fig = plt.figure(figsize=(12, 4))\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.plot(x_arr, bertweet_v1_regression_model_history_df['loss'], '-o', label='Train loss')\n",
        "ax.plot(x_arr, bertweet_v1_regression_model_history_df['val_loss'], '--<', label='Validation loss')\n",
        "ax.legend(fontsize=15)\n",
        "ax.set_xlabel('Epoch', size=15)\n",
        "ax.set_ylabel('Loss', size=15)\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 2)\n",
        "ax.plot(x_arr, bertweet_v1_regression_model_history_df['MCRMSE'], '-o', label='Train MCRMSE')\n",
        "ax.plot(x_arr, bertweet_v1_regression_model_history_df['val_MCRMSE'], '--<', label='Validation MCRMSE')\n",
        "ax.legend(fontsize=15)\n",
        "ax.set_xlabel('Epoch', size=15)\n",
        "ax.set_ylabel('Accuracy', size=15)\n",
        "ax.set_ylim(0,1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SvDIj6zQkru_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}